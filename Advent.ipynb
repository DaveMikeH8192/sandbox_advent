{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af4d6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values=\"\"\"R21\n",
    "R37\n",
    "L39\n",
    "L11\n",
    "L3\n",
    "R20\n",
    "R7\n",
    "R1\n",
    "R49\n",
    "L39\n",
    "L47\n",
    "R27\n",
    "L45\n",
    "L8\n",
    "L34\n",
    "L48\n",
    "L28\n",
    "L15\n",
    "R22\n",
    "R26\n",
    "R40\n",
    "L13\n",
    "R29\n",
    "L38\n",
    "L49\n",
    "L10\n",
    "R12\n",
    "R15\n",
    "R15\n",
    "R37\n",
    "R30\n",
    "R19\n",
    "L36\n",
    "L42\n",
    "L46\n",
    "L43\n",
    "L40\n",
    "L49\n",
    "L1\n",
    "L40\n",
    "L29\n",
    "R20\n",
    "R3\n",
    "R19\n",
    "L31\n",
    "R49\n",
    "R22\n",
    "L21\n",
    "R42\n",
    "R80\n",
    "L46\n",
    "R2\n",
    "R1\n",
    "R56\n",
    "L46\n",
    "L3\n",
    "L63\n",
    "L90\n",
    "L42\n",
    "R85\n",
    "L12\n",
    "L12\n",
    "L36\n",
    "R49\n",
    "R59\n",
    "L33\n",
    "L56\n",
    "R59\n",
    "R50\n",
    "R53\n",
    "L62\n",
    "L8\n",
    "R21\n",
    "R97\n",
    "R20\n",
    "L99\n",
    "R21\n",
    "L89\n",
    "R37\n",
    "L28\n",
    "R54\n",
    "R59\n",
    "L5\n",
    "R28\n",
    "L25\n",
    "L83\n",
    "R23\n",
    "R42\n",
    "R35\n",
    "L86\n",
    "L83\n",
    "R33\n",
    "R36\n",
    "L15\n",
    "L85\n",
    "L18\n",
    "R86\n",
    "R30\n",
    "L98\n",
    "R76\n",
    "R624\n",
    "L595\n",
    "R53\n",
    "L78\n",
    "R69\n",
    "L9\n",
    "R60\n",
    "L998\n",
    "R62\n",
    "R82\n",
    "L579\n",
    "L67\n",
    "R73\n",
    "R22\n",
    "R9\n",
    "R63\n",
    "R33\n",
    "L39\n",
    "L98\n",
    "L63\n",
    "L122\n",
    "R557\n",
    "L6\n",
    "R71\n",
    "R92\n",
    "R8\n",
    "L944\n",
    "L42\n",
    "L467\n",
    "L77\n",
    "R919\n",
    "R777\n",
    "R94\n",
    "L60\n",
    "L894\n",
    "R49\n",
    "R45\n",
    "R13\n",
    "L13\n",
    "L20\n",
    "R90\n",
    "R30\n",
    "R69\n",
    "L69\n",
    "L30\n",
    "L70\n",
    "L91\n",
    "R80\n",
    "L89\n",
    "L37\n",
    "L98\n",
    "R545\n",
    "R96\n",
    "L236\n",
    "R54\n",
    "R76\n",
    "L78\n",
    "L66\n",
    "L56\n",
    "R48\n",
    "R63\n",
    "R27\n",
    "R15\n",
    "L84\n",
    "L512\n",
    "L15\n",
    "L764\n",
    "R22\n",
    "L70\n",
    "R70\n",
    "L98\n",
    "R47\n",
    "L657\n",
    "R11\n",
    "R766\n",
    "R71\n",
    "L40\n",
    "L91\n",
    "L9\n",
    "R1\n",
    "R245\n",
    "L580\n",
    "R34\n",
    "R37\n",
    "L35\n",
    "R98\n",
    "R67\n",
    "L1\n",
    "L66\n",
    "L2\n",
    "L46\n",
    "L92\n",
    "L519\n",
    "R580\n",
    "R79\n",
    "R328\n",
    "R533\n",
    "L15\n",
    "L46\n",
    "R88\n",
    "R86\n",
    "L52\n",
    "R45\n",
    "L29\n",
    "L38\n",
    "R94\n",
    "R80\n",
    "R15\n",
    "L12\n",
    "L77\n",
    "R88\n",
    "R28\n",
    "R84\n",
    "R84\n",
    "L84\n",
    "R709\n",
    "L87\n",
    "R78\n",
    "R30\n",
    "R770\n",
    "L947\n",
    "L53\n",
    "L50\n",
    "R826\n",
    "R69\n",
    "R55\n",
    "R177\n",
    "R30\n",
    "L90\n",
    "R39\n",
    "R44\n",
    "R68\n",
    "R32\n",
    "R80\n",
    "R23\n",
    "L29\n",
    "L97\n",
    "R6\n",
    "R17\n",
    "L51\n",
    "L386\n",
    "R86\n",
    "R444\n",
    "L86\n",
    "R176\n",
    "L265\n",
    "L18\n",
    "L15\n",
    "L757\n",
    "L75\n",
    "R612\n",
    "L64\n",
    "L69\n",
    "L22\n",
    "R56\n",
    "L66\n",
    "L83\n",
    "R30\n",
    "L87\n",
    "R55\n",
    "R85\n",
    "L94\n",
    "L398\n",
    "L27\n",
    "L65\n",
    "R84\n",
    "R1\n",
    "L27\n",
    "R26\n",
    "L756\n",
    "L18\n",
    "R308\n",
    "L34\n",
    "R2\n",
    "R41\n",
    "R57\n",
    "L155\n",
    "L45\n",
    "L90\n",
    "L12\n",
    "L78\n",
    "L20\n",
    "R37\n",
    "L40\n",
    "L397\n",
    "L49\n",
    "R49\n",
    "L85\n",
    "L2\n",
    "L269\n",
    "L66\n",
    "R243\n",
    "R430\n",
    "L51\n",
    "L56\n",
    "L444\n",
    "R23\n",
    "R177\n",
    "R51\n",
    "L12\n",
    "R61\n",
    "R85\n",
    "R68\n",
    "L732\n",
    "R29\n",
    "L50\n",
    "R27\n",
    "R17\n",
    "R14\n",
    "R23\n",
    "R19\n",
    "L49\n",
    "R207\n",
    "L10\n",
    "R793\n",
    "L799\n",
    "L56\n",
    "R314\n",
    "L17\n",
    "L67\n",
    "R38\n",
    "L24\n",
    "R92\n",
    "L49\n",
    "L42\n",
    "L31\n",
    "L435\n",
    "R11\n",
    "L2\n",
    "R618\n",
    "L892\n",
    "L29\n",
    "R18\n",
    "R437\n",
    "R774\n",
    "R97\n",
    "L254\n",
    "L91\n",
    "R848\n",
    "L21\n",
    "R321\n",
    "L63\n",
    "L37\n",
    "L87\n",
    "L13\n",
    "L12\n",
    "R68\n",
    "L12\n",
    "R45\n",
    "R911\n",
    "L54\n",
    "L43\n",
    "L41\n",
    "R38\n",
    "L38\n",
    "L62\n",
    "R98\n",
    "R44\n",
    "L701\n",
    "R59\n",
    "L46\n",
    "R64\n",
    "L18\n",
    "L33\n",
    "R85\n",
    "R65\n",
    "L77\n",
    "L44\n",
    "L49\n",
    "R53\n",
    "R30\n",
    "L35\n",
    "R48\n",
    "R139\n",
    "R86\n",
    "R32\n",
    "R15\n",
    "L15\n",
    "L35\n",
    "R35\n",
    "L20\n",
    "R916\n",
    "L14\n",
    "R801\n",
    "R66\n",
    "R20\n",
    "R31\n",
    "R24\n",
    "R76\n",
    "R13\n",
    "L13\n",
    "R978\n",
    "R76\n",
    "R813\n",
    "R89\n",
    "L56\n",
    "R27\n",
    "R36\n",
    "L63\n",
    "L81\n",
    "R25\n",
    "R767\n",
    "L11\n",
    "R831\n",
    "L51\n",
    "R65\n",
    "R88\n",
    "L570\n",
    "R891\n",
    "R33\n",
    "R13\n",
    "L54\n",
    "L23\n",
    "L123\n",
    "L69\n",
    "R60\n",
    "R9\n",
    "R66\n",
    "R34\n",
    "R43\n",
    "R78\n",
    "R83\n",
    "R58\n",
    "L55\n",
    "L41\n",
    "R34\n",
    "L37\n",
    "R69\n",
    "R68\n",
    "L98\n",
    "L429\n",
    "L73\n",
    "R92\n",
    "R241\n",
    "L83\n",
    "R50\n",
    "R136\n",
    "L96\n",
    "L321\n",
    "L5\n",
    "R24\n",
    "R5\n",
    "L65\n",
    "L78\n",
    "R15\n",
    "L13\n",
    "R18\n",
    "L220\n",
    "R9\n",
    "L32\n",
    "L4\n",
    "R266\n",
    "R46\n",
    "R15\n",
    "R486\n",
    "R14\n",
    "L85\n",
    "R85\n",
    "R32\n",
    "L59\n",
    "L17\n",
    "L27\n",
    "R24\n",
    "R47\n",
    "R984\n",
    "R99\n",
    "R17\n",
    "L83\n",
    "R83\n",
    "L40\n",
    "L279\n",
    "R419\n",
    "L46\n",
    "R71\n",
    "L13\n",
    "R88\n",
    "R64\n",
    "L64\n",
    "L20\n",
    "R20\n",
    "R33\n",
    "R689\n",
    "R3\n",
    "L52\n",
    "L73\n",
    "R19\n",
    "L23\n",
    "R12\n",
    "R92\n",
    "R8\n",
    "R92\n",
    "R66\n",
    "R70\n",
    "R44\n",
    "L44\n",
    "R61\n",
    "R82\n",
    "R21\n",
    "R824\n",
    "L66\n",
    "L62\n",
    "R4\n",
    "L60\n",
    "L40\n",
    "L835\n",
    "L46\n",
    "R65\n",
    "R48\n",
    "L32\n",
    "L36\n",
    "L664\n",
    "L52\n",
    "L48\n",
    "L50\n",
    "L50\n",
    "L56\n",
    "R15\n",
    "L35\n",
    "L24\n",
    "R19\n",
    "L15\n",
    "R6\n",
    "L8\n",
    "L42\n",
    "L60\n",
    "L640\n",
    "R116\n",
    "R451\n",
    "L49\n",
    "R88\n",
    "R24\n",
    "L90\n",
    "R56\n",
    "R44\n",
    "R79\n",
    "R74\n",
    "L6\n",
    "R53\n",
    "L45\n",
    "R45\n",
    "L792\n",
    "R92\n",
    "R17\n",
    "R8\n",
    "R75\n",
    "L30\n",
    "R30\n",
    "L89\n",
    "L11\n",
    "L210\n",
    "L84\n",
    "L85\n",
    "L21\n",
    "R52\n",
    "L42\n",
    "R190\n",
    "R38\n",
    "L15\n",
    "L49\n",
    "R8\n",
    "R10\n",
    "L992\n",
    "L35\n",
    "R935\n",
    "R69\n",
    "L69\n",
    "L463\n",
    "L44\n",
    "L59\n",
    "R88\n",
    "L22\n",
    "R98\n",
    "R43\n",
    "L10\n",
    "R69\n",
    "R4\n",
    "L965\n",
    "R55\n",
    "L57\n",
    "L4\n",
    "L37\n",
    "R971\n",
    "R16\n",
    "R856\n",
    "L75\n",
    "R4\n",
    "R71\n",
    "L82\n",
    "R79\n",
    "R64\n",
    "R4\n",
    "R46\n",
    "L66\n",
    "L84\n",
    "R27\n",
    "L27\n",
    "L97\n",
    "R114\n",
    "R66\n",
    "R75\n",
    "R18\n",
    "R48\n",
    "R76\n",
    "L71\n",
    "L229\n",
    "L71\n",
    "R97\n",
    "L26\n",
    "R65\n",
    "R85\n",
    "R50\n",
    "R66\n",
    "L66\n",
    "R51\n",
    "R55\n",
    "L106\n",
    "L641\n",
    "L59\n",
    "R87\n",
    "L95\n",
    "R39\n",
    "L31\n",
    "R199\n",
    "R1\n",
    "L54\n",
    "L446\n",
    "R92\n",
    "R8\n",
    "R22\n",
    "L36\n",
    "L86\n",
    "R64\n",
    "L56\n",
    "L89\n",
    "R881\n",
    "R257\n",
    "R75\n",
    "L629\n",
    "L67\n",
    "R85\n",
    "R32\n",
    "L41\n",
    "L12\n",
    "L60\n",
    "L40\n",
    "R267\n",
    "L67\n",
    "R38\n",
    "L717\n",
    "L35\n",
    "R53\n",
    "L77\n",
    "L919\n",
    "R57\n",
    "R83\n",
    "L83\n",
    "L349\n",
    "R49\n",
    "R477\n",
    "L77\n",
    "R96\n",
    "R4\n",
    "L183\n",
    "R5\n",
    "R78\n",
    "L69\n",
    "R53\n",
    "L84\n",
    "L87\n",
    "L13\n",
    "L70\n",
    "R70\n",
    "R254\n",
    "R46\n",
    "L965\n",
    "R8\n",
    "R57\n",
    "R36\n",
    "R3\n",
    "R61\n",
    "R39\n",
    "R61\n",
    "L5\n",
    "L95\n",
    "R896\n",
    "L896\n",
    "R792\n",
    "R287\n",
    "R790\n",
    "R25\n",
    "R32\n",
    "L92\n",
    "R474\n",
    "R92\n",
    "L15\n",
    "R15\n",
    "L36\n",
    "L64\n",
    "R8\n",
    "R91\n",
    "L77\n",
    "L718\n",
    "R427\n",
    "L31\n",
    "L6\n",
    "L788\n",
    "L6\n",
    "R80\n",
    "R20\n",
    "L79\n",
    "R33\n",
    "L947\n",
    "R93\n",
    "R413\n",
    "R88\n",
    "L83\n",
    "L18\n",
    "L452\n",
    "R68\n",
    "L29\n",
    "R79\n",
    "R3\n",
    "R31\n",
    "R33\n",
    "L10\n",
    "L55\n",
    "R32\n",
    "R875\n",
    "L170\n",
    "R95\n",
    "R544\n",
    "R248\n",
    "L92\n",
    "L29\n",
    "R56\n",
    "L50\n",
    "R23\n",
    "L84\n",
    "L755\n",
    "R24\n",
    "R515\n",
    "R64\n",
    "R47\n",
    "L89\n",
    "L23\n",
    "R1\n",
    "L56\n",
    "R88\n",
    "R168\n",
    "L90\n",
    "L10\n",
    "R84\n",
    "R30\n",
    "L14\n",
    "L27\n",
    "R27\n",
    "L91\n",
    "L169\n",
    "R251\n",
    "R73\n",
    "R23\n",
    "L10\n",
    "R812\n",
    "L92\n",
    "L61\n",
    "R71\n",
    "L59\n",
    "R52\n",
    "R88\n",
    "R46\n",
    "R20\n",
    "L54\n",
    "L46\n",
    "R11\n",
    "L65\n",
    "L26\n",
    "R81\n",
    "R645\n",
    "L72\n",
    "R10\n",
    "R41\n",
    "R97\n",
    "R924\n",
    "L62\n",
    "R62\n",
    "L37\n",
    "R5\n",
    "R32\n",
    "L40\n",
    "R90\n",
    "R89\n",
    "L93\n",
    "L22\n",
    "R503\n",
    "R87\n",
    "R81\n",
    "L31\n",
    "R91\n",
    "L47\n",
    "L8\n",
    "L11\n",
    "L56\n",
    "L45\n",
    "R35\n",
    "R97\n",
    "L20\n",
    "R99\n",
    "L134\n",
    "R35\n",
    "R59\n",
    "R41\n",
    "R34\n",
    "L16\n",
    "R28\n",
    "L61\n",
    "R715\n",
    "L476\n",
    "R76\n",
    "L75\n",
    "L25\n",
    "R40\n",
    "R31\n",
    "L30\n",
    "R41\n",
    "L82\n",
    "L709\n",
    "L111\n",
    "R791\n",
    "R429\n",
    "R1\n",
    "R79\n",
    "L32\n",
    "L99\n",
    "L46\n",
    "L48\n",
    "L55\n",
    "L50\n",
    "R70\n",
    "R16\n",
    "R564\n",
    "L47\n",
    "L11\n",
    "R496\n",
    "R25\n",
    "L83\n",
    "R75\n",
    "R61\n",
    "L53\n",
    "L89\n",
    "R26\n",
    "R79\n",
    "R21\n",
    "L92\n",
    "L92\n",
    "L62\n",
    "L54\n",
    "R93\n",
    "L55\n",
    "R29\n",
    "L44\n",
    "L573\n",
    "L77\n",
    "L33\n",
    "R869\n",
    "R91\n",
    "R5\n",
    "L647\n",
    "R59\n",
    "R61\n",
    "L178\n",
    "R92\n",
    "R8\n",
    "L42\n",
    "L58\n",
    "L698\n",
    "R73\n",
    "L75\n",
    "R7\n",
    "R93\n",
    "R17\n",
    "L93\n",
    "R50\n",
    "L42\n",
    "L62\n",
    "R30\n",
    "R66\n",
    "L66\n",
    "R48\n",
    "L48\n",
    "L22\n",
    "R891\n",
    "L2\n",
    "L67\n",
    "L3\n",
    "L97\n",
    "R19\n",
    "R925\n",
    "R21\n",
    "R24\n",
    "L89\n",
    "R71\n",
    "L71\n",
    "R86\n",
    "R14\n",
    "L833\n",
    "R33\n",
    "R50\n",
    "R150\n",
    "R43\n",
    "R95\n",
    "R66\n",
    "R96\n",
    "R74\n",
    "L21\n",
    "L768\n",
    "R481\n",
    "R934\n",
    "L228\n",
    "L32\n",
    "L136\n",
    "L28\n",
    "R66\n",
    "L85\n",
    "R67\n",
    "L72\n",
    "R20\n",
    "R58\n",
    "L30\n",
    "L58\n",
    "R758\n",
    "R22\n",
    "R29\n",
    "L51\n",
    "R95\n",
    "L893\n",
    "L386\n",
    "R369\n",
    "R62\n",
    "L47\n",
    "R12\n",
    "R71\n",
    "R917\n",
    "L65\n",
    "R38\n",
    "R989\n",
    "L68\n",
    "L99\n",
    "L711\n",
    "R31\n",
    "L15\n",
    "L367\n",
    "L33\n",
    "R93\n",
    "R7\n",
    "L2\n",
    "L98\n",
    "L24\n",
    "L76\n",
    "R53\n",
    "L972\n",
    "R19\n",
    "L14\n",
    "L386\n",
    "R21\n",
    "R79\n",
    "L32\n",
    "R756\n",
    "L15\n",
    "R83\n",
    "L90\n",
    "L98\n",
    "L7\n",
    "R3\n",
    "L6\n",
    "R4\n",
    "L3\n",
    "R5\n",
    "L80\n",
    "R138\n",
    "L58\n",
    "R951\n",
    "R98\n",
    "L54\n",
    "R97\n",
    "L72\n",
    "R80\n",
    "L93\n",
    "L17\n",
    "R43\n",
    "L10\n",
    "R77\n",
    "L939\n",
    "R99\n",
    "R45\n",
    "R264\n",
    "R358\n",
    "L50\n",
    "R85\n",
    "L62\n",
    "R54\n",
    "R818\n",
    "L28\n",
    "L81\n",
    "L44\n",
    "R581\n",
    "L965\n",
    "R41\n",
    "R24\n",
    "L9\n",
    "R390\n",
    "R52\n",
    "L20\n",
    "L39\n",
    "L49\n",
    "L59\n",
    "L966\n",
    "L87\n",
    "R87\n",
    "L445\n",
    "L36\n",
    "R382\n",
    "R622\n",
    "R813\n",
    "R264\n",
    "L18\n",
    "R83\n",
    "L65\n",
    "R305\n",
    "R95\n",
    "L228\n",
    "L857\n",
    "L729\n",
    "R58\n",
    "L44\n",
    "R19\n",
    "R81\n",
    "L80\n",
    "R26\n",
    "R14\n",
    "L75\n",
    "L21\n",
    "L58\n",
    "L74\n",
    "R68\n",
    "L4\n",
    "L896\n",
    "L29\n",
    "R32\n",
    "R62\n",
    "R36\n",
    "R853\n",
    "R24\n",
    "L18\n",
    "R87\n",
    "L347\n",
    "R980\n",
    "L181\n",
    "L98\n",
    "R85\n",
    "L30\n",
    "R342\n",
    "L8\n",
    "L10\n",
    "L55\n",
    "L9\n",
    "L416\n",
    "R4\n",
    "L85\n",
    "L138\n",
    "R89\n",
    "R30\n",
    "L33\n",
    "L67\n",
    "R31\n",
    "R14\n",
    "R80\n",
    "R75\n",
    "L71\n",
    "R6\n",
    "R65\n",
    "R42\n",
    "L56\n",
    "L86\n",
    "R529\n",
    "R220\n",
    "R41\n",
    "R8\n",
    "L88\n",
    "R54\n",
    "R11\n",
    "R70\n",
    "R29\n",
    "L74\n",
    "L8\n",
    "L92\n",
    "L283\n",
    "L25\n",
    "R88\n",
    "L449\n",
    "L65\n",
    "L66\n",
    "R87\n",
    "L10\n",
    "L77\n",
    "R68\n",
    "L68\n",
    "L29\n",
    "L60\n",
    "R989\n",
    "R958\n",
    "R160\n",
    "R67\n",
    "R15\n",
    "R85\n",
    "L6\n",
    "L43\n",
    "R13\n",
    "R51\n",
    "L49\n",
    "L51\n",
    "L85\n",
    "L76\n",
    "R78\n",
    "L17\n",
    "L488\n",
    "L12\n",
    "L2\n",
    "L98\n",
    "R834\n",
    "L34\n",
    "L58\n",
    "R20\n",
    "L34\n",
    "L28\n",
    "L2\n",
    "R2\n",
    "R432\n",
    "R68\n",
    "R676\n",
    "R13\n",
    "R11\n",
    "R660\n",
    "L760\n",
    "R227\n",
    "L27\n",
    "L65\n",
    "R7\n",
    "L542\n",
    "R26\n",
    "R562\n",
    "L26\n",
    "L62\n",
    "R96\n",
    "L96\n",
    "R11\n",
    "L11\n",
    "L24\n",
    "L84\n",
    "R8\n",
    "L42\n",
    "R42\n",
    "R67\n",
    "R233\n",
    "R9\n",
    "R91\n",
    "L12\n",
    "L66\n",
    "L63\n",
    "L1\n",
    "L58\n",
    "L35\n",
    "L314\n",
    "L51\n",
    "R24\n",
    "R864\n",
    "R22\n",
    "R90\n",
    "L28\n",
    "R56\n",
    "L28\n",
    "R97\n",
    "R93\n",
    "R79\n",
    "L98\n",
    "R92\n",
    "R37\n",
    "R88\n",
    "L445\n",
    "R44\n",
    "L87\n",
    "R46\n",
    "R865\n",
    "R89\n",
    "R380\n",
    "L789\n",
    "L19\n",
    "R564\n",
    "R95\n",
    "L27\n",
    "L186\n",
    "R4\n",
    "L75\n",
    "L47\n",
    "L342\n",
    "L17\n",
    "L41\n",
    "L731\n",
    "L1\n",
    "R63\n",
    "L616\n",
    "R10\n",
    "L80\n",
    "L45\n",
    "R84\n",
    "R80\n",
    "L64\n",
    "L125\n",
    "R82\n",
    "L86\n",
    "L71\n",
    "R44\n",
    "L244\n",
    "R17\n",
    "R83\n",
    "R642\n",
    "L32\n",
    "R69\n",
    "R22\n",
    "R12\n",
    "R81\n",
    "L139\n",
    "R86\n",
    "L41\n",
    "R28\n",
    "L758\n",
    "L970\n",
    "R756\n",
    "L2\n",
    "L54\n",
    "L691\n",
    "R91\n",
    "L63\n",
    "R30\n",
    "L69\n",
    "L35\n",
    "R37\n",
    "L33\n",
    "L67\n",
    "R85\n",
    "L98\n",
    "L35\n",
    "R31\n",
    "R217\n",
    "L688\n",
    "R88\n",
    "R29\n",
    "R20\n",
    "L239\n",
    "R47\n",
    "R2\n",
    "R31\n",
    "R780\n",
    "R30\n",
    "L30\n",
    "R415\n",
    "L85\n",
    "L565\n",
    "L27\n",
    "L57\n",
    "R99\n",
    "L826\n",
    "L19\n",
    "R18\n",
    "R78\n",
    "L43\n",
    "R94\n",
    "L452\n",
    "R81\n",
    "L25\n",
    "L56\n",
    "L6\n",
    "L58\n",
    "L36\n",
    "R12\n",
    "L12\n",
    "L21\n",
    "L6\n",
    "L44\n",
    "R78\n",
    "R93\n",
    "L90\n",
    "L403\n",
    "L41\n",
    "R72\n",
    "L58\n",
    "R20\n",
    "R11\n",
    "L6\n",
    "L5\n",
    "R46\n",
    "L65\n",
    "R354\n",
    "L35\n",
    "L23\n",
    "L95\n",
    "L85\n",
    "R39\n",
    "R60\n",
    "L93\n",
    "L95\n",
    "L839\n",
    "R31\n",
    "L22\n",
    "L78\n",
    "R81\n",
    "R19\n",
    "L925\n",
    "R21\n",
    "R5\n",
    "R84\n",
    "R2\n",
    "L887\n",
    "R623\n",
    "R77\n",
    "L944\n",
    "R20\n",
    "R55\n",
    "L31\n",
    "R928\n",
    "L28\n",
    "R59\n",
    "L91\n",
    "R98\n",
    "L66\n",
    "R19\n",
    "R53\n",
    "L72\n",
    "L17\n",
    "L16\n",
    "R13\n",
    "L71\n",
    "R33\n",
    "L330\n",
    "R88\n",
    "R52\n",
    "L52\n",
    "R22\n",
    "L62\n",
    "L154\n",
    "L6\n",
    "R31\n",
    "L32\n",
    "L99\n",
    "R40\n",
    "L29\n",
    "R69\n",
    "R22\n",
    "L13\n",
    "R811\n",
    "L27\n",
    "R27\n",
    "L95\n",
    "L75\n",
    "R97\n",
    "R73\n",
    "L515\n",
    "L45\n",
    "R689\n",
    "R71\n",
    "R24\n",
    "R444\n",
    "R77\n",
    "R55\n",
    "R37\n",
    "R11\n",
    "R52\n",
    "L93\n",
    "L78\n",
    "R671\n",
    "R159\n",
    "L507\n",
    "L57\n",
    "R1\n",
    "L638\n",
    "L59\n",
    "R37\n",
    "L236\n",
    "R51\n",
    "R49\n",
    "R985\n",
    "R61\n",
    "R54\n",
    "L44\n",
    "L90\n",
    "R34\n",
    "L27\n",
    "R559\n",
    "R57\n",
    "L3\n",
    "R81\n",
    "L67\n",
    "L97\n",
    "L6\n",
    "L35\n",
    "L92\n",
    "R30\n",
    "L22\n",
    "R22\n",
    "L73\n",
    "L927\n",
    "L23\n",
    "L11\n",
    "R88\n",
    "R85\n",
    "L13\n",
    "L90\n",
    "R51\n",
    "R28\n",
    "L397\n",
    "L46\n",
    "R12\n",
    "R225\n",
    "L50\n",
    "L659\n",
    "L29\n",
    "R76\n",
    "R78\n",
    "R19\n",
    "L98\n",
    "R758\n",
    "L104\n",
    "L16\n",
    "R16\n",
    "R256\n",
    "R50\n",
    "R94\n",
    "L1\n",
    "L99\n",
    "L89\n",
    "L358\n",
    "L63\n",
    "R10\n",
    "R26\n",
    "R14\n",
    "L40\n",
    "R152\n",
    "L83\n",
    "R31\n",
    "R13\n",
    "L13\n",
    "R86\n",
    "L556\n",
    "R13\n",
    "L43\n",
    "R94\n",
    "R17\n",
    "R61\n",
    "L128\n",
    "R665\n",
    "L40\n",
    "R69\n",
    "L47\n",
    "R87\n",
    "L812\n",
    "L89\n",
    "L77\n",
    "R4\n",
    "R296\n",
    "L29\n",
    "L18\n",
    "L53\n",
    "L16\n",
    "L98\n",
    "L514\n",
    "R82\n",
    "L54\n",
    "L21\n",
    "L7\n",
    "R728\n",
    "R51\n",
    "L37\n",
    "R86\n",
    "R63\n",
    "L63\n",
    "L5\n",
    "R5\n",
    "R741\n",
    "L41\n",
    "R62\n",
    "R338\n",
    "L51\n",
    "L89\n",
    "R273\n",
    "R94\n",
    "R4\n",
    "R69\n",
    "R710\n",
    "R991\n",
    "L5\n",
    "R4\n",
    "R53\n",
    "L15\n",
    "L47\n",
    "L76\n",
    "R95\n",
    "L62\n",
    "R46\n",
    "L83\n",
    "R95\n",
    "L44\n",
    "R41\n",
    "L38\n",
    "R53\n",
    "L527\n",
    "R509\n",
    "L87\n",
    "R236\n",
    "L849\n",
    "R64\n",
    "R23\n",
    "L84\n",
    "R256\n",
    "L59\n",
    "L71\n",
    "L57\n",
    "L10\n",
    "L62\n",
    "L18\n",
    "R25\n",
    "R52\n",
    "R99\n",
    "L15\n",
    "R57\n",
    "L23\n",
    "L25\n",
    "L31\n",
    "L12\n",
    "R177\n",
    "L96\n",
    "L12\n",
    "L36\n",
    "L84\n",
    "L6\n",
    "L152\n",
    "L976\n",
    "R1\n",
    "L56\n",
    "R31\n",
    "L76\n",
    "R76\n",
    "L330\n",
    "L643\n",
    "R51\n",
    "L282\n",
    "L41\n",
    "R945\n",
    "R63\n",
    "L48\n",
    "R739\n",
    "R46\n",
    "R310\n",
    "L38\n",
    "L372\n",
    "L54\n",
    "L37\n",
    "L518\n",
    "L94\n",
    "L897\n",
    "R94\n",
    "L8\n",
    "L64\n",
    "R51\n",
    "L22\n",
    "R49\n",
    "R68\n",
    "R32\n",
    "R135\n",
    "L15\n",
    "L20\n",
    "L690\n",
    "R94\n",
    "L4\n",
    "R33\n",
    "L33\n",
    "R43\n",
    "R57\n",
    "L75\n",
    "L8\n",
    "L117\n",
    "L1\n",
    "R57\n",
    "L556\n",
    "L76\n",
    "R176\n",
    "R69\n",
    "L628\n",
    "R39\n",
    "R65\n",
    "R35\n",
    "R24\n",
    "L67\n",
    "R63\n",
    "L52\n",
    "L48\n",
    "L90\n",
    "L97\n",
    "L13\n",
    "L42\n",
    "R81\n",
    "R62\n",
    "R99\n",
    "R17\n",
    "L17\n",
    "R752\n",
    "R48\n",
    "R41\n",
    "R59\n",
    "R46\n",
    "L65\n",
    "L78\n",
    "R97\n",
    "R95\n",
    "L6\n",
    "L69\n",
    "L20\n",
    "L72\n",
    "L74\n",
    "L54\n",
    "L99\n",
    "R68\n",
    "L1\n",
    "L68\n",
    "L21\n",
    "R21\n",
    "R66\n",
    "L24\n",
    "L36\n",
    "R94\n",
    "R52\n",
    "L73\n",
    "R84\n",
    "R37\n",
    "L562\n",
    "R1\n",
    "R61\n",
    "R98\n",
    "L98\n",
    "R82\n",
    "L3\n",
    "L1\n",
    "L22\n",
    "L827\n",
    "L578\n",
    "R49\n",
    "R94\n",
    "L72\n",
    "R95\n",
    "L79\n",
    "R72\n",
    "L81\n",
    "R71\n",
    "L7\n",
    "L47\n",
    "R638\n",
    "L69\n",
    "L26\n",
    "R11\n",
    "R963\n",
    "L88\n",
    "L76\n",
    "L10\n",
    "R11\n",
    "R31\n",
    "L64\n",
    "L67\n",
    "R43\n",
    "L685\n",
    "R942\n",
    "L818\n",
    "L2\n",
    "R72\n",
    "R572\n",
    "R63\n",
    "L602\n",
    "L45\n",
    "R60\n",
    "R34\n",
    "L534\n",
    "L72\n",
    "L28\n",
    "R43\n",
    "L83\n",
    "R12\n",
    "R97\n",
    "R653\n",
    "R78\n",
    "L45\n",
    "L45\n",
    "L10\n",
    "L931\n",
    "R710\n",
    "R21\n",
    "R68\n",
    "R95\n",
    "R70\n",
    "R67\n",
    "R92\n",
    "L92\n",
    "R57\n",
    "R762\n",
    "R74\n",
    "R7\n",
    "L96\n",
    "L37\n",
    "L67\n",
    "L95\n",
    "L38\n",
    "R128\n",
    "R7\n",
    "L2\n",
    "R87\n",
    "R13\n",
    "R42\n",
    "L475\n",
    "R32\n",
    "L67\n",
    "R68\n",
    "L316\n",
    "L84\n",
    "L73\n",
    "L927\n",
    "R636\n",
    "L536\n",
    "L3\n",
    "L797\n",
    "L21\n",
    "R95\n",
    "R18\n",
    "R73\n",
    "R14\n",
    "L35\n",
    "R12\n",
    "R570\n",
    "L35\n",
    "R63\n",
    "L355\n",
    "L39\n",
    "L88\n",
    "L972\n",
    "R912\n",
    "R78\n",
    "R310\n",
    "R23\n",
    "R92\n",
    "R88\n",
    "R97\n",
    "R10\n",
    "L510\n",
    "L26\n",
    "R426\n",
    "L60\n",
    "L40\n",
    "L76\n",
    "R376\n",
    "L74\n",
    "L34\n",
    "R8\n",
    "L914\n",
    "R14\n",
    "R79\n",
    "R306\n",
    "L85\n",
    "L97\n",
    "R57\n",
    "L960\n",
    "L4\n",
    "R1\n",
    "R64\n",
    "L21\n",
    "L40\n",
    "L51\n",
    "L3\n",
    "L57\n",
    "L43\n",
    "R25\n",
    "R10\n",
    "L81\n",
    "R16\n",
    "R61\n",
    "R6\n",
    "R94\n",
    "L51\n",
    "L85\n",
    "R41\n",
    "R18\n",
    "R49\n",
    "L73\n",
    "R45\n",
    "R37\n",
    "L52\n",
    "L367\n",
    "L959\n",
    "R10\n",
    "L65\n",
    "R832\n",
    "L57\n",
    "L69\n",
    "L31\n",
    "R75\n",
    "R94\n",
    "R12\n",
    "R19\n",
    "L83\n",
    "R354\n",
    "R71\n",
    "R58\n",
    "L49\n",
    "L51\n",
    "R67\n",
    "R56\n",
    "L23\n",
    "R6\n",
    "L562\n",
    "R976\n",
    "R535\n",
    "L920\n",
    "R136\n",
    "L444\n",
    "L27\n",
    "L28\n",
    "L72\n",
    "L407\n",
    "R184\n",
    "L35\n",
    "R13\n",
    "R45\n",
    "L14\n",
    "R14\n",
    "L61\n",
    "L298\n",
    "L60\n",
    "R84\n",
    "R135\n",
    "R49\n",
    "R51\n",
    "R57\n",
    "R26\n",
    "L239\n",
    "R78\n",
    "L22\n",
    "R70\n",
    "L970\n",
    "R77\n",
    "R764\n",
    "L90\n",
    "R53\n",
    "L307\n",
    "L242\n",
    "L55\n",
    "L91\n",
    "R80\n",
    "L40\n",
    "R23\n",
    "R38\n",
    "L25\n",
    "R15\n",
    "L54\n",
    "L761\n",
    "R59\n",
    "R56\n",
    "L482\n",
    "R753\n",
    "L71\n",
    "R65\n",
    "L89\n",
    "L4\n",
    "L72\n",
    "R25\n",
    "R12\n",
    "R15\n",
    "R522\n",
    "L40\n",
    "R66\n",
    "R5\n",
    "L151\n",
    "R33\n",
    "L30\n",
    "R76\n",
    "R62\n",
    "R45\n",
    "R14\n",
    "L611\n",
    "R57\n",
    "L46\n",
    "R79\n",
    "L68\n",
    "L65\n",
    "R11\n",
    "L11\n",
    "L62\n",
    "R69\n",
    "R93\n",
    "L61\n",
    "L9\n",
    "L743\n",
    "R22\n",
    "L9\n",
    "R92\n",
    "R80\n",
    "R685\n",
    "L57\n",
    "R66\n",
    "R76\n",
    "R58\n",
    "L172\n",
    "L75\n",
    "L96\n",
    "R443\n",
    "R8\n",
    "L94\n",
    "R86\n",
    "L51\n",
    "R319\n",
    "L34\n",
    "L95\n",
    "R15\n",
    "L49\n",
    "L5\n",
    "L68\n",
    "L94\n",
    "L45\n",
    "L93\n",
    "L42\n",
    "R19\n",
    "L13\n",
    "L27\n",
    "R5\n",
    "L63\n",
    "R116\n",
    "R5\n",
    "R85\n",
    "L93\n",
    "L77\n",
    "L15\n",
    "R36\n",
    "L836\n",
    "L87\n",
    "R87\n",
    "R80\n",
    "R44\n",
    "L24\n",
    "L162\n",
    "L14\n",
    "R47\n",
    "L71\n",
    "R81\n",
    "L81\n",
    "R46\n",
    "L44\n",
    "R101\n",
    "R52\n",
    "L55\n",
    "L948\n",
    "R827\n",
    "R73\n",
    "L52\n",
    "L2\n",
    "R42\n",
    "R63\n",
    "L3\n",
    "R48\n",
    "L48\n",
    "R47\n",
    "L47\n",
    "R30\n",
    "L91\n",
    "R597\n",
    "L444\n",
    "L92\n",
    "R14\n",
    "L69\n",
    "R55\n",
    "R69\n",
    "L11\n",
    "L58\n",
    "L666\n",
    "R66\n",
    "R68\n",
    "R32\n",
    "L71\n",
    "L9\n",
    "R74\n",
    "L615\n",
    "R56\n",
    "R87\n",
    "L23\n",
    "R245\n",
    "R98\n",
    "L42\n",
    "L16\n",
    "L11\n",
    "L169\n",
    "R96\n",
    "R89\n",
    "L28\n",
    "L61\n",
    "L79\n",
    "L221\n",
    "L81\n",
    "L5\n",
    "L14\n",
    "R90\n",
    "L90\n",
    "L51\n",
    "L175\n",
    "L82\n",
    "R8\n",
    "R81\n",
    "L640\n",
    "L99\n",
    "L42\n",
    "L14\n",
    "L13\n",
    "R68\n",
    "L36\n",
    "R15\n",
    "L20\n",
    "R30\n",
    "R58\n",
    "R7\n",
    "R36\n",
    "R69\n",
    "L66\n",
    "L32\n",
    "L776\n",
    "R74\n",
    "L45\n",
    "R45\n",
    "L18\n",
    "L82\n",
    "L22\n",
    "L8\n",
    "R58\n",
    "R19\n",
    "R53\n",
    "R51\n",
    "L9\n",
    "R60\n",
    "L53\n",
    "R62\n",
    "L33\n",
    "L64\n",
    "R32\n",
    "L46\n",
    "R19\n",
    "R61\n",
    "L94\n",
    "R14\n",
    "L86\n",
    "R39\n",
    "L53\n",
    "L31\n",
    "L15\n",
    "R84\n",
    "L51\n",
    "R910\n",
    "R22\n",
    "L964\n",
    "L22\n",
    "L66\n",
    "L567\n",
    "R98\n",
    "R423\n",
    "R20\n",
    "L15\n",
    "L26\n",
    "L62\n",
    "L14\n",
    "R98\n",
    "R68\n",
    "L62\n",
    "L524\n",
    "R95\n",
    "L612\n",
    "L838\n",
    "R918\n",
    "R31\n",
    "L47\n",
    "R549\n",
    "R65\n",
    "R35\n",
    "R78\n",
    "R49\n",
    "R73\n",
    "R50\n",
    "R50\n",
    "R41\n",
    "L211\n",
    "R54\n",
    "L96\n",
    "R66\n",
    "L54\n",
    "R189\n",
    "R911\n",
    "R66\n",
    "R34\n",
    "R456\n",
    "R91\n",
    "R53\n",
    "R59\n",
    "R4\n",
    "R116\n",
    "R20\n",
    "R304\n",
    "R42\n",
    "L563\n",
    "L82\n",
    "L429\n",
    "L71\n",
    "L78\n",
    "L97\n",
    "L69\n",
    "L56\n",
    "R185\n",
    "L87\n",
    "R21\n",
    "R481\n",
    "R30\n",
    "R18\n",
    "R93\n",
    "R77\n",
    "L918\n",
    "R22\n",
    "R73\n",
    "L41\n",
    "L16\n",
    "L74\n",
    "R136\n",
    "R98\n",
    "R39\n",
    "L37\n",
    "L47\n",
    "R47\n",
    "L404\n",
    "L84\n",
    "L67\n",
    "L86\n",
    "R88\n",
    "L47\n",
    "R420\n",
    "R56\n",
    "L30\n",
    "R90\n",
    "L58\n",
    "R22\n",
    "R910\n",
    "L77\n",
    "R78\n",
    "R13\n",
    "R876\n",
    "L91\n",
    "L53\n",
    "R83\n",
    "R591\n",
    "R670\n",
    "L405\n",
    "L95\n",
    "L920\n",
    "L80\n",
    "R46\n",
    "L4\n",
    "L42\n",
    "R7\n",
    "R24\n",
    "L22\n",
    "R84\n",
    "R33\n",
    "L26\n",
    "R836\n",
    "L936\n",
    "R23\n",
    "L23\n",
    "L52\n",
    "R805\n",
    "R210\n",
    "L77\n",
    "L86\n",
    "R64\n",
    "L64\n",
    "L598\n",
    "R98\n",
    "L254\n",
    "L46\n",
    "R99\n",
    "L99\n",
    "L94\n",
    "L6\n",
    "L51\n",
    "R488\n",
    "L65\n",
    "L72\n",
    "L8\n",
    "R701\n",
    "L129\n",
    "L164\n",
    "L64\n",
    "L21\n",
    "R28\n",
    "L43\n",
    "L60\n",
    "L140\n",
    "R558\n",
    "R818\n",
    "L4\n",
    "R56\n",
    "R72\n",
    "R80\n",
    "R20\n",
    "R291\n",
    "L56\n",
    "R65\n",
    "L29\n",
    "L482\n",
    "R11\n",
    "R71\n",
    "R87\n",
    "L26\n",
    "L232\n",
    "L38\n",
    "R90\n",
    "R767\n",
    "L19\n",
    "R51\n",
    "L6\n",
    "R96\n",
    "L41\n",
    "R30\n",
    "R86\n",
    "R84\n",
    "L21\n",
    "L86\n",
    "L340\n",
    "L65\n",
    "L88\n",
    "L320\n",
    "L227\n",
    "L68\n",
    "L7\n",
    "L78\n",
    "L914\n",
    "L86\n",
    "L73\n",
    "L27\n",
    "R15\n",
    "L40\n",
    "R421\n",
    "R143\n",
    "R461\n",
    "L368\n",
    "L46\n",
    "R293\n",
    "R60\n",
    "L24\n",
    "L34\n",
    "L343\n",
    "L38\n",
    "L9\n",
    "R93\n",
    "L27\n",
    "L89\n",
    "R32\n",
    "R19\n",
    "L619\n",
    "L25\n",
    "L140\n",
    "L13\n",
    "R78\n",
    "R945\n",
    "R118\n",
    "R85\n",
    "L12\n",
    "R313\n",
    "R53\n",
    "R98\n",
    "L27\n",
    "R957\n",
    "L30\n",
    "R51\n",
    "L51\n",
    "L42\n",
    "R19\n",
    "R23\n",
    "L87\n",
    "R140\n",
    "L4\n",
    "R51\n",
    "L60\n",
    "L708\n",
    "L67\n",
    "R535\n",
    "L20\n",
    "R82\n",
    "R573\n",
    "R65\n",
    "L65\n",
    "L886\n",
    "R86\n",
    "L80\n",
    "L7\n",
    "L433\n",
    "R862\n",
    "L92\n",
    "L385\n",
    "R36\n",
    "R32\n",
    "R32\n",
    "R67\n",
    "R68\n",
    "R82\n",
    "L93\n",
    "L24\n",
    "L85\n",
    "R24\n",
    "L27\n",
    "R23\n",
    "R65\n",
    "L7\n",
    "R907\n",
    "L356\n",
    "R95\n",
    "L81\n",
    "R242\n",
    "L47\n",
    "L76\n",
    "R992\n",
    "R31\n",
    "R79\n",
    "L179\n",
    "R508\n",
    "L2\n",
    "R694\n",
    "R1\n",
    "R526\n",
    "L27\n",
    "L53\n",
    "L47\n",
    "R17\n",
    "L7\n",
    "R42\n",
    "R409\n",
    "R54\n",
    "L86\n",
    "L19\n",
    "L86\n",
    "R506\n",
    "L11\n",
    "L19\n",
    "L57\n",
    "L61\n",
    "R18\n",
    "R14\n",
    "L92\n",
    "R38\n",
    "R40\n",
    "L25\n",
    "R25\n",
    "R30\n",
    "R70\n",
    "L58\n",
    "R12\n",
    "R5\n",
    "L48\n",
    "R89\n",
    "R989\n",
    "L77\n",
    "R88\n",
    "R306\n",
    "L306\n",
    "L99\n",
    "R99\n",
    "R9\n",
    "R90\n",
    "L99\n",
    "L35\n",
    "R30\n",
    "R40\n",
    "R65\n",
    "R73\n",
    "L15\n",
    "R42\n",
    "L63\n",
    "R72\n",
    "R91\n",
    "L59\n",
    "L57\n",
    "R16\n",
    "L40\n",
    "R740\n",
    "R11\n",
    "L11\n",
    "R30\n",
    "L930\n",
    "R536\n",
    "R931\n",
    "R833\n",
    "L385\n",
    "R58\n",
    "R166\n",
    "L19\n",
    "R40\n",
    "L589\n",
    "R29\n",
    "R37\n",
    "L198\n",
    "L39\n",
    "L53\n",
    "L24\n",
    "L3\n",
    "L21\n",
    "R941\n",
    "R960\n",
    "R75\n",
    "R26\n",
    "L1\n",
    "R71\n",
    "R44\n",
    "L556\n",
    "L95\n",
    "R36\n",
    "R328\n",
    "R15\n",
    "R57\n",
    "R477\n",
    "L109\n",
    "L4\n",
    "L64\n",
    "L561\n",
    "L32\n",
    "L49\n",
    "L92\n",
    "R834\n",
    "R6\n",
    "R494\n",
    "L99\n",
    "R971\n",
    "R628\n",
    "R10\n",
    "R53\n",
    "L63\n",
    "R67\n",
    "R993\n",
    "R43\n",
    "L4\n",
    "L15\n",
    "R564\n",
    "R852\n",
    "R45\n",
    "R49\n",
    "L86\n",
    "L117\n",
    "R18\n",
    "R1\n",
    "L838\n",
    "R28\n",
    "R78\n",
    "L74\n",
    "R96\n",
    "L113\n",
    "L409\n",
    "R53\n",
    "R30\n",
    "R38\n",
    "R15\n",
    "R286\n",
    "L83\n",
    "R81\n",
    "L67\n",
    "L22\n",
    "L12\n",
    "R98\n",
    "L95\n",
    "R79\n",
    "R27\n",
    "L148\n",
    "R149\n",
    "L72\n",
    "L821\n",
    "L14\n",
    "R73\n",
    "R27\n",
    "R44\n",
    "L67\n",
    "R23\n",
    "L8\n",
    "R8\n",
    "R60\n",
    "R72\n",
    "L32\n",
    "L12\n",
    "L88\n",
    "L19\n",
    "L81\n",
    "L68\n",
    "L6\n",
    "L22\n",
    "R85\n",
    "L77\n",
    "R88\n",
    "L86\n",
    "R33\n",
    "R49\n",
    "R61\n",
    "L57\n",
    "L95\n",
    "L72\n",
    "L27\n",
    "R747\n",
    "L753\n",
    "L74\n",
    "R47\n",
    "R77\n",
    "L38\n",
    "L12\n",
    "L10\n",
    "L90\n",
    "R895\n",
    "R5\n",
    "L77\n",
    "L11\n",
    "R74\n",
    "L86\n",
    "L1\n",
    "R36\n",
    "R65\n",
    "R42\n",
    "L42\n",
    "L88\n",
    "R56\n",
    "L68\n",
    "R82\n",
    "L82\n",
    "R904\n",
    "L33\n",
    "L64\n",
    "R293\n",
    "R29\n",
    "L829\n",
    "R27\n",
    "R96\n",
    "L23\n",
    "L66\n",
    "L473\n",
    "R39\n",
    "R35\n",
    "L41\n",
    "L61\n",
    "R67\n",
    "L51\n",
    "L80\n",
    "L69\n",
    "L91\n",
    "L87\n",
    "L471\n",
    "L51\n",
    "R714\n",
    "L56\n",
    "L44\n",
    "L12\n",
    "R868\n",
    "L50\n",
    "R4\n",
    "L51\n",
    "R510\n",
    "L83\n",
    "L60\n",
    "L38\n",
    "L789\n",
    "R641\n",
    "R49\n",
    "L5\n",
    "R2\n",
    "L39\n",
    "L61\n",
    "L86\n",
    "R12\n",
    "R59\n",
    "R3\n",
    "L54\n",
    "L34\n",
    "L468\n",
    "L832\n",
    "L32\n",
    "R41\n",
    "R38\n",
    "R67\n",
    "L54\n",
    "L60\n",
    "L69\n",
    "L81\n",
    "R50\n",
    "L7\n",
    "L78\n",
    "R84\n",
    "R95\n",
    "R43\n",
    "R9\n",
    "L46\n",
    "R69\n",
    "R31\n",
    "R70\n",
    "R12\n",
    "R141\n",
    "R371\n",
    "R62\n",
    "R659\n",
    "R61\n",
    "R80\n",
    "R98\n",
    "L27\n",
    "R51\n",
    "R22\n",
    "L901\n",
    "R626\n",
    "L25\n",
    "L71\n",
    "L54\n",
    "R25\n",
    "R7\n",
    "L45\n",
    "R38\n",
    "R61\n",
    "R42\n",
    "L96\n",
    "L921\n",
    "R14\n",
    "L45\n",
    "R52\n",
    "L807\n",
    "R27\n",
    "L27\n",
    "R44\n",
    "R475\n",
    "L10\n",
    "R91\n",
    "L79\n",
    "R320\n",
    "L63\n",
    "R83\n",
    "R73\n",
    "L29\n",
    "R852\n",
    "R373\n",
    "L85\n",
    "L45\n",
    "R5\n",
    "L505\n",
    "R66\n",
    "L4\n",
    "R38\n",
    "R11\n",
    "L11\n",
    "R975\n",
    "R25\n",
    "R77\n",
    "L777\n",
    "L51\n",
    "L43\n",
    "L29\n",
    "R4\n",
    "L97\n",
    "R841\n",
    "L12\n",
    "R87\n",
    "L69\n",
    "R94\n",
    "R75\n",
    "L68\n",
    "L32\n",
    "R13\n",
    "R51\n",
    "R10\n",
    "R78\n",
    "L57\n",
    "R40\n",
    "L65\n",
    "L70\n",
    "L20\n",
    "L99\n",
    "L26\n",
    "R8\n",
    "L29\n",
    "L34\n",
    "R1\n",
    "R99\n",
    "R61\n",
    "L8\n",
    "R47\n",
    "L53\n",
    "R16\n",
    "R697\n",
    "R7\n",
    "R33\n",
    "R499\n",
    "R75\n",
    "R58\n",
    "L94\n",
    "L26\n",
    "R88\n",
    "L82\n",
    "R82\n",
    "L681\n",
    "R65\n",
    "R16\n",
    "L37\n",
    "L82\n",
    "R44\n",
    "R83\n",
    "R92\n",
    "R14\n",
    "L35\n",
    "R87\n",
    "R5\n",
    "R91\n",
    "L62\n",
    "R50\n",
    "R63\n",
    "L13\n",
    "L362\n",
    "R62\n",
    "L98\n",
    "L2\n",
    "L34\n",
    "R34\n",
    "L52\n",
    "R51\n",
    "R44\n",
    "R60\n",
    "R397\n",
    "R68\n",
    "R74\n",
    "R58\n",
    "R575\n",
    "L75\n",
    "L27\n",
    "L73\n",
    "R32\n",
    "R168\n",
    "R3\n",
    "R20\n",
    "L930\n",
    "R28\n",
    "R81\n",
    "R43\n",
    "L45\n",
    "R42\n",
    "R72\n",
    "L14\n",
    "L81\n",
    "L48\n",
    "L71\n",
    "R13\n",
    "R853\n",
    "R94\n",
    "L60\n",
    "R93\n",
    "R57\n",
    "R557\n",
    "R93\n",
    "L86\n",
    "R86\n",
    "R409\n",
    "R426\n",
    "R65\n",
    "L6\n",
    "L12\n",
    "R58\n",
    "L51\n",
    "R65\n",
    "L54\n",
    "L64\n",
    "R64\n",
    "L32\n",
    "L9\n",
    "L225\n",
    "R20\n",
    "R642\n",
    "L96\n",
    "R24\n",
    "L71\n",
    "R43\n",
    "R62\n",
    "L88\n",
    "L74\n",
    "R4\n",
    "L80\n",
    "L20\n",
    "L64\n",
    "R64\n",
    "R53\n",
    "R97\n",
    "R69\n",
    "L44\n",
    "L45\n",
    "R9\n",
    "L839\n",
    "L792\n",
    "R92\n",
    "R60\n",
    "L60\n",
    "R845\n",
    "R27\n",
    "L49\n",
    "R94\n",
    "R52\n",
    "R68\n",
    "R99\n",
    "R64\n",
    "L55\n",
    "L26\n",
    "R12\n",
    "R169\n",
    "L39\n",
    "L61\n",
    "L73\n",
    "R24\n",
    "L729\n",
    "L22\n",
    "R48\n",
    "R55\n",
    "R69\n",
    "R852\n",
    "L524\n",
    "L17\n",
    "L434\n",
    "L95\n",
    "R47\n",
    "R99\n",
    "R26\n",
    "R74\n",
    "L7\n",
    "L72\n",
    "L16\n",
    "R66\n",
    "R743\n",
    "L2\n",
    "R82\n",
    "L62\n",
    "R58\n",
    "R291\n",
    "L79\n",
    "L2\n",
    "L1\n",
    "R1\n",
    "R35\n",
    "L435\n",
    "L75\n",
    "R75\n",
    "R489\n",
    "R66\n",
    "L467\n",
    "L81\n",
    "L40\n",
    "L22\n",
    "R55\n",
    "L78\n",
    "R73\n",
    "R4\n",
    "L68\n",
    "L30\n",
    "R59\n",
    "R840\n",
    "L169\n",
    "L57\n",
    "L78\n",
    "R94\n",
    "R14\n",
    "L4\n",
    "R76\n",
    "R49\n",
    "R75\n",
    "L86\n",
    "R86\n",
    "R552\n",
    "L52\n",
    "R22\n",
    "R278\n",
    "R66\n",
    "R34\n",
    "L2\n",
    "R97\n",
    "R965\n",
    "R40\n",
    "L58\n",
    "R94\n",
    "L60\n",
    "L77\n",
    "L899\n",
    "R72\n",
    "R32\n",
    "R817\n",
    "R67\n",
    "R12\n",
    "L82\n",
    "R222\n",
    "L40\n",
    "R47\n",
    "L747\n",
    "L61\n",
    "R29\n",
    "L395\n",
    "R869\n",
    "L30\n",
    "L94\n",
    "L28\n",
    "R44\n",
    "L134\n",
    "L286\n",
    "L893\n",
    "L546\n",
    "R25\n",
    "L71\n",
    "R771\n",
    "L69\n",
    "L7\n",
    "R17\n",
    "L407\n",
    "R66\n",
    "L88\n",
    "R177\n",
    "L94\n",
    "R186\n",
    "L96\n",
    "L94\n",
    "L52\n",
    "R533\n",
    "L40\n",
    "R14\n",
    "L156\n",
    "L829\n",
    "R88\n",
    "L49\n",
    "R88\n",
    "R12\n",
    "R38\n",
    "R62\n",
    "L25\n",
    "L75\n",
    "R47\n",
    "L70\n",
    "R23\n",
    "L99\n",
    "L56\n",
    "R44\n",
    "L61\n",
    "R72\n",
    "L142\n",
    "L58\n",
    "L57\n",
    "R57\n",
    "L95\n",
    "R51\n",
    "R7\n",
    "R20\n",
    "R41\n",
    "L51\n",
    "R139\n",
    "R88\n",
    "R985\n",
    "R315\n",
    "L39\n",
    "L67\n",
    "R59\n",
    "L853\n",
    "R91\n",
    "R83\n",
    "R45\n",
    "R381\n",
    "R609\n",
    "R91\n",
    "L2\n",
    "R708\n",
    "R94\n",
    "L66\n",
    "L34\n",
    "R48\n",
    "L43\n",
    "L5\n",
    "R96\n",
    "L15\n",
    "L81\n",
    "R58\n",
    "L646\n",
    "R23\n",
    "R865\n",
    "R688\n",
    "R712\n",
    "R11\n",
    "L38\n",
    "L50\n",
    "L86\n",
    "R369\n",
    "L62\n",
    "L85\n",
    "R41\n",
    "R20\n",
    "L35\n",
    "L56\n",
    "R41\n",
    "R95\n",
    "R58\n",
    "L60\n",
    "L63\n",
    "L40\n",
    "R41\n",
    "L1\n",
    "L3\n",
    "R93\n",
    "L90\n",
    "R27\n",
    "L76\n",
    "R11\n",
    "R116\n",
    "R69\n",
    "R5\n",
    "R48\n",
    "R36\n",
    "R41\n",
    "R523\n",
    "R28\n",
    "R48\n",
    "R4\n",
    "R44\n",
    "L155\n",
    "R60\n",
    "R71\n",
    "L4\n",
    "L30\n",
    "R12\n",
    "L60\n",
    "L18\n",
    "L49\n",
    "R33\n",
    "R38\n",
    "L22\n",
    "L116\n",
    "L70\n",
    "R86\n",
    "R40\n",
    "R56\n",
    "L94\n",
    "R37\n",
    "R553\n",
    "L92\n",
    "L931\n",
    "L69\n",
    "R39\n",
    "R594\n",
    "L53\n",
    "R20\n",
    "L36\n",
    "R236\n",
    "R247\n",
    "R58\n",
    "L5\n",
    "R54\n",
    "L38\n",
    "R84\n",
    "L51\n",
    "L49\n",
    "R545\n",
    "L32\n",
    "R87\n",
    "R78\n",
    "R422\n",
    "L255\n",
    "R55\n",
    "R96\n",
    "R603\n",
    "R19\n",
    "L49\n",
    "L10\n",
    "L35\n",
    "R88\n",
    "R788\n",
    "L302\n",
    "R2\n",
    "L85\n",
    "R1\n",
    "L494\n",
    "L40\n",
    "R10\n",
    "L92\n",
    "R59\n",
    "R241\n",
    "L645\n",
    "R106\n",
    "R4\n",
    "L61\n",
    "L555\n",
    "R51\n",
    "L81\n",
    "R26\n",
    "L64\n",
    "R19\n",
    "L70\n",
    "R96\n",
    "L26\n",
    "L180\n",
    "L77\n",
    "R91\n",
    "L51\n",
    "R17\n",
    "L91\n",
    "R91\n",
    "L14\n",
    "R41\n",
    "R79\n",
    "R44\n",
    "R5\n",
    "L53\n",
    "L40\n",
    "L59\n",
    "L3\n",
    "L53\n",
    "R53\n",
    "L292\n",
    "R92\n",
    "L20\n",
    "L80\n",
    "R371\n",
    "R29\n",
    "L14\n",
    "R14\n",
    "L74\n",
    "L26\n",
    "R597\n",
    "R49\n",
    "L78\n",
    "L68\n",
    "R468\n",
    "R64\n",
    "L36\n",
    "L2\n",
    "R65\n",
    "L46\n",
    "R21\n",
    "L451\n",
    "L1\n",
    "R518\n",
    "R96\n",
    "R59\n",
    "R24\n",
    "R21\n",
    "R58\n",
    "R42\n",
    "R87\n",
    "L4\n",
    "R13\n",
    "L7\n",
    "L552\n",
    "R80\n",
    "L817\n",
    "L20\n",
    "R535\n",
    "R85\n",
    "R775\n",
    "L75\n",
    "L119\n",
    "L30\n",
    "R76\n",
    "L41\n",
    "L86\n",
    "L832\n",
    "R32\n",
    "R68\n",
    "R32\n",
    "L34\n",
    "R34\n",
    "R3\n",
    "L703\n",
    "R22\n",
    "L8\n",
    "R86\n",
    "R460\n",
    "L75\n",
    "R7\n",
    "L7\n",
    "R817\n",
    "R698\n",
    "L170\n",
    "R37\n",
    "L567\n",
    "R13\n",
    "R75\n",
    "R12\n",
    "L46\n",
    "L98\n",
    "L6\n",
    "R30\n",
    "R20\n",
    "L78\n",
    "L19\n",
    "R50\n",
    "R18\n",
    "L31\n",
    "L90\n",
    "R5\n",
    "L12\n",
    "R57\n",
    "R10\n",
    "L10\n",
    "R173\n",
    "R79\n",
    "L52\n",
    "L76\n",
    "L87\n",
    "L81\n",
    "L203\n",
    "L53\n",
    "R74\n",
    "L73\n",
    "R17\n",
    "R18\n",
    "L180\n",
    "R44\n",
    "R27\n",
    "R147\n",
    "L274\n",
    "R19\n",
    "R89\n",
    "R92\n",
    "L3\n",
    "R80\n",
    "L677\n",
    "R64\n",
    "L64\n",
    "L20\n",
    "L80\n",
    "L35\n",
    "L70\n",
    "R14\n",
    "R97\n",
    "R50\n",
    "R60\n",
    "L16\n",
    "L342\n",
    "R33\n",
    "R9\n",
    "L17\n",
    "R17\n",
    "R353\n",
    "R597\n",
    "L75\n",
    "R25\n",
    "L86\n",
    "R70\n",
    "R16\n",
    "L68\n",
    "L94\n",
    "L23\n",
    "L38\n",
    "L67\n",
    "R90\n",
    "R19\n",
    "L419\n",
    "L46\n",
    "L54\n",
    "L74\n",
    "R28\n",
    "L57\n",
    "L79\n",
    "L18\n",
    "R109\n",
    "R38\n",
    "L47\n",
    "R95\n",
    "R5\n",
    "L29\n",
    "R83\n",
    "R25\n",
    "R32\n",
    "R60\n",
    "L712\n",
    "R841\n",
    "L732\n",
    "R9\n",
    "L82\n",
    "R54\n",
    "L86\n",
    "L49\n",
    "R86\n",
    "R98\n",
    "R36\n",
    "L34\n",
    "L50\n",
    "L50\n",
    "L29\n",
    "R805\n",
    "R93\n",
    "R10\n",
    "L79\n",
    "L739\n",
    "L51\n",
    "R90\n",
    "L12\n",
    "R79\n",
    "L60\n",
    "L373\n",
    "L34\n",
    "L4\n",
    "L116\n",
    "L45\n",
    "R98\n",
    "L6\n",
    "R18\n",
    "R55\n",
    "L84\n",
    "L4\n",
    "R88\n",
    "L53\n",
    "R53\n",
    "R41\n",
    "L641\n",
    "R1\n",
    "L17\n",
    "R16\n",
    "L94\n",
    "R11\n",
    "L42\n",
    "L75\n",
    "L788\n",
    "R956\n",
    "R98\n",
    "L188\n",
    "L78\n",
    "L84\n",
    "L3\n",
    "R87\n",
    "R315\n",
    "R97\n",
    "R88\n",
    "R36\n",
    "R76\n",
    "R55\n",
    "L71\n",
    "L28\n",
    "R72\n",
    "L740\n",
    "R53\n",
    "L61\n",
    "L75\n",
    "L17\n",
    "L79\n",
    "L30\n",
    "L727\n",
    "R836\n",
    "R12\n",
    "R92\n",
    "R96\n",
    "R69\n",
    "L69\n",
    "R15\n",
    "L879\n",
    "L36\n",
    "L48\n",
    "R3\n",
    "L855\n",
    "L80\n",
    "L20\n",
    "R289\n",
    "R9\n",
    "L98\n",
    "R40\n",
    "R26\n",
    "L39\n",
    "L62\n",
    "L65\n",
    "R28\n",
    "L28\n",
    "R81\n",
    "L11\n",
    "L70\n",
    "R43\n",
    "L43\n",
    "L94\n",
    "R24\n",
    "L30\n",
    "L769\n",
    "L31\n",
    "R846\n",
    "R867\n",
    "R551\n",
    "L93\n",
    "L4\n",
    "L836\n",
    "R47\n",
    "L870\n",
    "L8\n",
    "L21\n",
    "L97\n",
    "R18\n",
    "L60\n",
    "L44\n",
    "L32\n",
    "L464\n",
    "R727\n",
    "R73\n",
    "L382\n",
    "R60\n",
    "R304\n",
    "R18\n",
    "R22\n",
    "R78\n",
    "R59\n",
    "L56\n",
    "L431\n",
    "L83\n",
    "L89\n",
    "R59\n",
    "R413\n",
    "L72\n",
    "R78\n",
    "R392\n",
    "R4\n",
    "R64\n",
    "R62\n",
    "R39\n",
    "R55\n",
    "R551\n",
    "L25\n",
    "L45\n",
    "L875\n",
    "R90\n",
    "R87\n",
    "R23\n",
    "R98\n",
    "R2\n",
    "L21\n",
    "R130\n",
    "L56\n",
    "L77\n",
    "R93\n",
    "R31\n",
    "L13\n",
    "R22\n",
    "L62\n",
    "R353\n",
    "L85\n",
    "L15\n",
    "R63\n",
    "R637\n",
    "L750\n",
    "L18\n",
    "R31\n",
    "R5\n",
    "R932\n",
    "L53\n",
    "R53\n",
    "L41\n",
    "R99\n",
    "R684\n",
    "R49\n",
    "L36\n",
    "L55\n",
    "R675\n",
    "R22\n",
    "L97\n",
    "R41\n",
    "R9\n",
    "R50\n",
    "L43\n",
    "L37\n",
    "L20\n",
    "L83\n",
    "L73\n",
    "R56\n",
    "R79\n",
    "L79\n",
    "R90\n",
    "L90\n",
    "R91\n",
    "L30\n",
    "L74\n",
    "L64\n",
    "R42\n",
    "R87\n",
    "L31\n",
    "R96\n",
    "L17\n",
    "R25\n",
    "R75\n",
    "L1\n",
    "R784\n",
    "R13\n",
    "L96\n",
    "L36\n",
    "R91\n",
    "R37\n",
    "L68\n",
    "L69\n",
    "R843\n",
    "R2\n",
    "L63\n",
    "L37\n",
    "L987\n",
    "R87\n",
    "L40\n",
    "R86\n",
    "R54\n",
    "L55\n",
    "L64\n",
    "L51\n",
    "R70\n",
    "R63\n",
    "L31\n",
    "L21\n",
    "R21\n",
    "L72\n",
    "R40\n",
    "L31\n",
    "R209\n",
    "R86\n",
    "R36\n",
    "R21\n",
    "L56\n",
    "R35\n",
    "R78\n",
    "L83\n",
    "L65\n",
    "L96\n",
    "R24\n",
    "R82\n",
    "L1\n",
    "R61\n",
    "L41\n",
    "R58\n",
    "R83\n",
    "L61\n",
    "R61\n",
    "R94\n",
    "L94\n",
    "L13\n",
    "R993\n",
    "L19\n",
    "R95\n",
    "L56\n",
    "L79\n",
    "L58\n",
    "L463\n",
    "L10\n",
    "R20\n",
    "R12\n",
    "L54\n",
    "L74\n",
    "R606\n",
    "R98\n",
    "L906\n",
    "L24\n",
    "L9\n",
    "L711\n",
    "R6\n",
    "L12\n",
    "R40\n",
    "R50\n",
    "L51\n",
    "R15\n",
    "L77\n",
    "R22\n",
    "R77\n",
    "L35\n",
    "R217\n",
    "R33\n",
    "R90\n",
    "R77\n",
    "L84\n",
    "L7\n",
    "R38\n",
    "L51\n",
    "L969\n",
    "R43\n",
    "L270\n",
    "R73\n",
    "R27\n",
    "L84\n",
    "R54\n",
    "L70\n",
    "R87\n",
    "L87\n",
    "L22\n",
    "R122\n",
    "L872\n",
    "R72\n",
    "R64\n",
    "L80\n",
    "L95\n",
    "R611\n",
    "R59\n",
    "R79\n",
    "R755\n",
    "L93\n",
    "R89\n",
    "L89\n",
    "R1\n",
    "L66\n",
    "R965\n",
    "L60\n",
    "L40\n",
    "L330\n",
    "L71\n",
    "R194\n",
    "R7\n",
    "L55\n",
    "R98\n",
    "L543\n",
    "R55\n",
    "R45\n",
    "L70\n",
    "R70\n",
    "L82\n",
    "R512\n",
    "L571\n",
    "L59\n",
    "R22\n",
    "L856\n",
    "R1\n",
    "R33\n",
    "R32\n",
    "L396\n",
    "L71\n",
    "R57\n",
    "L777\n",
    "L9\n",
    "R64\n",
    "L656\n",
    "R22\n",
    "L66\n",
    "R85\n",
    "L94\n",
    "R727\n",
    "L18\n",
    "R26\n",
    "R114\n",
    "L40\n",
    "L210\n",
    "L33\n",
    "R38\n",
    "L95\n",
    "L63\n",
    "R535\n",
    "L9\n",
    "R18\n",
    "R84\n",
    "L50\n",
    "L81\n",
    "R54\n",
    "L57\n",
    "R42\n",
    "R127\n",
    "R56\n",
    "R44\n",
    "L16\n",
    "R16\n",
    "L87\n",
    "L26\n",
    "R34\n",
    "R79\n",
    "L41\n",
    "L65\n",
    "L94\n",
    "L56\n",
    "L47\n",
    "L97\n",
    "R58\n",
    "R671\n",
    "L29\n",
    "L68\n",
    "L310\n",
    "L22\n",
    "R10\n",
    "R83\n",
    "R676\n",
    "L24\n",
    "L50\n",
    "R5\n",
    "R5\n",
    "L11\n",
    "L34\n",
    "L60\n",
    "R64\n",
    "R36\n",
    "R78\n",
    "L78\n",
    "L317\n",
    "R17\n",
    "L570\n",
    "L20\n",
    "L28\n",
    "R37\n",
    "R81\n",
    "R81\n",
    "L81\n",
    "L83\n",
    "R83\n",
    "L62\n",
    "L38\n",
    "R37\n",
    "L775\n",
    "R38\n",
    "L29\n",
    "R92\n",
    "R56\n",
    "L19\n",
    "R53\n",
    "L58\n",
    "R37\n",
    "L748\n",
    "R16\n",
    "R17\n",
    "R563\n",
    "R20\n",
    "R81\n",
    "L39\n",
    "L110\n",
    "L132\n",
    "R12\n",
    "R82\n",
    "L94\n",
    "R12\n",
    "L516\n",
    "R34\n",
    "L4\n",
    "L56\n",
    "L51\n",
    "R81\n",
    "R60\n",
    "L36\n",
    "L29\n",
    "R5\n",
    "R38\n",
    "L76\n",
    "L62\n",
    "R877\n",
    "L77\n",
    "R16\n",
    "R574\n",
    "R209\n",
    "L72\n",
    "R58\n",
    "L26\n",
    "R41\n",
    "R87\n",
    "R13\n",
    "L82\n",
    "R282\n",
    "R12\n",
    "L89\n",
    "L46\n",
    "L83\n",
    "L94\n",
    "L283\n",
    "R381\n",
    "L3\n",
    "R5\n",
    "R41\n",
    "R59\n",
    "R22\n",
    "L22\n",
    "R4\n",
    "L73\n",
    "R372\n",
    "R57\n",
    "R5\n",
    "R746\n",
    "R79\n",
    "R10\n",
    "L94\n",
    "L6\n",
    "L31\n",
    "L30\n",
    "R61\n",
    "L59\n",
    "L592\n",
    "R51\n",
    "L85\n",
    "R57\n",
    "R82\n",
    "L54\n",
    "R61\n",
    "L773\n",
    "R12\n",
    "R57\n",
    "R617\n",
    "L747\n",
    "L68\n",
    "R41\n",
    "L96\n",
    "L304\n",
    "R881\n",
    "L51\n",
    "L10\n",
    "R411\n",
    "R83\n",
    "R86\n",
    "R641\n",
    "R959\n",
    "L839\n",
    "R57\n",
    "R82\n",
    "L35\n",
    "L94\n",
    "L45\n",
    "L26\n",
    "L59\n",
    "L30\n",
    "R4\n",
    "L3\n",
    "L71\n",
    "L373\n",
    "L768\n",
    "L51\n",
    "R75\n",
    "L26\n",
    "R2\n",
    "R66\n",
    "L28\n",
    "R7\n",
    "L545\n",
    "L80\n",
    "L53\n",
    "L67\n",
    "L473\n",
    "R36\n",
    "R37\n",
    "R97\n",
    "L62\n",
    "R289\n",
    "R47\n",
    "R71\n",
    "R46\n",
    "L88\n",
    "R99\n",
    "L2\n",
    "R3\n",
    "R15\n",
    "L16\n",
    "L2\n",
    "L11\n",
    "L86\n",
    "L14\n",
    "L70\n",
    "R430\n",
    "R53\n",
    "L88\n",
    "R28\n",
    "L88\n",
    "R92\n",
    "L42\n",
    "L72\n",
    "L598\n",
    "R769\n",
    "L11\n",
    "L15\n",
    "L74\n",
    "R13\n",
    "L35\n",
    "L78\n",
    "R471\n",
    "R329\n",
    "L7\n",
    "R74\n",
    "R493\n",
    "R36\n",
    "L596\n",
    "L39\n",
    "L9\n",
    "L60\n",
    "R24\n",
    "R84\n",
    "L26\n",
    "L74\n",
    "L51\n",
    "L64\n",
    "L85\n",
    "R256\n",
    "R64\n",
    "R80\n",
    "L33\n",
    "R33\n",
    "L80\n",
    "L52\n",
    "L71\n",
    "L397\n",
    "L99\n",
    "R31\n",
    "R68\n",
    "L34\n",
    "L59\n",
    "R93\n",
    "L78\n",
    "L22\n",
    "R171\n",
    "L71\n",
    "R93\n",
    "L93\n",
    "L82\n",
    "R82\n",
    "L58\n",
    "L327\n",
    "L63\n",
    "L52\n",
    "L958\n",
    "R224\n",
    "L466\n",
    "R73\n",
    "L9\n",
    "R392\n",
    "R46\n",
    "R82\n",
    "R22\n",
    "L37\n",
    "R31\n",
    "L77\n",
    "R77\n",
    "L88\n",
    "L171\n",
    "L18\n",
    "R6\n",
    "R271\n",
    "L1\n",
    "R55\n",
    "L47\n",
    "L71\n",
    "L16\n",
    "R86\n",
    "R94\n",
    "L95\n",
    "R95\n",
    "R75\n",
    "L61\n",
    "R11\n",
    "L53\n",
    "R63\n",
    "R37\n",
    "L33\n",
    "L939\n",
    "R70\n",
    "R892\n",
    "R938\n",
    "R47\n",
    "R53\n",
    "L964\n",
    "R64\n",
    "R48\n",
    "R52\n",
    "L35\n",
    "R636\n",
    "L53\n",
    "L96\n",
    "L64\n",
    "L851\n",
    "L73\n",
    "R36\n",
    "L55\n",
    "R55\n",
    "R28\n",
    "L72\n",
    "R98\n",
    "L516\n",
    "R79\n",
    "R28\n",
    "L74\n",
    "R36\n",
    "L7\n",
    "L213\n",
    "L87\n",
    "L503\n",
    "L197\n",
    "R60\n",
    "R8\n",
    "L58\n",
    "R80\n",
    "R66\n",
    "L769\n",
    "R255\n",
    "R58\n",
    "L80\n",
    "L50\n",
    "L27\n",
    "L43\n",
    "L59\n",
    "L41\n",
    "L60\n",
    "R63\n",
    "L3\n",
    "R93\n",
    "L89\n",
    "R21\n",
    "L525\n",
    "R24\n",
    "R75\n",
    "L6\n",
    "R48\n",
    "L972\n",
    "L208\n",
    "R91\n",
    "L52\n",
    "L150\n",
    "L79\n",
    "R469\n",
    "L1\n",
    "R98\n",
    "R48\n",
    "R801\n",
    "L586\n",
    "L59\n",
    "L66\n",
    "R223\n",
    "L898\n",
    "L65\n",
    "L35\n",
    "L752\n",
    "R42\n",
    "R10\n",
    "L62\n",
    "L38\n",
    "R92\n",
    "R8\n",
    "L10\n",
    "R610\n",
    "R85\n",
    "R68\n",
    "R724\n",
    "L77\n",
    "L507\n",
    "L703\n",
    "R10\n",
    "L148\n",
    "L219\n",
    "L33\n",
    "R178\n",
    "R22\n",
    "L86\n",
    "L1\n",
    "R758\n",
    "R929\n",
    "R20\n",
    "R8\n",
    "L406\n",
    "R37\n",
    "R71\n",
    "L721\n",
    "R49\n",
    "L58\n",
    "L5\n",
    "R576\n",
    "R47\n",
    "R31\n",
    "L102\n",
    "R153\n",
    "L37\n",
    "R18\n",
    "L78\n",
    "R97\n",
    "L46\n",
    "L54\n",
    "L1\n",
    "R44\n",
    "L79\n",
    "L64\n",
    "L10\n",
    "R26\n",
    "R84\n",
    "R383\n",
    "R516\n",
    "R139\n",
    "R83\n",
    "R38\n",
    "R53\n",
    "L12\n",
    "R963\n",
    "R88\n",
    "L10\n",
    "L838\n",
    "R53\n",
    "L556\n",
    "L125\n",
    "L75\n",
    "R53\n",
    "L46\n",
    "L597\n",
    "R90\n",
    "R64\n",
    "R9\n",
    "R43\n",
    "L47\n",
    "L73\n",
    "R34\n",
    "L30\n",
    "L50\n",
    "R12\n",
    "R38\n",
    "L172\n",
    "R72\n",
    "R35\n",
    "R65\n",
    "L48\n",
    "L4\n",
    "R52\n",
    "L69\n",
    "R42\n",
    "R27\n",
    "R3\n",
    "R97\n",
    "R40\n",
    "L40\n",
    "L24\n",
    "R42\n",
    "R69\n",
    "R13\n",
    "R87\n",
    "R57\n",
    "L198\n",
    "L6\n",
    "L40\n",
    "R155\n",
    "R62\n",
    "L3\n",
    "R36\n",
    "R50\n",
    "R71\n",
    "R9\n",
    "R4\n",
    "L84\n",
    "L67\n",
    "L33\n",
    "L49\n",
    "L13\n",
    "R62\n",
    "L70\n",
    "R71\n",
    "L1\n",
    "L113\n",
    "R13\n",
    "R36\n",
    "R864\n",
    "R397\n",
    "R99\n",
    "R4\n",
    "R722\n",
    "R78\n",
    "R36\n",
    "L88\n",
    "R72\n",
    "L362\n",
    "R68\n",
    "R74\n",
    "R37\n",
    "R63\n",
    "L50\n",
    "L50\n",
    "L55\n",
    "L81\n",
    "L564\n",
    "L19\n",
    "R87\n",
    "L22\n",
    "L16\n",
    "L85\n",
    "R86\n",
    "R69\n",
    "L19\n",
    "L581\n",
    "R62\n",
    "R135\n",
    "L97\n",
    "R92\n",
    "R558\n",
    "R704\n",
    "L94\n",
    "R140\n",
    "L467\n",
    "R18\n",
    "L651\n",
    "L94\n",
    "R94\n",
    "R47\n",
    "L47\n",
    "R64\n",
    "R26\n",
    "L90\n",
    "R11\n",
    "R41\n",
    "L52\n",
    "R534\n",
    "R70\n",
    "L76\n",
    "L180\n",
    "L548\n",
    "L97\n",
    "R97\n",
    "L84\n",
    "L10\n",
    "R94\n",
    "R64\n",
    "L64\n",
    "R7\n",
    "L7\n",
    "R42\n",
    "R172\n",
    "L14\n",
    "R994\n",
    "L67\n",
    "R73\n",
    "R2\n",
    "R69\n",
    "L84\n",
    "L172\n",
    "L715\n",
    "R57\n",
    "L57\n",
    "L73\n",
    "R958\n",
    "L75\n",
    "R3\n",
    "R50\n",
    "L42\n",
    "R79\n",
    "R895\n",
    "R37\n",
    "R43\n",
    "R630\n",
    "R786\n",
    "L191\n",
    "R84\n",
    "L80\n",
    "R51\n",
    "L820\n",
    "R7\n",
    "R27\n",
    "R31\n",
    "R804\n",
    "R72\n",
    "L176\n",
    "L78\n",
    "L22\n",
    "R38\n",
    "L438\n",
    "R12\n",
    "R988\n",
    "R2\n",
    "R98\n",
    "L83\n",
    "L42\n",
    "R220\n",
    "L95\n",
    "R84\n",
    "R16\n",
    "L99\n",
    "R48\n",
    "L423\n",
    "R71\n",
    "L297\n",
    "L70\n",
    "R70\n",
    "L56\n",
    "L455\n",
    "L434\n",
    "R68\n",
    "L67\n",
    "R744\n",
    "R16\n",
    "L16\n",
    "L68\n",
    "L64\n",
    "R80\n",
    "R52\n",
    "L314\n",
    "R163\n",
    "R719\n",
    "L68\n",
    "R20\n",
    "R80\n",
    "R26\n",
    "L726\n",
    "R12\n",
    "L22\n",
    "R84\n",
    "R57\n",
    "L842\n",
    "R11\n",
    "L89\n",
    "R63\n",
    "L71\n",
    "L3\n",
    "R99\n",
    "L12\n",
    "R13\n",
    "R99\n",
    "L309\n",
    "R10\n",
    "L20\n",
    "L66\n",
    "L645\n",
    "R431\n",
    "R1\n",
    "L201\n",
    "R189\n",
    "R71\n",
    "L98\n",
    "L47\n",
    "L15\n",
    "L71\n",
    "L29\n",
    "L67\n",
    "L33\n",
    "R30\n",
    "R540\n",
    "L937\n",
    "R89\n",
    "L62\n",
    "L41\n",
    "L532\n",
    "R13\n",
    "R931\n",
    "R69\n",
    "R33\n",
    "R67\n",
    "R65\n",
    "R19\n",
    "L199\n",
    "L85\n",
    "R71\n",
    "L33\n",
    "L42\n",
    "L96\n",
    "L583\n",
    "L17\n",
    "R7\n",
    "L7\n",
    "R49\n",
    "L89\n",
    "R40\n",
    "L12\n",
    "R12\n",
    "R27\n",
    "L589\n",
    "R33\n",
    "R29\n",
    "R3\n",
    "R197\n",
    "L67\n",
    "R44\n",
    "L77\n",
    "R14\n",
    "L914\n",
    "R21\n",
    "L21\n",
    "L31\n",
    "L318\n",
    "R49\n",
    "L237\n",
    "L763\n",
    "R67\n",
    "L3\n",
    "L264\n",
    "R85\n",
    "R95\n",
    "L59\n",
    "R7\n",
    "R72\n",
    "L93\n",
    "R64\n",
    "L38\n",
    "R85\n",
    "L930\n",
    "R516\n",
    "L833\n",
    "R29\n",
    "R50\n",
    "L46\n",
    "L15\n",
    "L89\n",
    "R52\n",
    "R29\n",
    "R19\n",
    "R61\n",
    "L63\n",
    "L66\n",
    "R68\n",
    "R46\n",
    "L746\n",
    "R28\n",
    "R909\n",
    "L48\n",
    "L89\n",
    "R15\n",
    "R85\n",
    "L672\n",
    "R88\n",
    "R8\n",
    "R10\n",
    "L40\n",
    "R6\n",
    "R81\n",
    "R37\n",
    "L97\n",
    "R62\n",
    "R82\n",
    "R78\n",
    "L16\n",
    "R73\n",
    "L86\n",
    "R59\n",
    "L73\n",
    "L96\n",
    "R96\n",
    "R30\n",
    "L57\n",
    "L73\n",
    "R18\n",
    "R82\n",
    "L41\n",
    "L65\n",
    "R82\n",
    "R55\n",
    "R69\n",
    "R46\n",
    "R1\n",
    "R53\n",
    "R29\n",
    "L29\n",
    "L91\n",
    "L9\n",
    "L69\n",
    "L96\n",
    "R91\n",
    "L26\n",
    "L67\n",
    "R67\n",
    "L79\n",
    "L28\n",
    "L93\n",
    "R9\n",
    "L73\n",
    "R64\n",
    "R85\n",
    "L97\n",
    "L99\n",
    "R30\n",
    "R44\n",
    "R48\n",
    "R48\n",
    "R40\n",
    "L14\n",
    "L37\n",
    "L5\n",
    "L36\n",
    "L27\n",
    "R31\n",
    "R19\n",
    "R5\n",
    "L35\n",
    "L43\n",
    "R41\n",
    "L8\n",
    "L17\n",
    "L39\n",
    "R20\n",
    "R41\n",
    "L50\n",
    "R12\n",
    "L34\n",
    "L12\n",
    "L20\n",
    "R6\n",
    "L43\n",
    "L4\n",
    "L35\n",
    "R22\n",
    "L8\n",
    "L4\n",
    "L38\n",
    "R40\n",
    "R44\n",
    "L7\n",
    "L31\n",
    "R17\n",
    "R31\n",
    "L25\n",
    "R2\n",
    "R34\n",
    "L39\n",
    "L6\n",
    "R6\n",
    "L13\n",
    "L17\n",
    "R12\n",
    "L17\n",
    "R7\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7976eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values=\"\"\"L68\n",
    "L30\n",
    "R48\n",
    "L5\n",
    "R60\n",
    "L55\n",
    "L1\n",
    "L99\n",
    "R14\n",
    "L82\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d962b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R21 71 0\n",
      "R37 8 1\n",
      "L39 69 2\n",
      "L11 58 2\n",
      "L3 55 2\n",
      "R20 75 2\n",
      "R7 82 2\n",
      "R1 83 2\n",
      "R49 32 3\n",
      "L39 93 4\n",
      "L47 46 4\n",
      "R27 73 4\n",
      "L45 28 4\n",
      "L8 20 4\n",
      "L34 86 5\n",
      "L48 38 5\n",
      "L28 10 5\n",
      "L15 95 6\n",
      "R22 17 7\n",
      "R26 43 7\n",
      "R40 83 7\n",
      "L13 70 7\n",
      "R29 99 7\n",
      "L38 61 7\n",
      "L49 12 7\n",
      "L10 2 7\n",
      "R12 14 7\n",
      "R15 29 7\n",
      "R15 44 7\n",
      "R37 81 7\n",
      "R30 11 8\n",
      "R19 30 8\n",
      "L36 94 9\n",
      "L42 52 9\n",
      "L46 6 9\n",
      "L43 63 10\n",
      "L40 23 10\n",
      "L49 74 11\n",
      "L1 73 11\n",
      "L40 33 11\n",
      "L29 4 11\n",
      "R20 24 11\n",
      "R3 27 11\n",
      "R19 46 11\n",
      "L31 15 11\n",
      "R49 64 11\n",
      "R22 86 11\n",
      "L21 65 11\n",
      "R42 7 12\n",
      "R80 87 12\n",
      "L46 41 12\n",
      "R2 43 12\n",
      "R1 44 12\n",
      "R56 0 13\n",
      "L46 54 13\n",
      "L3 51 13\n",
      "L63 88 14\n",
      "L90 98 15\n",
      "L42 56 15\n",
      "R85 41 16\n",
      "L12 29 16\n",
      "L12 17 16\n",
      "L36 81 17\n",
      "R49 30 18\n",
      "R59 89 18\n",
      "L33 56 18\n",
      "L56 0 19\n",
      "R59 59 19\n",
      "R50 9 20\n",
      "R53 62 20\n",
      "L62 0 21\n",
      "L8 92 21\n",
      "R21 13 22\n",
      "R97 10 23\n",
      "R20 30 23\n",
      "L99 31 24\n",
      "R21 52 24\n",
      "L89 63 25\n",
      "R37 0 26\n",
      "L28 72 26\n",
      "R54 26 27\n",
      "R59 85 27\n",
      "L5 80 27\n",
      "R28 8 28\n",
      "L25 83 29\n",
      "L83 0 30\n",
      "R23 23 30\n",
      "R42 65 30\n",
      "R35 0 31\n",
      "L86 14 31\n",
      "L83 31 32\n",
      "R33 64 32\n",
      "R36 0 33\n",
      "L15 85 33\n",
      "L85 0 34\n",
      "L18 82 34\n",
      "R86 68 35\n",
      "R30 98 35\n",
      "L98 0 36\n",
      "R76 76 36\n",
      "R624 0 43\n",
      "L595 5 48\n",
      "R53 58 48\n",
      "L78 80 49\n",
      "R69 49 50\n",
      "L9 40 50\n",
      "R60 0 51\n",
      "L998 2 60\n",
      "R62 64 60\n",
      "R82 46 61\n",
      "L579 67 67\n",
      "L67 0 68\n",
      "R73 73 68\n",
      "R22 95 68\n",
      "R9 4 69\n",
      "R63 67 69\n",
      "R33 0 70\n",
      "L39 61 70\n",
      "L98 63 71\n",
      "L63 0 72\n",
      "L122 78 73\n",
      "R557 35 79\n",
      "L6 29 79\n",
      "R71 0 80\n",
      "R92 92 80\n",
      "R8 0 81\n",
      "L944 56 90\n",
      "L42 14 90\n",
      "L467 47 95\n",
      "L77 70 96\n",
      "R919 89 105\n",
      "R777 66 113\n",
      "R94 60 114\n",
      "L60 0 115\n",
      "L894 6 123\n",
      "R49 55 123\n",
      "R45 0 124\n",
      "R13 13 124\n",
      "L13 0 125\n",
      "L20 80 125\n",
      "R90 70 126\n",
      "R30 0 127\n",
      "R69 69 127\n",
      "L69 0 128\n",
      "L30 70 128\n",
      "L70 0 129\n",
      "L91 9 129\n",
      "R80 89 129\n",
      "L89 0 130\n",
      "L37 63 130\n",
      "L98 65 131\n",
      "R545 10 137\n",
      "R96 6 138\n",
      "L236 70 141\n",
      "R54 24 142\n",
      "R76 0 143\n",
      "L78 22 143\n",
      "L66 56 144\n",
      "L56 0 145\n",
      "R48 48 145\n",
      "R63 11 146\n",
      "R27 38 146\n",
      "R15 53 146\n",
      "L84 69 147\n",
      "L512 57 152\n",
      "L15 42 152\n",
      "L764 78 160\n",
      "R22 0 161\n",
      "L70 30 161\n",
      "R70 0 162\n",
      "L98 2 162\n",
      "R47 49 162\n",
      "L657 92 169\n",
      "R11 3 170\n",
      "R766 69 177\n",
      "R71 40 178\n",
      "L40 0 179\n",
      "L91 9 179\n",
      "L9 0 180\n",
      "R1 1 180\n",
      "R245 46 182\n",
      "L580 66 188\n",
      "R34 0 189\n",
      "R37 37 189\n",
      "L35 2 189\n",
      "R98 0 190\n",
      "R67 67 190\n",
      "L1 66 190\n",
      "L66 0 191\n",
      "L2 98 191\n",
      "L46 52 191\n",
      "L92 60 192\n",
      "L519 41 197\n",
      "R580 21 203\n",
      "R79 0 204\n",
      "R328 28 207\n",
      "R533 61 212\n",
      "L15 46 212\n",
      "L46 0 213\n",
      "R88 88 213\n",
      "R86 74 214\n",
      "L52 22 214\n",
      "R45 67 214\n",
      "L29 38 214\n",
      "L38 0 215\n",
      "R94 94 215\n",
      "R80 74 216\n",
      "R15 89 216\n",
      "L12 77 216\n",
      "L77 0 217\n",
      "R88 88 217\n",
      "R28 16 218\n",
      "R84 0 219\n",
      "R84 84 219\n",
      "L84 0 220\n",
      "R709 9 227\n",
      "L87 22 228\n",
      "R78 0 229\n",
      "R30 30 229\n",
      "R770 0 237\n",
      "L947 53 246\n",
      "L53 0 247\n",
      "L50 50 247\n",
      "R826 76 255\n",
      "R69 45 256\n",
      "R55 0 257\n",
      "R177 77 258\n",
      "R30 7 259\n",
      "L90 17 260\n",
      "R39 56 260\n",
      "R44 0 261\n",
      "R68 68 261\n",
      "R32 0 262\n",
      "R80 80 262\n",
      "R23 3 263\n",
      "L29 74 264\n",
      "L97 77 265\n",
      "R6 83 265\n",
      "R17 0 266\n",
      "L51 49 266\n",
      "L386 63 270\n",
      "R86 49 271\n",
      "R444 93 275\n",
      "L86 7 275\n",
      "R176 83 276\n",
      "L265 18 278\n",
      "L18 0 279\n",
      "L15 85 279\n",
      "L757 28 286\n",
      "L75 53 287\n",
      "R612 65 293\n",
      "L64 1 293\n",
      "L69 32 294\n",
      "L22 10 294\n",
      "R56 66 294\n",
      "L66 0 295\n",
      "L83 17 295\n",
      "R30 47 295\n",
      "L87 60 296\n",
      "R55 15 297\n",
      "R85 0 298\n",
      "L94 6 298\n",
      "L398 8 302\n",
      "L27 81 303\n",
      "L65 16 303\n",
      "R84 0 304\n",
      "R1 1 304\n",
      "L27 74 305\n",
      "R26 0 306\n",
      "L756 44 313\n",
      "L18 26 313\n",
      "R308 34 316\n",
      "L34 0 317\n",
      "R2 2 317\n",
      "R41 43 317\n",
      "R57 0 318\n",
      "L155 45 319\n",
      "L45 0 320\n",
      "L90 10 320\n",
      "L12 98 321\n",
      "L78 20 321\n",
      "L20 0 322\n",
      "R37 37 322\n",
      "L40 97 323\n",
      "L397 0 327\n",
      "L49 51 327\n",
      "R49 0 328\n",
      "L85 15 328\n",
      "L2 13 328\n",
      "L269 44 331\n",
      "L66 78 332\n",
      "R243 21 335\n",
      "R430 51 339\n",
      "L51 0 340\n",
      "L56 44 340\n",
      "L444 0 345\n",
      "R23 23 345\n",
      "R177 0 347\n",
      "R51 51 347\n",
      "L12 39 347\n",
      "R61 0 348\n",
      "R85 85 348\n",
      "R68 53 349\n",
      "L732 21 356\n",
      "R29 50 356\n",
      "L50 0 357\n",
      "R27 27 357\n",
      "R17 44 357\n",
      "R14 58 357\n",
      "R23 81 357\n",
      "R19 0 358\n",
      "L49 51 358\n",
      "R207 58 360\n",
      "L10 48 360\n",
      "R793 41 368\n",
      "L799 42 376\n",
      "L56 86 377\n",
      "R314 0 381\n",
      "L17 83 381\n",
      "L67 16 381\n",
      "R38 54 381\n",
      "L24 30 381\n",
      "R92 22 382\n",
      "L49 73 383\n",
      "L42 31 383\n",
      "L31 0 384\n",
      "L435 65 388\n",
      "R11 76 388\n",
      "L2 74 388\n",
      "R618 92 394\n",
      "L892 0 403\n",
      "L29 71 403\n",
      "R18 89 403\n",
      "R437 26 408\n",
      "R774 0 416\n",
      "R97 97 416\n",
      "L254 43 418\n",
      "L91 52 419\n",
      "R848 0 428\n",
      "L21 79 428\n",
      "R321 0 432\n",
      "L63 37 432\n",
      "L37 0 433\n",
      "L87 13 433\n",
      "L13 0 434\n",
      "L12 88 434\n",
      "R68 56 435\n",
      "L12 44 435\n",
      "R45 89 435\n",
      "R911 0 445\n",
      "L54 46 445\n",
      "L43 3 445\n",
      "L41 62 446\n",
      "R38 0 447\n",
      "L38 62 447\n",
      "L62 0 448\n",
      "R98 98 448\n",
      "R44 42 449\n",
      "L701 41 456\n",
      "R59 0 457\n",
      "L46 54 457\n",
      "R64 18 458\n",
      "L18 0 459\n",
      "L33 67 459\n",
      "R85 52 460\n",
      "R65 17 461\n",
      "L77 40 462\n",
      "L44 96 463\n",
      "L49 47 463\n",
      "R53 0 464\n",
      "R30 30 464\n",
      "L35 95 465\n",
      "R48 43 466\n",
      "R139 82 467\n",
      "R86 68 468\n",
      "R32 0 469\n",
      "R15 15 469\n",
      "L15 0 470\n",
      "L35 65 470\n",
      "R35 0 471\n",
      "L20 80 471\n",
      "R916 96 480\n",
      "L14 82 480\n",
      "R801 83 488\n",
      "R66 49 489\n",
      "R20 69 489\n",
      "R31 0 490\n",
      "R24 24 490\n",
      "R76 0 491\n",
      "R13 13 491\n",
      "L13 0 492\n",
      "R978 78 501\n",
      "R76 54 502\n",
      "R813 67 510\n",
      "R89 56 511\n",
      "L56 0 512\n",
      "R27 27 512\n",
      "R36 63 512\n",
      "L63 0 513\n",
      "L81 19 513\n",
      "R25 44 513\n",
      "R767 11 521\n",
      "L11 0 522\n",
      "R831 31 530\n",
      "L51 80 531\n",
      "R65 45 532\n",
      "R88 33 533\n",
      "L570 63 539\n",
      "R891 54 548\n",
      "R33 87 548\n",
      "R13 0 549\n",
      "L54 46 549\n",
      "L23 23 549\n",
      "L123 0 551\n",
      "L69 31 551\n",
      "R60 91 551\n",
      "R9 0 552\n",
      "R66 66 552\n",
      "R34 0 553\n",
      "R43 43 553\n",
      "R78 21 554\n",
      "R83 4 555\n",
      "R58 62 555\n",
      "L55 7 555\n",
      "L41 66 556\n",
      "R34 0 557\n",
      "L37 63 557\n",
      "R69 32 558\n",
      "R68 0 559\n",
      "L98 2 559\n",
      "L429 73 564\n",
      "L73 0 565\n",
      "R92 92 565\n",
      "R241 33 568\n",
      "L83 50 569\n",
      "R50 0 570\n",
      "R136 36 571\n",
      "L96 40 572\n",
      "L321 19 575\n",
      "L5 14 575\n",
      "R24 38 575\n",
      "R5 43 575\n",
      "L65 78 576\n",
      "L78 0 577\n",
      "R15 15 577\n",
      "L13 2 577\n",
      "R18 20 577\n",
      "L220 0 580\n",
      "R9 9 580\n",
      "L32 77 581\n",
      "L4 73 581\n",
      "R266 39 584\n",
      "R46 85 584\n",
      "R15 0 585\n",
      "R486 86 589\n",
      "R14 0 590\n",
      "L85 15 590\n",
      "R85 0 591\n",
      "R32 32 591\n",
      "L59 73 592\n",
      "L17 56 592\n",
      "L27 29 592\n",
      "R24 53 592\n",
      "R47 0 593\n",
      "R984 84 602\n",
      "R99 83 603\n",
      "R17 0 604\n",
      "L83 17 604\n",
      "R83 0 605\n",
      "L40 60 605\n",
      "L279 81 608\n",
      "R419 0 613\n",
      "L46 54 613\n",
      "R71 25 614\n",
      "L13 12 614\n",
      "R88 0 615\n",
      "R64 64 615\n",
      "L64 0 616\n",
      "L20 80 616\n",
      "R20 0 617\n",
      "R33 33 617\n",
      "R689 22 624\n",
      "R3 25 624\n",
      "L52 73 625\n",
      "L73 0 626\n",
      "R19 19 626\n",
      "L23 96 627\n",
      "R12 8 628\n",
      "R92 0 629\n",
      "R8 8 629\n",
      "R92 0 630\n",
      "R66 66 630\n",
      "R70 36 631\n",
      "R44 80 631\n",
      "L44 36 631\n",
      "R61 97 631\n",
      "R82 79 632\n",
      "R21 0 633\n",
      "R824 24 641\n",
      "L66 58 642\n",
      "L62 96 643\n",
      "R4 0 644\n",
      "L60 40 644\n",
      "L40 0 645\n",
      "L835 65 653\n",
      "L46 19 653\n",
      "R65 84 653\n",
      "R48 32 654\n",
      "L32 0 655\n",
      "L36 64 655\n",
      "L664 0 662\n",
      "L52 48 662\n",
      "L48 0 663\n",
      "L50 50 663\n",
      "L50 0 664\n",
      "L56 44 664\n",
      "R15 59 664\n",
      "L35 24 664\n",
      "L24 0 665\n",
      "R19 19 665\n",
      "L15 4 665\n",
      "R6 10 665\n",
      "L8 2 665\n",
      "L42 60 666\n",
      "L60 0 667\n",
      "L640 60 673\n",
      "R116 76 674\n",
      "R451 27 679\n",
      "L49 78 680\n",
      "R88 66 681\n",
      "R24 90 681\n",
      "L90 0 682\n",
      "R56 56 682\n",
      "R44 0 683\n",
      "R79 79 683\n",
      "R74 53 684\n",
      "L6 47 684\n",
      "R53 0 685\n",
      "L45 55 685\n",
      "R45 0 686\n",
      "L792 8 693\n",
      "R92 0 694\n",
      "R17 17 694\n",
      "R8 25 694\n",
      "R75 0 695\n",
      "L30 70 695\n",
      "R30 0 696\n",
      "L89 11 696\n",
      "L11 0 697\n",
      "L210 90 699\n",
      "L84 6 699\n",
      "L85 21 700\n",
      "L21 0 701\n",
      "R52 52 701\n",
      "L42 10 701\n",
      "R190 0 703\n",
      "R38 38 703\n",
      "L15 23 703\n",
      "L49 74 704\n",
      "R8 82 704\n",
      "R10 92 704\n",
      "L992 0 714\n",
      "L35 65 714\n",
      "R935 0 724\n",
      "R69 69 724\n",
      "L69 0 725\n",
      "L463 37 729\n",
      "L44 93 730\n",
      "L59 34 730\n",
      "R88 22 731\n",
      "L22 0 732\n",
      "R98 98 732\n",
      "R43 41 733\n",
      "L10 31 733\n",
      "R69 0 734\n",
      "R4 4 734\n",
      "L965 39 744\n",
      "R55 94 744\n",
      "L57 37 744\n",
      "L4 33 744\n",
      "L37 96 745\n",
      "R971 67 755\n",
      "R16 83 755\n",
      "R856 39 764\n",
      "L75 64 765\n",
      "R4 68 765\n",
      "R71 39 766\n",
      "L82 57 767\n",
      "R79 36 768\n",
      "R64 0 769\n",
      "R4 4 769\n",
      "R46 50 769\n",
      "L66 84 770\n",
      "L84 0 771\n",
      "R27 27 771\n",
      "L27 0 772\n",
      "L97 3 772\n",
      "R114 17 773\n",
      "R66 83 773\n",
      "R75 58 774\n",
      "R18 76 774\n",
      "R48 24 775\n",
      "R76 0 776\n",
      "L71 29 776\n",
      "L229 0 779\n",
      "L71 29 779\n",
      "R97 26 780\n",
      "L26 0 781\n",
      "R65 65 781\n",
      "R85 50 782\n",
      "R50 0 783\n",
      "R66 66 783\n",
      "L66 0 784\n",
      "R51 51 784\n",
      "R55 6 785\n",
      "L106 0 787\n",
      "L641 59 793\n",
      "L59 0 794\n",
      "R87 87 794\n",
      "L95 92 795\n",
      "R39 31 796\n",
      "L31 0 797\n",
      "R199 99 798\n",
      "R1 0 799\n",
      "L54 46 799\n",
      "L446 0 804\n",
      "R92 92 804\n",
      "R8 0 805\n",
      "R22 22 805\n",
      "L36 86 806\n",
      "L86 0 807\n",
      "R64 64 807\n",
      "L56 8 807\n",
      "L89 19 808\n",
      "R881 0 817\n",
      "R257 57 819\n",
      "R75 32 820\n",
      "L629 3 826\n",
      "L67 36 827\n",
      "R85 21 828\n",
      "R32 53 828\n",
      "L41 12 828\n",
      "L12 0 829\n",
      "L60 40 829\n",
      "L40 0 830\n",
      "R267 67 832\n",
      "L67 0 833\n",
      "R38 38 833\n",
      "L717 21 840\n",
      "L35 86 841\n",
      "R53 39 842\n",
      "L77 62 843\n",
      "L919 43 852\n",
      "R57 0 853\n",
      "R83 83 853\n",
      "L83 0 854\n",
      "L349 51 857\n",
      "R49 0 858\n",
      "R477 77 862\n",
      "L77 0 863\n",
      "R96 96 863\n",
      "R4 0 864\n",
      "L183 17 865\n",
      "R5 22 865\n",
      "R78 0 866\n",
      "L69 31 866\n",
      "R53 84 866\n",
      "L84 0 867\n",
      "L87 13 867\n",
      "L13 0 868\n",
      "L70 30 868\n",
      "R70 0 869\n",
      "R254 54 871\n",
      "R46 0 872\n",
      "L965 35 881\n",
      "R8 43 881\n",
      "R57 0 882\n",
      "R36 36 882\n",
      "R3 39 882\n",
      "R61 0 883\n",
      "R39 39 883\n",
      "R61 0 884\n",
      "L5 95 884\n",
      "L95 0 885\n",
      "R896 96 893\n",
      "L896 0 902\n",
      "R792 92 909\n",
      "R287 79 912\n",
      "R790 69 920\n",
      "R25 94 920\n",
      "R32 26 921\n",
      "L92 34 922\n",
      "R474 8 927\n",
      "R92 0 928\n",
      "L15 85 928\n",
      "R15 0 929\n",
      "L36 64 929\n",
      "L64 0 930\n",
      "R8 8 930\n",
      "R91 99 930\n",
      "L77 22 930\n",
      "L718 4 937\n",
      "R427 31 941\n",
      "L31 0 942\n",
      "L6 94 942\n",
      "L788 6 949\n",
      "L6 0 950\n",
      "R80 80 950\n",
      "R20 0 951\n",
      "L79 21 951\n",
      "R33 54 951\n",
      "L947 7 960\n",
      "R93 0 961\n",
      "R413 13 965\n",
      "R88 1 966\n",
      "L83 18 967\n",
      "L18 0 968\n",
      "L452 48 972\n",
      "R68 16 973\n",
      "L29 87 974\n",
      "R79 66 975\n",
      "R3 69 975\n",
      "R31 0 976\n",
      "R33 33 976\n",
      "L10 23 976\n",
      "L55 68 977\n",
      "R32 0 978\n",
      "R875 75 986\n",
      "L170 5 987\n",
      "R95 0 988\n",
      "R544 44 993\n",
      "R248 92 995\n",
      "L92 0 996\n",
      "L29 71 996\n",
      "R56 27 997\n",
      "L50 77 998\n",
      "R23 0 999\n",
      "L84 16 999\n",
      "L755 61 1007\n",
      "R24 85 1007\n",
      "R515 0 1013\n",
      "R64 64 1013\n",
      "R47 11 1014\n",
      "L89 22 1015\n",
      "L23 99 1016\n",
      "R1 0 1017\n",
      "L56 44 1017\n",
      "R88 32 1018\n",
      "R168 0 1020\n",
      "L90 10 1020\n",
      "L10 0 1021\n",
      "R84 84 1021\n",
      "R30 14 1022\n",
      "L14 0 1023\n",
      "L27 73 1023\n",
      "R27 0 1024\n",
      "L91 9 1024\n",
      "L169 40 1026\n",
      "R251 91 1028\n",
      "R73 64 1029\n",
      "R23 87 1029\n",
      "L10 77 1029\n",
      "R812 89 1037\n",
      "L92 97 1038\n",
      "L61 36 1038\n",
      "R71 7 1039\n",
      "L59 48 1040\n",
      "R52 0 1041\n",
      "R88 88 1041\n",
      "R46 34 1042\n",
      "R20 54 1042\n",
      "L54 0 1043\n",
      "L46 54 1043\n",
      "R11 65 1043\n",
      "L65 0 1044\n",
      "L26 74 1044\n",
      "R81 55 1045\n",
      "R645 0 1052\n",
      "L72 28 1052\n",
      "R10 38 1052\n",
      "R41 79 1052\n",
      "R97 76 1053\n",
      "R924 0 1063\n",
      "L62 38 1063\n",
      "R62 0 1064\n",
      "L37 63 1064\n",
      "R5 68 1064\n",
      "R32 0 1065\n",
      "L40 60 1065\n",
      "R90 50 1066\n",
      "R89 39 1067\n",
      "L93 46 1068\n",
      "L22 24 1068\n",
      "R503 27 1073\n",
      "R87 14 1074\n",
      "R81 95 1074\n",
      "L31 64 1074\n",
      "R91 55 1075\n",
      "L47 8 1075\n",
      "L8 0 1076\n",
      "L11 89 1076\n",
      "L56 33 1076\n",
      "L45 88 1077\n",
      "R35 23 1078\n",
      "R97 20 1079\n",
      "L20 0 1080\n",
      "R99 99 1080\n",
      "L134 65 1081\n",
      "R35 0 1082\n",
      "R59 59 1082\n",
      "R41 0 1083\n",
      "R34 34 1083\n",
      "L16 18 1083\n",
      "R28 46 1083\n",
      "L61 85 1084\n",
      "R715 0 1092\n",
      "L476 24 1096\n",
      "R76 0 1097\n",
      "L75 25 1097\n",
      "L25 0 1098\n",
      "R40 40 1098\n",
      "R31 71 1098\n",
      "L30 41 1098\n",
      "R41 82 1098\n",
      "L82 0 1099\n",
      "L709 91 1106\n",
      "L111 80 1107\n",
      "R791 71 1115\n",
      "R429 0 1120\n",
      "R1 1 1120\n",
      "R79 80 1120\n",
      "L32 48 1120\n",
      "L99 49 1121\n",
      "L46 3 1121\n",
      "L48 55 1122\n",
      "L55 0 1123\n",
      "L50 50 1123\n",
      "R70 20 1124\n",
      "R16 36 1124\n",
      "R564 0 1130\n",
      "L47 53 1130\n",
      "L11 42 1130\n",
      "R496 38 1135\n",
      "R25 63 1135\n",
      "L83 80 1136\n",
      "R75 55 1137\n",
      "R61 16 1138\n",
      "L53 63 1139\n",
      "L89 74 1140\n",
      "R26 0 1141\n",
      "R79 79 1141\n",
      "R21 0 1142\n",
      "L92 8 1142\n",
      "L92 16 1143\n",
      "L62 54 1144\n",
      "L54 0 1145\n",
      "R93 93 1145\n",
      "L55 38 1145\n",
      "R29 67 1145\n",
      "L44 23 1145\n",
      "L573 50 1151\n",
      "L77 73 1152\n",
      "L33 40 1152\n",
      "R869 9 1161\n",
      "R91 0 1162\n",
      "R5 5 1162\n",
      "L647 58 1169\n",
      "R59 17 1170\n",
      "R61 78 1170\n",
      "L178 0 1172\n",
      "R92 92 1172\n",
      "R8 0 1173\n",
      "L42 58 1173\n",
      "L58 0 1174\n",
      "L698 2 1180\n",
      "R73 75 1180\n",
      "L75 0 1181\n",
      "R7 7 1181\n",
      "R93 0 1182\n",
      "R17 17 1182\n",
      "L93 24 1183\n",
      "R50 74 1183\n",
      "L42 32 1183\n",
      "L62 70 1184\n",
      "R30 0 1185\n",
      "R66 66 1185\n",
      "L66 0 1186\n",
      "R48 48 1186\n",
      "L48 0 1187\n",
      "L22 78 1187\n",
      "R891 69 1196\n",
      "L2 67 1196\n",
      "L67 0 1197\n",
      "L3 97 1197\n",
      "L97 0 1198\n",
      "R19 19 1198\n",
      "R925 44 1207\n",
      "R21 65 1207\n",
      "R24 89 1207\n",
      "L89 0 1208\n",
      "R71 71 1208\n",
      "L71 0 1209\n",
      "R86 86 1209\n",
      "R14 0 1210\n",
      "L833 67 1218\n",
      "R33 0 1219\n",
      "R50 50 1219\n",
      "R150 0 1221\n",
      "R43 43 1221\n",
      "R95 38 1222\n",
      "R66 4 1223\n",
      "R96 0 1224\n",
      "R74 74 1224\n",
      "L21 53 1224\n",
      "L768 85 1232\n",
      "R481 66 1237\n",
      "R934 0 1247\n",
      "L228 72 1249\n",
      "L32 40 1249\n",
      "L136 4 1250\n",
      "L28 76 1251\n",
      "R66 42 1252\n",
      "L85 57 1253\n",
      "R67 24 1254\n",
      "L72 52 1255\n",
      "R20 72 1255\n",
      "R58 30 1256\n",
      "L30 0 1257\n",
      "L58 42 1257\n",
      "R758 0 1265\n",
      "R22 22 1265\n",
      "R29 51 1265\n",
      "L51 0 1266\n",
      "R95 95 1266\n",
      "L893 2 1274\n",
      "L386 16 1278\n",
      "R369 85 1281\n",
      "R62 47 1282\n",
      "L47 0 1283\n",
      "R12 12 1283\n",
      "R71 83 1283\n",
      "R917 0 1293\n",
      "L65 35 1293\n",
      "R38 73 1293\n",
      "R989 62 1303\n",
      "L68 94 1304\n",
      "L99 95 1305\n",
      "L711 84 1312\n",
      "R31 15 1313\n",
      "L15 0 1314\n",
      "L367 33 1317\n",
      "L33 0 1318\n",
      "R93 93 1318\n",
      "R7 0 1319\n",
      "L2 98 1319\n",
      "L98 0 1320\n",
      "L24 76 1320\n",
      "L76 0 1321\n",
      "R53 53 1321\n",
      "L972 81 1331\n",
      "R19 0 1332\n",
      "L14 86 1332\n",
      "L386 0 1336\n",
      "R21 21 1336\n",
      "R79 0 1337\n",
      "L32 68 1337\n",
      "R756 24 1345\n",
      "L15 9 1345\n",
      "R83 92 1345\n",
      "L90 2 1345\n",
      "L98 4 1346\n",
      "L7 97 1347\n",
      "R3 0 1348\n",
      "L6 94 1348\n",
      "R4 98 1348\n",
      "L3 95 1348\n",
      "R5 0 1349\n",
      "L80 20 1349\n",
      "R138 58 1350\n",
      "L58 0 1351\n",
      "R951 51 1360\n",
      "R98 49 1361\n",
      "L54 95 1362\n",
      "R97 92 1363\n",
      "L72 20 1363\n",
      "R80 0 1364\n",
      "L93 7 1364\n",
      "L17 90 1365\n",
      "R43 33 1366\n",
      "L10 23 1366\n",
      "R77 0 1367\n",
      "L939 61 1376\n",
      "R99 60 1377\n",
      "R45 5 1378\n",
      "R264 69 1380\n",
      "R358 27 1384\n",
      "L50 77 1385\n",
      "R85 62 1386\n",
      "L62 0 1387\n",
      "R54 54 1387\n",
      "R818 72 1395\n",
      "L28 44 1395\n",
      "L81 63 1396\n",
      "L44 19 1396\n",
      "R581 0 1402\n",
      "L965 35 1411\n",
      "R41 76 1411\n",
      "R24 0 1412\n",
      "L9 91 1412\n",
      "R390 81 1416\n",
      "R52 33 1417\n",
      "L20 13 1417\n",
      "L39 74 1418\n",
      "L49 25 1418\n",
      "L59 66 1419\n",
      "L966 0 1429\n",
      "L87 13 1429\n",
      "R87 0 1430\n",
      "L445 55 1434\n",
      "L36 19 1434\n",
      "R382 1 1438\n",
      "R622 23 1444\n",
      "R813 36 1452\n",
      "R264 0 1455\n",
      "L18 82 1455\n",
      "R83 65 1456\n",
      "L65 0 1457\n",
      "R305 5 1460\n",
      "R95 0 1461\n",
      "L228 72 1463\n",
      "L857 15 1471\n",
      "L729 86 1479\n",
      "R58 44 1480\n",
      "L44 0 1481\n",
      "R19 19 1481\n",
      "R81 0 1482\n",
      "L80 20 1482\n",
      "R26 46 1482\n",
      "R14 60 1482\n",
      "L75 85 1483\n",
      "L21 64 1483\n",
      "L58 6 1483\n",
      "L74 32 1484\n",
      "R68 0 1485\n",
      "L4 96 1485\n",
      "L896 0 1494\n",
      "L29 71 1494\n",
      "R32 3 1495\n",
      "R62 65 1495\n",
      "R36 1 1496\n",
      "R853 54 1504\n",
      "R24 78 1504\n",
      "L18 60 1504\n",
      "R87 47 1505\n",
      "L347 0 1509\n",
      "R980 80 1518\n",
      "L181 99 1520\n",
      "L98 1 1520\n",
      "R85 86 1520\n",
      "L30 56 1520\n",
      "R342 98 1523\n",
      "L8 90 1523\n",
      "L10 80 1523\n",
      "L55 25 1523\n",
      "L9 16 1523\n",
      "L416 0 1528\n",
      "R4 4 1528\n",
      "L85 19 1529\n",
      "L138 81 1531\n",
      "R89 70 1532\n",
      "R30 0 1533\n",
      "L33 67 1533\n",
      "L67 0 1534\n",
      "R31 31 1534\n",
      "R14 45 1534\n",
      "R80 25 1535\n",
      "R75 0 1536\n",
      "L71 29 1536\n",
      "R6 35 1536\n",
      "R65 0 1537\n",
      "R42 42 1537\n",
      "L56 86 1538\n",
      "L86 0 1539\n",
      "R529 29 1544\n",
      "R220 49 1546\n",
      "R41 90 1546\n",
      "R8 98 1546\n",
      "L88 10 1546\n",
      "R54 64 1546\n",
      "R11 75 1546\n",
      "R70 45 1547\n",
      "R29 74 1547\n",
      "L74 0 1548\n",
      "L8 92 1548\n",
      "L92 0 1549\n",
      "L283 17 1551\n",
      "L25 92 1552\n",
      "R88 80 1553\n",
      "L449 31 1557\n",
      "L65 66 1558\n",
      "L66 0 1559\n",
      "R87 87 1559\n",
      "L10 77 1559\n",
      "L77 0 1560\n",
      "R68 68 1560\n",
      "L68 0 1561\n",
      "L29 71 1561\n",
      "L60 11 1561\n",
      "R989 0 1571\n",
      "R958 58 1580\n",
      "R160 18 1582\n",
      "R67 85 1582\n",
      "R15 0 1583\n",
      "R85 85 1583\n",
      "L6 79 1583\n",
      "L43 36 1583\n",
      "R13 49 1583\n",
      "R51 0 1584\n",
      "L49 51 1584\n",
      "L51 0 1585\n",
      "L85 15 1585\n",
      "L76 39 1586\n",
      "R78 17 1587\n",
      "L17 0 1588\n",
      "L488 12 1592\n",
      "L12 0 1593\n",
      "L2 98 1593\n",
      "L98 0 1594\n",
      "R834 34 1602\n",
      "L34 0 1603\n",
      "L58 42 1603\n",
      "R20 62 1603\n",
      "L34 28 1603\n",
      "L28 0 1604\n",
      "L2 98 1604\n",
      "R2 0 1605\n",
      "R432 32 1609\n",
      "R68 0 1610\n",
      "R676 76 1616\n",
      "R13 89 1616\n",
      "R11 0 1617\n",
      "R660 60 1623\n",
      "L760 0 1631\n",
      "R227 27 1633\n",
      "L27 0 1634\n",
      "L65 35 1634\n",
      "R7 42 1634\n",
      "L542 0 1640\n",
      "R26 26 1640\n",
      "R562 88 1645\n",
      "L26 62 1645\n",
      "L62 0 1646\n",
      "R96 96 1646\n",
      "L96 0 1647\n",
      "R11 11 1647\n",
      "L11 0 1648\n",
      "L24 76 1648\n",
      "L84 92 1649\n",
      "R8 0 1650\n",
      "L42 58 1650\n",
      "R42 0 1651\n",
      "R67 67 1651\n",
      "R233 0 1654\n",
      "R9 9 1654\n",
      "R91 0 1655\n",
      "L12 88 1655\n",
      "L66 22 1655\n",
      "L63 59 1656\n",
      "L1 58 1656\n",
      "L58 0 1657\n",
      "L35 65 1657\n",
      "L314 51 1660\n",
      "L51 0 1661\n",
      "R24 24 1661\n",
      "R864 88 1669\n",
      "R22 10 1670\n",
      "R90 0 1671\n",
      "L28 72 1671\n",
      "R56 28 1672\n",
      "L28 0 1673\n",
      "R97 97 1673\n",
      "R93 90 1674\n",
      "R79 69 1675\n",
      "L98 71 1676\n",
      "R92 63 1677\n",
      "R37 0 1678\n",
      "R88 88 1678\n",
      "L445 43 1682\n",
      "R44 87 1682\n",
      "L87 0 1683\n",
      "R46 46 1683\n",
      "R865 11 1692\n",
      "R89 0 1693\n",
      "R380 80 1696\n",
      "L789 91 1704\n",
      "L19 72 1704\n",
      "R564 36 1710\n",
      "R95 31 1711\n",
      "L27 4 1711\n",
      "L186 18 1713\n",
      "R4 22 1713\n",
      "L75 47 1714\n",
      "L47 0 1715\n",
      "L342 58 1718\n",
      "L17 41 1718\n",
      "L41 0 1719\n",
      "L731 69 1726\n",
      "L1 68 1726\n",
      "R63 31 1727\n",
      "L616 15 1733\n",
      "R10 25 1733\n",
      "L80 45 1734\n",
      "L45 0 1735\n",
      "R84 84 1735\n",
      "R80 64 1736\n",
      "L64 0 1737\n",
      "L125 75 1738\n",
      "R82 57 1739\n",
      "L86 71 1740\n",
      "L71 0 1741\n",
      "R44 44 1741\n",
      "L244 0 1744\n",
      "R17 17 1744\n",
      "R83 0 1745\n",
      "R642 42 1751\n",
      "L32 10 1751\n",
      "R69 79 1751\n",
      "R22 1 1752\n",
      "R12 13 1752\n",
      "R81 94 1752\n",
      "L139 55 1753\n",
      "R86 41 1754\n",
      "L41 0 1755\n",
      "R28 28 1755\n",
      "L758 70 1763\n",
      "L970 0 1773\n",
      "R756 56 1780\n",
      "L2 54 1780\n",
      "L54 0 1781\n",
      "L691 9 1787\n",
      "R91 0 1788\n",
      "L63 37 1788\n",
      "R30 67 1788\n",
      "L69 98 1789\n",
      "L35 63 1789\n",
      "R37 0 1790\n",
      "L33 67 1790\n",
      "L67 0 1791\n",
      "R85 85 1791\n",
      "L98 87 1792\n",
      "L35 52 1792\n",
      "R31 83 1792\n",
      "R217 0 1795\n",
      "L688 12 1801\n",
      "R88 0 1802\n",
      "R29 29 1802\n",
      "R20 49 1802\n",
      "L239 10 1804\n",
      "R47 57 1804\n",
      "R2 59 1804\n",
      "R31 90 1804\n",
      "R780 70 1812\n",
      "R30 0 1813\n",
      "L30 70 1813\n",
      "R415 85 1817\n",
      "L85 0 1818\n",
      "L565 35 1823\n",
      "L27 8 1823\n",
      "L57 51 1824\n",
      "R99 50 1825\n",
      "L826 24 1833\n",
      "L19 5 1833\n",
      "R18 23 1833\n",
      "R78 1 1834\n",
      "L43 58 1835\n",
      "R94 52 1836\n",
      "L452 0 1841\n",
      "R81 81 1841\n",
      "L25 56 1841\n",
      "L56 0 1842\n",
      "L6 94 1842\n",
      "L58 36 1842\n",
      "L36 0 1843\n",
      "R12 12 1843\n",
      "L12 0 1844\n",
      "L21 79 1844\n",
      "L6 73 1844\n",
      "L44 29 1844\n",
      "R78 7 1845\n",
      "R93 0 1846\n",
      "L90 10 1846\n",
      "L403 7 1850\n",
      "L41 66 1851\n",
      "R72 38 1852\n",
      "L58 80 1853\n",
      "R20 0 1854\n",
      "R11 11 1854\n",
      "L6 5 1854\n",
      "L5 0 1855\n",
      "R46 46 1855\n",
      "L65 81 1856\n",
      "R354 35 1860\n",
      "L35 0 1861\n",
      "L23 77 1861\n",
      "L95 82 1862\n",
      "L85 97 1863\n",
      "R39 36 1864\n",
      "R60 96 1864\n",
      "L93 3 1864\n",
      "L95 8 1865\n",
      "L839 69 1874\n",
      "R31 0 1875\n",
      "L22 78 1875\n",
      "L78 0 1876\n",
      "R81 81 1876\n",
      "R19 0 1877\n",
      "L925 75 1886\n",
      "R21 96 1886\n",
      "R5 1 1887\n",
      "R84 85 1887\n",
      "R2 87 1887\n",
      "L887 0 1896\n",
      "R623 23 1902\n",
      "R77 0 1903\n",
      "L944 56 1912\n",
      "R20 76 1912\n",
      "R55 31 1913\n",
      "L31 0 1914\n",
      "R928 28 1923\n",
      "L28 0 1924\n",
      "R59 59 1924\n",
      "L91 68 1925\n",
      "R98 66 1926\n",
      "L66 0 1927\n",
      "R19 19 1927\n",
      "R53 72 1927\n",
      "L72 0 1928\n",
      "L17 83 1928\n",
      "L16 67 1928\n",
      "R13 80 1928\n",
      "L71 9 1928\n",
      "R33 42 1928\n",
      "L330 12 1931\n",
      "R88 0 1932\n",
      "R52 52 1932\n",
      "L52 0 1933\n",
      "R22 22 1933\n",
      "L62 60 1934\n",
      "L154 6 1935\n",
      "L6 0 1936\n",
      "R31 31 1936\n",
      "L32 99 1937\n",
      "L99 0 1938\n",
      "R40 40 1938\n",
      "L29 11 1938\n",
      "R69 80 1938\n",
      "R22 2 1939\n",
      "L13 89 1940\n",
      "R811 0 1949\n",
      "L27 73 1949\n",
      "R27 0 1950\n",
      "L95 5 1950\n",
      "L75 30 1951\n",
      "R97 27 1952\n",
      "R73 0 1953\n",
      "L515 85 1958\n",
      "L45 40 1958\n",
      "R689 29 1965\n",
      "R71 0 1966\n",
      "R24 24 1966\n",
      "R444 68 1970\n",
      "R77 45 1971\n",
      "R55 0 1972\n",
      "R37 37 1972\n",
      "R11 48 1972\n",
      "R52 0 1973\n",
      "L93 7 1973\n",
      "L78 29 1974\n",
      "R671 0 1981\n",
      "R159 59 1982\n",
      "L507 52 1987\n",
      "L57 95 1988\n",
      "R1 96 1988\n",
      "L638 58 1994\n",
      "L59 99 1995\n",
      "R37 36 1996\n",
      "L236 0 1999\n",
      "R51 51 1999\n",
      "R49 0 2000\n",
      "R985 85 2009\n",
      "R61 46 2010\n",
      "R54 0 2011\n",
      "L44 56 2011\n",
      "L90 66 2012\n",
      "R34 0 2013\n",
      "L27 73 2013\n",
      "R559 32 2019\n",
      "R57 89 2019\n",
      "L3 86 2019\n",
      "R81 67 2020\n",
      "L67 0 2021\n",
      "L97 3 2021\n",
      "L6 97 2022\n",
      "L35 62 2022\n",
      "L92 70 2023\n",
      "R30 0 2024\n",
      "L22 78 2024\n",
      "R22 0 2025\n",
      "L73 27 2025\n",
      "L927 0 2035\n",
      "L23 77 2035\n",
      "L11 66 2035\n",
      "R88 54 2036\n",
      "R85 39 2037\n",
      "L13 26 2037\n",
      "L90 36 2038\n",
      "R51 87 2038\n",
      "R28 15 2039\n",
      "L397 18 2043\n",
      "L46 72 2044\n",
      "R12 84 2044\n",
      "R225 9 2047\n",
      "L50 59 2048\n",
      "L659 0 2055\n",
      "L29 71 2055\n",
      "R76 47 2056\n",
      "R78 25 2057\n",
      "R19 44 2057\n",
      "L98 46 2058\n",
      "R758 4 2066\n",
      "L104 0 2068\n",
      "L16 84 2068\n",
      "R16 0 2069\n",
      "R256 56 2071\n",
      "R50 6 2072\n",
      "R94 0 2073\n",
      "L1 99 2073\n",
      "L99 0 2074\n",
      "L89 11 2074\n",
      "L358 53 2078\n",
      "L63 90 2079\n",
      "R10 0 2080\n",
      "R26 26 2080\n",
      "R14 40 2080\n",
      "L40 0 2081\n",
      "R152 52 2082\n",
      "L83 69 2083\n",
      "R31 0 2084\n",
      "R13 13 2084\n",
      "L13 0 2085\n",
      "R86 86 2085\n",
      "L556 30 2090\n",
      "R13 43 2090\n",
      "L43 0 2091\n",
      "R94 94 2091\n",
      "R17 11 2092\n",
      "R61 72 2092\n",
      "L128 44 2093\n",
      "R665 9 2100\n",
      "L40 69 2101\n",
      "R69 38 2102\n",
      "L47 91 2103\n",
      "R87 78 2104\n",
      "L812 66 2112\n",
      "L89 77 2113\n",
      "L77 0 2114\n",
      "R4 4 2114\n",
      "R296 0 2117\n",
      "L29 71 2117\n",
      "L18 53 2117\n",
      "L53 0 2118\n",
      "L16 84 2118\n",
      "L98 86 2119\n",
      "L514 72 2124\n",
      "R82 54 2125\n",
      "L54 0 2126\n",
      "L21 79 2126\n",
      "L7 72 2126\n",
      "R728 0 2134\n",
      "R51 51 2134\n",
      "L37 14 2134\n",
      "R86 0 2135\n",
      "R63 63 2135\n",
      "L63 0 2136\n",
      "L5 95 2136\n",
      "R5 0 2137\n",
      "R741 41 2144\n",
      "L41 0 2145\n",
      "R62 62 2145\n",
      "R338 0 2149\n",
      "L51 49 2149\n",
      "L89 60 2150\n",
      "R273 33 2153\n",
      "R94 27 2154\n",
      "R4 31 2154\n",
      "R69 0 2155\n",
      "R710 10 2162\n",
      "R991 1 2172\n",
      "L5 96 2173\n",
      "R4 0 2174\n",
      "R53 53 2174\n",
      "L15 38 2174\n",
      "L47 91 2175\n",
      "L76 15 2175\n",
      "R95 10 2176\n",
      "L62 48 2177\n",
      "R46 94 2177\n",
      "L83 11 2177\n",
      "R95 6 2178\n",
      "L44 62 2179\n",
      "R41 3 2180\n",
      "L38 65 2181\n",
      "R53 18 2182\n",
      "L527 91 2188\n",
      "R509 0 2194\n",
      "L87 13 2194\n",
      "R236 49 2196\n",
      "L849 0 2205\n",
      "R64 64 2205\n",
      "R23 87 2205\n",
      "L84 3 2205\n",
      "R256 59 2207\n",
      "L59 0 2208\n",
      "L71 29 2208\n",
      "L57 72 2209\n",
      "L10 62 2209\n",
      "L62 0 2210\n",
      "L18 82 2210\n",
      "R25 7 2211\n",
      "R52 59 2211\n",
      "R99 58 2212\n",
      "L15 43 2212\n",
      "R57 0 2213\n",
      "L23 77 2213\n",
      "L25 52 2213\n",
      "L31 21 2213\n",
      "L12 9 2213\n",
      "R177 86 2214\n",
      "L96 90 2215\n",
      "L12 78 2215\n",
      "L36 42 2215\n",
      "L84 58 2216\n",
      "L6 52 2216\n",
      "L152 0 2218\n",
      "L976 24 2227\n",
      "R1 25 2227\n",
      "L56 69 2228\n",
      "R31 0 2229\n",
      "L76 24 2229\n",
      "R76 0 2230\n",
      "L330 70 2233\n",
      "L643 27 2239\n",
      "R51 78 2239\n",
      "L282 96 2242\n",
      "L41 55 2242\n",
      "R945 0 2252\n",
      "R63 63 2252\n",
      "L48 15 2252\n",
      "R739 54 2259\n",
      "R46 0 2260\n",
      "R310 10 2263\n",
      "L38 72 2264\n",
      "L372 0 2268\n",
      "L54 46 2268\n",
      "L37 9 2268\n",
      "L518 91 2274\n",
      "L94 97 2275\n",
      "L897 0 2284\n",
      "R94 94 2284\n",
      "L8 86 2284\n",
      "L64 22 2284\n",
      "R51 73 2284\n",
      "L22 51 2284\n",
      "R49 0 2285\n",
      "R68 68 2285\n",
      "R32 0 2286\n",
      "R135 35 2287\n",
      "L15 20 2287\n",
      "L20 0 2288\n",
      "L690 10 2294\n",
      "R94 4 2295\n",
      "L4 0 2296\n",
      "R33 33 2296\n",
      "L33 0 2297\n",
      "R43 43 2297\n",
      "R57 0 2298\n",
      "L75 25 2298\n",
      "L8 17 2298\n",
      "L117 0 2300\n",
      "L1 99 2300\n",
      "R57 56 2301\n",
      "L556 0 2307\n",
      "L76 24 2307\n",
      "R176 0 2309\n",
      "R69 69 2309\n",
      "L628 41 2315\n",
      "R39 80 2315\n",
      "R65 45 2316\n",
      "R35 80 2316\n",
      "R24 4 2317\n",
      "L67 37 2318\n",
      "R63 0 2319\n",
      "L52 48 2319\n",
      "L48 0 2320\n",
      "L90 10 2320\n",
      "L97 13 2321\n",
      "L13 0 2322\n",
      "L42 58 2322\n",
      "R81 39 2323\n",
      "R62 1 2324\n",
      "R99 0 2325\n",
      "R17 17 2325\n",
      "L17 0 2326\n",
      "R752 52 2333\n",
      "R48 0 2334\n",
      "R41 41 2334\n",
      "R59 0 2335\n",
      "R46 46 2335\n",
      "L65 81 2336\n",
      "L78 3 2336\n",
      "R97 0 2337\n",
      "R95 95 2337\n",
      "L6 89 2337\n",
      "L69 20 2337\n",
      "L20 0 2338\n",
      "L72 28 2338\n",
      "L74 54 2339\n",
      "L54 0 2340\n",
      "L99 1 2340\n",
      "R68 69 2340\n",
      "L1 68 2340\n",
      "L68 0 2341\n",
      "L21 79 2341\n",
      "R21 0 2342\n",
      "R66 66 2342\n",
      "L24 42 2342\n",
      "L36 6 2342\n",
      "R94 0 2343\n",
      "R52 52 2343\n",
      "L73 79 2344\n",
      "R84 63 2345\n",
      "R37 0 2346\n",
      "L562 38 2351\n",
      "R1 39 2351\n",
      "R61 0 2352\n",
      "R98 98 2352\n",
      "L98 0 2353\n",
      "R82 82 2353\n",
      "L3 79 2353\n",
      "L1 78 2353\n",
      "L22 56 2353\n",
      "L827 29 2361\n",
      "L578 51 2367\n",
      "R49 0 2368\n",
      "R94 94 2368\n",
      "L72 22 2368\n",
      "R95 17 2369\n",
      "L79 38 2370\n",
      "R72 10 2371\n",
      "L81 29 2372\n",
      "R71 0 2373\n",
      "L7 93 2373\n",
      "L47 46 2373\n",
      "R638 84 2379\n",
      "L69 15 2379\n",
      "L26 89 2380\n",
      "R11 0 2381\n",
      "R963 63 2390\n",
      "L88 75 2391\n",
      "L76 99 2392\n",
      "L10 89 2392\n",
      "R11 0 2393\n",
      "R31 31 2393\n",
      "L64 67 2394\n",
      "L67 0 2395\n",
      "R43 43 2395\n",
      "L685 58 2402\n",
      "R942 0 2412\n",
      "L818 82 2420\n",
      "L2 80 2420\n",
      "R72 52 2421\n",
      "R572 24 2427\n",
      "R63 87 2427\n",
      "L602 85 2433\n",
      "L45 40 2433\n",
      "R60 0 2434\n",
      "R34 34 2434\n",
      "L534 0 2440\n",
      "L72 28 2440\n",
      "L28 0 2441\n",
      "R43 43 2441\n",
      "L83 60 2442\n",
      "R12 72 2442\n",
      "R97 69 2443\n",
      "R653 22 2450\n",
      "R78 0 2451\n",
      "L45 55 2451\n",
      "L45 10 2451\n",
      "L10 0 2452\n",
      "L931 69 2461\n",
      "R710 79 2468\n",
      "R21 0 2469\n",
      "R68 68 2469\n",
      "R95 63 2470\n",
      "R70 33 2471\n",
      "R67 0 2472\n",
      "R92 92 2472\n",
      "L92 0 2473\n",
      "R57 57 2473\n",
      "R762 19 2481\n",
      "R74 93 2481\n",
      "R7 0 2482\n",
      "L96 4 2482\n",
      "L37 67 2483\n",
      "L67 0 2484\n",
      "L95 5 2484\n",
      "L38 67 2485\n",
      "R128 95 2486\n",
      "R7 2 2487\n",
      "L2 0 2488\n",
      "R87 87 2488\n",
      "R13 0 2489\n",
      "R42 42 2489\n",
      "L475 67 2494\n",
      "R32 99 2494\n",
      "L67 32 2494\n",
      "R68 0 2495\n",
      "L316 84 2498\n",
      "L84 0 2499\n",
      "L73 27 2499\n",
      "L927 0 2509\n",
      "R636 36 2515\n",
      "L536 0 2521\n",
      "L3 97 2521\n",
      "L797 0 2529\n",
      "L21 79 2529\n",
      "R95 74 2530\n",
      "R18 92 2530\n",
      "R73 65 2531\n",
      "R14 79 2531\n",
      "L35 44 2531\n",
      "R12 56 2531\n",
      "R570 26 2537\n",
      "L35 91 2538\n",
      "R63 54 2539\n",
      "L355 99 2543\n",
      "L39 60 2543\n",
      "L88 72 2544\n",
      "L972 0 2554\n",
      "R912 12 2563\n",
      "R78 90 2563\n",
      "R310 0 2567\n",
      "R23 23 2567\n",
      "R92 15 2568\n",
      "R88 3 2569\n",
      "R97 0 2570\n",
      "R10 10 2570\n",
      "L510 0 2576\n",
      "L26 74 2576\n",
      "R426 0 2581\n",
      "L60 40 2581\n",
      "L40 0 2582\n",
      "L76 24 2582\n",
      "R376 0 2586\n",
      "L74 26 2586\n",
      "L34 92 2587\n",
      "R8 0 2588\n",
      "L914 86 2597\n",
      "R14 0 2598\n",
      "R79 79 2598\n",
      "R306 85 2601\n",
      "L85 0 2602\n",
      "L97 3 2602\n",
      "R57 60 2602\n",
      "L960 0 2612\n",
      "L4 96 2612\n",
      "R1 97 2612\n",
      "R64 61 2613\n",
      "L21 40 2613\n",
      "L40 0 2614\n",
      "L51 49 2614\n",
      "L3 46 2614\n",
      "L57 89 2615\n",
      "L43 46 2615\n",
      "R25 71 2615\n",
      "R10 81 2615\n",
      "L81 0 2616\n",
      "R16 16 2616\n",
      "R61 77 2616\n",
      "R6 83 2616\n",
      "R94 77 2617\n",
      "L51 26 2617\n",
      "L85 41 2618\n",
      "R41 82 2618\n",
      "R18 0 2619\n",
      "R49 49 2619\n",
      "L73 76 2620\n",
      "R45 21 2621\n",
      "R37 58 2621\n",
      "L52 6 2621\n",
      "L367 39 2625\n",
      "L959 80 2635\n",
      "R10 90 2635\n",
      "L65 25 2635\n",
      "R832 57 2643\n",
      "L57 0 2644\n",
      "L69 31 2644\n",
      "L31 0 2645\n",
      "R75 75 2645\n",
      "R94 69 2646\n",
      "R12 81 2646\n",
      "R19 0 2647\n",
      "L83 17 2647\n",
      "R354 71 2650\n",
      "R71 42 2651\n",
      "R58 0 2652\n",
      "L49 51 2652\n",
      "L51 0 2653\n",
      "R67 67 2653\n",
      "R56 23 2654\n",
      "L23 0 2655\n",
      "R6 6 2655\n",
      "L562 44 2661\n",
      "R976 20 2671\n",
      "R535 55 2676\n",
      "L920 35 2685\n",
      "R136 71 2686\n",
      "L444 27 2690\n",
      "L27 0 2691\n",
      "L28 72 2691\n",
      "L72 0 2692\n",
      "L407 93 2696\n",
      "R184 77 2698\n",
      "L35 42 2698\n",
      "R13 55 2698\n",
      "R45 0 2699\n",
      "L14 86 2699\n",
      "R14 0 2700\n",
      "L61 39 2700\n",
      "L298 41 2703\n",
      "L60 81 2704\n",
      "R84 65 2705\n",
      "R135 0 2707\n",
      "R49 49 2707\n",
      "R51 0 2708\n",
      "R57 57 2708\n",
      "R26 83 2708\n",
      "L239 44 2710\n",
      "R78 22 2711\n",
      "L22 0 2712\n",
      "R70 70 2712\n",
      "L970 0 2722\n",
      "R77 77 2722\n",
      "R764 41 2730\n",
      "L90 51 2731\n",
      "R53 4 2732\n",
      "L307 97 2736\n",
      "L242 55 2738\n",
      "L55 0 2739\n",
      "L91 9 2739\n",
      "R80 89 2739\n",
      "L40 49 2739\n",
      "R23 72 2739\n",
      "R38 10 2740\n",
      "L25 85 2741\n",
      "R15 0 2742\n",
      "L54 46 2742\n",
      "L761 85 2750\n",
      "R59 44 2751\n",
      "R56 0 2752\n",
      "L482 18 2756\n",
      "R753 71 2763\n",
      "L71 0 2764\n",
      "R65 65 2764\n",
      "L89 76 2765\n",
      "L4 72 2765\n",
      "L72 0 2766\n",
      "R25 25 2766\n",
      "R12 37 2766\n",
      "R15 52 2766\n",
      "R522 74 2771\n",
      "L40 34 2771\n",
      "R66 0 2772\n",
      "R5 5 2772\n",
      "L151 54 2774\n",
      "R33 87 2774\n",
      "L30 57 2774\n",
      "R76 33 2775\n",
      "R62 95 2775\n",
      "R45 40 2776\n",
      "R14 54 2776\n",
      "L611 43 2782\n",
      "R57 0 2783\n",
      "L46 54 2783\n",
      "R79 33 2784\n",
      "L68 65 2785\n",
      "L65 0 2786\n",
      "R11 11 2786\n",
      "L11 0 2787\n",
      "L62 38 2787\n",
      "R69 7 2788\n",
      "R93 0 2789\n",
      "L61 39 2789\n",
      "L9 30 2789\n",
      "L743 87 2797\n",
      "R22 9 2798\n",
      "L9 0 2799\n",
      "R92 92 2799\n",
      "R80 72 2800\n",
      "R685 57 2807\n",
      "L57 0 2808\n",
      "R66 66 2808\n",
      "R76 42 2809\n",
      "R58 0 2810\n",
      "L172 28 2811\n",
      "L75 53 2812\n",
      "L96 57 2813\n",
      "R443 0 2818\n",
      "R8 8 2818\n",
      "L94 14 2819\n",
      "R86 0 2820\n",
      "L51 49 2820\n",
      "R319 68 2823\n",
      "L34 34 2823\n",
      "L95 39 2824\n",
      "R15 54 2824\n",
      "L49 5 2824\n",
      "L5 0 2825\n",
      "L68 32 2825\n",
      "L94 38 2826\n",
      "L45 93 2827\n",
      "L93 0 2828\n",
      "L42 58 2828\n",
      "R19 77 2828\n",
      "L13 64 2828\n",
      "L27 37 2828\n",
      "R5 42 2828\n",
      "L63 79 2829\n",
      "R116 95 2830\n",
      "R5 0 2831\n",
      "R85 85 2831\n",
      "L93 92 2832\n",
      "L77 15 2832\n",
      "L15 0 2833\n",
      "R36 36 2833\n",
      "L836 0 2842\n",
      "L87 13 2842\n",
      "R87 0 2843\n",
      "R80 80 2843\n",
      "R44 24 2844\n",
      "L24 0 2845\n",
      "L162 38 2846\n",
      "L14 24 2846\n",
      "R47 71 2846\n",
      "L71 0 2847\n",
      "R81 81 2847\n",
      "L81 0 2848\n",
      "R46 46 2848\n",
      "L44 2 2848\n",
      "R101 3 2849\n",
      "R52 55 2849\n",
      "L55 0 2850\n",
      "L948 52 2859\n",
      "R827 79 2867\n",
      "R73 52 2868\n",
      "L52 0 2869\n",
      "L2 98 2869\n",
      "R42 40 2870\n",
      "R63 3 2871\n",
      "L3 0 2872\n",
      "R48 48 2872\n",
      "L48 0 2873\n",
      "R47 47 2873\n",
      "L47 0 2874\n",
      "R30 30 2874\n",
      "L91 39 2875\n",
      "R597 36 2881\n",
      "L444 92 2886\n",
      "L92 0 2887\n",
      "R14 14 2887\n",
      "L69 45 2888\n",
      "R55 0 2889\n",
      "R69 69 2889\n",
      "L11 58 2889\n",
      "L58 0 2890\n",
      "L666 34 2896\n",
      "R66 0 2897\n",
      "R68 68 2897\n",
      "R32 0 2898\n",
      "L71 29 2898\n",
      "L9 20 2898\n",
      "R74 94 2898\n",
      "L615 79 2904\n",
      "R56 35 2905\n",
      "R87 22 2906\n",
      "L23 99 2907\n",
      "R245 44 2910\n",
      "R98 42 2911\n",
      "L42 0 2912\n",
      "L16 84 2912\n",
      "L11 73 2912\n",
      "L169 4 2913\n",
      "R96 0 2914\n",
      "R89 89 2914\n",
      "L28 61 2914\n",
      "L61 0 2915\n",
      "L79 21 2915\n",
      "L221 0 2918\n",
      "L81 19 2918\n",
      "L5 14 2918\n",
      "L14 0 2919\n",
      "R90 90 2919\n",
      "L90 0 2920\n",
      "L51 49 2920\n",
      "L175 74 2922\n",
      "L82 92 2923\n",
      "R8 0 2924\n",
      "R81 81 2924\n",
      "L640 41 2930\n",
      "L99 42 2931\n",
      "L42 0 2932\n",
      "L14 86 2932\n",
      "L13 73 2932\n",
      "R68 41 2933\n",
      "L36 5 2933\n",
      "R15 20 2933\n",
      "L20 0 2934\n",
      "R30 30 2934\n",
      "R58 88 2934\n",
      "R7 95 2934\n",
      "R36 31 2935\n",
      "R69 0 2936\n",
      "L66 34 2936\n",
      "L32 2 2936\n",
      "L776 26 2944\n",
      "R74 0 2945\n",
      "L45 55 2945\n",
      "R45 0 2946\n",
      "L18 82 2946\n",
      "L82 0 2947\n",
      "L22 78 2947\n",
      "L8 70 2947\n",
      "R58 28 2948\n",
      "R19 47 2948\n",
      "R53 0 2949\n",
      "R51 51 2949\n",
      "L9 42 2949\n",
      "R60 2 2950\n",
      "L53 49 2951\n",
      "R62 11 2952\n",
      "L33 78 2953\n",
      "L64 14 2953\n",
      "R32 46 2953\n",
      "L46 0 2954\n",
      "R19 19 2954\n",
      "R61 80 2954\n",
      "L94 86 2955\n",
      "R14 0 2956\n",
      "L86 14 2956\n",
      "R39 53 2956\n",
      "L53 0 2957\n",
      "L31 69 2957\n",
      "L15 54 2957\n",
      "R84 38 2958\n",
      "L51 87 2959\n",
      "R910 97 2968\n",
      "R22 19 2969\n",
      "L964 55 2979\n",
      "L22 33 2979\n",
      "L66 67 2980\n",
      "L567 0 2986\n",
      "R98 98 2986\n",
      "R423 21 2991\n",
      "R20 41 2991\n",
      "L15 26 2991\n",
      "L26 0 2992\n",
      "L62 38 2992\n",
      "L14 24 2992\n",
      "R98 22 2993\n",
      "R68 90 2993\n",
      "L62 28 2993\n",
      "L524 4 2998\n",
      "R95 99 2998\n",
      "L612 87 3004\n",
      "L838 49 3012\n",
      "R918 67 3021\n",
      "R31 98 3021\n",
      "L47 51 3021\n",
      "R549 0 3027\n",
      "R65 65 3027\n",
      "R35 0 3028\n",
      "R78 78 3028\n",
      "R49 27 3029\n",
      "R73 0 3030\n",
      "R50 50 3030\n",
      "R50 0 3031\n",
      "R41 41 3031\n",
      "L211 30 3033\n",
      "R54 84 3033\n",
      "L96 88 3034\n",
      "R66 54 3035\n",
      "L54 0 3036\n",
      "R189 89 3037\n",
      "R911 0 3047\n",
      "R66 66 3047\n",
      "R34 0 3048\n",
      "R456 56 3052\n",
      "R91 47 3053\n",
      "R53 0 3054\n",
      "R59 59 3054\n",
      "R4 63 3054\n",
      "R116 79 3055\n",
      "R20 99 3055\n",
      "R304 3 3059\n",
      "R42 45 3059\n",
      "L563 82 3065\n",
      "L82 0 3066\n",
      "L429 71 3070\n",
      "L71 0 3071\n",
      "L78 22 3071\n",
      "L97 25 3072\n",
      "L69 56 3073\n",
      "L56 0 3074\n",
      "R185 85 3075\n",
      "L87 98 3076\n",
      "R21 19 3077\n",
      "R481 0 3082\n",
      "R30 30 3082\n",
      "R18 48 3082\n",
      "R93 41 3083\n",
      "R77 18 3084\n",
      "L918 0 3094\n",
      "R22 22 3094\n",
      "R73 95 3094\n",
      "L41 54 3094\n",
      "L16 38 3094\n",
      "L74 64 3095\n",
      "R136 0 3097\n",
      "R98 98 3097\n",
      "R39 37 3098\n",
      "L37 0 3099\n",
      "L47 53 3099\n",
      "R47 0 3100\n",
      "L404 96 3104\n",
      "L84 12 3104\n",
      "L67 45 3105\n",
      "L86 59 3106\n",
      "R88 47 3107\n",
      "L47 0 3108\n",
      "R420 20 3112\n",
      "R56 76 3112\n",
      "L30 46 3112\n",
      "R90 36 3113\n",
      "L58 78 3114\n",
      "R22 0 3115\n",
      "R910 10 3124\n",
      "L77 33 3125\n",
      "R78 11 3126\n",
      "R13 24 3126\n",
      "R876 0 3135\n",
      "L91 9 3135\n",
      "L53 56 3136\n",
      "R83 39 3137\n",
      "R591 30 3143\n",
      "R670 0 3150\n",
      "L405 95 3154\n",
      "L95 0 3155\n",
      "L920 80 3164\n",
      "L80 0 3165\n",
      "R46 46 3165\n",
      "L4 42 3165\n",
      "L42 0 3166\n",
      "R7 7 3166\n",
      "R24 31 3166\n",
      "L22 9 3166\n",
      "R84 93 3166\n",
      "R33 26 3167\n",
      "L26 0 3168\n",
      "R836 36 3176\n",
      "L936 0 3186\n",
      "R23 23 3186\n",
      "L23 0 3187\n",
      "L52 48 3187\n",
      "R805 53 3195\n",
      "R210 63 3197\n",
      "L77 86 3198\n",
      "L86 0 3199\n",
      "R64 64 3199\n",
      "L64 0 3200\n",
      "L598 2 3205\n",
      "R98 0 3206\n",
      "L254 46 3208\n",
      "L46 0 3209\n",
      "R99 99 3209\n",
      "L99 0 3210\n",
      "L94 6 3210\n",
      "L6 0 3211\n",
      "L51 49 3211\n",
      "R488 37 3216\n",
      "L65 72 3217\n",
      "L72 0 3218\n",
      "L8 92 3218\n",
      "R701 93 3225\n",
      "L129 64 3226\n",
      "L164 0 3228\n",
      "L64 36 3228\n",
      "L21 15 3228\n",
      "R28 43 3228\n",
      "L43 0 3229\n",
      "L60 40 3229\n",
      "L140 0 3231\n",
      "R558 58 3236\n",
      "R818 76 3244\n",
      "L4 72 3244\n",
      "R56 28 3245\n",
      "R72 0 3246\n",
      "R80 80 3246\n",
      "R20 0 3247\n",
      "R291 91 3249\n",
      "L56 35 3249\n",
      "R65 0 3250\n",
      "L29 71 3250\n",
      "L482 89 3255\n",
      "R11 0 3256\n",
      "R71 71 3256\n",
      "R87 58 3257\n",
      "L26 32 3257\n",
      "L232 0 3260\n",
      "L38 62 3260\n",
      "R90 52 3261\n",
      "R767 19 3269\n",
      "L19 0 3270\n",
      "R51 51 3270\n",
      "L6 45 3270\n",
      "R96 41 3271\n",
      "L41 0 3272\n",
      "R30 30 3272\n",
      "R86 16 3273\n",
      "R84 0 3274\n",
      "L21 79 3274\n",
      "L86 93 3275\n",
      "L340 53 3278\n",
      "L65 88 3279\n",
      "L88 0 3280\n",
      "L320 80 3283\n",
      "L227 53 3285\n",
      "L68 85 3286\n",
      "L7 78 3286\n",
      "L78 0 3287\n",
      "L914 86 3296\n",
      "L86 0 3297\n",
      "L73 27 3297\n",
      "L27 0 3298\n",
      "R15 15 3298\n",
      "L40 75 3299\n",
      "R421 96 3303\n",
      "R143 39 3305\n",
      "R461 0 3310\n",
      "L368 32 3313\n",
      "L46 86 3314\n",
      "R293 79 3317\n",
      "R60 39 3318\n",
      "L24 15 3318\n",
      "L34 81 3319\n",
      "L343 38 3322\n",
      "L38 0 3323\n",
      "L9 91 3323\n",
      "R93 84 3324\n",
      "L27 57 3324\n",
      "L89 68 3325\n",
      "R32 0 3326\n",
      "R19 19 3326\n",
      "L619 0 3333\n",
      "L25 75 3333\n",
      "L140 35 3334\n",
      "L13 22 3334\n",
      "R78 0 3335\n",
      "R945 45 3344\n",
      "R118 63 3345\n",
      "R85 48 3346\n",
      "L12 36 3346\n",
      "R313 49 3349\n",
      "R53 2 3350\n",
      "R98 0 3351\n",
      "L27 73 3351\n",
      "R957 30 3361\n",
      "L30 0 3362\n",
      "R51 51 3362\n",
      "L51 0 3363\n",
      "L42 58 3363\n",
      "R19 77 3363\n",
      "R23 0 3364\n",
      "L87 13 3364\n",
      "R140 53 3365\n",
      "L4 49 3365\n",
      "R51 0 3366\n",
      "L60 40 3366\n",
      "L708 32 3373\n",
      "L67 65 3374\n",
      "R535 0 3380\n",
      "L20 80 3380\n",
      "R82 62 3381\n",
      "R573 35 3387\n",
      "R65 0 3388\n",
      "L65 35 3388\n",
      "L886 49 3397\n",
      "R86 35 3398\n",
      "L80 55 3399\n",
      "L7 48 3399\n",
      "L433 15 3403\n",
      "R862 77 3411\n",
      "L92 85 3412\n",
      "L385 0 3416\n",
      "R36 36 3416\n",
      "R32 68 3416\n",
      "R32 0 3417\n",
      "R67 67 3417\n",
      "R68 35 3418\n",
      "R82 17 3419\n",
      "L93 24 3420\n",
      "L24 0 3421\n",
      "L85 15 3421\n",
      "R24 39 3421\n",
      "L27 12 3421\n",
      "R23 35 3421\n",
      "R65 0 3422\n",
      "L7 93 3422\n",
      "R907 0 3432\n",
      "L356 44 3435\n",
      "R95 39 3436\n",
      "L81 58 3437\n",
      "R242 0 3440\n",
      "L47 53 3440\n",
      "L76 77 3441\n",
      "R992 69 3451\n",
      "R31 0 3452\n",
      "R79 79 3452\n",
      "L179 0 3454\n",
      "R508 8 3459\n",
      "L2 6 3459\n",
      "R694 0 3466\n",
      "R1 1 3466\n",
      "R526 27 3471\n",
      "L27 0 3472\n",
      "L53 47 3472\n",
      "L47 0 3473\n",
      "R17 17 3473\n",
      "L7 10 3473\n",
      "R42 52 3473\n",
      "R409 61 3477\n",
      "R54 15 3478\n",
      "L86 29 3479\n",
      "L19 10 3479\n",
      "L86 24 3480\n",
      "R506 30 3485\n",
      "L11 19 3485\n",
      "L19 0 3486\n",
      "L57 43 3486\n",
      "L61 82 3487\n",
      "R18 0 3488\n",
      "R14 14 3488\n",
      "L92 22 3489\n",
      "R38 60 3489\n",
      "R40 0 3490\n",
      "L25 75 3490\n",
      "R25 0 3491\n",
      "R30 30 3491\n",
      "R70 0 3492\n",
      "L58 42 3492\n",
      "R12 54 3492\n",
      "R5 59 3492\n",
      "L48 11 3492\n",
      "R89 0 3493\n",
      "R989 89 3502\n",
      "L77 12 3502\n",
      "R88 0 3503\n",
      "R306 6 3506\n",
      "L306 0 3510\n",
      "L99 1 3510\n",
      "R99 0 3511\n",
      "R9 9 3511\n",
      "R90 99 3511\n",
      "L99 0 3512\n",
      "L35 65 3512\n",
      "R30 95 3512\n",
      "R40 35 3513\n",
      "R65 0 3514\n",
      "R73 73 3514\n",
      "L15 58 3514\n",
      "R42 0 3515\n",
      "L63 37 3515\n",
      "R72 9 3516\n",
      "R91 0 3517\n",
      "L59 41 3517\n",
      "L57 84 3518\n",
      "R16 0 3519\n",
      "L40 60 3519\n",
      "R740 0 3527\n",
      "R11 11 3527\n",
      "L11 0 3528\n",
      "R30 30 3528\n",
      "L930 0 3538\n",
      "R536 36 3543\n",
      "R931 67 3552\n",
      "R833 0 3561\n",
      "L385 15 3564\n",
      "R58 73 3564\n",
      "R166 39 3566\n",
      "L19 20 3566\n",
      "R40 60 3566\n",
      "L589 71 3572\n",
      "R29 0 3573\n",
      "R37 37 3573\n",
      "L198 39 3575\n",
      "L39 0 3576\n",
      "L53 47 3576\n",
      "L24 23 3576\n",
      "L3 20 3576\n",
      "L21 99 3577\n",
      "R941 40 3587\n",
      "R960 0 3597\n",
      "R75 75 3597\n",
      "R26 1 3598\n",
      "L1 0 3599\n",
      "R71 71 3599\n",
      "R44 15 3600\n",
      "L556 59 3606\n",
      "L95 64 3607\n",
      "R36 0 3608\n",
      "R328 28 3611\n",
      "R15 43 3611\n",
      "R57 0 3612\n",
      "R477 77 3616\n",
      "L109 68 3617\n",
      "L4 64 3617\n",
      "L64 0 3618\n",
      "L561 39 3623\n",
      "L32 7 3623\n",
      "L49 58 3624\n",
      "L92 66 3625\n",
      "R834 0 3634\n",
      "R6 6 3634\n",
      "R494 0 3639\n",
      "L99 1 3639\n",
      "R971 72 3648\n",
      "R628 0 3655\n",
      "R10 10 3655\n",
      "R53 63 3655\n",
      "L63 0 3656\n",
      "R67 67 3656\n",
      "R993 60 3666\n",
      "R43 3 3667\n",
      "L4 99 3668\n",
      "L15 84 3668\n",
      "R564 48 3674\n",
      "R852 0 3683\n",
      "R45 45 3683\n",
      "R49 94 3683\n",
      "L86 8 3683\n",
      "L117 91 3685\n",
      "R18 9 3686\n",
      "R1 10 3686\n",
      "L838 72 3695\n",
      "R28 0 3696\n",
      "R78 78 3696\n",
      "L74 4 3696\n",
      "R96 0 3697\n",
      "L113 87 3698\n",
      "L409 78 3702\n",
      "R53 31 3703\n",
      "R30 61 3703\n",
      "R38 99 3703\n",
      "R15 14 3704\n",
      "R286 0 3707\n",
      "L83 17 3707\n",
      "R81 98 3707\n",
      "L67 31 3707\n",
      "L22 9 3707\n",
      "L12 97 3708\n",
      "R98 95 3709\n",
      "L95 0 3710\n",
      "R79 79 3710\n",
      "R27 6 3711\n",
      "L148 58 3713\n",
      "R149 7 3715\n",
      "L72 35 3716\n",
      "L821 14 3724\n",
      "L14 0 3725\n",
      "R73 73 3725\n",
      "R27 0 3726\n",
      "R44 44 3726\n",
      "L67 77 3727\n",
      "R23 0 3728\n",
      "L8 92 3728\n",
      "R8 0 3729\n",
      "R60 60 3729\n",
      "R72 32 3730\n",
      "L32 0 3731\n",
      "L12 88 3731\n",
      "L88 0 3732\n",
      "L19 81 3732\n",
      "L81 0 3733\n",
      "L68 32 3733\n",
      "L6 26 3733\n",
      "L22 4 3733\n",
      "R85 89 3733\n",
      "L77 12 3733\n",
      "R88 0 3734\n",
      "L86 14 3734\n",
      "R33 47 3734\n",
      "R49 96 3734\n",
      "R61 57 3735\n",
      "L57 0 3736\n",
      "L95 5 3736\n",
      "L72 33 3737\n",
      "L27 6 3737\n",
      "R747 53 3744\n",
      "L753 0 3752\n",
      "L74 26 3752\n",
      "R47 73 3752\n",
      "R77 50 3753\n",
      "L38 12 3753\n",
      "L12 0 3754\n",
      "L10 90 3754\n",
      "L90 0 3755\n",
      "R895 95 3763\n",
      "R5 0 3764\n",
      "L77 23 3764\n",
      "L11 12 3764\n",
      "R74 86 3764\n",
      "L86 0 3765\n",
      "L1 99 3765\n",
      "R36 35 3766\n",
      "R65 0 3767\n",
      "R42 42 3767\n",
      "L42 0 3768\n",
      "L88 12 3768\n",
      "R56 68 3768\n",
      "L68 0 3769\n",
      "R82 82 3769\n",
      "L82 0 3770\n",
      "R904 4 3779\n",
      "L33 71 3780\n",
      "L64 7 3780\n",
      "R293 0 3783\n",
      "R29 29 3783\n",
      "L829 0 3792\n",
      "R27 27 3792\n",
      "R96 23 3793\n",
      "L23 0 3794\n",
      "L66 34 3794\n",
      "L473 61 3799\n",
      "R39 0 3800\n",
      "R35 35 3800\n",
      "L41 94 3801\n",
      "L61 33 3801\n",
      "R67 0 3802\n",
      "L51 49 3802\n",
      "L80 69 3803\n",
      "L69 0 3804\n",
      "L91 9 3804\n",
      "L87 22 3805\n",
      "L471 51 3810\n",
      "L51 0 3811\n",
      "R714 14 3818\n",
      "L56 58 3819\n",
      "L44 14 3819\n",
      "L12 2 3819\n",
      "R868 70 3827\n",
      "L50 20 3827\n",
      "R4 24 3827\n",
      "L51 73 3828\n",
      "R510 83 3833\n",
      "L83 0 3834\n",
      "L60 40 3834\n",
      "L38 2 3834\n",
      "L789 13 3842\n",
      "R641 54 3848\n",
      "R49 3 3849\n",
      "L5 98 3850\n",
      "R2 0 3851\n",
      "L39 61 3851\n",
      "L61 0 3852\n",
      "L86 14 3852\n",
      "R12 26 3852\n",
      "R59 85 3852\n",
      "R3 88 3852\n",
      "L54 34 3852\n",
      "L34 0 3853\n",
      "L468 32 3857\n",
      "L832 0 3866\n",
      "L32 68 3866\n",
      "R41 9 3867\n",
      "R38 47 3867\n",
      "R67 14 3868\n",
      "L54 60 3869\n",
      "L60 0 3870\n",
      "L69 31 3870\n",
      "L81 50 3871\n",
      "R50 0 3872\n",
      "L7 93 3872\n",
      "L78 15 3872\n",
      "R84 99 3872\n",
      "R95 94 3873\n",
      "R43 37 3874\n",
      "R9 46 3874\n",
      "L46 0 3875\n",
      "R69 69 3875\n",
      "R31 0 3876\n",
      "R70 70 3876\n",
      "R12 82 3876\n",
      "R141 23 3878\n",
      "R371 94 3881\n",
      "R62 56 3882\n",
      "R659 15 3889\n",
      "R61 76 3889\n",
      "R80 56 3890\n",
      "R98 54 3891\n",
      "L27 27 3891\n",
      "R51 78 3891\n",
      "R22 0 3892\n",
      "L901 99 3901\n",
      "R626 25 3908\n",
      "L25 0 3909\n",
      "L71 29 3909\n",
      "L54 75 3910\n",
      "R25 0 3911\n",
      "R7 7 3911\n",
      "L45 62 3912\n",
      "R38 0 3913\n",
      "R61 61 3913\n",
      "R42 3 3914\n",
      "L96 7 3915\n",
      "L921 86 3925\n",
      "R14 0 3926\n",
      "L45 55 3926\n",
      "R52 7 3927\n",
      "L807 0 3936\n",
      "R27 27 3936\n",
      "L27 0 3937\n",
      "R44 44 3937\n",
      "R475 19 3942\n",
      "L10 9 3942\n",
      "R91 0 3943\n",
      "L79 21 3943\n",
      "R320 41 3946\n",
      "L63 78 3947\n",
      "R83 61 3948\n",
      "R73 34 3949\n",
      "L29 5 3949\n",
      "R852 57 3957\n",
      "R373 30 3961\n",
      "L85 45 3962\n",
      "L45 0 3963\n",
      "R5 5 3963\n",
      "L505 0 3969\n",
      "R66 66 3969\n",
      "L4 62 3969\n",
      "R38 0 3970\n",
      "R11 11 3970\n",
      "L11 0 3971\n",
      "R975 75 3980\n",
      "R25 0 3981\n",
      "R77 77 3981\n",
      "L777 0 3989\n",
      "L51 49 3989\n",
      "L43 6 3989\n",
      "L29 77 3990\n",
      "R4 81 3990\n",
      "L97 84 3991\n",
      "R841 25 4000\n",
      "L12 13 4000\n",
      "R87 0 4001\n",
      "L69 31 4001\n",
      "R94 25 4002\n",
      "R75 0 4003\n",
      "L68 32 4003\n",
      "L32 0 4004\n",
      "R13 13 4004\n",
      "R51 64 4004\n",
      "R10 74 4004\n",
      "R78 52 4005\n",
      "L57 95 4006\n",
      "R40 35 4007\n",
      "L65 70 4008\n",
      "L70 0 4009\n",
      "L20 80 4009\n",
      "L99 81 4010\n",
      "L26 55 4010\n",
      "R8 63 4010\n",
      "L29 34 4010\n",
      "L34 0 4011\n",
      "R1 1 4011\n",
      "R99 0 4012\n",
      "R61 61 4012\n",
      "L8 53 4012\n",
      "R47 0 4013\n",
      "L53 47 4013\n",
      "R16 63 4013\n",
      "R697 60 4020\n",
      "R7 67 4020\n",
      "R33 0 4021\n",
      "R499 99 4025\n",
      "R75 74 4026\n",
      "R58 32 4027\n",
      "L94 38 4028\n",
      "L26 12 4028\n",
      "R88 0 4029\n",
      "L82 18 4029\n",
      "R82 0 4030\n",
      "L681 19 4036\n",
      "R65 84 4036\n",
      "R16 0 4037\n",
      "L37 63 4037\n",
      "L82 81 4038\n",
      "R44 25 4039\n",
      "R83 8 4040\n",
      "R92 0 4041\n",
      "R14 14 4041\n",
      "L35 79 4042\n",
      "R87 66 4043\n",
      "R5 71 4043\n",
      "R91 62 4044\n",
      "L62 0 4045\n",
      "R50 50 4045\n",
      "R63 13 4046\n",
      "L13 0 4047\n",
      "L362 38 4050\n",
      "R62 0 4051\n",
      "L98 2 4051\n",
      "L2 0 4052\n",
      "L34 66 4052\n",
      "R34 0 4053\n",
      "L52 48 4053\n",
      "R51 99 4053\n",
      "R44 43 4054\n",
      "R60 3 4055\n",
      "R397 0 4059\n",
      "R68 68 4059\n",
      "R74 42 4060\n",
      "R58 0 4061\n",
      "R575 75 4066\n",
      "L75 0 4067\n",
      "L27 73 4067\n",
      "L73 0 4068\n",
      "R32 32 4068\n",
      "R168 0 4070\n",
      "R3 3 4070\n",
      "R20 23 4070\n",
      "L930 93 4080\n",
      "R28 21 4081\n",
      "R81 2 4082\n",
      "R43 45 4082\n",
      "L45 0 4083\n",
      "R42 42 4083\n",
      "R72 14 4084\n",
      "L14 0 4085\n",
      "L81 19 4085\n",
      "L48 71 4086\n",
      "L71 0 4087\n",
      "R13 13 4087\n",
      "R853 66 4095\n",
      "R94 60 4096\n",
      "L60 0 4097\n",
      "R93 93 4097\n",
      "R57 50 4098\n",
      "R557 7 4104\n",
      "R93 0 4105\n",
      "L86 14 4105\n",
      "R86 0 4106\n",
      "R409 9 4110\n",
      "R426 35 4114\n",
      "R65 0 4115\n",
      "L6 94 4115\n",
      "L12 82 4115\n",
      "R58 40 4116\n",
      "L51 89 4117\n",
      "R65 54 4118\n",
      "L54 0 4119\n",
      "L64 36 4119\n",
      "R64 0 4120\n",
      "L32 68 4120\n",
      "L9 59 4120\n",
      "L225 34 4122\n",
      "R20 54 4122\n",
      "R642 96 4128\n",
      "L96 0 4129\n",
      "R24 24 4129\n",
      "L71 53 4130\n",
      "R43 96 4130\n",
      "R62 58 4131\n",
      "L88 70 4132\n",
      "L74 96 4133\n",
      "R4 0 4134\n",
      "L80 20 4134\n",
      "L20 0 4135\n",
      "L64 36 4135\n",
      "R64 0 4136\n",
      "R53 53 4136\n",
      "R97 50 4137\n",
      "R69 19 4138\n",
      "L44 75 4139\n",
      "L45 30 4139\n",
      "R9 39 4139\n",
      "L839 0 4148\n",
      "L792 8 4155\n",
      "R92 0 4156\n",
      "R60 60 4156\n",
      "L60 0 4157\n",
      "R845 45 4165\n",
      "R27 72 4165\n",
      "L49 23 4165\n",
      "R94 17 4166\n",
      "R52 69 4166\n",
      "R68 37 4167\n",
      "R99 36 4168\n",
      "R64 0 4169\n",
      "L55 45 4169\n",
      "L26 19 4169\n",
      "R12 31 4169\n",
      "R169 0 4171\n",
      "L39 61 4171\n",
      "L61 0 4172\n",
      "L73 27 4172\n",
      "R24 51 4172\n",
      "L729 22 4179\n",
      "L22 0 4180\n",
      "R48 48 4180\n",
      "R55 3 4181\n",
      "R69 72 4181\n",
      "R852 24 4190\n",
      "L524 0 4196\n",
      "L17 83 4196\n",
      "L434 49 4200\n",
      "L95 54 4201\n",
      "R47 1 4202\n",
      "R99 0 4203\n",
      "R26 26 4203\n",
      "R74 0 4204\n",
      "L7 93 4204\n",
      "L72 21 4204\n",
      "L16 5 4204\n",
      "R66 71 4204\n",
      "R743 14 4212\n",
      "L2 12 4212\n",
      "R82 94 4212\n",
      "L62 32 4212\n",
      "R58 90 4212\n",
      "R291 81 4215\n",
      "L79 2 4215\n",
      "L2 0 4216\n",
      "L1 99 4216\n",
      "R1 0 4217\n",
      "R35 35 4217\n",
      "L435 0 4222\n",
      "L75 25 4222\n",
      "R75 0 4223\n",
      "R489 89 4227\n",
      "R66 55 4228\n",
      "L467 88 4233\n",
      "L81 7 4233\n",
      "L40 67 4234\n",
      "L22 45 4234\n",
      "R55 0 4235\n",
      "L78 22 4235\n",
      "R73 95 4235\n",
      "R4 99 4235\n",
      "L68 31 4235\n",
      "L30 1 4235\n",
      "R59 60 4235\n",
      "R840 0 4244\n",
      "L169 31 4245\n",
      "L57 74 4246\n",
      "L78 96 4247\n",
      "R94 90 4248\n",
      "R14 4 4249\n",
      "L4 0 4250\n",
      "R76 76 4250\n",
      "R49 25 4251\n",
      "R75 0 4252\n",
      "L86 14 4252\n",
      "R86 0 4253\n",
      "R552 52 4258\n",
      "L52 0 4259\n",
      "R22 22 4259\n",
      "R278 0 4262\n",
      "R66 66 4262\n",
      "R34 0 4263\n",
      "L2 98 4263\n",
      "R97 95 4264\n",
      "R965 60 4274\n",
      "R40 0 4275\n",
      "L58 42 4275\n",
      "R94 36 4276\n",
      "L60 76 4277\n",
      "L77 99 4278\n",
      "L899 0 4287\n",
      "R72 72 4287\n",
      "R32 4 4288\n",
      "R817 21 4296\n",
      "R67 88 4296\n",
      "R12 0 4297\n",
      "L82 18 4297\n",
      "R222 40 4299\n",
      "L40 0 4300\n",
      "R47 47 4300\n",
      "L747 0 4308\n",
      "L61 39 4308\n",
      "R29 68 4308\n",
      "L395 73 4312\n",
      "R869 42 4321\n",
      "L30 12 4321\n",
      "L94 18 4322\n",
      "L28 90 4323\n",
      "R44 34 4324\n",
      "L134 0 4326\n",
      "L286 14 4328\n",
      "L893 21 4337\n",
      "L546 75 4343\n",
      "R25 0 4344\n",
      "L71 29 4344\n",
      "R771 0 4352\n",
      "L69 31 4352\n",
      "L7 24 4352\n",
      "R17 41 4352\n",
      "L407 34 4356\n",
      "R66 0 4357\n",
      "L88 12 4357\n",
      "R177 89 4358\n",
      "L94 95 4359\n",
      "R186 81 4361\n",
      "L96 85 4362\n",
      "L94 91 4363\n",
      "L52 39 4363\n",
      "R533 72 4368\n",
      "L40 32 4368\n",
      "R14 46 4368\n",
      "L156 90 4370\n",
      "L829 61 4378\n",
      "R88 49 4379\n",
      "L49 0 4380\n",
      "R88 88 4380\n",
      "R12 0 4381\n",
      "R38 38 4381\n",
      "R62 0 4382\n",
      "L25 75 4382\n",
      "L75 0 4383\n",
      "R47 47 4383\n",
      "L70 77 4384\n",
      "R23 0 4385\n",
      "L99 1 4385\n",
      "L56 45 4386\n",
      "R44 89 4386\n",
      "L61 28 4386\n",
      "R72 0 4387\n",
      "L142 58 4388\n",
      "L58 0 4389\n",
      "L57 43 4389\n",
      "R57 0 4390\n",
      "L95 5 4390\n",
      "R51 56 4390\n",
      "R7 63 4390\n",
      "R20 83 4390\n",
      "R41 24 4391\n",
      "L51 73 4392\n",
      "R139 12 4394\n",
      "R88 0 4395\n",
      "R985 85 4404\n",
      "R315 0 4408\n",
      "L39 61 4408\n",
      "L67 94 4409\n",
      "R59 53 4410\n",
      "L853 0 4419\n",
      "R91 91 4419\n",
      "R83 74 4420\n",
      "R45 19 4421\n",
      "R381 0 4425\n",
      "R609 9 4431\n",
      "R91 0 4432\n",
      "L2 98 4432\n",
      "R708 6 4440\n",
      "R94 0 4441\n",
      "L66 34 4441\n",
      "L34 0 4442\n",
      "R48 48 4442\n",
      "L43 5 4442\n",
      "L5 0 4443\n",
      "R96 96 4443\n",
      "L15 81 4443\n",
      "L81 0 4444\n",
      "R58 58 4444\n",
      "L646 12 4450\n",
      "R23 35 4450\n",
      "R865 0 4459\n",
      "R688 88 4465\n",
      "R712 0 4473\n",
      "R11 11 4473\n",
      "L38 73 4474\n",
      "L50 23 4474\n",
      "L86 37 4475\n",
      "R369 6 4479\n",
      "L62 44 4480\n",
      "L85 59 4481\n",
      "R41 0 4482\n",
      "R20 20 4482\n",
      "L35 85 4483\n",
      "L56 29 4483\n",
      "R41 70 4483\n",
      "R95 65 4484\n",
      "R58 23 4485\n",
      "L60 63 4486\n",
      "L63 0 4487\n",
      "L40 60 4487\n",
      "R41 1 4488\n",
      "L1 0 4489\n",
      "L3 97 4489\n",
      "R93 90 4490\n",
      "L90 0 4491\n",
      "R27 27 4491\n",
      "L76 51 4492\n",
      "R11 62 4492\n",
      "R116 78 4493\n",
      "R69 47 4494\n",
      "R5 52 4494\n",
      "R48 0 4495\n",
      "R36 36 4495\n",
      "R41 77 4495\n",
      "R523 0 4501\n",
      "R28 28 4501\n",
      "R48 76 4501\n",
      "R4 80 4501\n",
      "R44 24 4502\n",
      "L155 69 4504\n",
      "R60 29 4505\n",
      "R71 0 4506\n",
      "L4 96 4506\n",
      "L30 66 4506\n",
      "R12 78 4506\n",
      "L60 18 4506\n",
      "L18 0 4507\n",
      "L49 51 4507\n",
      "R33 84 4507\n",
      "R38 22 4508\n",
      "L22 0 4509\n",
      "L116 84 4510\n",
      "L70 14 4510\n",
      "R86 0 4511\n",
      "R40 40 4511\n",
      "R56 96 4511\n",
      "L94 2 4511\n",
      "R37 39 4511\n",
      "R553 92 4516\n",
      "L92 0 4517\n",
      "L931 69 4526\n",
      "L69 0 4527\n",
      "R39 39 4527\n",
      "R594 33 4533\n",
      "L53 80 4534\n",
      "R20 0 4535\n",
      "L36 64 4535\n",
      "R236 0 4538\n",
      "R247 47 4540\n",
      "R58 5 4541\n",
      "L5 0 4542\n",
      "R54 54 4542\n",
      "L38 16 4542\n",
      "R84 0 4543\n",
      "L51 49 4543\n",
      "L49 0 4544\n",
      "R545 45 4549\n",
      "L32 13 4549\n",
      "R87 0 4550\n",
      "R78 78 4550\n",
      "R422 0 4555\n",
      "L255 45 4557\n",
      "R55 0 4558\n",
      "R96 96 4558\n",
      "R603 99 4564\n",
      "R19 18 4565\n",
      "L49 69 4566\n",
      "L10 59 4566\n",
      "L35 24 4566\n",
      "R88 12 4567\n",
      "R788 0 4575\n",
      "L302 98 4578\n",
      "R2 0 4579\n",
      "L85 15 4579\n",
      "R1 16 4579\n",
      "L494 22 4584\n",
      "L40 82 4585\n",
      "R10 92 4585\n",
      "L92 0 4586\n",
      "R59 59 4586\n",
      "R241 0 4589\n",
      "L645 55 4595\n",
      "R106 61 4596\n",
      "R4 65 4596\n",
      "L61 4 4596\n",
      "L555 49 4602\n",
      "R51 0 4603\n",
      "L81 19 4603\n",
      "R26 45 4603\n",
      "L64 81 4604\n",
      "R19 0 4605\n",
      "L70 30 4605\n",
      "R96 26 4606\n",
      "L26 0 4607\n",
      "L180 20 4608\n",
      "L77 43 4609\n",
      "R91 34 4610\n",
      "L51 83 4611\n",
      "R17 0 4612\n",
      "L91 9 4612\n",
      "R91 0 4613\n",
      "L14 86 4613\n",
      "R41 27 4614\n",
      "R79 6 4615\n",
      "R44 50 4615\n",
      "R5 55 4615\n",
      "L53 2 4615\n",
      "L40 62 4616\n",
      "L59 3 4616\n",
      "L3 0 4617\n",
      "L53 47 4617\n",
      "R53 0 4618\n",
      "L292 8 4620\n",
      "R92 0 4621\n",
      "L20 80 4621\n",
      "L80 0 4622\n",
      "R371 71 4625\n",
      "R29 0 4626\n",
      "L14 86 4626\n",
      "R14 0 4627\n",
      "L74 26 4627\n",
      "L26 0 4628\n",
      "R597 97 4633\n",
      "R49 46 4634\n",
      "L78 68 4635\n",
      "L68 0 4636\n",
      "R468 68 4640\n",
      "R64 32 4641\n",
      "L36 96 4642\n",
      "L2 94 4642\n",
      "R65 59 4643\n",
      "L46 13 4643\n",
      "R21 34 4643\n",
      "L451 83 4648\n",
      "L1 82 4648\n",
      "R518 0 4654\n",
      "R96 96 4654\n",
      "R59 55 4655\n",
      "R24 79 4655\n",
      "R21 0 4656\n",
      "R58 58 4656\n",
      "R42 0 4657\n",
      "R87 87 4657\n",
      "L4 83 4657\n",
      "R13 96 4657\n",
      "L7 89 4657\n",
      "L552 37 4662\n",
      "R80 17 4663\n",
      "L817 0 4672\n",
      "L20 80 4672\n",
      "R535 15 4678\n",
      "R85 0 4679\n",
      "R775 75 4686\n",
      "L75 0 4687\n",
      "L119 81 4688\n",
      "L30 51 4688\n",
      "R76 27 4689\n",
      "L41 86 4690\n",
      "L86 0 4691\n",
      "L832 68 4699\n",
      "R32 0 4700\n",
      "R68 68 4700\n",
      "R32 0 4701\n",
      "L34 66 4701\n",
      "R34 0 4702\n",
      "R3 3 4702\n",
      "L703 0 4710\n",
      "R22 22 4710\n",
      "L8 14 4710\n",
      "R86 0 4711\n",
      "R460 60 4715\n",
      "L75 85 4716\n",
      "R7 92 4716\n",
      "L7 85 4716\n",
      "R817 2 4725\n",
      "R698 0 4732\n",
      "L170 30 4733\n",
      "R37 67 4733\n",
      "L567 0 4739\n",
      "R13 13 4739\n",
      "R75 88 4739\n",
      "R12 0 4740\n",
      "L46 54 4740\n",
      "L98 56 4741\n",
      "L6 50 4741\n",
      "R30 80 4741\n",
      "R20 0 4742\n",
      "L78 22 4742\n",
      "L19 3 4742\n",
      "R50 53 4742\n",
      "R18 71 4742\n",
      "L31 40 4742\n",
      "L90 50 4743\n",
      "R5 55 4743\n",
      "L12 43 4743\n",
      "R57 0 4744\n",
      "R10 10 4744\n",
      "L10 0 4745\n",
      "R173 73 4746\n",
      "R79 52 4747\n",
      "L52 0 4748\n",
      "L76 24 4748\n",
      "L87 37 4749\n",
      "L81 56 4750\n",
      "L203 53 4752\n",
      "L53 0 4753\n",
      "R74 74 4753\n",
      "L73 1 4753\n",
      "R17 18 4753\n",
      "R18 36 4753\n",
      "L180 56 4755\n",
      "R44 0 4756\n",
      "R27 27 4756\n",
      "R147 74 4757\n",
      "L274 0 4760\n",
      "R19 19 4760\n",
      "R89 8 4761\n",
      "R92 0 4762\n",
      "L3 97 4762\n",
      "R80 77 4763\n",
      "L677 0 4770\n",
      "R64 64 4770\n",
      "L64 0 4771\n",
      "L20 80 4771\n",
      "L80 0 4772\n",
      "L35 65 4772\n",
      "L70 95 4773\n",
      "R14 9 4774\n",
      "R97 6 4775\n",
      "R50 56 4775\n",
      "R60 16 4776\n",
      "L16 0 4777\n",
      "L342 58 4780\n",
      "R33 91 4780\n",
      "R9 0 4781\n",
      "L17 83 4781\n",
      "R17 0 4782\n",
      "R353 53 4785\n",
      "R597 50 4791\n",
      "L75 75 4792\n",
      "R25 0 4793\n",
      "L86 14 4793\n",
      "R70 84 4793\n",
      "R16 0 4794\n",
      "L68 32 4794\n",
      "L94 38 4795\n",
      "L23 15 4795\n",
      "L38 77 4796\n",
      "L67 10 4796\n",
      "R90 0 4797\n",
      "R19 19 4797\n",
      "L419 0 4802\n",
      "L46 54 4802\n",
      "L54 0 4803\n",
      "L74 26 4803\n",
      "R28 54 4803\n",
      "L57 97 4804\n",
      "L79 18 4804\n",
      "L18 0 4805\n",
      "R109 9 4806\n",
      "R38 47 4806\n",
      "L47 0 4807\n",
      "R95 95 4807\n",
      "R5 0 4808\n",
      "L29 71 4808\n",
      "R83 54 4809\n",
      "R25 79 4809\n",
      "R32 11 4810\n",
      "R60 71 4810\n",
      "L712 59 4817\n",
      "R841 0 4826\n",
      "L732 68 4833\n",
      "R9 77 4833\n",
      "L82 95 4834\n",
      "R54 49 4835\n",
      "L86 63 4836\n",
      "L49 14 4836\n",
      "R86 0 4837\n",
      "R98 98 4837\n",
      "R36 34 4838\n",
      "L34 0 4839\n",
      "L50 50 4839\n",
      "L50 0 4840\n",
      "L29 71 4840\n",
      "R805 76 4848\n",
      "R93 69 4849\n",
      "R10 79 4849\n",
      "L79 0 4850\n",
      "L739 61 4857\n",
      "L51 10 4857\n",
      "R90 0 4858\n",
      "L12 88 4858\n",
      "R79 67 4859\n",
      "L60 7 4859\n",
      "L373 34 4863\n",
      "L34 0 4864\n",
      "L4 96 4864\n",
      "L116 80 4865\n",
      "L45 35 4865\n",
      "R98 33 4866\n",
      "L6 27 4866\n",
      "R18 45 4866\n",
      "R55 0 4867\n",
      "L84 16 4867\n",
      "L4 12 4867\n",
      "R88 0 4868\n",
      "L53 47 4868\n",
      "R53 0 4869\n",
      "R41 41 4869\n",
      "L641 0 4876\n",
      "R1 1 4876\n",
      "L17 84 4877\n",
      "R16 0 4878\n",
      "L94 6 4878\n",
      "R11 17 4878\n",
      "L42 75 4879\n",
      "L75 0 4880\n",
      "L788 12 4887\n",
      "R956 68 4896\n",
      "R98 66 4897\n",
      "L188 78 4899\n",
      "L78 0 4900\n",
      "L84 16 4900\n",
      "L3 13 4900\n",
      "R87 0 4901\n",
      "R315 15 4904\n",
      "R97 12 4905\n",
      "R88 0 4906\n",
      "R36 36 4906\n",
      "R76 12 4907\n",
      "R55 67 4907\n",
      "L71 96 4908\n",
      "L28 68 4908\n",
      "R72 40 4909\n",
      "L740 0 4917\n",
      "R53 53 4917\n",
      "L61 92 4918\n",
      "L75 17 4918\n",
      "L17 0 4919\n",
      "L79 21 4919\n",
      "L30 91 4920\n",
      "L727 64 4927\n",
      "R836 0 4936\n",
      "R12 12 4936\n",
      "R92 4 4937\n",
      "R96 0 4938\n",
      "R69 69 4938\n",
      "L69 0 4939\n",
      "R15 15 4939\n",
      "L879 36 4948\n",
      "L36 0 4949\n",
      "L48 52 4949\n",
      "R3 55 4949\n",
      "L855 0 4958\n",
      "L80 20 4958\n",
      "L20 0 4959\n",
      "R289 89 4961\n",
      "R9 98 4961\n",
      "L98 0 4962\n",
      "R40 40 4962\n",
      "R26 66 4962\n",
      "L39 27 4962\n",
      "L62 65 4963\n",
      "L65 0 4964\n",
      "R28 28 4964\n",
      "L28 0 4965\n",
      "R81 81 4965\n",
      "L11 70 4965\n",
      "L70 0 4966\n",
      "R43 43 4966\n",
      "L43 0 4967\n",
      "L94 6 4967\n",
      "R24 30 4967\n",
      "L30 0 4968\n",
      "L769 31 4975\n",
      "L31 0 4976\n",
      "R846 46 4984\n",
      "R867 13 4993\n",
      "R551 64 4998\n",
      "L93 71 4999\n",
      "L4 67 4999\n",
      "L836 31 5007\n",
      "R47 78 5007\n",
      "L870 8 5015\n",
      "L8 0 5016\n",
      "L21 79 5016\n",
      "L97 82 5017\n",
      "R18 0 5018\n",
      "L60 40 5018\n",
      "L44 96 5019\n",
      "L32 64 5019\n",
      "L464 0 5024\n",
      "R727 27 5031\n",
      "R73 0 5032\n",
      "L382 18 5035\n",
      "R60 78 5035\n",
      "R304 82 5038\n",
      "R18 0 5039\n",
      "R22 22 5039\n",
      "R78 0 5040\n",
      "R59 59 5040\n",
      "L56 3 5040\n",
      "L431 72 5045\n",
      "L83 89 5046\n",
      "L89 0 5047\n",
      "R59 59 5047\n",
      "R413 72 5051\n",
      "L72 0 5052\n",
      "R78 78 5052\n",
      "R392 70 5056\n",
      "R4 74 5056\n",
      "R64 38 5057\n",
      "R62 0 5058\n",
      "R39 39 5058\n",
      "R55 94 5058\n",
      "R551 45 5064\n",
      "L25 20 5064\n",
      "L45 75 5065\n",
      "L875 0 5074\n",
      "R90 90 5074\n",
      "R87 77 5075\n",
      "R23 0 5076\n",
      "R98 98 5076\n",
      "R2 0 5077\n",
      "L21 79 5077\n",
      "R130 9 5079\n",
      "L56 53 5080\n",
      "L77 76 5081\n",
      "R93 69 5082\n",
      "R31 0 5083\n",
      "L13 87 5083\n",
      "R22 9 5084\n",
      "L62 47 5085\n",
      "R353 0 5089\n",
      "L85 15 5089\n",
      "L15 0 5090\n",
      "R63 63 5090\n",
      "R637 0 5097\n",
      "L750 50 5104\n",
      "L18 32 5104\n",
      "R31 63 5104\n",
      "R5 68 5104\n",
      "R932 0 5114\n",
      "L53 47 5114\n",
      "R53 0 5115\n",
      "L41 59 5115\n",
      "R99 58 5116\n",
      "R684 42 5123\n",
      "R49 91 5123\n",
      "L36 55 5123\n",
      "L55 0 5124\n",
      "R675 75 5130\n",
      "R22 97 5130\n",
      "L97 0 5131\n",
      "R41 41 5131\n",
      "R9 50 5131\n",
      "R50 0 5132\n",
      "L43 57 5132\n",
      "L37 20 5132\n",
      "L20 0 5133\n",
      "L83 17 5133\n",
      "L73 44 5134\n",
      "R56 0 5135\n",
      "R79 79 5135\n",
      "L79 0 5136\n",
      "R90 90 5136\n",
      "L90 0 5137\n",
      "R91 91 5137\n",
      "L30 61 5137\n",
      "L74 87 5138\n",
      "L64 23 5138\n",
      "R42 65 5138\n",
      "R87 52 5139\n",
      "L31 21 5139\n",
      "R96 17 5140\n",
      "L17 0 5141\n",
      "R25 25 5141\n",
      "R75 0 5142\n",
      "L1 99 5142\n",
      "R784 83 5150\n",
      "R13 96 5150\n",
      "L96 0 5151\n",
      "L36 64 5151\n",
      "R91 55 5152\n",
      "R37 92 5152\n",
      "L68 24 5152\n",
      "L69 55 5153\n",
      "R843 98 5161\n",
      "R2 0 5162\n",
      "L63 37 5162\n",
      "L37 0 5163\n",
      "L987 13 5172\n",
      "R87 0 5173\n",
      "L40 60 5173\n",
      "R86 46 5174\n",
      "R54 0 5175\n",
      "L55 45 5175\n",
      "L64 81 5176\n",
      "L51 30 5176\n",
      "R70 0 5177\n",
      "R63 63 5177\n",
      "L31 32 5177\n",
      "L21 11 5177\n",
      "R21 32 5177\n",
      "L72 60 5178\n",
      "R40 0 5179\n",
      "L31 69 5179\n",
      "R209 78 5181\n",
      "R86 64 5182\n",
      "R36 0 5183\n",
      "R21 21 5183\n",
      "L56 65 5184\n",
      "R35 0 5185\n",
      "R78 78 5185\n",
      "L83 95 5186\n",
      "L65 30 5186\n",
      "L96 34 5187\n",
      "R24 58 5187\n",
      "R82 40 5188\n",
      "L1 39 5188\n",
      "R61 0 5189\n",
      "L41 59 5189\n",
      "R58 17 5190\n",
      "R83 0 5191\n",
      "L61 39 5191\n",
      "R61 0 5192\n",
      "R94 94 5192\n",
      "L94 0 5193\n",
      "L13 87 5193\n",
      "R993 80 5203\n",
      "L19 61 5203\n",
      "R95 56 5204\n",
      "L56 0 5205\n",
      "L79 21 5205\n",
      "L58 63 5206\n",
      "L463 0 5211\n",
      "L10 90 5211\n",
      "R20 10 5212\n",
      "R12 22 5212\n",
      "L54 68 5213\n",
      "L74 94 5214\n",
      "R606 0 5221\n",
      "R98 98 5221\n",
      "L906 92 5230\n",
      "L24 68 5230\n",
      "L9 59 5230\n",
      "L711 48 5237\n",
      "R6 54 5237\n",
      "L12 42 5237\n",
      "R40 82 5237\n",
      "R50 32 5238\n",
      "L51 81 5239\n",
      "R15 96 5239\n",
      "L77 19 5239\n",
      "R22 41 5239\n",
      "R77 18 5240\n",
      "L35 83 5241\n",
      "R217 0 5244\n",
      "R33 33 5244\n",
      "R90 23 5245\n",
      "R77 0 5246\n",
      "L84 16 5246\n",
      "L7 9 5246\n",
      "R38 47 5246\n",
      "L51 96 5247\n",
      "L969 27 5256\n",
      "R43 70 5256\n",
      "L270 0 5259\n",
      "R73 73 5259\n",
      "R27 0 5260\n",
      "L84 16 5260\n",
      "R54 70 5260\n",
      "L70 0 5261\n",
      "R87 87 5261\n",
      "L87 0 5262\n",
      "L22 78 5262\n",
      "R122 0 5264\n",
      "L872 28 5272\n",
      "R72 0 5273\n",
      "R64 64 5273\n",
      "L80 84 5274\n",
      "L95 89 5275\n",
      "R611 0 5282\n",
      "R59 59 5282\n",
      "R79 38 5283\n",
      "R755 93 5290\n",
      "L93 0 5291\n",
      "R89 89 5291\n",
      "L89 0 5292\n",
      "R1 1 5292\n",
      "L66 35 5293\n",
      "R965 0 5303\n",
      "L60 40 5303\n",
      "L40 0 5304\n",
      "L330 70 5307\n",
      "L71 99 5308\n",
      "R194 93 5310\n",
      "R7 0 5311\n",
      "L55 45 5311\n",
      "R98 43 5312\n",
      "L543 0 5318\n",
      "R55 55 5318\n",
      "R45 0 5319\n",
      "L70 30 5319\n",
      "R70 0 5320\n",
      "L82 18 5320\n",
      "R512 30 5325\n",
      "L571 59 5331\n",
      "L59 0 5332\n",
      "R22 22 5332\n",
      "L856 66 5341\n",
      "R1 67 5341\n",
      "R33 0 5342\n",
      "R32 32 5342\n",
      "L396 36 5346\n",
      "L71 65 5347\n",
      "R57 22 5348\n",
      "L777 45 5356\n",
      "L9 36 5356\n",
      "R64 0 5357\n",
      "L656 44 5363\n",
      "R22 66 5363\n",
      "L66 0 5364\n",
      "R85 85 5364\n",
      "L94 91 5365\n",
      "R727 18 5373\n",
      "L18 0 5374\n",
      "R26 26 5374\n",
      "R114 40 5375\n",
      "L40 0 5376\n",
      "L210 90 5378\n",
      "L33 57 5378\n",
      "R38 95 5378\n",
      "L95 0 5379\n",
      "L63 37 5379\n",
      "R535 72 5384\n",
      "L9 63 5384\n",
      "R18 81 5384\n",
      "R84 65 5385\n",
      "L50 15 5385\n",
      "L81 34 5386\n",
      "R54 88 5386\n",
      "L57 31 5386\n",
      "R42 73 5386\n",
      "R127 0 5388\n",
      "R56 56 5388\n",
      "R44 0 5389\n",
      "L16 84 5389\n",
      "R16 0 5390\n",
      "L87 13 5390\n",
      "L26 87 5391\n",
      "R34 21 5392\n",
      "R79 0 5393\n",
      "L41 59 5393\n",
      "L65 94 5394\n",
      "L94 0 5395\n",
      "L56 44 5395\n",
      "L47 97 5396\n",
      "L97 0 5397\n",
      "R58 58 5397\n",
      "R671 29 5404\n",
      "L29 0 5405\n",
      "L68 32 5405\n",
      "L310 22 5408\n",
      "L22 0 5409\n",
      "R10 10 5409\n",
      "R83 93 5409\n",
      "R676 69 5416\n",
      "L24 45 5416\n",
      "L50 95 5417\n",
      "R5 0 5418\n",
      "R5 5 5418\n",
      "L11 94 5419\n",
      "L34 60 5419\n",
      "L60 0 5420\n",
      "R64 64 5420\n",
      "R36 0 5421\n",
      "R78 78 5421\n",
      "L78 0 5422\n",
      "L317 83 5425\n",
      "R17 0 5426\n",
      "L570 30 5431\n",
      "L20 10 5431\n",
      "L28 82 5432\n",
      "R37 19 5433\n",
      "R81 0 5434\n",
      "R81 81 5434\n",
      "L81 0 5435\n",
      "L83 17 5435\n",
      "R83 0 5436\n",
      "L62 38 5436\n",
      "L38 0 5437\n",
      "R37 37 5437\n",
      "L775 62 5445\n",
      "R38 0 5446\n",
      "L29 71 5446\n",
      "R92 63 5447\n",
      "R56 19 5448\n",
      "L19 0 5449\n",
      "R53 53 5449\n",
      "L58 95 5450\n",
      "R37 32 5451\n",
      "L748 84 5459\n",
      "R16 0 5460\n",
      "R17 17 5460\n",
      "R563 80 5465\n",
      "R20 0 5466\n",
      "R81 81 5466\n",
      "L39 42 5466\n",
      "L110 32 5467\n",
      "L132 0 5469\n",
      "R12 12 5469\n",
      "R82 94 5469\n",
      "L94 0 5470\n",
      "R12 12 5470\n",
      "L516 96 5476\n",
      "R34 30 5477\n",
      "L4 26 5477\n",
      "L56 70 5478\n",
      "L51 19 5478\n",
      "R81 0 5479\n",
      "R60 60 5479\n",
      "L36 24 5479\n",
      "L29 95 5480\n",
      "R5 0 5481\n",
      "R38 38 5481\n",
      "L76 62 5482\n",
      "L62 0 5483\n",
      "R877 77 5491\n",
      "L77 0 5492\n",
      "R16 16 5492\n",
      "R574 90 5497\n",
      "R209 99 5499\n",
      "L72 27 5499\n",
      "R58 85 5499\n",
      "L26 59 5499\n",
      "R41 0 5500\n",
      "R87 87 5500\n",
      "R13 0 5501\n",
      "L82 18 5501\n",
      "R282 0 5504\n",
      "R12 12 5504\n",
      "L89 23 5505\n",
      "L46 77 5506\n",
      "L83 94 5507\n",
      "L94 0 5508\n",
      "L283 17 5510\n",
      "R381 98 5513\n",
      "L3 95 5513\n",
      "R5 0 5514\n",
      "R41 41 5514\n",
      "R59 0 5515\n",
      "R22 22 5515\n",
      "L22 0 5516\n",
      "R4 4 5516\n",
      "L73 31 5517\n",
      "R372 3 5521\n",
      "R57 60 5521\n",
      "R5 65 5521\n",
      "R746 11 5529\n",
      "R79 90 5529\n",
      "R10 0 5530\n",
      "L94 6 5530\n",
      "L6 0 5531\n",
      "L31 69 5531\n",
      "L30 39 5531\n",
      "R61 0 5532\n",
      "L59 41 5532\n",
      "L592 49 5538\n",
      "R51 0 5539\n",
      "L85 15 5539\n",
      "R57 72 5539\n",
      "R82 54 5540\n",
      "L54 0 5541\n",
      "R61 61 5541\n",
      "L773 88 5549\n",
      "R12 0 5550\n",
      "R57 57 5550\n",
      "R617 74 5556\n",
      "L747 27 5563\n",
      "L68 59 5564\n",
      "R41 0 5565\n",
      "L96 4 5565\n",
      "L304 0 5569\n",
      "R881 81 5577\n",
      "L51 30 5577\n",
      "L10 20 5577\n",
      "R411 31 5581\n",
      "R83 14 5582\n",
      "R86 0 5583\n",
      "R641 41 5589\n",
      "R959 0 5599\n",
      "L839 61 5607\n",
      "R57 18 5608\n",
      "R82 0 5609\n",
      "L35 65 5609\n",
      "L94 71 5610\n",
      "L45 26 5610\n",
      "L26 0 5611\n",
      "L59 41 5611\n",
      "L30 11 5611\n",
      "R4 15 5611\n",
      "L3 12 5611\n",
      "L71 41 5612\n",
      "L373 68 5616\n",
      "L768 0 5624\n",
      "L51 49 5624\n",
      "R75 24 5625\n",
      "L26 98 5626\n",
      "R2 0 5627\n",
      "R66 66 5627\n",
      "L28 38 5627\n",
      "R7 45 5627\n",
      "L545 0 5633\n",
      "L80 20 5633\n",
      "L53 67 5634\n",
      "L67 0 5635\n",
      "L473 27 5639\n",
      "R36 63 5639\n",
      "R37 0 5640\n",
      "R97 97 5640\n",
      "L62 35 5640\n",
      "R289 24 5643\n",
      "R47 71 5643\n",
      "R71 42 5644\n",
      "R46 88 5644\n",
      "L88 0 5645\n",
      "R99 99 5645\n",
      "L2 97 5645\n",
      "R3 0 5646\n",
      "R15 15 5646\n",
      "L16 99 5647\n",
      "L2 97 5647\n",
      "L11 86 5647\n",
      "L86 0 5648\n",
      "L14 86 5648\n",
      "L70 16 5648\n",
      "R430 46 5652\n",
      "R53 99 5652\n",
      "L88 11 5652\n",
      "R28 39 5652\n",
      "L88 51 5653\n",
      "R92 43 5654\n",
      "L42 1 5654\n",
      "L72 29 5655\n",
      "L598 31 5661\n",
      "R769 0 5669\n",
      "L11 89 5669\n",
      "L15 74 5669\n",
      "L74 0 5670\n",
      "R13 13 5670\n",
      "L35 78 5671\n",
      "L78 0 5672\n",
      "R471 71 5676\n",
      "R329 0 5680\n",
      "L7 93 5680\n",
      "R74 67 5681\n",
      "R493 60 5686\n",
      "R36 96 5686\n",
      "L596 0 5692\n",
      "L39 61 5692\n",
      "L9 52 5692\n",
      "L60 92 5693\n",
      "R24 16 5694\n",
      "R84 0 5695\n",
      "L26 74 5695\n",
      "L74 0 5696\n",
      "L51 49 5696\n",
      "L64 85 5697\n",
      "L85 0 5698\n",
      "R256 56 5700\n",
      "R64 20 5701\n",
      "R80 0 5702\n",
      "L33 67 5702\n",
      "R33 0 5703\n",
      "L80 20 5703\n",
      "L52 68 5704\n",
      "L71 97 5705\n",
      "L397 0 5709\n",
      "L99 1 5709\n",
      "R31 32 5709\n",
      "R68 0 5710\n",
      "L34 66 5710\n",
      "L59 7 5710\n",
      "R93 0 5711\n",
      "L78 22 5711\n",
      "L22 0 5712\n",
      "R171 71 5713\n",
      "L71 0 5714\n",
      "R93 93 5714\n",
      "L93 0 5715\n",
      "L82 18 5715\n",
      "R82 0 5716\n",
      "L58 42 5716\n",
      "L327 15 5719\n",
      "L63 52 5720\n",
      "L52 0 5721\n",
      "L958 42 5730\n",
      "R224 66 5732\n",
      "L466 0 5737\n",
      "R73 73 5737\n",
      "L9 64 5737\n",
      "R392 56 5741\n",
      "R46 2 5742\n",
      "R82 84 5742\n",
      "R22 6 5743\n",
      "L37 69 5744\n",
      "R31 0 5745\n",
      "L77 23 5745\n",
      "R77 0 5746\n",
      "L88 12 5746\n",
      "L171 41 5748\n",
      "L18 23 5748\n",
      "R6 29 5748\n",
      "R271 0 5751\n",
      "L1 99 5751\n",
      "R55 54 5752\n",
      "L47 7 5752\n",
      "L71 36 5753\n",
      "L16 20 5753\n",
      "R86 6 5754\n",
      "R94 0 5755\n",
      "L95 5 5755\n",
      "R95 0 5756\n",
      "R75 75 5756\n",
      "L61 14 5756\n",
      "R11 25 5756\n",
      "L53 72 5757\n",
      "R63 35 5758\n",
      "R37 72 5758\n",
      "L33 39 5758\n",
      "L939 0 5768\n",
      "R70 70 5768\n",
      "R892 62 5777\n",
      "R938 0 5787\n",
      "R47 47 5787\n",
      "R53 0 5788\n",
      "L964 36 5797\n",
      "R64 0 5798\n",
      "R48 48 5798\n",
      "R52 0 5799\n",
      "L35 65 5799\n",
      "R636 1 5806\n",
      "L53 48 5807\n",
      "L96 52 5808\n",
      "L64 88 5809\n",
      "L851 37 5817\n",
      "L73 64 5818\n",
      "R36 0 5819\n",
      "L55 45 5819\n",
      "R55 0 5820\n",
      "R28 28 5820\n",
      "L72 56 5821\n",
      "R98 54 5822\n",
      "L516 38 5827\n",
      "R79 17 5828\n",
      "R28 45 5828\n",
      "L74 71 5829\n",
      "R36 7 5830\n",
      "L7 0 5831\n",
      "L213 87 5833\n",
      "L87 0 5834\n",
      "L503 97 5839\n",
      "L197 0 5841\n",
      "R60 60 5841\n",
      "R8 68 5841\n",
      "L58 10 5841\n",
      "R80 90 5841\n",
      "R66 56 5842\n",
      "L769 87 5850\n",
      "R255 42 5853\n",
      "R58 0 5854\n",
      "L80 20 5854\n",
      "L50 70 5855\n",
      "L27 43 5855\n",
      "L43 0 5856\n",
      "L59 41 5856\n",
      "L41 0 5857\n",
      "L60 40 5857\n",
      "R63 3 5858\n",
      "L3 0 5859\n",
      "R93 93 5859\n",
      "L89 4 5859\n",
      "R21 25 5859\n",
      "L525 0 5865\n",
      "R24 24 5865\n",
      "R75 99 5865\n",
      "L6 93 5865\n",
      "R48 41 5866\n",
      "L972 69 5876\n",
      "L208 61 5878\n",
      "R91 52 5879\n",
      "L52 0 5880\n",
      "L150 50 5881\n",
      "L79 71 5882\n",
      "R469 40 5887\n",
      "L1 39 5887\n",
      "R98 37 5888\n",
      "R48 85 5888\n",
      "R801 86 5896\n",
      "L586 0 5902\n",
      "L59 41 5902\n",
      "L66 75 5903\n",
      "R223 98 5905\n",
      "L898 0 5914\n",
      "L65 35 5914\n",
      "L35 0 5915\n",
      "L752 48 5922\n",
      "R42 90 5922\n",
      "R10 0 5923\n",
      "L62 38 5923\n",
      "L38 0 5924\n",
      "R92 92 5924\n",
      "R8 0 5925\n",
      "L10 90 5925\n",
      "R610 0 5932\n",
      "R85 85 5932\n",
      "R68 53 5933\n",
      "R724 77 5940\n",
      "L77 0 5941\n",
      "L507 93 5946\n",
      "L703 90 5953\n",
      "R10 0 5954\n",
      "L148 52 5955\n",
      "L219 33 5957\n",
      "L33 0 5958\n",
      "R178 78 5959\n",
      "R22 0 5960\n",
      "L86 14 5960\n",
      "L1 13 5960\n",
      "R758 71 5967\n",
      "R929 0 5977\n",
      "R20 20 5977\n",
      "R8 28 5977\n",
      "L406 22 5981\n",
      "R37 59 5981\n",
      "R71 30 5982\n",
      "L721 9 5989\n",
      "R49 58 5989\n",
      "L58 0 5990\n",
      "L5 95 5990\n",
      "R576 71 5996\n",
      "R47 18 5997\n",
      "R31 49 5997\n",
      "L102 47 5998\n",
      "R153 0 6000\n",
      "L37 63 6000\n",
      "R18 81 6000\n",
      "L78 3 6000\n",
      "R97 0 6001\n",
      "L46 54 6001\n",
      "L54 0 6002\n",
      "L1 99 6002\n",
      "R44 43 6003\n",
      "L79 64 6004\n",
      "L64 0 6005\n",
      "L10 90 6005\n",
      "R26 16 6006\n",
      "R84 0 6007\n",
      "R383 83 6010\n",
      "R516 99 6015\n",
      "R139 38 6017\n",
      "R83 21 6018\n",
      "R38 59 6018\n",
      "R53 12 6019\n",
      "L12 0 6020\n",
      "R963 63 6029\n",
      "R88 51 6030\n",
      "L10 41 6030\n",
      "L838 3 6038\n",
      "R53 56 6038\n",
      "L556 0 6044\n",
      "L125 75 6045\n",
      "L75 0 6046\n",
      "R53 53 6046\n",
      "L46 7 6046\n",
      "L597 10 6052\n",
      "R90 0 6053\n",
      "R64 64 6053\n",
      "R9 73 6053\n",
      "R43 16 6054\n",
      "L47 69 6055\n",
      "L73 96 6056\n",
      "R34 30 6057\n",
      "L30 0 6058\n",
      "L50 50 6058\n",
      "R12 62 6058\n",
      "R38 0 6059\n",
      "L172 28 6060\n",
      "R72 0 6061\n",
      "R35 35 6061\n",
      "R65 0 6062\n",
      "L48 52 6062\n",
      "L4 48 6062\n",
      "R52 0 6063\n",
      "L69 31 6063\n",
      "R42 73 6063\n",
      "R27 0 6064\n",
      "R3 3 6064\n",
      "R97 0 6065\n",
      "R40 40 6065\n",
      "L40 0 6066\n",
      "L24 76 6066\n",
      "R42 18 6067\n",
      "R69 87 6067\n",
      "R13 0 6068\n",
      "R87 87 6068\n",
      "R57 44 6069\n",
      "L198 46 6071\n",
      "L6 40 6071\n",
      "L40 0 6072\n",
      "R155 55 6073\n",
      "R62 17 6074\n",
      "L3 14 6074\n",
      "R36 50 6074\n",
      "R50 0 6075\n",
      "R71 71 6075\n",
      "R9 80 6075\n",
      "R4 84 6075\n",
      "L84 0 6076\n",
      "L67 33 6076\n",
      "L33 0 6077\n",
      "L49 51 6077\n",
      "L13 38 6077\n",
      "R62 0 6078\n",
      "L70 30 6078\n",
      "R71 1 6079\n",
      "L1 0 6080\n",
      "L113 87 6081\n",
      "R13 0 6082\n",
      "R36 36 6082\n",
      "R864 0 6091\n",
      "R397 97 6094\n",
      "R99 96 6095\n",
      "R4 0 6096\n",
      "R722 22 6103\n",
      "R78 0 6104\n",
      "R36 36 6104\n",
      "L88 48 6105\n",
      "R72 20 6106\n",
      "L362 58 6110\n",
      "R68 26 6111\n",
      "R74 0 6112\n",
      "R37 37 6112\n",
      "R63 0 6113\n",
      "L50 50 6113\n",
      "L50 0 6114\n",
      "L55 45 6114\n",
      "L81 64 6115\n",
      "L564 0 6121\n",
      "L19 81 6121\n",
      "R87 68 6122\n",
      "L22 46 6122\n",
      "L16 30 6122\n",
      "L85 45 6123\n",
      "R86 31 6124\n",
      "R69 0 6125\n",
      "L19 81 6125\n",
      "L581 0 6131\n",
      "R62 62 6131\n",
      "R135 97 6132\n",
      "L97 0 6133\n",
      "R92 92 6133\n",
      "R558 50 6139\n",
      "R704 54 6146\n",
      "L94 60 6147\n",
      "R140 0 6149\n",
      "L467 33 6153\n",
      "R18 51 6153\n",
      "L651 0 6160\n",
      "L94 6 6160\n",
      "R94 0 6161\n",
      "R47 47 6161\n",
      "L47 0 6162\n",
      "R64 64 6162\n",
      "R26 90 6162\n",
      "L90 0 6163\n",
      "R11 11 6163\n",
      "R41 52 6163\n",
      "L52 0 6164\n",
      "R534 34 6169\n",
      "R70 4 6170\n",
      "L76 28 6171\n",
      "L180 48 6173\n",
      "L548 0 6179\n",
      "L97 3 6179\n",
      "R97 0 6180\n",
      "L84 16 6180\n",
      "L10 6 6180\n",
      "R94 0 6181\n",
      "R64 64 6181\n",
      "L64 0 6182\n",
      "R7 7 6182\n",
      "L7 0 6183\n",
      "R42 42 6183\n",
      "R172 14 6185\n",
      "L14 0 6186\n",
      "R994 94 6195\n",
      "L67 27 6195\n",
      "R73 0 6196\n",
      "R2 2 6196\n",
      "R69 71 6196\n",
      "L84 87 6197\n",
      "L172 15 6198\n",
      "L715 0 6206\n",
      "R57 57 6206\n",
      "L57 0 6207\n",
      "L73 27 6207\n",
      "R958 85 6216\n",
      "L75 10 6216\n",
      "R3 13 6216\n",
      "R50 63 6216\n",
      "L42 21 6216\n",
      "R79 0 6217\n",
      "R895 95 6225\n",
      "R37 32 6226\n",
      "R43 75 6226\n",
      "R630 5 6233\n",
      "R786 91 6240\n",
      "L191 0 6242\n",
      "R84 84 6242\n",
      "L80 4 6242\n",
      "R51 55 6242\n",
      "L820 35 6250\n",
      "R7 42 6250\n",
      "R27 69 6250\n",
      "R31 0 6251\n",
      "R804 4 6259\n",
      "R72 76 6259\n",
      "L176 0 6261\n",
      "L78 22 6261\n",
      "L22 0 6262\n",
      "R38 38 6262\n",
      "L438 0 6267\n",
      "R12 12 6267\n",
      "R988 0 6277\n",
      "R2 2 6277\n",
      "R98 0 6278\n",
      "L83 17 6278\n",
      "L42 75 6279\n",
      "R220 95 6281\n",
      "L95 0 6282\n",
      "R84 84 6282\n",
      "R16 0 6283\n",
      "L99 1 6283\n",
      "R48 49 6283\n",
      "L423 26 6287\n",
      "R71 97 6287\n",
      "L297 0 6290\n",
      "L70 30 6290\n",
      "R70 0 6291\n",
      "L56 44 6291\n",
      "L455 89 6296\n",
      "L434 55 6300\n",
      "R68 23 6301\n",
      "L67 56 6302\n",
      "R744 0 6310\n",
      "R16 16 6310\n",
      "L16 0 6311\n",
      "L68 32 6311\n",
      "L64 68 6312\n",
      "R80 48 6313\n",
      "R52 0 6314\n",
      "L314 86 6317\n",
      "R163 49 6319\n",
      "R719 68 6326\n",
      "L68 0 6327\n",
      "R20 20 6327\n",
      "R80 0 6328\n",
      "R26 26 6328\n",
      "L726 0 6336\n",
      "R12 12 6336\n",
      "L22 90 6337\n",
      "R84 74 6338\n",
      "R57 31 6339\n",
      "L842 89 6348\n",
      "R11 0 6349\n",
      "L89 11 6349\n",
      "R63 74 6349\n",
      "L71 3 6349\n",
      "L3 0 6350\n",
      "R99 99 6350\n",
      "L12 87 6350\n",
      "R13 0 6351\n",
      "R99 99 6351\n",
      "L309 90 6354\n",
      "R10 0 6355\n",
      "L20 80 6355\n",
      "L66 14 6355\n",
      "L645 69 6362\n",
      "R431 0 6367\n",
      "R1 1 6367\n",
      "L201 0 6370\n",
      "R189 89 6371\n",
      "R71 60 6372\n",
      "L98 62 6373\n",
      "L47 15 6373\n",
      "L15 0 6374\n",
      "L71 29 6374\n",
      "L29 0 6375\n",
      "L67 33 6375\n",
      "L33 0 6376\n",
      "R30 30 6376\n",
      "R540 70 6381\n",
      "L937 33 6390\n",
      "R89 22 6391\n",
      "L62 60 6392\n",
      "L41 19 6392\n",
      "L532 87 6398\n",
      "R13 0 6399\n",
      "R931 31 6408\n",
      "R69 0 6409\n",
      "R33 33 6409\n",
      "R67 0 6410\n",
      "R65 65 6410\n",
      "R19 84 6410\n",
      "L199 85 6412\n",
      "L85 0 6413\n",
      "R71 71 6413\n",
      "L33 38 6413\n",
      "L42 96 6414\n",
      "L96 0 6415\n",
      "L583 17 6420\n",
      "L17 0 6421\n",
      "R7 7 6421\n",
      "L7 0 6422\n",
      "R49 49 6422\n",
      "L89 60 6423\n",
      "R40 0 6424\n",
      "L12 88 6424\n",
      "R12 0 6425\n",
      "R27 27 6425\n",
      "L589 38 6431\n",
      "R33 71 6431\n",
      "R29 0 6432\n",
      "R3 3 6432\n",
      "R197 0 6434\n",
      "L67 33 6434\n",
      "R44 77 6434\n",
      "L77 0 6435\n",
      "R14 14 6435\n",
      "L914 0 6445\n",
      "R21 21 6445\n",
      "L21 0 6446\n",
      "L31 69 6446\n",
      "L318 51 6449\n",
      "R49 0 6450\n",
      "L237 63 6452\n",
      "L763 0 6460\n",
      "R67 67 6460\n",
      "L3 64 6460\n",
      "L264 0 6463\n",
      "R85 85 6463\n",
      "R95 80 6464\n",
      "L59 21 6464\n",
      "R7 28 6464\n",
      "R72 0 6465\n",
      "L93 7 6465\n",
      "R64 71 6465\n",
      "L38 33 6465\n",
      "R85 18 6466\n",
      "L930 88 6476\n",
      "R516 4 6482\n",
      "L833 71 6491\n",
      "R29 0 6492\n",
      "R50 50 6492\n",
      "L46 4 6492\n",
      "L15 89 6493\n",
      "L89 0 6494\n",
      "R52 52 6494\n",
      "R29 81 6494\n",
      "R19 0 6495\n",
      "R61 61 6495\n",
      "L63 98 6496\n",
      "L66 32 6496\n",
      "R68 0 6497\n",
      "R46 46 6497\n",
      "L746 0 6505\n",
      "R28 28 6505\n",
      "R909 37 6514\n",
      "L48 89 6515\n",
      "L89 0 6516\n",
      "R15 15 6516\n",
      "R85 0 6517\n",
      "L672 28 6523\n",
      "R88 16 6524\n",
      "R8 24 6524\n",
      "R10 34 6524\n",
      "L40 94 6525\n",
      "R6 0 6526\n",
      "R81 81 6526\n",
      "R37 18 6527\n",
      "L97 21 6528\n",
      "R62 83 6528\n",
      "R82 65 6529\n",
      "R78 43 6530\n",
      "L16 27 6530\n",
      "R73 0 6531\n",
      "L86 14 6531\n",
      "R59 73 6531\n",
      "L73 0 6532\n",
      "L96 4 6532\n",
      "R96 0 6533\n",
      "R30 30 6533\n",
      "L57 73 6534\n",
      "L73 0 6535\n",
      "R18 18 6535\n",
      "R82 0 6536\n",
      "L41 59 6536\n",
      "L65 94 6537\n",
      "R82 76 6538\n",
      "R55 31 6539\n",
      "R69 0 6540\n",
      "R46 46 6540\n",
      "R1 47 6540\n",
      "R53 0 6541\n",
      "R29 29 6541\n",
      "L29 0 6542\n",
      "L91 9 6542\n",
      "L9 0 6543\n",
      "L69 31 6543\n",
      "L96 35 6544\n",
      "R91 26 6545\n",
      "L26 0 6546\n",
      "L67 33 6546\n",
      "R67 0 6547\n",
      "L79 21 6547\n",
      "L28 93 6548\n",
      "L93 0 6549\n",
      "R9 9 6549\n",
      "L73 36 6550\n",
      "R64 0 6551\n",
      "R85 85 6551\n",
      "L97 88 6552\n",
      "L99 89 6553\n",
      "R30 19 6554\n",
      "R44 63 6554\n",
      "R48 11 6555\n",
      "R48 59 6555\n",
      "R40 99 6555\n",
      "L14 85 6555\n",
      "L37 48 6555\n",
      "L5 43 6555\n",
      "L36 7 6555\n",
      "L27 80 6556\n",
      "R31 11 6557\n",
      "R19 30 6557\n",
      "R5 35 6557\n",
      "L35 0 6558\n",
      "L43 57 6558\n",
      "R41 98 6558\n",
      "L8 90 6558\n",
      "L17 73 6558\n",
      "L39 34 6558\n",
      "R20 54 6558\n",
      "R41 95 6558\n",
      "L50 45 6558\n",
      "R12 57 6558\n",
      "L34 23 6558\n",
      "L12 11 6558\n",
      "L20 91 6559\n",
      "R6 97 6559\n",
      "L43 54 6559\n",
      "L4 50 6559\n",
      "L35 15 6559\n",
      "R22 37 6559\n",
      "L8 29 6559\n",
      "L4 25 6559\n",
      "L38 87 6560\n",
      "R40 27 6561\n",
      "R44 71 6561\n",
      "L7 64 6561\n",
      "L31 33 6561\n",
      "R17 50 6561\n",
      "R31 81 6561\n",
      "L25 56 6561\n",
      "R2 58 6561\n",
      "R34 92 6561\n",
      "L39 53 6561\n",
      "L6 47 6561\n",
      "R6 53 6561\n",
      "L13 40 6561\n",
      "L17 23 6561\n",
      "R12 35 6561\n",
      "L17 18 6561\n",
      "R7 25 6561\n",
      "R7 4499 25\n",
      "6561\n"
     ]
    }
   ],
   "source": [
    "def digests(input_values):\n",
    "    input_values = input_values.split(\"\\n\")\n",
    "    location = 50\n",
    "    total = 0\n",
    "    num_times = 0\n",
    "    for line in input_values:\n",
    "        num_times += 1\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            direction, distance = line[0], int(line[1:])\n",
    "        if(direction == \"R\"):\n",
    "            distance = distance\n",
    "        else:\n",
    "            distance = -distance\n",
    "        raw_value = location + distance\n",
    "        if(location!=0 and raw_value%100==0 and raw_value<1):\n",
    "            total+=1\n",
    "        if(location==0 and raw_value<0):\n",
    "            raw_value+=100\n",
    "        location = (location + distance)%100\n",
    "        total += abs(raw_value//100)\n",
    "        print(line,location,total)\n",
    "\n",
    "    print(line,num_times,location)\n",
    "    return total\n",
    "\n",
    "print(digests(input_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38ae4dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0//100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c729b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digests(input_values):\n",
    "    input_values = input_values.split(\"\\n\")\n",
    "    location = 50\n",
    "    total = 0\n",
    "    num_times = 0\n",
    "    for line in input_values:\n",
    "        num_times += 1\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            direction, distance = line[0], int(line[1:])\n",
    "        if(direction == \"R\"):\n",
    "            distance = distance\n",
    "        else:\n",
    "            distance = -distance\n",
    "        raw_value = location + distance\n",
    "        location = (location + distance)%100\n",
    "        total += abs(raw_value//100)\n",
    "\n",
    "    print(num_times,location)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9037c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "6580 is too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2525fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = \"\"\"R1000\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e9c1d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digests(input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = \"\"\"R21\n",
    "R37x\n",
    "L39x\n",
    "L11x\n",
    "L3x\n",
    "R20x\n",
    "R7x\n",
    "R1x\n",
    "R49x\n",
    "L39x\n",
    "L47\n",
    "R27\n",
    "L45\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "50->29->92(+1)->31(+2)->42->45->25->18->17->68(+3)->7(+4)->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6415fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(digests(input_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3575274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "74af45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line:  67562556-67743658\n",
      "initial and final_values: 67566756.0 67746774.0\n",
      "    Value:  67566756.0\n",
      "start and end points:  6756 6774\n",
      "    Value:  67576757\n",
      "    Value:  67586758\n",
      "    Value:  67596759\n",
      "    Value:  67606760\n",
      "    Value:  67616761\n",
      "    Value:  67626762\n",
      "    Value:  67636763\n",
      "    Value:  67646764\n",
      "    Value:  67656765\n",
      "    Value:  67666766\n",
      "    Value:  67676767\n",
      "    Value:  67686768\n",
      "    Value:  67696769\n",
      "    Value:  67706770\n",
      "    Value:  67716771\n",
      "    Value:  67726772\n",
      "    Value:  67736773\n",
      "\n",
      "line:  62064792-62301480\n",
      "initial and final_values: 62066206.0 62306230.0\n",
      "    Value:  62066206.0\n",
      "start and end points:  6206 6230\n",
      "    Value:  62076207\n",
      "    Value:  62086208\n",
      "    Value:  62096209\n",
      "    Value:  62106210\n",
      "    Value:  62116211\n",
      "    Value:  62126212\n",
      "    Value:  62136213\n",
      "    Value:  62146214\n",
      "    Value:  62156215\n",
      "    Value:  62166216\n",
      "    Value:  62176217\n",
      "    Value:  62186218\n",
      "    Value:  62196219\n",
      "    Value:  62206220\n",
      "    Value:  62216221\n",
      "    Value:  62226222\n",
      "    Value:  62236223\n",
      "    Value:  62246224\n",
      "    Value:  62256225\n",
      "    Value:  62266226\n",
      "    Value:  62276227\n",
      "    Value:  62286228\n",
      "    Value:  62296229\n",
      "\n",
      "line:  4394592-4512674\n",
      "Skipping line: 4394592-4512674\n",
      "line:  3308-4582\n",
      "initial and final_values: 3333.0 4545.0\n",
      "    Value:  3333.0\n",
      "start and end points:  33 45\n",
      "    Value:  3434\n",
      "    Value:  3535\n",
      "    Value:  3636\n",
      "    Value:  3737\n",
      "    Value:  3838\n",
      "    Value:  3939\n",
      "    Value:  4040\n",
      "    Value:  4141\n",
      "    Value:  4242\n",
      "    Value:  4343\n",
      "    Value:  4444\n",
      "    Final Value:  4545.0\n",
      "\n",
      "line:  69552998-69828126\n",
      "initial and final_values: 69556955.0 69826982.0\n",
      "    Value:  69556955.0\n",
      "start and end points:  6955 6982\n",
      "    Value:  69566956\n",
      "    Value:  69576957\n",
      "    Value:  69586958\n",
      "    Value:  69596959\n",
      "    Value:  69606960\n",
      "    Value:  69616961\n",
      "    Value:  69626962\n",
      "    Value:  69636963\n",
      "    Value:  69646964\n",
      "    Value:  69656965\n",
      "    Value:  69666966\n",
      "    Value:  69676967\n",
      "    Value:  69686968\n",
      "    Value:  69696969\n",
      "    Value:  69706970\n",
      "    Value:  69716971\n",
      "    Value:  69726972\n",
      "    Value:  69736973\n",
      "    Value:  69746974\n",
      "    Value:  69756975\n",
      "    Value:  69766976\n",
      "    Value:  69776977\n",
      "    Value:  69786978\n",
      "    Value:  69796979\n",
      "    Value:  69806980\n",
      "    Value:  69816981\n",
      "    Final Value:  69826982.0\n",
      "\n",
      "line:  9123-12332\n",
      "initial and final_values: 9191.0 9999.0\n",
      "    Value:  9191.0\n",
      "start and end points:  91 99\n",
      "    Value:  9292\n",
      "    Value:  9393\n",
      "    Value:  9494\n",
      "    Value:  9595\n",
      "    Value:  9696\n",
      "    Value:  9797\n",
      "    Value:  9898\n",
      "    Final Value:  9999.0\n",
      "\n",
      "line:  1095-1358\n",
      "initial and final_values: 1010.0 1313.0\n",
      "start and end points:  10 13\n",
      "    Value:  1111\n",
      "    Value:  1212\n",
      "    Final Value:  1313.0\n",
      "\n",
      "line:  23-48\n",
      "initial and final_values: 22.0 44.0\n",
      "start and end points:  2 4\n",
      "    Value:  33\n",
      "    Final Value:  44.0\n",
      "\n",
      "line:  294-400\n",
      "Skipping line: 294-400\n",
      "line:  3511416-3689352\n",
      "Skipping line: 3511416-3689352\n",
      "line:  1007333-1150296\n",
      "Skipping line: 1007333-1150296\n",
      "line:  2929221721-2929361280\n",
      "initial and final_values: 2929229292.0 2929329293.0\n",
      "    Value:  2929229292.0\n",
      "start and end points:  29292 29293\n",
      "    Final Value:  2929329293.0\n",
      "\n",
      "line:  309711-443410\n",
      "initial and final_values: 309309.0 443443.0\n",
      "start and end points:  309 443\n",
      "    Value:  310310\n",
      "    Value:  311311\n",
      "    Value:  312312\n",
      "    Value:  313313\n",
      "    Value:  314314\n",
      "    Value:  315315\n",
      "    Value:  316316\n",
      "    Value:  317317\n",
      "    Value:  318318\n",
      "    Value:  319319\n",
      "    Value:  320320\n",
      "    Value:  321321\n",
      "    Value:  322322\n",
      "    Value:  323323\n",
      "    Value:  324324\n",
      "    Value:  325325\n",
      "    Value:  326326\n",
      "    Value:  327327\n",
      "    Value:  328328\n",
      "    Value:  329329\n",
      "    Value:  330330\n",
      "    Value:  331331\n",
      "    Value:  332332\n",
      "    Value:  333333\n",
      "    Value:  334334\n",
      "    Value:  335335\n",
      "    Value:  336336\n",
      "    Value:  337337\n",
      "    Value:  338338\n",
      "    Value:  339339\n",
      "    Value:  340340\n",
      "    Value:  341341\n",
      "    Value:  342342\n",
      "    Value:  343343\n",
      "    Value:  344344\n",
      "    Value:  345345\n",
      "    Value:  346346\n",
      "    Value:  347347\n",
      "    Value:  348348\n",
      "    Value:  349349\n",
      "    Value:  350350\n",
      "    Value:  351351\n",
      "    Value:  352352\n",
      "    Value:  353353\n",
      "    Value:  354354\n",
      "    Value:  355355\n",
      "    Value:  356356\n",
      "    Value:  357357\n",
      "    Value:  358358\n",
      "    Value:  359359\n",
      "    Value:  360360\n",
      "    Value:  361361\n",
      "    Value:  362362\n",
      "    Value:  363363\n",
      "    Value:  364364\n",
      "    Value:  365365\n",
      "    Value:  366366\n",
      "    Value:  367367\n",
      "    Value:  368368\n",
      "    Value:  369369\n",
      "    Value:  370370\n",
      "    Value:  371371\n",
      "    Value:  372372\n",
      "    Value:  373373\n",
      "    Value:  374374\n",
      "    Value:  375375\n",
      "    Value:  376376\n",
      "    Value:  377377\n",
      "    Value:  378378\n",
      "    Value:  379379\n",
      "    Value:  380380\n",
      "    Value:  381381\n",
      "    Value:  382382\n",
      "    Value:  383383\n",
      "    Value:  384384\n",
      "    Value:  385385\n",
      "    Value:  386386\n",
      "    Value:  387387\n",
      "    Value:  388388\n",
      "    Value:  389389\n",
      "    Value:  390390\n",
      "    Value:  391391\n",
      "    Value:  392392\n",
      "    Value:  393393\n",
      "    Value:  394394\n",
      "    Value:  395395\n",
      "    Value:  396396\n",
      "    Value:  397397\n",
      "    Value:  398398\n",
      "    Value:  399399\n",
      "    Value:  400400\n",
      "    Value:  401401\n",
      "    Value:  402402\n",
      "    Value:  403403\n",
      "    Value:  404404\n",
      "    Value:  405405\n",
      "    Value:  406406\n",
      "    Value:  407407\n",
      "    Value:  408408\n",
      "    Value:  409409\n",
      "    Value:  410410\n",
      "    Value:  411411\n",
      "    Value:  412412\n",
      "    Value:  413413\n",
      "    Value:  414414\n",
      "    Value:  415415\n",
      "    Value:  416416\n",
      "    Value:  417417\n",
      "    Value:  418418\n",
      "    Value:  419419\n",
      "    Value:  420420\n",
      "    Value:  421421\n",
      "    Value:  422422\n",
      "    Value:  423423\n",
      "    Value:  424424\n",
      "    Value:  425425\n",
      "    Value:  426426\n",
      "    Value:  427427\n",
      "    Value:  428428\n",
      "    Value:  429429\n",
      "    Value:  430430\n",
      "    Value:  431431\n",
      "    Value:  432432\n",
      "    Value:  433433\n",
      "    Value:  434434\n",
      "    Value:  435435\n",
      "    Value:  436436\n",
      "    Value:  437437\n",
      "    Value:  438438\n",
      "    Value:  439439\n",
      "    Value:  440440\n",
      "    Value:  441441\n",
      "    Value:  442442\n",
      "\n",
      "line:  2131524-2335082\n",
      "Skipping line: 2131524-2335082\n",
      "line:  81867-97148\n",
      "Skipping line: 81867-97148\n",
      "line:  9574291560-9574498524\n",
      "initial and final_values: 9574295742.0 9574495744.0\n",
      "    Value:  9574295742.0\n",
      "start and end points:  95742 95744\n",
      "    Value:  9574395743\n",
      "    Final Value:  9574495744.0\n",
      "\n",
      "line:  648635477-648670391\n",
      "Skipping line: 648635477-648670391\n",
      "line:  1-18\n",
      "initial and final_values: 11.0 11.0\n",
      "    Value:  11.0\n",
      "\n",
      "line:  5735-8423\n",
      "initial and final_values: 5757.0 8484.0\n",
      "    Value:  5757.0\n",
      "start and end points:  57 84\n",
      "    Value:  5858\n",
      "    Value:  5959\n",
      "    Value:  6060\n",
      "    Value:  6161\n",
      "    Value:  6262\n",
      "    Value:  6363\n",
      "    Value:  6464\n",
      "    Value:  6565\n",
      "    Value:  6666\n",
      "    Value:  6767\n",
      "    Value:  6868\n",
      "    Value:  6969\n",
      "    Value:  7070\n",
      "    Value:  7171\n",
      "    Value:  7272\n",
      "    Value:  7373\n",
      "    Value:  7474\n",
      "    Value:  7575\n",
      "    Value:  7676\n",
      "    Value:  7777\n",
      "    Value:  7878\n",
      "    Value:  7979\n",
      "    Value:  8080\n",
      "    Value:  8181\n",
      "    Value:  8282\n",
      "    Value:  8383\n",
      "\n",
      "line:  58-72\n",
      "initial and final_values: 55.0 77.0\n",
      "start and end points:  5 7\n",
      "    Value:  66\n",
      "\n",
      "line:  538-812\n",
      "Skipping line: 538-812\n",
      "line:  698652479-698760276\n",
      "Skipping line: 698652479-698760276\n",
      "line:  727833-843820\n",
      "initial and final_values: 727727.0 843843.0\n",
      "start and end points:  727 843\n",
      "    Value:  728728\n",
      "    Value:  729729\n",
      "    Value:  730730\n",
      "    Value:  731731\n",
      "    Value:  732732\n",
      "    Value:  733733\n",
      "    Value:  734734\n",
      "    Value:  735735\n",
      "    Value:  736736\n",
      "    Value:  737737\n",
      "    Value:  738738\n",
      "    Value:  739739\n",
      "    Value:  740740\n",
      "    Value:  741741\n",
      "    Value:  742742\n",
      "    Value:  743743\n",
      "    Value:  744744\n",
      "    Value:  745745\n",
      "    Value:  746746\n",
      "    Value:  747747\n",
      "    Value:  748748\n",
      "    Value:  749749\n",
      "    Value:  750750\n",
      "    Value:  751751\n",
      "    Value:  752752\n",
      "    Value:  753753\n",
      "    Value:  754754\n",
      "    Value:  755755\n",
      "    Value:  756756\n",
      "    Value:  757757\n",
      "    Value:  758758\n",
      "    Value:  759759\n",
      "    Value:  760760\n",
      "    Value:  761761\n",
      "    Value:  762762\n",
      "    Value:  763763\n",
      "    Value:  764764\n",
      "    Value:  765765\n",
      "    Value:  766766\n",
      "    Value:  767767\n",
      "    Value:  768768\n",
      "    Value:  769769\n",
      "    Value:  770770\n",
      "    Value:  771771\n",
      "    Value:  772772\n",
      "    Value:  773773\n",
      "    Value:  774774\n",
      "    Value:  775775\n",
      "    Value:  776776\n",
      "    Value:  777777\n",
      "    Value:  778778\n",
      "    Value:  779779\n",
      "    Value:  780780\n",
      "    Value:  781781\n",
      "    Value:  782782\n",
      "    Value:  783783\n",
      "    Value:  784784\n",
      "    Value:  785785\n",
      "    Value:  786786\n",
      "    Value:  787787\n",
      "    Value:  788788\n",
      "    Value:  789789\n",
      "    Value:  790790\n",
      "    Value:  791791\n",
      "    Value:  792792\n",
      "    Value:  793793\n",
      "    Value:  794794\n",
      "    Value:  795795\n",
      "    Value:  796796\n",
      "    Value:  797797\n",
      "    Value:  798798\n",
      "    Value:  799799\n",
      "    Value:  800800\n",
      "    Value:  801801\n",
      "    Value:  802802\n",
      "    Value:  803803\n",
      "    Value:  804804\n",
      "    Value:  805805\n",
      "    Value:  806806\n",
      "    Value:  807807\n",
      "    Value:  808808\n",
      "    Value:  809809\n",
      "    Value:  810810\n",
      "    Value:  811811\n",
      "    Value:  812812\n",
      "    Value:  813813\n",
      "    Value:  814814\n",
      "    Value:  815815\n",
      "    Value:  816816\n",
      "    Value:  817817\n",
      "    Value:  818818\n",
      "    Value:  819819\n",
      "    Value:  820820\n",
      "    Value:  821821\n",
      "    Value:  822822\n",
      "    Value:  823823\n",
      "    Value:  824824\n",
      "    Value:  825825\n",
      "    Value:  826826\n",
      "    Value:  827827\n",
      "    Value:  828828\n",
      "    Value:  829829\n",
      "    Value:  830830\n",
      "    Value:  831831\n",
      "    Value:  832832\n",
      "    Value:  833833\n",
      "    Value:  834834\n",
      "    Value:  835835\n",
      "    Value:  836836\n",
      "    Value:  837837\n",
      "    Value:  838838\n",
      "    Value:  839839\n",
      "    Value:  840840\n",
      "    Value:  841841\n",
      "    Value:  842842\n",
      "\n",
      "line:  15609927-15646018\n",
      "initial and final_values: 15601560.0 15641564.0\n",
      "start and end points:  1560 1564\n",
      "    Value:  15611561\n",
      "    Value:  15621562\n",
      "    Value:  15631563\n",
      "    Final Value:  15641564.0\n",
      "\n",
      "line:  1491-1766\n",
      "initial and final_values: 1414.0 1717.0\n",
      "start and end points:  14 17\n",
      "    Value:  1515\n",
      "    Value:  1616\n",
      "    Final Value:  1717.0\n",
      "\n",
      "line:  53435-76187\n",
      "Skipping line: 53435-76187\n",
      "line:  196475-300384\n",
      "initial and final_values: 196196.0 300300.0\n",
      "start and end points:  196 300\n",
      "    Value:  197197\n",
      "    Value:  198198\n",
      "    Value:  199199\n",
      "    Value:  200200\n",
      "    Value:  201201\n",
      "    Value:  202202\n",
      "    Value:  203203\n",
      "    Value:  204204\n",
      "    Value:  205205\n",
      "    Value:  206206\n",
      "    Value:  207207\n",
      "    Value:  208208\n",
      "    Value:  209209\n",
      "    Value:  210210\n",
      "    Value:  211211\n",
      "    Value:  212212\n",
      "    Value:  213213\n",
      "    Value:  214214\n",
      "    Value:  215215\n",
      "    Value:  216216\n",
      "    Value:  217217\n",
      "    Value:  218218\n",
      "    Value:  219219\n",
      "    Value:  220220\n",
      "    Value:  221221\n",
      "    Value:  222222\n",
      "    Value:  223223\n",
      "    Value:  224224\n",
      "    Value:  225225\n",
      "    Value:  226226\n",
      "    Value:  227227\n",
      "    Value:  228228\n",
      "    Value:  229229\n",
      "    Value:  230230\n",
      "    Value:  231231\n",
      "    Value:  232232\n",
      "    Value:  233233\n",
      "    Value:  234234\n",
      "    Value:  235235\n",
      "    Value:  236236\n",
      "    Value:  237237\n",
      "    Value:  238238\n",
      "    Value:  239239\n",
      "    Value:  240240\n",
      "    Value:  241241\n",
      "    Value:  242242\n",
      "    Value:  243243\n",
      "    Value:  244244\n",
      "    Value:  245245\n",
      "    Value:  246246\n",
      "    Value:  247247\n",
      "    Value:  248248\n",
      "    Value:  249249\n",
      "    Value:  250250\n",
      "    Value:  251251\n",
      "    Value:  252252\n",
      "    Value:  253253\n",
      "    Value:  254254\n",
      "    Value:  255255\n",
      "    Value:  256256\n",
      "    Value:  257257\n",
      "    Value:  258258\n",
      "    Value:  259259\n",
      "    Value:  260260\n",
      "    Value:  261261\n",
      "    Value:  262262\n",
      "    Value:  263263\n",
      "    Value:  264264\n",
      "    Value:  265265\n",
      "    Value:  266266\n",
      "    Value:  267267\n",
      "    Value:  268268\n",
      "    Value:  269269\n",
      "    Value:  270270\n",
      "    Value:  271271\n",
      "    Value:  272272\n",
      "    Value:  273273\n",
      "    Value:  274274\n",
      "    Value:  275275\n",
      "    Value:  276276\n",
      "    Value:  277277\n",
      "    Value:  278278\n",
      "    Value:  279279\n",
      "    Value:  280280\n",
      "    Value:  281281\n",
      "    Value:  282282\n",
      "    Value:  283283\n",
      "    Value:  284284\n",
      "    Value:  285285\n",
      "    Value:  286286\n",
      "    Value:  287287\n",
      "    Value:  288288\n",
      "    Value:  289289\n",
      "    Value:  290290\n",
      "    Value:  291291\n",
      "    Value:  292292\n",
      "    Value:  293293\n",
      "    Value:  294294\n",
      "    Value:  295295\n",
      "    Value:  296296\n",
      "    Value:  297297\n",
      "    Value:  298298\n",
      "    Value:  299299\n",
      "    Final Value:  300300.0\n",
      "\n",
      "line:  852101-903928\n",
      "initial and final_values: 852852.0 903903.0\n",
      "    Value:  852852.0\n",
      "start and end points:  852 903\n",
      "    Value:  853853\n",
      "    Value:  854854\n",
      "    Value:  855855\n",
      "    Value:  856856\n",
      "    Value:  857857\n",
      "    Value:  858858\n",
      "    Value:  859859\n",
      "    Value:  860860\n",
      "    Value:  861861\n",
      "    Value:  862862\n",
      "    Value:  863863\n",
      "    Value:  864864\n",
      "    Value:  865865\n",
      "    Value:  866866\n",
      "    Value:  867867\n",
      "    Value:  868868\n",
      "    Value:  869869\n",
      "    Value:  870870\n",
      "    Value:  871871\n",
      "    Value:  872872\n",
      "    Value:  873873\n",
      "    Value:  874874\n",
      "    Value:  875875\n",
      "    Value:  876876\n",
      "    Value:  877877\n",
      "    Value:  878878\n",
      "    Value:  879879\n",
      "    Value:  880880\n",
      "    Value:  881881\n",
      "    Value:  882882\n",
      "    Value:  883883\n",
      "    Value:  884884\n",
      "    Value:  885885\n",
      "    Value:  886886\n",
      "    Value:  887887\n",
      "    Value:  888888\n",
      "    Value:  889889\n",
      "    Value:  890890\n",
      "    Value:  891891\n",
      "    Value:  892892\n",
      "    Value:  893893\n",
      "    Value:  894894\n",
      "    Value:  895895\n",
      "    Value:  896896\n",
      "    Value:  897897\n",
      "    Value:  898898\n",
      "    Value:  899899\n",
      "    Value:  900900\n",
      "    Value:  901901\n",
      "    Value:  902902\n",
      "    Final Value:  903903.0\n",
      "\n",
      "line:  73-97\n",
      "initial and final_values: 77.0 99.0\n",
      "    Value:  77.0\n",
      "start and end points:  7 9\n",
      "    Value:  88\n",
      "\n",
      "line:  1894-2622\n",
      "initial and final_values: 1818.0 2626.0\n",
      "start and end points:  18 26\n",
      "    Value:  1919\n",
      "    Value:  2020\n",
      "    Value:  2121\n",
      "    Value:  2222\n",
      "    Value:  2323\n",
      "    Value:  2424\n",
      "    Value:  2525\n",
      "\n",
      "line:  58406664-58466933\n",
      "initial and final_values: 58405840.0 58465846.0\n",
      "start and end points:  5840 5846\n",
      "    Value:  58415841\n",
      "    Value:  58425842\n",
      "    Value:  58435843\n",
      "    Value:  58445844\n",
      "    Value:  58455845\n",
      "    Final Value:  58465846.0\n",
      "\n",
      "line:  6767640219-6767697605\n",
      "initial and final_values: 6767667676.0 6767667676.0\n",
      "    Value:  6767667676.0\n",
      "\n",
      "line:  523453-569572\n",
      "initial and final_values: 523523.0 569569.0\n",
      "    Value:  523523.0\n",
      "start and end points:  523 569\n",
      "    Value:  524524\n",
      "    Value:  525525\n",
      "    Value:  526526\n",
      "    Value:  527527\n",
      "    Value:  528528\n",
      "    Value:  529529\n",
      "    Value:  530530\n",
      "    Value:  531531\n",
      "    Value:  532532\n",
      "    Value:  533533\n",
      "    Value:  534534\n",
      "    Value:  535535\n",
      "    Value:  536536\n",
      "    Value:  537537\n",
      "    Value:  538538\n",
      "    Value:  539539\n",
      "    Value:  540540\n",
      "    Value:  541541\n",
      "    Value:  542542\n",
      "    Value:  543543\n",
      "    Value:  544544\n",
      "    Value:  545545\n",
      "    Value:  546546\n",
      "    Value:  547547\n",
      "    Value:  548548\n",
      "    Value:  549549\n",
      "    Value:  550550\n",
      "    Value:  551551\n",
      "    Value:  552552\n",
      "    Value:  553553\n",
      "    Value:  554554\n",
      "    Value:  555555\n",
      "    Value:  556556\n",
      "    Value:  557557\n",
      "    Value:  558558\n",
      "    Value:  559559\n",
      "    Value:  560560\n",
      "    Value:  561561\n",
      "    Value:  562562\n",
      "    Value:  563563\n",
      "    Value:  564564\n",
      "    Value:  565565\n",
      "    Value:  566566\n",
      "    Value:  567567\n",
      "    Value:  568568\n",
      "    Final Value:  569569.0\n",
      "\n",
      "line:  7979723815-7979848548\n",
      "initial and final_values: 7979779797.0 7979879798.0\n",
      "    Value:  7979779797.0\n",
      "start and end points:  79797 79798\n",
      "\n",
      "line:  149-216\n",
      "Skipping line: 149-216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54641809925.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzle_input = \"\"\"67562556-67743658,62064792-62301480,4394592-4512674,3308-4582,69552998-69828126,9123-12332,1095-1358,23-48,294-400,3511416-3689352,1007333-1150296,2929221721-2929361280,309711-443410,2131524-2335082,81867-97148,9574291560-9574498524,648635477-648670391,1-18,5735-8423,58-72,538-812,698652479-698760276,727833-843820,15609927-15646018,1491-1766,53435-76187,196475-300384,852101-903928,73-97,1894-2622,58406664-58466933,6767640219-6767697605,523453-569572,7979723815-7979848548,149-216\"\"\"\n",
    "#puzzle_input = \"\"\"3308-4582\"\"\"\n",
    "def digest_input_day2(puzzle_input):\n",
    "    puzzle_input = puzzle_input.split(\",\")\n",
    "    total = 0\n",
    "    for line in puzzle_input:\n",
    "        print(\"line: \",line)\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            start, end = line.split(\"-\")\n",
    "        num_digits_start = len(str(start))\n",
    "        num_digits_end = len(str(end))\n",
    "        if(num_digits_start%2==1):\n",
    "            start = \"1\"+\"0\"*((num_digits_start))\n",
    "            num_digits_start +=1\n",
    "        if(num_digits_end%2==1):\n",
    "            end = \"9\"*(num_digits_end-1)\n",
    "            num_digits_end -=1\n",
    "        if(int(start)>int(end)):\n",
    "            print(f\"Skipping line: {line}\")\n",
    "            continue\n",
    "        initial_val = int(start[:int(len(start)/2)])*(10**(len(start)/2)+1)\n",
    "        final_val = int(end[:int(len(end)/2)])*(10**(len(end)/2)+1)\n",
    "        print(\"initial and final_values:\" ,initial_val,final_val)\n",
    "        if(initial_val>=int(start) and initial_val<=int(end)):\n",
    "            total+=initial_val\n",
    "            print(\"    Value: \",initial_val)\n",
    "        if(final_val==initial_val):\n",
    "            print()\n",
    "            continue\n",
    "\n",
    "        start_point = int(start[:int(len(start)/2)])\n",
    "        end_point = int(end[:int(len(end)/2)])\n",
    "        print(\"start and end points: \",start_point,end_point)\n",
    "        for i in range(start_point+1,end_point):\n",
    "            val=i*(10**(math.floor(math.log10(i+.1))+1)+1)\n",
    "            total+=val\n",
    "            print(\"    Value: \",val)\n",
    "        if(final_val>=int(start) and final_val<=int(end)):\n",
    "            print(\"    Final Value: \",final_val)\n",
    "            total+=final_val\n",
    "        print()\n",
    "    return total\n",
    "digest_input_day2(puzzle_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8037f050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line:  67562556-67743658\n",
      "67566756\n",
      "67576757\n",
      "67586758\n",
      "67596759\n",
      "67606760\n",
      "67616761\n",
      "67626762\n",
      "67636763\n",
      "67646764\n",
      "67656765\n",
      "67666766\n",
      "67676767\n",
      "67686768\n",
      "67696769\n",
      "67706770\n",
      "67716771\n",
      "67726772\n",
      "67736773\n",
      "line:  62064792-62301480\n",
      "62066206\n",
      "62076207\n",
      "62086208\n",
      "62096209\n",
      "62106210\n",
      "62116211\n",
      "62126212\n",
      "62136213\n",
      "62146214\n",
      "62156215\n",
      "62166216\n",
      "62176217\n",
      "62186218\n",
      "62196219\n",
      "62206220\n",
      "62216221\n",
      "62226222\n",
      "62236223\n",
      "62246224\n",
      "62256225\n",
      "62266226\n",
      "62276227\n",
      "62286228\n",
      "62296229\n",
      "line:  4394592-4512674\n",
      "4444444\n",
      "line:  3308-4582\n",
      "3333\n",
      "3434\n",
      "3535\n",
      "3636\n",
      "3737\n",
      "3838\n",
      "3939\n",
      "4040\n",
      "4141\n",
      "4242\n",
      "4343\n",
      "4444\n",
      "4545\n",
      "line:  69552998-69828126\n",
      "69556955\n",
      "69566956\n",
      "69576957\n",
      "69586958\n",
      "69596959\n",
      "69606960\n",
      "69616961\n",
      "69626962\n",
      "69636963\n",
      "69646964\n",
      "69656965\n",
      "69666966\n",
      "69676967\n",
      "69686968\n",
      "69696969\n",
      "69706970\n",
      "69716971\n",
      "69726972\n",
      "69736973\n",
      "69746974\n",
      "69756975\n",
      "69766976\n",
      "69776977\n",
      "69786978\n",
      "69796979\n",
      "69806980\n",
      "69816981\n",
      "69826982\n",
      "line:  9123-12332\n",
      "9191\n",
      "9292\n",
      "9393\n",
      "9494\n",
      "9595\n",
      "9696\n",
      "9797\n",
      "9898\n",
      "9999\n",
      "11111\n",
      "line:  1095-1358\n",
      "1111\n",
      "1212\n",
      "1313\n",
      "line:  23-48\n",
      "33\n",
      "44\n",
      "line:  294-400\n",
      "333\n",
      "line:  3511416-3689352\n",
      "line:  1007333-1150296\n",
      "1111111\n",
      "line:  2929221721-2929361280\n",
      "2929229292\n",
      "2929292929\n",
      "2929329293\n",
      "line:  309711-443410\n",
      "310310\n",
      "311311\n",
      "312312\n",
      "313131\n",
      "313313\n",
      "314314\n",
      "315315\n",
      "316316\n",
      "317317\n",
      "318318\n",
      "319319\n",
      "320320\n",
      "321321\n",
      "322322\n",
      "323232\n",
      "323323\n",
      "324324\n",
      "325325\n",
      "326326\n",
      "327327\n",
      "328328\n",
      "329329\n",
      "330330\n",
      "331331\n",
      "332332\n",
      "333333\n",
      "334334\n",
      "335335\n",
      "336336\n",
      "337337\n",
      "338338\n",
      "339339\n",
      "340340\n",
      "341341\n",
      "342342\n",
      "343343\n",
      "343434\n",
      "344344\n",
      "345345\n",
      "346346\n",
      "347347\n",
      "348348\n",
      "349349\n",
      "350350\n",
      "351351\n",
      "352352\n",
      "353353\n",
      "353535\n",
      "354354\n",
      "355355\n",
      "356356\n",
      "357357\n",
      "358358\n",
      "359359\n",
      "360360\n",
      "361361\n",
      "362362\n",
      "363363\n",
      "363636\n",
      "364364\n",
      "365365\n",
      "366366\n",
      "367367\n",
      "368368\n",
      "369369\n",
      "370370\n",
      "371371\n",
      "372372\n",
      "373373\n",
      "373737\n",
      "374374\n",
      "375375\n",
      "376376\n",
      "377377\n",
      "378378\n",
      "379379\n",
      "380380\n",
      "381381\n",
      "382382\n",
      "383383\n",
      "383838\n",
      "384384\n",
      "385385\n",
      "386386\n",
      "387387\n",
      "388388\n",
      "389389\n",
      "390390\n",
      "391391\n",
      "392392\n",
      "393393\n",
      "393939\n",
      "394394\n",
      "395395\n",
      "396396\n",
      "397397\n",
      "398398\n",
      "399399\n",
      "400400\n",
      "401401\n",
      "402402\n",
      "403403\n",
      "404040\n",
      "404404\n",
      "405405\n",
      "406406\n",
      "407407\n",
      "408408\n",
      "409409\n",
      "410410\n",
      "411411\n",
      "412412\n",
      "413413\n",
      "414141\n",
      "414414\n",
      "415415\n",
      "416416\n",
      "417417\n",
      "418418\n",
      "419419\n",
      "420420\n",
      "421421\n",
      "422422\n",
      "423423\n",
      "424242\n",
      "424424\n",
      "425425\n",
      "426426\n",
      "427427\n",
      "428428\n",
      "429429\n",
      "430430\n",
      "431431\n",
      "432432\n",
      "433433\n",
      "434343\n",
      "434434\n",
      "435435\n",
      "436436\n",
      "437437\n",
      "438438\n",
      "439439\n",
      "440440\n",
      "441441\n",
      "442442\n",
      "line:  2131524-2335082\n",
      "2222222\n",
      "line:  81867-97148\n",
      "88888\n",
      "line:  9574291560-9574498524\n",
      "9574295742\n",
      "9574395743\n",
      "9574495744\n",
      "line:  648635477-648670391\n",
      "648648648\n",
      "line:  1-18\n",
      "11\n",
      "line:  5735-8423\n",
      "5757\n",
      "5858\n",
      "5959\n",
      "6060\n",
      "6161\n",
      "6262\n",
      "6363\n",
      "6464\n",
      "6565\n",
      "6666\n",
      "6767\n",
      "6868\n",
      "6969\n",
      "7070\n",
      "7171\n",
      "7272\n",
      "7373\n",
      "7474\n",
      "7575\n",
      "7676\n",
      "7777\n",
      "7878\n",
      "7979\n",
      "8080\n",
      "8181\n",
      "8282\n",
      "8383\n",
      "line:  58-72\n",
      "66\n",
      "line:  538-812\n",
      "555\n",
      "666\n",
      "777\n",
      "line:  698652479-698760276\n",
      "698698698\n",
      "line:  727833-843820\n",
      "728728\n",
      "729729\n",
      "730730\n",
      "731731\n",
      "732732\n",
      "733733\n",
      "734734\n",
      "735735\n",
      "736736\n",
      "737373\n",
      "737737\n",
      "738738\n",
      "739739\n",
      "740740\n",
      "741741\n",
      "742742\n",
      "743743\n",
      "744744\n",
      "745745\n",
      "746746\n",
      "747474\n",
      "747747\n",
      "748748\n",
      "749749\n",
      "750750\n",
      "751751\n",
      "752752\n",
      "753753\n",
      "754754\n",
      "755755\n",
      "756756\n",
      "757575\n",
      "757757\n",
      "758758\n",
      "759759\n",
      "760760\n",
      "761761\n",
      "762762\n",
      "763763\n",
      "764764\n",
      "765765\n",
      "766766\n",
      "767676\n",
      "767767\n",
      "768768\n",
      "769769\n",
      "770770\n",
      "771771\n",
      "772772\n",
      "773773\n",
      "774774\n",
      "775775\n",
      "776776\n",
      "777777\n",
      "778778\n",
      "779779\n",
      "780780\n",
      "781781\n",
      "782782\n",
      "783783\n",
      "784784\n",
      "785785\n",
      "786786\n",
      "787787\n",
      "787878\n",
      "788788\n",
      "789789\n",
      "790790\n",
      "791791\n",
      "792792\n",
      "793793\n",
      "794794\n",
      "795795\n",
      "796796\n",
      "797797\n",
      "797979\n",
      "798798\n",
      "799799\n",
      "800800\n",
      "801801\n",
      "802802\n",
      "803803\n",
      "804804\n",
      "805805\n",
      "806806\n",
      "807807\n",
      "808080\n",
      "808808\n",
      "809809\n",
      "810810\n",
      "811811\n",
      "812812\n",
      "813813\n",
      "814814\n",
      "815815\n",
      "816816\n",
      "817817\n",
      "818181\n",
      "818818\n",
      "819819\n",
      "820820\n",
      "821821\n",
      "822822\n",
      "823823\n",
      "824824\n",
      "825825\n",
      "826826\n",
      "827827\n",
      "828282\n",
      "828828\n",
      "829829\n",
      "830830\n",
      "831831\n",
      "832832\n",
      "833833\n",
      "834834\n",
      "835835\n",
      "836836\n",
      "837837\n",
      "838383\n",
      "838838\n",
      "839839\n",
      "840840\n",
      "841841\n",
      "842842\n",
      "line:  15609927-15646018\n",
      "15611561\n",
      "15621562\n",
      "15631563\n",
      "15641564\n",
      "line:  1491-1766\n",
      "1515\n",
      "1616\n",
      "1717\n",
      "line:  53435-76187\n",
      "55555\n",
      "66666\n",
      "line:  196475-300384\n",
      "197197\n",
      "198198\n",
      "199199\n",
      "200200\n",
      "201201\n",
      "202020\n",
      "202202\n",
      "203203\n",
      "204204\n",
      "205205\n",
      "206206\n",
      "207207\n",
      "208208\n",
      "209209\n",
      "210210\n",
      "211211\n",
      "212121\n",
      "212212\n",
      "213213\n",
      "214214\n",
      "215215\n",
      "216216\n",
      "217217\n",
      "218218\n",
      "219219\n",
      "220220\n",
      "221221\n",
      "222222\n",
      "223223\n",
      "224224\n",
      "225225\n",
      "226226\n",
      "227227\n",
      "228228\n",
      "229229\n",
      "230230\n",
      "231231\n",
      "232232\n",
      "232323\n",
      "233233\n",
      "234234\n",
      "235235\n",
      "236236\n",
      "237237\n",
      "238238\n",
      "239239\n",
      "240240\n",
      "241241\n",
      "242242\n",
      "242424\n",
      "243243\n",
      "244244\n",
      "245245\n",
      "246246\n",
      "247247\n",
      "248248\n",
      "249249\n",
      "250250\n",
      "251251\n",
      "252252\n",
      "252525\n",
      "253253\n",
      "254254\n",
      "255255\n",
      "256256\n",
      "257257\n",
      "258258\n",
      "259259\n",
      "260260\n",
      "261261\n",
      "262262\n",
      "262626\n",
      "263263\n",
      "264264\n",
      "265265\n",
      "266266\n",
      "267267\n",
      "268268\n",
      "269269\n",
      "270270\n",
      "271271\n",
      "272272\n",
      "272727\n",
      "273273\n",
      "274274\n",
      "275275\n",
      "276276\n",
      "277277\n",
      "278278\n",
      "279279\n",
      "280280\n",
      "281281\n",
      "282282\n",
      "282828\n",
      "283283\n",
      "284284\n",
      "285285\n",
      "286286\n",
      "287287\n",
      "288288\n",
      "289289\n",
      "290290\n",
      "291291\n",
      "292292\n",
      "292929\n",
      "293293\n",
      "294294\n",
      "295295\n",
      "296296\n",
      "297297\n",
      "298298\n",
      "299299\n",
      "300300\n",
      "line:  852101-903928\n",
      "852852\n",
      "853853\n",
      "854854\n",
      "855855\n",
      "856856\n",
      "857857\n",
      "858585\n",
      "858858\n",
      "859859\n",
      "860860\n",
      "861861\n",
      "862862\n",
      "863863\n",
      "864864\n",
      "865865\n",
      "866866\n",
      "867867\n",
      "868686\n",
      "868868\n",
      "869869\n",
      "870870\n",
      "871871\n",
      "872872\n",
      "873873\n",
      "874874\n",
      "875875\n",
      "876876\n",
      "877877\n",
      "878787\n",
      "878878\n",
      "879879\n",
      "880880\n",
      "881881\n",
      "882882\n",
      "883883\n",
      "884884\n",
      "885885\n",
      "886886\n",
      "887887\n",
      "888888\n",
      "889889\n",
      "890890\n",
      "891891\n",
      "892892\n",
      "893893\n",
      "894894\n",
      "895895\n",
      "896896\n",
      "897897\n",
      "898898\n",
      "898989\n",
      "899899\n",
      "900900\n",
      "901901\n",
      "902902\n",
      "903903\n",
      "line:  73-97\n",
      "77\n",
      "88\n",
      "line:  1894-2622\n",
      "1919\n",
      "2020\n",
      "2121\n",
      "2222\n",
      "2323\n",
      "2424\n",
      "2525\n",
      "line:  58406664-58466933\n",
      "58415841\n",
      "58425842\n",
      "58435843\n",
      "58445844\n",
      "58455845\n",
      "58465846\n",
      "line:  6767640219-6767697605\n",
      "6767667676\n",
      "6767676767\n",
      "line:  523453-569572\n",
      "523523\n",
      "524524\n",
      "525252\n",
      "525525\n",
      "526526\n",
      "527527\n",
      "528528\n",
      "529529\n",
      "530530\n",
      "531531\n",
      "532532\n",
      "533533\n",
      "534534\n",
      "535353\n",
      "535535\n",
      "536536\n",
      "537537\n",
      "538538\n",
      "539539\n",
      "540540\n",
      "541541\n",
      "542542\n",
      "543543\n",
      "544544\n",
      "545454\n",
      "545545\n",
      "546546\n",
      "547547\n",
      "548548\n",
      "549549\n",
      "550550\n",
      "551551\n",
      "552552\n",
      "553553\n",
      "554554\n",
      "555555\n",
      "556556\n",
      "557557\n",
      "558558\n",
      "559559\n",
      "560560\n",
      "561561\n",
      "562562\n",
      "563563\n",
      "564564\n",
      "565565\n",
      "565656\n",
      "566566\n",
      "567567\n",
      "568568\n",
      "569569\n",
      "line:  7979723815-7979848548\n",
      "7979779797\n",
      "7979797979\n",
      "line:  149-216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73694270688"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzle_input = \"\"\"67562556-67743658,62064792-62301480,4394592-4512674,3308-4582,69552998-69828126,9123-12332,1095-1358,23-48,294-400,3511416-3689352,1007333-1150296,2929221721-2929361280,309711-443410,2131524-2335082,81867-97148,9574291560-9574498524,648635477-648670391,1-18,5735-8423,58-72,538-812,698652479-698760276,727833-843820,15609927-15646018,1491-1766,53435-76187,196475-300384,852101-903928,73-97,1894-2622,58406664-58466933,6767640219-6767697605,523453-569572,7979723815-7979848548,149-216\"\"\"\n",
    "#puzzle_input = \"\"\"3308-4582\"\"\"\n",
    "def digest_input_day2(puzzle_input):\n",
    "    puzzle_input = puzzle_input.split(\",\")\n",
    "    total = 0\n",
    "    for line in puzzle_input:\n",
    "        print(\"line: \",line)\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            start, end = line.split(\"-\")\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        for i in repeat_set:\n",
    "            if(i>=start and i<=end):\n",
    "                total+=i\n",
    "                print(i)\n",
    "            if(i>end):\n",
    "                break\n",
    "    return total\n",
    "digest_input_day2(puzzle_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "501d74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"987654321111111\n",
    "811111111111119\n",
    "234234234234278\n",
    "818181911112111\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "556f8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_set = []\n",
    "for i in range(1,10):\n",
    "    repeat_set.append(int(str(i)*2))\n",
    "    repeat_set.append(int(str(i)*3))\n",
    "    repeat_set.append(int(str(i)*4))\n",
    "    repeat_set.append(int(str(i)*5))\n",
    "    repeat_set.append(int(str(i)*6))\n",
    "    repeat_set.append(int(str(i)*7))\n",
    "    repeat_set.append(int(str(i)*8))\n",
    "    repeat_set.append(int(str(i)*9))\n",
    "for i in range(10,100):\n",
    "    repeat_set.append(int(str(i)*2))\n",
    "    repeat_set.append(int(str(i)*3))\n",
    "    repeat_set.append(int(str(i)*4))\n",
    "    repeat_set.append(int(str(i)*5))\n",
    "for i in range(100,1000):\n",
    "    repeat_set.append(int(str(i)*2))\n",
    "    repeat_set.append(int(str(i)*3))\n",
    "for i in range(1000,100000):\n",
    "    repeat_set.append(int(str(i)*2))\n",
    "    \n",
    "\n",
    "repeat_set = list(set(repeat_set))\n",
    "repeat_set.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9d7abde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6767676767 in repeat_set_double_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f082c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "26c87940",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_set_double_only = []\n",
    "for i in range(1,10):\n",
    "    repeat_set_double_only.append(int(str(i)*2))\n",
    "for i in range(10,100):\n",
    "    repeat_set_double_only.append(int(str(i)*2))\n",
    "for i in range(100,1000):\n",
    "    repeat_set_double_only.append(int(str(i)*2))\n",
    "\n",
    "for i in range(1000,100000):\n",
    "    repeat_set_double_only.append(int(str(i)*2))\n",
    "\n",
    "repeat_set_double_only = list(set(repeat_set_double_only))\n",
    "repeat_set_double_only.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4a541e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101087"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repeat_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40243537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333303333"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67562556-67743658,\n",
    "62064792-62301480,\n",
    "4394592-4512674,\n",
    "3308-4582,\n",
    "69552998-69828126,\n",
    "9123-12332,\n",
    "1095-1358,\n",
    "23-48,\n",
    "294-400,\n",
    "3511416-3689352,\n",
    "1007333-1150296,\n",
    "2929221721-2929361280,\n",
    "309711-443410,\n",
    "2131524-2335082,\n",
    "81867-97148,\n",
    "9574291560-9574498524,\n",
    "648635477-648670391,\n",
    "1-18,\n",
    "5735-8423,\n",
    "58-72,\n",
    "538-812,\n",
    "698652479-698760276,\n",
    "727833-843820,\n",
    "15609927-15646018,\n",
    "1491-1766,\n",
    "53435-76187,\n",
    "196475-300384,\n",
    "852101-903928,\n",
    "73-97,\n",
    "1894-2622,\n",
    "58406664-58466933,\n",
    "6767640219-6767697605,\n",
    "523453-569572,\n",
    "7979723815-7979848548,\n",
    "149-216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fac8d16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor(math.log10(999+.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bd74e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"3322343713826221125922247222221263232222632332333222231223221432225352522227622122311323531262273513\n",
    "5533541345563534455432555454434414411366573335634663523353143544535254433516534123415359511733347333\n",
    "5532443324543354334233535245352312442222335133745252534323323433314215153243323345352424242533443324\n",
    "3314233525331533334433356655344332512114344543343333333735333552355224322331352586346366445245345344\n",
    "2222222131233223213122432212242222223222222222222331323313222221221423122226231623122133212223321222\n",
    "4466395697424268345845444435653448432633445644934252297266844237444446338517598273746441644874441323\n",
    "3153123332212223122222323521322234131641332252236124424121222627323232222223432212242333232223223132\n",
    "2122244442221334322121122222442233221211211122322222243322123422242113115214133241122122245112212242\n",
    "2222231611222212122222122223132223322313222122421522222222122212122371121222322422321221222222224222\n",
    "5674895338787443475556575582778563243436587758457866742534475636934447667764856666465344545567423855\n",
    "2156321142229122521321224222222125124232121212222223223252222122252312222542242322171222225222222242\n",
    "2336345434222232222122433221242521212661522222252273543432333424332452225233222422321254132325324332\n",
    "4222242242122467322114245222222222425172342243821263244222222252222132222264222122623222222222224242\n",
    "2222529222522455731222227312245221216422122262222222212221222122242283312222222233322212226527222122\n",
    "6455965542499962595336742431688552236644961226666585285288436218255986786648444226469852596728929545\n",
    "2212222323222112212212212224122151222272352132342221223122122222222262212312122221222321221221322222\n",
    "8543956666456338383755774643576443747477564677476656854678655646678467375565833648547658448963567754\n",
    "2253552574354533643435521322242242222432512442224624542825536754122224752353423345242263351252543363\n",
    "1222922632227527122625232217322332451222124222221312573122632322423212122331542332223111292533322312\n",
    "3333324317536223433334335535365133333333425366333333322262325213233323456353333332632342323153533333\n",
    "3351222212222422322221242211212222221622312212213312223223262142252322212213222222321221123212223213\n",
    "4354844334533334337634463543532364433458737532443345443345134353344724418243335466453796344333316643\n",
    "4224222222221222422422322123124122332142125122232224332343232122222321224113222322212361211232432322\n",
    "3182842453254222869722363523762213224424432426223185562252252333282222226315852134463632283225726122\n",
    "4212714216262222224242232367333523422722422425632323224212611422231513212262657313545212443632681292\n",
    "3534144333352443333433323443333323333333243433533323314333434333333333333322543333343233843434336234\n",
    "3455363263344442447434444442443764444443444433662434233343364643463555442543352355434564374431433334\n",
    "3321311232232223122322231223222422222454222412222232232122232232224123222221224252322232324333322312\n",
    "2413454752624343567736343132164652177257215635272753552754134747357253347721231464334615317351241189\n",
    "4322232322222333241221323123422322224423342422316233224223133322217432223317221222322222213322312223\n",
    "4334854253984544832143242262343423334426383333343473947433322956732252612253412294242345224124435584\n",
    "4441435744541225333943242263235382245445353346343434243832484834342153856333323743743434133443393264\n",
    "3333414353522533574432633331383454132323354332435535253333124232324315565444333343313432224333535323\n",
    "3332333333342221132322415122233233232228123222322322213132122431522332223211212222323224242114221334\n",
    "3786344916554264365455555543461137644494552237543554333465636626223332422332363564544456673366825533\n",
    "5677473617549554646576477928762565728861786968737498265818674767667593729428778588766528737657963375\n",
    "4465354243244445652628552254554455557455423523536266222545543663666364566454555465573632556258494584\n",
    "2122211122431522122222222123222122222122222222222222212122222222221222222321132222222332422221222232\n",
    "4333124133412132343414142314141233121331322234112131114221333311241234232241221424311444233443456789\n",
    "3353333324645345155522132334634233134334223331354553342433233337345335636623233233355454532143555544\n",
    "2145253131224214231113132523233343221232349142333212233323223332231234223122122331223132433252132112\n",
    "1323222831237432244524333351373322233431222222221137133532243232114565523323222126635341223235323321\n",
    "3542744451535546645262487844583345653453276864536582563548225722243448642433483463335489586757262658\n",
    "2122212212222432222242212222132821112122222222222233352243232362212222222123232132424322122232322122\n",
    "4222212421121121222272212413717172225221231253131366422265241222245311224242327222212222124212222227\n",
    "4447433545333465353424333526624335635544334413232355335543354458433334451344445454323633533533232436\n",
    "3333335323333433634333223465333232324223354343233327332352313543642433312233443435452256313227334363\n",
    "2344234322523233121332522344222531245233411325242122322632224252333222338323323322314341312123322222\n",
    "7323262315255623222366222272751463671637332322233447235253535123662223343134342222453532646133322233\n",
    "7334422636522324432242226442223485334327113224334451435241222132323443243321134312124413322425433144\n",
    "2325243243211834331323434542335222421724123222232522545122424224242233223132322253443222222223322931\n",
    "2212221222323322222231322221232212131122222324223632222223324112124222322123221233222434324211223232\n",
    "7333336224734175224282243222323222343122244226132121121231223224422332322422223232462232313223237232\n",
    "9637467524135452556787687633376634365457446673438435736567565239556263774248443427677564451555251334\n",
    "1323332321112222221323232231461221121132232232222139111323222211231413223332221422112232322621262133\n",
    "3232224443222324433312242142424224132522222133224242244442221332214221222215125315221432542314221222\n",
    "2223263433443233412523245332242245424434342133425323213233221332433324432344242224242434245332223453\n",
    "1232323112342223232433228233123432344452212268224344423323332244261425324212322213233442213832324413\n",
    "5734129645333473631659759634354479432696372564343357258637945665659636578239394546795281492573338493\n",
    "6673456645624542763235643454334414535554564445465543822441568442143535452536344343544236364444436435\n",
    "3474445456345652245535643353635242773253263554555737222643436664514524534554255455246444553415373434\n",
    "2443353345236342444238934633314414434744383132434444333335343443363234433233633353333323334343226343\n",
    "2443433522353433144324431353334313343433533533444323323323463523257336245236433343453233434353232442\n",
    "1222212451321222131321222212362121112222212216222211322352425123231212222221142244112322221222222422\n",
    "2332341313443234215323443325332243225225122333342232213221233322132322334213332211324315242422122233\n",
    "5553332124341232255222211321513223431352442214314623262243133223423342224225532243222532152223432224\n",
    "2432272328277132311283622224266424492334864461412526252839633313123972262224323286142234161278212149\n",
    "4122121333232427112322262132423332235333323332522333323333553324221313333382312324233333322352432332\n",
    "3122435362544344433334666644474344424315344314333634433443444366344462454466232445644433446342235564\n",
    "4695855477579365657968467975546445475664557856687665635296969757665566566625845565666765748546795764\n",
    "3334414323531467455573785553754539554365838377337554353544467376573689335657588252433463835728633556\n",
    "2332224312122222322312222221222122722122212322222122121232332132212323212322123212223222223221221223\n",
    "2123314432235443336222335436247266634212243124241324332123431322843223563223536255125336232237323321\n",
    "2424722334544144122333324343435344431562235185215334143443343214324412532513242643222342325241354224\n",
    "4434133446332243332523736353233323342488123333333363353333343343235231212933333393333243233432355331\n",
    "1767437687556656859666968937667653957888526658723348969546277283675333664734464776743273527617393351\n",
    "2121421436216735211532255522527221252262223334227321125111757551624121222217234242612184112222122622\n",
    "2324363233464334534644242333453343334534533348244453433342152335343622362163335433453263634473633331\n",
    "2224123148521161225226325222572522427424112772221222222122422214222226226226229325222252112242462622\n",
    "4855762986744876557898747454634886656644567363259545663462845954357632526879863645587548645777844653\n",
    "3331445225645446548546232445333445733437454334494374533232354443844672244447234373327744433255634733\n",
    "2251323233132222433212212222231223224222312322342322232122322233122322434223214222123224212222322142\n",
    "4343744443442434343215343443426542524344433454412642445517454343235446422344436442733343414442423644\n",
    "3929433523363261432724434623353265216446774375854434323135533332443573446232343482334523245445325165\n",
    "5425332652227272274321344753442245114243352322322334533243323262264251232323233467422322642142717846\n",
    "2321221832473382323122123383128235122333222524235232223113243342332533222251132622232323243233325311\n",
    "1334122463333222852243223432222222225653363223313338612319524243522353643343434242447352242222222231\n",
    "3332334314233232433241433231334312338223234231423324333212243332333333223233522223324323533232243212\n",
    "3426392233433336424338341444234332534853895444347553454643486416386342794794393283354234595456222243\n",
    "2322241433222424324251172324444633124222232322342214424332322422234432114442222333442322625145524414\n",
    "2222122332223212131322331611253522322132222212233212122351233223133122322232225232342523252213123431\n",
    "3534144555415534766756854455465176347378748255555485462455537453535155644625358284384765242546464483\n",
    "6787289764377776637564746767796374872275625635567945678437794854698573836444993677464685367674547484\n",
    "4144246334424224244243147534443443344141332522323443333624432422341434343124334235245441414244543334\n",
    "4923243425223223332248542222262242523323253252652923212634422223313343333336323532333324352263348222\n",
    "2542214432227362255334724341422352422412434235523523142432454444121236132244445434543325643542532443\n",
    "4611333333422244422431423233323334335342537274473343434433455232236244442341333232334243334443433343\n",
    "5954968558692569335538736485864574795539545439567559555985645369577945456966646697956986585554549346\n",
    "4437325535333443474324415294624643444544424244872443344442433825444442344421842742312942432826443333\n",
    "2222621114422222222222222231221322221221122211272243112231442421122222222222221412241321224222212321\n",
    "2123225222212222232212242223222222422442232432233222242414235412322222222222323226422123236313236222\n",
    "3223614234237332232532565331532242342361313324236225533537525223252345322235213355331243234223221435\n",
    "2423247341123224313421353233511234224313322536235523312243423332253335232244213312462634411243333235\n",
    "2222322321233213212121122222551111223232321315222222232222132321322223323222323123313215221223352213\n",
    "2224222421223221213312222242322114212131342132336132222123214141353272221343235235722334321522322322\n",
    "2544452338454357335126447274321894425343424444412356324224446334495533815233525734585535295444152314\n",
    "6554528442555663773732364734466653445335625735266365355453453374443544435432525344152666633464345436\n",
    "6733774447535764547154474865463485852567455763354642655645575444585737355346475532554684644645435358\n",
    "3434946339133134443333943335654394534323344336834533352343343345225534453433233344343367443325444534\n",
    "5413321455433855858383393293238536645882256354355658832415422519255472924853541352897566577923446583\n",
    "3333123554573544451332332434333211355132223725446434534223344534233325254321322433432243444451433432\n",
    "3332932245722332353123332351712533312256337233453333333334331332332334342343433234534439343323335324\n",
    "2225213322222252422222222222132222222222222432221122222229124322222242221333222235312122212212122122\n",
    "5233333323233313232733213243133233323332142523322333223321232223333263322333223223333236323223313233\n",
    "3242566235565746353334375364665356862534534544323356643423322532414365455446622692154445375434354445\n",
    "1113232223634521512131242415222325342256222223132122222224322543635452332442522122315262222222225113\n",
    "5439444446444456322443656238425334243344444354433336453334465444454434434664443556354243444334142455\n",
    "4422322223213233542232232363332244333332422322533413232313323231224155222333222412143235232231344221\n",
    "1323221323223243842221223222232233233212322323324223222233324221323212443314433552312552322433333322\n",
    "5323254535116754443155743257644322442566445354434533365135453424675456653663312614624337487456666125\n",
    "1624543384333312342833423125313254122125332635232822244334233154442322733233313523224268433443152244\n",
    "8634854444465287768227494734452354335446475322361595956756142535446526132254473453757366353524563658\n",
    "4215342614212435592333523332112444442223424424323274222229422226224253513262218343164143622324412213\n",
    "2225216222323256224333331232323312142322433223233352423321222433725123222332223132232335326232123242\n",
    "3221221112212332222221211221212132211124322322532221812233222822452212312222233322422112343221222122\n",
    "2221141312222323332422222321222223223221233313132223421322323121321234451112311336223112213223223222\n",
    "4536625635551656154644536237447535383646254646223665353645759637563545742455474259453643657663346426\n",
    "2321741222453212122222552242632222242222212225535224415222231552252251525444377223452542121425411254\n",
    "5753643735425954243423273173542336143494794452443273514375233435244328457526334521466948353542245253\n",
    "2312252322231212222222112225212323123221222213232222222412741213222222222222232222222222231222141323\n",
    "2222222212212222322241221242242422222222322224223242353122212122221221123215122332215221222114212311\n",
    "1242121142412152223212222222232222123122224212222222222222122222121212221142122221126221241222122232\n",
    "2221122242132241624252212122244222223241222124215432122212221222221213132222442121232221225222222222\n",
    "2322222222313222223222221322232312322434413211121212312322222233232221134344424321242322223133222232\n",
    "2324342133525223342322232222246442243237223332223222323322335122332433243323322323221232453225322312\n",
    "2642712222117522231222352252232472182157427222812227122222322113222582772222227224528221172222823187\n",
    "2361333418333433233323532622332131333332224323333333353333323323342693323633233343433333342333333342\n",
    "4646353556332343564395344464326524415644522344454243321333426412434624444662443647353353674664436542\n",
    "2322222143211122221111322232222133222121221222221132222212222227122222122221262122122222322242222223\n",
    "3221222232322212232224225832323123212231224323622221342122221221222122423223238135326222162115142223\n",
    "2341322422242222322443462222232323422231232223122221623252217342211424324237334222545232324643334224\n",
    "3514331233433433342336223323426431333233343235333432335638362433833253344733236612533423233333131316\n",
    "4241422442122223244722134224332323531132118222246343414332113123231414415413224242123222324323412322\n",
    "2944232632212421243333112232323122331213222331242322123343232224944232321232962222294221221233222722\n",
    "2485585653425555555457445436555242447425146755457354467625545552547464355555315526653252453455553755\n",
    "2231232122121226313322123121221222242621231233312223132321324242213211223322123221121612122222222222\n",
    "4447544736334336444453333346365245434394888333334473537544545355412381443347357353435534534434458355\n",
    "3332522324332223133323212422333312232333124332432222312333222312233213423332213222236331233234233322\n",
    "4576622442517286772238539815575857495348735477589767522467346266265464876742327432543172767777935123\n",
    "4557845228766656474476756668896487385654356575565764748764575494748645656398495485458368655857764796\n",
    "3574665436744137535424625165463234433233522555454534364362136442144454355965543422653364444464643643\n",
    "8923571349384294933583843468334537544363337453644882533335744787444232233384236513133534458656569326\n",
    "3145112222155212221523222422433224522214614154225222232422255143221273211552222332222223222322242321\n",
    "2134331421315222222222132122222322353132412222236112127422223226236322111322313422333222218421222286\n",
    "3212332221211222222223221332211222222112212522212322222522213243122121122223222212313221223122231223\n",
    "3332322431222323325212223226312174113233222123332332323224331223311343331322232212233232322243232213\n",
    "2214712322223242223115222114223244153222212134113222222222222222222242622373213441227272322133315223\n",
    "2443434133334733333337332243333333232323333623451334233333443231533334332313272452332213233733333144\n",
    "2123222222332223222325254323211312223552523222111223222232342222222324224224414424221221422324412242\n",
    "2323453342543523433235432452233353335333263333243232353254335432333343433323234433333333333333343333\n",
    "3984342585247337276344553472527278293553481686424838527263264233772325449343112423554533473367542474\n",
    "2135236433523522423532463521523245434345552414233354152364156525224255534155223532352252536433355632\n",
    "5233242222122312112221523124422323224212252242472212321222231242322322222232212222412122222242622622\n",
    "3473353439332258642425373146393824323645632342432322874284424625675415323143332733328233536383362582\n",
    "4246422442362483246244444443444534424264284322463684444344522214223242224442434243215162445235454144\n",
    "5535534242531463132273111544245244254523544255635211352524621445345455231526626244525553455554143545\n",
    "6745442253135453734327333343332343333433337271532343344532323334452642634144232264532442644343333234\n",
    "5413222352483352383142421531133233321132332223213234323324444232233323523343313223233334332333181433\n",
    "2222212222222232222622112222322221222222222222212221222222222212121221122233422112223222222222231212\n",
    "4234333342433235536443443334333432433333323333424334342144534442433242413423342333332323334333338334\n",
    "2231322225214662422233225222333344244232222322521655923122123263422428566236156124132364224622323232\n",
    "3223322344314233313232232421538425522223342313232342334262234223333224352272323331465324232631232214\n",
    "2232211222221552315233221122315122252223221342332322114311332422121322235321233222322243231232232232\n",
    "2233523932342352333543243526545543454315662534135323353343143343635431437535494322434523543565543242\n",
    "6239877257567574545356483653647255438677598822772367755397849662623297533345731757246683257235948777\n",
    "3364344338453435244446453354344625245644141444451366444344346334364445333643546424434665446454435333\n",
    "5126121241223448212255222224345123252411721254123224226332222251522275221232222212231235222122212127\n",
    "2211232222222422222222332222221122122212222422122221213222222222126222242222421222222212212221222222\n",
    "1311465354366532323242222625162152534233335634255652344135113466655621521432524144151563525413254789\n",
    "5968666685892765766996686768647799958796377478867547978486648894846698899976828746586867686688769978\n",
    "4626563225744726623245764243356244656552222473634125275554556874962784523556551456636624264656646248\n",
    "5222422212222222225242221212211222122227221222224225321222124132312222422612222112222232232222222222\n",
    "6547255445355363452635332463663476357333578734389473755238464336353448365683486584264712334423444435\n",
    "1722294213222422222422264231612232242453421234262313252426222612221252212212243436333211422322222253\n",
    "2282121332222236523323383233263236521722423242622432624222338423321224322322833122323332222723423247\n",
    "3362223523332332213353321353215414256233323233223313333482323323323323623222352336322233234322121132\n",
    "4533335433353333333232333333333223523343533543333915533232533733543445133353623253233323233532534353\n",
    "6522351242826232821271922222162252222222222262848526222221332224222126445349356543223222126221221219\n",
    "3112343422273333323422123323227943424333272332413243422322335214832472423533344241533423434232323221\n",
    "4335283232333634254263625474131237343414665434544541354423443435544444244314424652373458334236445444\n",
    "6227522221862312113392961524862537233252231243228951335325222225231225862227222272221242283415222234\n",
    "4233334236232351232232145232322426222212322261322231252121312262223132123322322322242241211232327313\n",
    "3353332323323311331132223383533323334323232323333433234332333333423224333332334333333333433333333232\n",
    "3444434452249444885444435344334234144244982434442242443445424914659444372436734942364343672444443377\n",
    "6317622422223322166413226232114422344333123467172215425555122323342222642724762452622734122423214722\n",
    "2465242854121354325444353631243413445258434433442424441533437242232434221534443411412442422264352342\n",
    "2127642584366285655444236633315477328841173315277387683635475418624775842834317242564766118885687139\n",
    "2131122323213222222222212132222122121222322522211221222222327123122221422122232222222222222422672222\n",
    "3523512243323514524111531243223544434534511514455154413135422533452112224432211332142334353325326789\n",
    "2232216322232322212222222222222122241222232113253222322221221322522224222222552222222221222322232222\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9fb93e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str=\"\"\"987654321111111\n",
    "811111111111119\n",
    "234234234234278\n",
    "818181911112111\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d7156231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16854\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for line in input_str.split(\"\\n\"):\n",
    "    first_val=int(line[0])\n",
    "    second_val=-1\n",
    "    for i in line[1:-1]:\n",
    "        if(int(i)>int(first_val)):\n",
    "            first_val=int(i)\n",
    "            second_val=-1\n",
    "        elif(int(i)>second_val):\n",
    "            second_val=int(i)\n",
    "    if(int(line[-1])>second_val):\n",
    "        second_val=int(line[-1])\n",
    "    total+=10*first_val+second_val\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6b2b0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_val(line,remaining_digits):\n",
    "    first_val=int(line[0])\n",
    "    idx = 0\n",
    "    counter = 1\n",
    "    s = line[1:-remaining_digits] if remaining_digits!=0 else line[1:]\n",
    "    for i in s:\n",
    "        if(int(i)>first_val):\n",
    "            first_val=int(i)\n",
    "            idx=counter\n",
    "        counter+=1\n",
    "    return first_val,idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "abfdb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_val(line,remaining_digits):\n",
    "    first_val=int(line[0])\n",
    "    idx = 0\n",
    "    counter = 1\n",
    "    if(remaining_digits!=0):\n",
    "        for i in line[1:-remaining_digits]:\n",
    "            if(int(i)>first_val):\n",
    "                first_val=int(i)\n",
    "                idx=counter\n",
    "            counter+=1\n",
    "    else:\n",
    "        for i in line[1:]:\n",
    "            if(int(i)>first_val):\n",
    "                first_val=int(i)\n",
    "                idx=counter\n",
    "            counter+=1\n",
    "    return first_val,idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e683279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_val(line,remaining_digits):\n",
    "    first_val=int(line[0])\n",
    "    idx = 0\n",
    "    counter = 1\n",
    "    s = line[1:-remaining_digits] if remaining_digits!=0 else line[1:]\n",
    "    for i in s:\n",
    "        if(int(i)>first_val):\n",
    "            first_val=int(i)\n",
    "            idx=counter\n",
    "        counter+=1\n",
    "    return first_val,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9eb286c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v(l,r):\n",
    " f,c,s,q=int(l[0]),1,l[1:-r] if r!=0 else l[1:],0\n",
    " for j in s:\n",
    "  if(int(j)>f):\n",
    "   f,q=int(j),c\n",
    "  c+=1\n",
    " return f,q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "850866b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v(line,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e579ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m input_str.split(sep=\u001b[38;5;28;01mNone\u001b[39;00m, maxsplit=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Return a list of the substrings in the string, using sep as the separator string.\n",
      "\n",
      "  sep\n",
      "    The separator used to split the string.\n",
      "\n",
      "    When set to None (the default value), will split on any whitespace\n",
      "    character (including \\n \\r \\t \\f and spaces) and will discard\n",
      "    empty strings from the result.\n",
      "  maxsplit\n",
      "    Maximum number of splits.\n",
      "    -1 (the default value) means no limit.\n",
      "\n",
      "Splitting starts at the front of the string and works to the end.\n",
      "\n",
      "Note, str.split() is mainly useful for data that has been intentionally\n",
      "delimited.  With natural text that includes punctuation, consider using\n",
      "the regular expression module.\n",
      "\u001b[31mType:\u001b[39m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "??input_str.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fec8009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16854\n",
      "167526011932478\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for z in 1,11:\n",
    " t=0\n",
    " for l in input_str.split():s=\"\";exec(\"for i in range(z,-1,-1):f,c,q=l[0],1,0;exec('for j in l[1:-i] if i else l[1:]:f,q,c=(j,c,c+1) if j>f else (f,q,c+1)');s,l=s+f,l[q+1:]\");t+=int(s)\n",
    " print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "fd99e090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\"\"import sys\n",
    "for z in 1,11:\n",
    " t=0\n",
    " for l in sys.argv[1].split():s=\"\";exec(\"for i in range(z,-1,-1):f,c,q=l[0],1,0;exec('for j in l[1:-i] if i else l[1:]:f,q,c=(j,c,c+1) if j>f else (f,q,c+1)');s,l=s+f,l[q+1:]\");t+=int(s)\n",
    " print(t)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e1448ea2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[274]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m s=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(z,-\u001b[32m1\u001b[39m,-\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m  f,c,u,q=\u001b[38;5;28mint\u001b[39m(l[\u001b[32m0\u001b[39m]),\u001b[32m1\u001b[39m,l[\u001b[32m1\u001b[39m:-r] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mr\u001b[49m!=\u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m l[\u001b[32m1\u001b[39m:],\u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m  \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m u:\n\u001b[32m      9\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mint\u001b[39m(j)>f):\n",
      "\u001b[31mNameError\u001b[39m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for z in [1,11]:\n",
    " t=0\n",
    " for l in input_str.split(\"\\n\"):\n",
    "  s=\"\"\n",
    "  for i in range(z,-1,-1):\n",
    "   f,c,u,q=int(l[0]),1,l[1:-r] if r!=0 else l[1:],0\n",
    "   for j in u:\n",
    "    if(int(j)>f):\n",
    "     f,q=int(j),c\n",
    "    c+=1\n",
    "   a,x=v(l,i)\n",
    "   s,l=s+str(a),l[x+1:]\n",
    "  t+=int(s)\n",
    " print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc86964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167526011932478"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for line in input_str.split(\"\\n\"):\n",
    "    str_counter = \"\"\n",
    "    for i in range(11,-1,-1):\n",
    "        val,idx = largest_val(line,i)\n",
    "        str_counter+=str(val)\n",
    "        line = line[idx+1:]\n",
    "    total+=int(str_counter)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d3469ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'81111111111111'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"811111111111119\"[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1ca163c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811111111111119 11 8 0\n",
      "11111111111119 10 1 0\n",
      "1111111111119 9 1 0\n",
      "111111111119 8 1 0\n",
      "11111111119 7 1 0\n",
      "1111111119 6 1 0\n",
      "111111119 5 1 0\n",
      "11111119 4 1 0\n",
      "1111119 3 1 0\n",
      "111119 2 1 0\n",
      "11119 1 1 0\n",
      "1119 0 9 3\n",
      "811111111119\n"
     ]
    }
   ],
   "source": [
    "input_str= \"811111111111119\" \n",
    "for line in input_str.split(\"\\n\"):\n",
    "    str_counter = \"\"\n",
    "    for i in range(11,-1,-1):\n",
    "        val,idx = largest_val(line,i)\n",
    "        print(line,i, val,idx)\n",
    "        str_counter+=str(val)\n",
    "        line = line[idx+1:]\n",
    "    print(str_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ceaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_val(\"111\",11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "cef18b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str=\"\"\"@.@...@@.@.@@@@@@.@@@@.@..@@..@.@@@.@@@@@..@@@.@.@@...@@..@@@@.@@@@@@@@@@@@@..@.@@@@.@.@.@@@.@@.@.@.@..@@@@@@@....@@@@...@@...@.@@@.@@@.@.\n",
    "@@..@@@@...@.@@@..@@.@.@@@@....@@@@@@..@@@.@@@....@.@@.@@@@..@...@.@.@@.@@@@@.@@.@@..@@.@@@@@@.@..@.@@@@@.@@@.@@.@.@@@@@@.@@@@.@.@@.@..@@@\n",
    "@@@@..@.@.@..@@.@.@@@...@@@@@..@..@.@@@@@.@..@.@.@.@@@.@@.@@@.@.@@.@@.@@@.@@.@@.@@..@.@@@.@@.@@.@@@@.@@@.@@@@@@@....@.@@@@@@@@@@.@.@@@@@..\n",
    ".@@@@@@.@@@@.@@.@..@@@.@..@@@@@@.@@@@@...@@.@@@@.@@.@..@@@@@.@@@@.@@....@@@..@.@@..@@@@@.@..@@@.@@@@.@@..@@@.@@@.@@.@..@..@.@@@@@@@@.@@@@@\n",
    ".@@@...@..@.@@@.@@@..@@..@.@..@@@..@.@@@.@.@.@@@@@.@@.@.@@@@.@.@@.@@@@.@@@@@@@.@.@..@@.@@@@.@....@@@@...@@@...@@..@..@.@..@@@@@@.@@.@.@@..\n",
    "@@@.@@@..@@@.@@@.@.@@..@@..@.@@@@@.@@.@..@..@@@@@@.@@@.@@@@.@@@@@@@..@@@@.@@@.@@@@@.@.@@@@.@.@..@.@@@@.@@@.@@.@@.@@@@.@.@..@.@..@@.@...@@.\n",
    "@@..@@@.@......@.@@@.@@@.@@.@@.@@..@@@...@@@@@...@.@.@....@@@@@@@.@@..@@.@@@.@@.@@@@..@@@..@...@@@.@@.@.@..@@.@@.@.@@.@@.@@@.@@@.@@@.@@.@@\n",
    "@@.@...@.@@@@@.@@@@.@@@@@...@.@.@@.@.@@..@@@@@.@.@@@@@@@@@@@@@.@..@@@@@.@@.@@@.@..@.@.@@@..@@@.@@@.@@.@@..@@@.@@.@@@@@@.@.@@@.@.@@@@.@.@.@\n",
    ".@.@.@..@.@.@..@@@.@@.@@@@@@@.@@.@@.@...@@@.@@.@@.@.@@@@@@.@.@@@.@@.@@@@@...@.@@.@@.@@@@...@.@@.@@@@@@@@.@@@@.@.....@@@.@@.@.@@@@@@@@..@@@\n",
    "@@@@@.@@.@..@@@.....@@.@@@@..@@@@@.@@@@.@@.@@.@@@@@@.@..@@@@..@@@@@..@.@@@@@@..@@@@@@.@..@..@@.@@@@.@@.@.@@@@@@..@@@.@@..@@@...@@.@@...@@@\n",
    ".@@.@@@@@@.@@@.@@.@@.@@@.@.@.@@@@.@.@@@@@@@@@@@@.@.@@@....@..@@.@@@@...@.@....@@@@@..@.@@@..@@@@@.@...@.@@@...@...@.@@@@@.@.@...@.@.@@@@.@\n",
    "@@.@...@@....@@..@@@@@.@@.@.@@..@.@.@@@@.@@@@@@@@@@@@@....@@@@@@@@.@..@@...@.@@@.@.@.....@@@.@@@@@.@.@.@@@@@@@@.@.@@.@@.@@@@.@@@@@@...@.@@\n",
    "@@@@..@@..@.@@@@@.@.@.@.@@@@@@@@.@....@.@.@.@@@@..@.@@..@..@@@@.@@.@..@.@..@@.@.@@@@@.@@@@@@@@@@@..@.@@.@@@@.@..@.@@.@@@@.@@@@@.@.@@@@.@@.\n",
    "@@@@@.@..@.@@@@@.@@@@@@.@@@@.@@@@@..@.@@@.@@.@.@@@@@@@@@@@@.@@@.@..@.@@.@@@.@@.@@.@@@@@@@@@@@@...@@@@.@@@.@.@@@.@@@.....@@.@@@.@@.@.@@@@.@\n",
    "..@.@@.@.@@@@.@@.@@@@@@@@@@@@.@@@@@@@.@..@@.@.@@.@@@@.@.@@@@@@@@.@.@@@@.@@@..@@..@@..@@@@@@..@@..@.@@.@.@.@@.@...@.@@.@@@@..@.@@@@@@@@@.@@\n",
    "@@@@@.@@..@...@..@@@.@@@.@@..@..@.@..@.@@@.@@.@@...@@.@@@@@.@@..@.@@@.@..@@.@@@.@@..@@@.@@@@..@@.@@@.@.@@@@@.@@.....@.@@@...@.@@@.@@@@@.@@\n",
    "@@@@@@.@@@.@@@@@.@@@@@.@@..@@.@...@@..@.@....@@@@.@..@@@@...@@..@@@@@@.@@@@....@.@@.@@@@@@.@@@@.@.@..@@@@@.@@@@@.@@@@@@@@@@@.@@@..@.@.@@@@\n",
    "@@@...@..@@@.@@..@@@.@.@@..@..@@@@@@@@@@@..@@@@@@.@@..@..@@@@@@@@@@@@@@@.@@@@.@@@..@@@@..@@@..@@@@@@@@.@...@@@.@....@.@@.@@....@@..@...@.@\n",
    ".@@.@@@...@@@@@.@.@@@..@@@@@@@@.@.@....@.@.@@@@@@@@..@@@.@.@.@@@@@@..@@@.@.@..@@@@@.@@@@.@..@@@..@@@@@@@.@@@..@..@@@@@@@.@.@@@@@@@.@@@.@@@\n",
    ".@@@..@@.@.@.@.@..@@.@@@.@@.@@.@.@@.@@@@.@@@.@@..@@@@..@@@@.@@.@.@@@.@....@@@@..@.@.@@.@@@@@.@..@@@@@@..@@@..@...@@.@@.@.@@.@.@@@@@@.@..@@\n",
    "@@@.@.@@.@@.@.@@.@@@.@@@@@.@@@.@@.@@@@@.@@@@.@.@@@@@@..@@@.@@@@@..@@@@@.@.@@@@@@...@@@@@@@@@@.@@@.@@.@.@@.@@@@@@@@@...@.@@@@@@@...@@@@@@@@\n",
    "@@@@@.@@......@@..@@@@...@@@@@@@@.@@@@@@@@@.@..@@@@@@@.@@..@.@@@@@.@@@@@.@...@@@......@@@@@.@@@.@..@@@..@@.@@@@@@@.@@...@@@@....@...@@@...\n",
    "@@.@@.......@@@@@@.@@@@@.@@@...@@.@@@@@.@@.@.@@@@.@.@@.@@..@@@@...@.@.@@..@@@@@.@.@@@@@.@@@...@@@@.@..@@@..@@@.@.@.@@@@@@.@.@@@@@.@@.@....\n",
    "..@@@@@@@@@.@..@@@@@@@@@@.@@@.@.@.@@@...@@@...@.@@..@.@..@.@.@.@...@@..@@@@...@@.@@@.@@@@..@@@@@.@@.@@@@@@@@@@@@..@@.@@@.@@..@@.@@.......@\n",
    ".@.@@@@.@.@@@.@@@@@@.@.@.@@.@@@..@@..@@@..@.@@..@.@@@@@@@....@@.@@@@....@.@@@....@@..@@@@.@@@.@@@@..@@.@.@@@..@.@@.@@@@@@.@.@@@.@.@.@...@.\n",
    "@@@@.@@.@@...@.@..@...@.@@@...@@@@.@@@@@.@@@@@@@@@@@@@.@.@@@.@@...@.@.@..@..@@@.@@@@.@..@@@@@@.@@@.@.@@..@@@@@.@@...@@@@.@.@@@@@@@.@..@@@@\n",
    ".......@@@@..@.@..@@@@@@@..@@@@@.@@@..@.@@.@@@@@@@@@@@@@@@@@.@.@.@@.@..@@@@@..@.@@@@@@@@@@@@@@@@@@.@@@@...@@@@@@.@.@.@@@@@..@@@@@.@.@.@@@@\n",
    "@.@..@@@.@@@@.@@@@.@..@@@@...@@..@@@@@@@@@@@@@..@@@..@@@@@@.@@@@@..@....@@.@@@.@..@.@@@...@.@@.@@@@@.@.@@.@.@@@.@@@@@@@@.@.@.@..@@.@@@@.@@\n",
    "@.@@@@@@.@@.@@@.@.@@@@..@@@.@@@@..@@@@@@@@.@@@@@...@..@@@@@@@.@@.@@.@@..@..@@@@@@@@@.@@.@@@@@.@@.@@@@@..@.@@@.@@@@@..@@...@@@@@.@@@.@@@...\n",
    "@.@@@@@..@.@@@@@.@@@@@@@..@..@@@.@@@.@@..@@.....@......@@@@.@@@@.@.@..@@..@@.@@.@@@@..@..@@@@@....@@@@@...@.@@@@@....@@@@@@@@@@..@@.@@.@@.\n",
    "@...@@@@@.@@@@.@@...@@@@@@@@..@..@@.@@.@@@..@.@@@.@@@@.@@....@......@@@..@.@.@@@@.@.@@@@.@@@@@@.@@..@@@.@@@.@@.@@@.@@@.@@@@.@@@@...@@@..@@\n",
    "@@@..@@@@@@@.@@.@@@@.@@@@.@@@@@.@@@.@@.@@..@.@@@..@@@..@.@@.@@@.@@@..@...@..@@@@..@..@@@@.@..@@@@.@@@.@@.@@.@@@@@.@@.@.@.@..@@@@.@.@@@.@@@\n",
    "@@.@.@@...@..@...@@.@@@...@@@@@@@@@@.@.@@@.@@@@.@.@@.@@.@@@@.@@@..@..@@@...@@.@@@.@@@@@.@.@@.@.@@@@..@@...@@@@@@.@@..@@....@@@@@...@..@.@@\n",
    ".@@@@@@.@..@.@@.@.@..@@@.@@@@@..@..@.@.@@@@.@..@@..@@@@@.@@.@@@@@@@@.@..@@@@@@@@@@.@@@@@@@.@..@.@@@@@@@..@..@@@@@@@..@.@@@.@@.@..@.@.@@@@@\n",
    "@.@@@..@@@.@@@@@@@@@..@.@@.@@.@@.@@@@.@@@@@@@@@@...@@@@@@@.....@@.@.@@.@@@@@@@..@....@@..@@@@@@@.@@...@.@....@@@..@@@@@@@@.@@..@@.@@@@@.@@\n",
    "@.....@@.@@@.@@@...@..@@@@....@@@@@..@.@@..@.@@@@@...@@.@.@@@@.@@..@@.@@@@@..@@.@...@.@@.@.@.@@.@@@.@@@@@@.@@@@@@.@@@@.@@@@@@@@.@@.@.@@@@@\n",
    ".@@@.@@.@.@....@@@@@@.@@@@@@.@@@@@.@.@...@@.@@@@@@@.@...@@@@@@.@@@.@@..@@@@..@@@@..@@.@@@.@...@@.@@@@..@@.@@@@@..@@...@@@@.@@..@@@@.@@@@.@\n",
    ".@@@.@....@@@..@.@@.@.@@@.@@@@@@@..@.@.@@@@@.@@@@@..@@.@@@@@@@@@@@@@@@@@@@@@.@@@@.@@...@......@.@@@@@@..@.@.@.@@@.@@@.@@@@.@@..@.@@@@@.@@@\n",
    "@...@.@@..@.@.@@@.@@....@.@@@.@@@@@@@@.@.@.@@@@.@@@@.@.@@.@@@@.@@@.@@@@.@.@...@.@@@.@@....@@..@@@.@@@@@.@@@.@.@@@.@@@.@@@@@..@....@.@.@@@@\n",
    ".@@@..@@.@...@@@@....@@@@.@@.@@.@.@@@@.@.@@.@@@@.@..@@.@@@...@@.@@@.@@@@@.@..@@@@.@...@@@..@@.@@@.@@.@@@@@..@@@@@@..@@@@.@.@.@@@@@.@@@@@.@\n",
    ".@.@@@...@@.@.@@@.@@@@.@..@.@@@@@.@@@@@@.@.@@@@.@....@.@@@@.@...@..@.@..@@@.@@@@@@.@.@..@@@.@.@@@@@..@@..@@@@@@@@@@@@.@@@.@@@.@@@.@@@@@..@\n",
    ".@@@@@@@@@.@.@@@.@@@@@@@.@@@@@@.@@@.@@..@@@@.@@..@.@@...@@.@@@@@@@@@@...@..@.@@@..@@@@@@@.@@@.....@@...@....@@@@@@@@.@@.@@....@...@@..@@@@\n",
    "@@@@@.@@@@@@@@@@@.@@.@.@@....@@.@@.@.@@.@.@@@@@@@@@.@@.@@@..@@@.@.@@@@@.@.@@..@@@@.@@.@@@@.@.@.@.@@@@@...@@.@@@.@@@@@@@.@.@.@@@@@@@...@@@@\n",
    "@@..@@.@....@@@@@....@..@@@@@.@.@@..@@@.@.@@@@.@@@@@..@@.@..@@@.@@@..@.@@.@@.@.@@@@@..@@@@@.@@...@@...@@@@@@@.@.@@@....@...@@@.@..@@@@@...\n",
    "@@@@..@.@@@@.@...@@@@@..@@@@@@....@@@@.@@.@..@.@@@@@@@.@.@@@@..@@@@@@@..@.@@@@@@@.@@@@@@@.@@.@@@@.@@...@.....@.@..@@@@@@.@@@@..@@@@..@@@@@\n",
    "@@@@@@@@@@@@@..@@.@@@@.@@@..@@@@@.@.@.@@@@@@...@.@.@@.@@@@.@@@@..@@@@.@.@@@@@.@..@@@@...@@@@@@@@.@@.@@@.@.@..@..@@.@@@@@@@@@.@.@@.@.@@@@@.\n",
    "@.@@@@@.@@@@@@@..@.@@.@@@@.@.@.@...@@@@@@.@@.@..@@@@@@@@@@.@@..@@@@...@@.@.@@@..@@@@.@@@@.@.@@@@@@.@@@@..@@.@.@@.@@..@@@.@.@@..@@@@.@.@...\n",
    "@..@@@@.@@@.@@@@@@@.@.@@@@@@@...@.@@...@@@@@..@.@@@..@@@@@@.@.@@@.@@@@.@..@@.@@@@..@.@@...@..@@@.@@@@@.@@@.@.@@.@...@..@@@@@@@.@.@.@@.@@.@\n",
    "@.@.@..@@@@@@@@.@@@@.@@@..@@@@@@.@@.@@@@@@@@.@.@@@..@@@@@@.@.@@@..@.@.@@@@@..@.@@..@@@..@..@@@@@.@@@.@@@@..@@@..@.@.@@@@@@@@@@@@.@@@@@@@@@\n",
    "@..@@@@@.@@.@@@.@@..@@@.@.@@.@.@@..@@@@@@@.@@...@.@@..@....@@@@@@@..@.@@@@@..@@@@@.@@@@@@..@@..@@@.@@.@@@@@.@@.@@@@@.@.@.@@.@.@@@.@@@@@@@.\n",
    "@@@@@@..@..@@@.@@@@@...@..@.@@.@..@.@@@@@.@@.@@@@@.@@@@.@@....@@...@...@.@@..@.@@@@@@..@.@@@@@@@@.@@..@@@.@@..@.@.@@..@@..@@.@@@.....@@@.@\n",
    "@@..@.@@..@.@@@.@@@@.@@@.@@@@@@.@.@@@@...@@@..@@@@.@@@@@@.@@....@.@@@@@.@@@@.@@@@@@.@@.@@@@@@..@..@.@@@@@@....@@.@.@@@@@@@@..@@..@@@@.@@..\n",
    "..@.@@@@@@.@.@@.@@...@@.@@@@.@.@@@.@@.@.@@@@@...@.@.@@.@@.@@@.@@.@@.@@@.@@...@@@@@.@@@.@.@@@.@@@.@@@@@.@@.@@@.@.@.@@.@@@.@@@@.@@..@@.@@.@@\n",
    "@@@@@.@@.@.@@@@.@@@@@@..@...@@@@@.@@@@@@@@@@.@.@@.@@@...@..@...@@@@@.@@.@@@.@@@@.@@..@..@@@..@..@@@@@.@.@..@@@.@@@@@@.@@.@..@@..@@...@@@.@\n",
    ".@...@@@@@@.@@@@@.@@@.@@@.@....@.@@@.@.@@@@@@..@@@.@..@.@@@@@.@@@@@@.@@@@@..@..@...@@@@@.@@@...@..@@.@.@@@@@@.@.@.@@@@.@.@.@.@@...@@@.@@@@\n",
    "@.@@@@.@@..@@@...@@.@@..@@@@@@@@@@.@.@....@...@@@..@@....@.@.@.@@@.@@@@@....@@@@@@@.@@.@@@@.@@@@..@@..@@@..@@..@..@@.@.@..@.@@@@@@@.@@@@.@\n",
    "..@@..@@@@@.@..@..@@.@@@.@@...@@@@@@.@@@.....@.@@@@@@..@..@@@@.@.@@@@.@...@.@..@@@@@@@@@..@.@.@...@@.@.@.@@@@.@@.@@.@@.@.@@@@...@@.@@@@@..\n",
    "@@@@@.@.@.@@..@@@@@@.@@....@.@@.@@@@.@@.@..@@.@@.@@@..@@@@@....@.@@..@.@.@@.@@.@@@@@.@@@@@.@@@@@@.@@@.@@.@@.@@@.@@@@@.@...@@@@.@@@..@@....\n",
    ".@@@@..@..@@@@@@@@.@..@@.@..@@...@..@@@.@.@@.@@...@@..@.....@@...@@@@...@@@@@@@@@.@@.@@@@.@@@..@.@.@..@@.@..@..@..@.@.@@@@.@@@@.@@@@@@.@@@\n",
    "@@@@@@@@@.@.@@.@.@...@@.@@@@.@.@..@@.@@..@@@@.@..@@.@@..@.@.....@@@..@@@@.@.@..@.@..@@@@..@@@@@@.@.@@..@.@.@.@@.@..@.@@@.@.@..@@@@..@@@@@@\n",
    "@.@@...@@@..@@.@..@.......@@@@@@@@.@@@.@@@@@..@@@.@@@@.@@@@@@.@@@.@@@@.@@@@....@@..@@.@@@@.@@@.@.@@...@@@....@@@..@.@@...@@@@..@@@.@@.@..@\n",
    ".@.@@..@@@@...@@.@@.@@@.@@.@@@@@.....@..@@.@@@@...@@@@@@@@.@@.@..@@@@@.@@@@@@@.@@@@@@@@@@@.@@@@..@@@..@@@.@@@@@.@@@@@@@@@@@.@@@.@@@.@...@.\n",
    "@@@@@.@@@@...@@@@.@@@.@...@@.@.@@@@@@.@@@@@@@@.@@@@@.@.....@@..@@.@.@@.@@.@@@..@.@@@@..@.@..@.@@..@@@.@.@@@..@@.@@@..@.@@@@..@..@@.@.@.@@@\n",
    ".@....@.@.@@@.@@@.@@@.@@@@.@.@..@@@...@@.....@@@.@@..@@..@@@@@..@@@@@@@@.@@@.@@@@.@.@@..@...@@@.@.@..@@.....@@@@@.@.@.@@@..@..@@@.@@@@@@@.\n",
    "@@@@@@@@@.@@@@@@@.@@@@@@@@@.@.@.@@@..@@.@.@...@@@@..@@@.@@.@@@@@.@@@@@..@@@@.@.@.@@.@@.@@@@@@@@.@@@.@@@@@@@@.@.@@.@@@@@@@..@@@@.@@.@@@@.@@\n",
    "@@@@@.@@@@@@.@.@@.@@@..@@@@@@@.@@@.@..@@@.@.@@....@@@@@@@@@@@...@@....@@.@@@@@....@@.@@@.@..@.@@@@@.@@.@@@@@.@@@.@...@@.@@@@@@..@@@.@.@@@@\n",
    "@.@@@.@..@..@.@.@.@..@..@@.@@..@..@@@@@@@@@.@.@@@.@@..@.@...@.@.@.@@.@...@@@.@@..@@@@.@.@@.@@.@@@@..@@@@.@@@.@@@@...@@.@.@.@...@@.....@@@@\n",
    "...@@.@@.@@@.@@.@@@..@@.@@@@@.@.@@@@@..@@.@.@.@@.@..@@.@@@@@@@...@.@@@@.@@.@@@@@@@..@@...@@.@@@@.@@@.@.@@...@@@@@@..@@@@@.@.@....@..@.@.@@\n",
    ".@....@@@@@@@..@@@.@@.@@@@@.@.@.@@.@@@@@@@.@..@..@@@@@.@@@@@@@@@@.@@@@@@.@@.@.@@@.@@@@@@@@@@@@.@.@@.@.@@@.@.@@@@@@..@@.@@...@@@.@@@@@@@@@.\n",
    "..@..@@.@.@.@@.@@@@@@@.@.@@@.@..@@@@.@.@@@@@..@@.@...@@.@@.@.@@@@..@@..@.@@..@@.@.@@@@.@@.@.@@..@@@.@@.......@@@@@@@@.@@@@@.@@@@@@@@@@.@@@\n",
    "@@@.@@@..@@@...@.@@.@@@@@@@@@.@@.@@@@@@@@.@@@.@@.@@@.@@@@.@.@.@..@@.@@@@@@@...@@@@.@@@..@.@@..@@@...@@.@@@.@.@.@.@.@@@@@@@@@@@@@@.@@@@@.@.\n",
    "...@@@.@@.@@@.@@@...@@@@.@..@@@@@.@.@.@@@@.@@@@.@@@.@@@.@.@.@.@@@@.@@.@.@@@@.@.@@.@@.@@.@@.@@@@.@..@@.@@.@@@@.@@...@...@@@.@..@@.@@@@@@@@@\n",
    "@@@@@@@@@...@.@@@..@@.@.@@@@@@@@@.@@@.@@@@.@....@@.@@..@@@@@...@@@@.@@.@@@@@@@@@@@.@@@@@@@..@@..@@@@@@@.@@.@.....@@.@@@@@@@.@.@.@@@.@@@@@@\n",
    "...@@@@.@@@.@.@@..@@@@@@.@@@.@...@.@@@.@@@@@@..@@@.@..@.....@@.@@.@@..@@..@@@.@@.@@@@.@@@@.@.@@.@.@@..@.@@@.@@..@..@@@.@@@@@..@..@.@..@@.@\n",
    "@@@@@@@@..@@@..@.@@@.@@@@.@@@@@@@@@@@@@.@.@@@@@@.@@@..@@.@@..@@@@.@@..@.....@.@@@.@..@.@.@@@@.@@@@...@..@@@@@@@.@.@.@@..@@@.@..@@@.@@@.@.@\n",
    "@..@@.@@.@@..@@.@@@@@.@@.@@@....@.@@.@@.@@@..@..@@.@@@.@...@@@..@@@@@@..@@@.@@@.@@..@.@@@@...@@@@.@.@..@@@@@.@@.@@@.@@@@.@.@@@.@@@.@@.@.@.\n",
    ".@@@.@...@.@@@@@@@@@@@@@@@.@@@@@@..@..@.@@@.@@@@@@....@.@@@..@@@@.@..@@@@@@@@.@.@.@@@@.@@..@.@@.@@@..@@@@@.@..@@...@@.@@.@@@.@@.@..@@.@@..\n",
    "@..@@@@@@@.@@@.@@@@@@@@@.@@@.@@@.@@@@@@@@@.@@...@@@..@@.@@@..@@@@@@@@@.@@.@@.@@.@@.@..@@@.@@.@@@@@@.@@@@@@..@@.@@@.@@@@.@@.@@@.@.@.@@.@@@@\n",
    ".@..@@@@@.@@@@@.@@.@@.@@@@.@@.@..@@@.@@.@@.@..@@.@@.@@@.@..@.@.@@...@@@@@@@@.@@...@.@@@@@.@@@@.@@@......@.@.@@.@@@@..@@@..@@...@@@@...@@.@\n",
    "@.@@@.@@..@.@@@@..@@.@@..@.@@@..@.@@@..@@@@@@@@@@@@....@.@@@@@.@@@@@.@@@.@...@@@@@@.@@@.@.@@@@@@@@@@..@@.@@@@@@@@@@.@@@@@@@.@.@@@@.@@@@..@\n",
    "@@.@.@.@@@@@.@@@@@..@.@@@@@.@@@.@.@@@@.@@@@@.@@.@.@..@@@@@...@.@@@.@@..@@@@.@@@.@@@.@@@@@@@@..@..@@@@@.@@...@@@@.@@@@@@@@.@...@.@@..@.@@@@\n",
    "@.@@@@@@@@@.@@@@@@..@@@@@@.@@@@@@....@@@@@..@.@..@...@.@@@.@@@.@...@@.@@@@..@@@@@@..@@@@.@..@@@..@@@.@@@..@@.@@.@@@@@..@@..@.@@.@@@@@@.@@.\n",
    "@....@@@@@@.@@.@@@@@@.@@@.@.@@@@@...@@@@.@@@@@@.@@@..@@@@@@@@@@@@..@@@..@@.@@@@..@@.@@@..@.@@@...@@@@..@.@@@@..@@.@@@.@@@.@@.@@@@@@@@@@.@@\n",
    "@.@.@.@.@.@@@@@.@@@..@.@..@@@.@..@@@.@@@@.@@@..@@..@.@@@@@@@@@@.@@@.@@@@.@@@.@@@@@@@@@@..@......@..@@@@..@@@.@@@.@...@@.@@..@@@@@@@@@.@@..\n",
    ".@..@@@@.@@..@@@@@...@@@@..@@.@..@@@@@@@.@.@.@@.@@@@@@@@.@.@@..@.@@@@@@@@@@@@.@@.@.@@@..@.@.@@@@.@@@@.@@@@@@@@.@..@@@@@@.@..@@.@.@..@.@.@@\n",
    "@@@@@@@.@.@@@.@@@@..@@.@.@@@..@@.@.@.@@@@@@@@..@@@.@.@.@@@.@@@@@.@@.@@.@@.@@@@..@..@.@.@@@..@@@@@..@@@@.@.@@..@@..@@@.@@@..@@@@@@@@@@@.@@@\n",
    ".@@.@.@.@@.@@.@@@@..@@@@@@.@..@@@@.@.@..@..@@@@@.@@.@@@@...@@@@@@@@@@@@@.@@@.@..@@@.@@.@.@@@@.@@.@.@@@@.@@@.@@@@....@@@@.@.@....@@@@.@...@\n",
    "@@..@.@@@@@@.@@@@@@@.@@@@..@@@@@@.....@@.@.@@@@.@@@@@.@@@@...@.@@@@@@.@@@.@@@@@@@@..@@@@.@@@..@@@....@..@@@..@@.@@@.@@.@.@@...@@@@@.@@@@@@\n",
    "@@@@@@@@.@@.@..@.@..@........@@.@.@@@.@@@@@.@@@@@@@@@.@@@@@.@@@@.@@@@@@@@.@.@@@.@...@.@.@.@@@.@.@.@@@@@@.@...@.@@...@@@@@.@@@@...@@.@@.@@@\n",
    "@.@@..@.@.@@....@@@@@..@..@@@@.@@@@@@@@.@...@..@@@@@@.@@@.@@@@@@@@@.@@@.@@@@@@@.@@..@..@.@@..@@.@@@@@@@..@.@@@...@@@@.@.@@.@@.@@@@@.@.@.@@\n",
    "..@@@.@@@@.@@....@@@....@@@@@....@.@@@@..@@..@@@@@@..@.@..@.@@@@@....@@.@@.@@@.@@@@.@@@@@@..@@.@@@@..@@@.@@.@@@@...@..@@@@@.@..@@@@@@@@.@.\n",
    "@...@..@@.@@.@@.@.@@..@.@@@@@@..@@@.@@@@..@@@@@.@@@@@.@.@.@.@@@@@@@@.@@@@..@@@@.@@..@.@@@@@@@@.@@@..@@.@.@@@@..@.@@@@.@@@@@@@.@..@@@..@@.@\n",
    "@.@@.@@@@..@.@@@@@@....@@@..@@@@@@.@@@.@@.@@.@@.@....@@@.@.@@@.@@@..@@@..@@@.@@@@@.@@@..@.@@.@@@..@.@@@.@@.@@@.@.@@.@@....@@.@@@.@@.@@@.@.\n",
    ".@@.@@@.@.@@@@@@.@@@@.....@.@@@.@.@@@@@@@@@@@@@@.@@.@@@@@@.@@....@.@@@.@.@@.@@.@..@@@@...@@@@@.@@..@@.@@@@..@@@@.@.@@...@@@@@@@.@.@@@@@...\n",
    "@.@@.@@..@@.@.@@@@..@@@@@@.@.@.@@@...@@@@@@.@@.@@@@.@@@.@..@..@.....@@@@.@@@@.@@.@@@.@.@@.@.@.@@@@@@.@@.@@@.@.@@@@@..@.@@@.@....@.@@@..@@@\n",
    ".@.@@@@@@@@@...@..@@@@@@.@@.@@.@@@.@@@...@...@@..@.@@.@.@..@.@.@@@@.@@@@@....@@@@..@@.@@@.@@@@@..@@@..@.@@@.@@@..@@..@.@@..@@@@.@@.@@.@@@@\n",
    ".@.@.@.@@.@@@@@.@.@..@@@.......@.@@@@@@@@.@@.@@@@@@@@..@@@.@@@@@@@@@@@....@@.@@.@@@...@@....@@@@.@..@.@@@@.@@...@.@@@.@@.@.@.@@@@..@.@@@..\n",
    "@.@@@@@.@@@@@@..@.@.....@..@@@@@@@@.@@@.@@.@@@.@@.@.@@.@@@.@@@.@.@@@@@@@@@@@.@.@@.@@@@.@@.@@@.@@.@@....@.@@.@@@@@@@..@@.@.@.@@@..@@.@@@.@.\n",
    "@@@.@@..@@.@@@@@.@@.@@@@@...@@.@@@.@@@@@.@@@.@.@.@@@@.@@@.@@@..@@@@..@@.@@.@.@@@@@.@..@@.@@@@@@@@@.@@..@.@@@.@@.@@@@@.@.@@@@.@..@@@..@.@@@\n",
    "@@.@@@@@.@...@@@@.@..@.@@@@@@@@@.@...@@@@@..@.@...@@@@@@.@@@.@@@..@@@@@@.@@.@@@@@.@@@.@@@@.@@.@@@@@.@@@@@@@.@..@@.@..@..@@@@@@@@.@..@@@...\n",
    "@@@.@@@.@@@..@@@@@@@@.@@@@@@@@@@..@@@@.@..@@@.@@@@@@.@@@@..@@.@..@@@@.@@@.@..@@@.@@@.@@@..@@@@@.@@@@.@.@..@@.@@@@@@@@@@@@@@..@@@.@..@@@..@\n",
    ".@.@....@@.@.@.@.@..@.@@@@.@@....@.@@.@@@...@@@@.@@@@.@@@.@@@.@..@@.@...@@.@@@@..@@@.@..@.@..@..@@@@@..@@@..@@...@..@@@@@@.@.@@.@@@@..@.@@\n",
    "@@@.@.@.@@@.@@@.@.@..@.@@@@@.@.@@.@.@@@@@@@.@..@@@@.@@@.@@@...@@@@@@@.@@@@@@@@@@@@@.@@@@@.@.@@.@@..@@@@@@@.@@@...@@.@@..@..@@..@.@@@@@@..@\n",
    ".@@..@...@@@@@@@.@.@.@@@@@..@.@.@.@@.@@.@@.@@@.@.@..@@@..@..@.@..@@@@@@@...@.@.@.@@@@@..@.@@@.@.@@.@..@@@..@@@@@@@@@@@@@.@@.@@.@@@@@@@@@@.\n",
    ".@@@@@.@@.@@@.@@@@@@.@.@@.@@@@..@..@@.@..@@.@@@@.@..@@@@@@@...@@@@@@.@@@@@@@@@....@@@@@@@@@.@.@@@@...@@@@.....@@..@@.@@.@.@@@.@@@@.@@.@@@@\n",
    "@@.@@@@@.@.@.@@@@@.@.@..@@@@.@..@@.@.@@@@@@@@@@@.@.@@....@@@@.@.@@.@@.@@@.@..@@@@@@.@@.@@....@@..@...@@@..@@@..@.@.@..@..@@@@.@@@@..@..@@@\n",
    "@..@@.@@.@@.@@@.@@@.@@@@@.@..@.@.@@.@.@@@@@@@.@.@.@@@@@@@@@.@@@@..@.@.@@@..@@@@@@@@@@.@@@@.@@.@@.@@..@@@@...@.@@..@@@@.@.@@@.@@@.@.@@@.@@.\n",
    "@@@@.@@.@.@@..@@..@.@@@.@.@.@...@@..@.@.@..@.@.@@@@@@@@.@.@@@@@@@.@@@@.@@@@.@..@.@@@...@.@.@@@@@.@@@@..@@@@@@@@@.@@@@..@@@@@.@...@@@.@@.@@\n",
    "@.@@.@@@@..@@.@.@@@.@.@...@.@..@@@.@@@@@@@@..@@@.@@..@@....@@@..@@@@@@..@@@@.@@..@.....@@@@@@..@@..@.@@@.@@@@..@.@@@@.@@@@@.@@@...@.@.@@@.\n",
    "@.@@@...@@@.@@..@@@@.@@@@@.@@@@.....@@@@@@@.@.@@@@@@.@@@@@..@@@.@@.@@.@@.@.@..@@..@@.@.@@.@.@.@@@@@@@@....@@..@...@@..@@@.@@.@@...@.@@.@.@\n",
    "@@@@@@@..@@@@@.@@@@@.@@.@.@@...@@@@@@@@@.@@.@.@@@@@@@@@@@@.@.@@.@.@@@@@@.@@@.@.@.@@@..@@.@...@@@.@..@@@@@@@.@@@.@@@.@.@@.@.@.@.@...@...@@@\n",
    "@@.@@@.@@@@.@....@...@@@.@..@@@.@@...@.@@@@@@@@..@@@.@@@.@@.......@@..@.@@.@@..@@.@@.@@@@....@.@@.@.@@.@@@@@@@@.@.@..@@.@@.@..@@@@@@@@@@@@\n",
    ".@.@@@...@@@@@@@@@@.@@@...@@@.@@@@@@.@.@@@.@.@@@@@.@@..@@@@..@.@@@.@@@@.@@@@.@@@.@.@@@..@..@@..@.@.@@@.@@@..@@@@@..@.@@.@@@.@.@....@@.@@@@\n",
    "@.@@.@@....@@@.@@@@.@@@@.@..@.@@@@@@@.@.@@.@..@.@@.@@@.@@@.@@.@.@@.@.@@@@@@@..@.@@@.@@..@@@@@@@@.@@@.@@..@@@.@@@@@@..@.@@@@@@@..@...@@...@\n",
    ".@@.@..@...@@@@@@@@@.@...@.@.@@@.@@@@.@@.@@@@@@@.@@@@@@.@@@@@.@@.@@....@.@@.@@.@@@.@@.@@....@@@@@.@@@...@@@@@.@@@@@@@.@.@@@.@@@@.@.@.@.@.@\n",
    "@@..@@.@@...@@..@@@@@@@@@.@@@.@@@..@@@@@.@@..@@@@@@@..@@.@@@....@.@@@@.@....@@@..@.@.@.@@@@@@@@.@..@.@@..@@@@..@@.....@@.@@@.@@..@.@.@.@@@\n",
    "@.@.@..@.@@@.@@@@@@.@..@@.@.@.@@@@.@@@.@@.@.@@.@.@.@@@..@.@@@@@@..@@.@@@@@@@@@@......@.@.@...@@.@@@@@.@@..@@@@@@.@.@@@...@@@@@@.@@@@@@@@.@\n",
    "@@@@.@@@.@@.@@@@@@.@.@@@.@@.@@@@@@@@@@@..@@@@@@...@@@@@@@.@.@@.@.@.@.@@@@.@@@@@....@@.@@@..@@@.@@@@@...@@@.@@@....@..@@@@@@..@...@@@..@@.@\n",
    "@.@@..@.@@@@@@.@@@.@.@....@..@.@@@@@@.@@@@@@@@@@...@@.@......@@..@@@@.@@@@@.@@@@...@@.@.@.@@.@@.@@@@@@.@@..@.@@@...@@@.@@.@@@@.@@@@@@@.@@@\n",
    "@..@@@.@@.@@@@...@@@@@..@@@.@@.@@@@.@..@@@@.@@.@@.@..@@@@@@@.@@@.@.@.@.@@.@@@.@@@.@@@.@..@@@.@..@@.@@@@@..@@@@.@.@@@@.@@@..@@@@@@@.@@.@@@@\n",
    "@..@.@@@..@@@@@@@@@.@@@@@..@@@@@@@.@@.@...@.@..@@@@.@@@@..@@@@.@@.@@.@...@.@.@@.@@.@.@@@...@.@..@@.@@..@@@@@.@.@@@...@@@..@@..@..@@...@.@.\n",
    "@..@.@.@@.@@@@@@.@@@@@..@..@.@@@@@..@.@@@.@@@.@@.@@@@@.@@@@@@@@.@@..@.@@@@.@@@@@@.@@@..@@@@....@...@.@@@@@@.@..@@@.@@@@@...@@@.@@.@@.@@@@@\n",
    "..@@@.@@..@@@@@@@.@@@@...@.@.@@..@@@.@@.@@@..@.@.@.@@@@@@@@@@@.@@@...@.@@.@@.@.@@@...@@@@.@@@@.@..@..@..@@@...@.@@@@@..@@@...@.@.@@.@@@..@\n",
    ".@@@.@@@@@@@@.@.@@.@@.....@.@@@@@@@@@.@..@@...@@....@@@...@...@@@@.@@@...@...@..@@@@.@.@@.@@@@@@@@@@@@@@@@@.@@@@@.@@@@@@@@@@@@@@@@@@.@@@@@\n",
    ".@...@.@@..@..@@@...@.@@@@@@@@@.@@@.@@@.@@@..@@.@@...@@.@@@@@.@@..@..@.@@.@@..@@..@@@@@@.@@@@.@.@.@..@..@@@@.@@@@@@@@.@@@@@...@.@@..@@@.@@\n",
    "@@@@@@@..@@@.@@@@..@...@....@@.@.@.@@.@..@.@@@.@@@@@.@.@@@@@@@...@@.@@@@@..@.@.@..@@@@.@@@@..@@...@@@.@@.@.@.@.@.@@@@@..@.@.@@@@@.@@.@@.@.\n",
    "@@.@@@@.@..@@..@@@@@@..@@@@@@@..@@..@..@@.@@@@@@..@@@@.@.@.@@@@@@@@..@.@@..@@@@@@@.@@@@.@....@.@@@@..@@.@.@.@@@@..@@..@...@..@@@@..@.@@@@.\n",
    "@.@@@@.@...@@..@@@@.@@@..@.@@@.@@@@@@@@@@.@@@@@@@@.@@@..@@@@@@.@.@@.@@..@@.@@...@@.@@@@@@@@.@@@@@..@@@@.@..@.@@@@.@@@@@..@@@.@@@@.@@@.@@.@\n",
    "@@@.@@..@@@.@@@@.@..@@@@.@@@@@@@.@.@.......@@@@@@.@@@@@.@.@@.@@@@..@@@@.@@..@@.@.@...@..@.@@@.....@@.@@@@.@..@...@@@...@@@@@..@.@.@@@@@@.@\n",
    ".@.@.@@.@.@.@@..@..@@@@@@@@@.@@@.@@@@.@@...@@@@@..@.@@@@.@.@@.@@@@@@@@.@@.@@.@@@@.@@@@..@.@.@@@.@@.@.@.@@@@@@@@.@@...@@..@@@.@.@@@@@.@@@@.\n",
    "@@@@@@..@@@.@@@@@.@@@.@.@@..@@@.@@@@..@.@@.@@......@@.@@@.@.@@@.@..@@@..@@@@.@@.@@@@..@@..@@.@@@...@@@@@@.@@@.@@.@@@@@@@@@.@@@@@@.@@@@@@.@\n",
    "@.@@.@@@@@@@@@@@@@@.@@@@.@@@@@.@.@.@@@@@@@.@@@@....@@..@..@.@@@@@@@@@..@..@@..@..@@@@.@@.@@@@.@.@.@@....@@.@@@@.@.@@@@..@@@@..@@@.@@..@@@@\n",
    "@@@@@@@@@@@@@@@@.@@@@.@@..@.@@@.@@@.@.@@@@@..@@@@@@..@@@@..@...@@...@@@@.@.@@...@.@@@@......@@.@@@@@..@.@@@@@.@@..@@@.....@@@@..@.@.@..@@@\n",
    "....@.@@@@@@.@@@@.@@@....@@@@@...@@@..@@..@@.@@@@.@..@@@.@@@.@.@@@..@@@.@@..@....@.@@@@@@@@@..@@@@@.@@@@@@....@@@..@@@@@@@@@...@@...@@@@..\n",
    "@.@@.@@@@.@@@.@@@..@@.@@@@..@@@.@....@@@@@@@@@@@@@.@@.@@@.@..@@@@@@..@@.@.@@@.@@@.@@.@.@.@.@@.@@@@.@@@.@.@@@@@.@.@@.@@.@.@@.@@.@.@@@.@...@\n",
    ".@@.@.@@@@.@@...@@@@@@@@@.....@@@@@@@.@@@..@@@......@..@.@@@.@@...@@@..@..@..@@@@@..@@@.@@..@.@@.@.@..@.@@@@.@..@@.@@@@@@..@@@.@@@.@@@@@.@\n",
    "@@.@@.@@..@@@@@.@@@@@@.@@.@.@.@@@.@@@@@@@@@@@@@@@@..@@@@@.@@.@.@@.@.@@..@@@.@@..@..@@.@..@@@@@@@@@.@@@@@@@@...@@@@@@..@@..@@@@@@@@@.@@@@@@\n",
    "@..@@.@.@@@..@..@.@@@@@.@@@@@@.@@@@@.@.@@.@.@@@.@@@@@.@.@@@@@@@.@.@@@@@@@@@@.@@.@@@@@.@@.@@@@.@@@@@.@@@@.@..@...@..@@@@@@..@...@.@@@@.@@.@\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "80860144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8713\n"
     ]
    }
   ],
   "source": [
    "def read_input(input_str):\n",
    "    count_rows = 0\n",
    "    count_cols = 0\n",
    "    tot_lines = []\n",
    "    for line in input_str.split():\n",
    "        line_store = [0 if char == '.' else 1 for char in line]\n",
    "        \n",
    "        tot_lines+=[line_store]\n",
    "        count_rows+=1\n",
    "    count_cols = len(line)\n",
    "    return count_rows,count_cols, tot_lines\n",
    "\n",
    "def check_pos(tp_wall,x,y,tot_rows,tot_cols):\n",
    "    count_adjacent = 0\n",
    "    if(tp_wall[x][y]==0):\n",
    "        return 0\n",
    "    for i in range(x-1,x+2):\n",
    "        for j in range(y-1,y+2):\n",
    "            if(i==x and j==y):\n",
    "                continue\n",
    "            if(i>=0 and i<tot_rows and j>=0 and j<tot_cols):\n",
    "                count_adjacent+=tp_wall[i][j]\n",
    "    if(count_adjacent<4):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "tot_rows,tot_cols,tp_wall = read_input(input_str)\n",
    "\n",
    "tot_count = 0\n",
    "initial_count = -1\n",
    "while(initial_count!=tot_count):\n",
    "    initial_count = tot_count\n",
    "    for i in range(tot_rows):\n",
    "        for j in range(tot_cols):\n",
    "            val = check_pos(tp_wall,i,j,tot_rows,tot_cols)\n",
    "            if(val==1):\n",
    "                tp_wall[i][j]=0\n",
    "            tot_count+=val\n",
    "print(tot_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "56ba9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"213205509444883-217326119178383\n",
    "204028058956732-206357346689122\n",
    "267638662803789-267638662803789\n",
    "161518128431535-162211655141254\n",
    "427815309156367-428209112233595\n",
    "424003402121023-424821946030767\n",
    "175023754421204-175023754421204\n",
    "193658747860277-195872396751820\n",
    "165174470608617-165455213184493\n",
    "142914847639458-146495235254098\n",
    "302161844316724-302811454083038\n",
    "201317146392281-203680438163617\n",
    "429470458932778-429545503098505\n",
    "276734673978459-280839273781544\n",
    "525388252879654-530788873362415\n",
    "302553299774028-302939011277575\n",
    "72206822427466-79146949214971\n",
    "302939011277575-303124699217159\n",
    "462933970020376-471346905712697\n",
    "403909304754428-410668871655703\n",
    "333550261133514-338887885936350\n",
    "193658747860277-199169520770507\n",
    "456205052796416-460819192832472\n",
    "81076166149322-81347583055330\n",
    "82391634373473-82596084043885\n",
    "399091147175413-399091147175413\n",
    "3799290744865-3799290744865\n",
    "82391634373473-83094841962568\n",
    "345618405179851-345618405179851\n",
    "83977081220581-84634191907261\n",
    "414809602890962-414809602890962\n",
    "59305869430952-59305869430952\n",
    "15915286053651-17141089021731\n",
    "81076166149322-81571317517920\n",
    "301057928920460-301057928920460\n",
    "206955088139744-209270512762890\n",
    "544411189949490-548557612115354\n",
    "241814573139760-250052324042398\n",
    "62005974637606-66244098101022\n",
    "253256394459803-260114323058272\n",
    "83279573835972-83596816559687\n",
    "161987919070964-162485745765190\n",
    "352570075757187-356028557783340\n",
    "333550261133514-337596191662566\n",
    "202595941199027-204735893907022\n",
    "135406693629827-136756337303456\n",
    "374606129846789-378124314651253\n",
    "312746952788203-317584934290883\n",
    "433405855667336-441707011426288\n",
    "222383944250845-230402701262548\n",
    "168497956858385-168986638151215\n",
    "82814697374730-83094841962568\n",
    "42818804685719-45140749679146\n",
    "87654485209002-88414327244873\n",
    "429470458932778-429545503098505\n",
    "163252311445123-163392231641762\n",
    "474235903668691-481728314013923\n",
    "365609753121507-367921024942666\n",
    "429470458932778-429545503098505\n",
    "116300309838728-118408321339437\n",
    "45140749679148-47696418275161\n",
    "286142177650644-287081268792188\n",
    "18683203355469-19697462096554\n",
    "486758001201230-491664846541474\n",
    "131362732886229-139045313257661\n",
    "367393906087255-370176258300954\n",
    "308468516859984-309203568483508\n",
    "378124314651255-381398793057510\n",
    "307412270675198-307973118165736\n",
    "495609920801633-498085043720681\n",
    "314812595098738-320363322564884\n",
    "326204386424004-330762376087721\n",
    "548557612115356-550666819579298\n",
    "236918001572818-239803208355915\n",
    "362403277362722-364894725875739\n",
    "493009916493525-495110373417581\n",
    "428970175235750-429057683979633\n",
    "83977081220581-84395290996630\n",
    "498952080726273-500652427572097\n",
    "525388252879654-525388252879654\n",
    "500289151886821-502306727407778\n",
    "84834990556933-85640324761394\n",
    "356028557783341-361512368222187\n",
    "425010948617421-425374568035215\n",
    "453561624497971-457649826440755\n",
    "444413035638328-450520289771835\n",
    "233562232194856-239803208355915\n",
    "215396115748227-219542066628513\n",
    "124686322091079-128725826006565\n",
    "253256394459803-260114323058272\n",
    "414809602890962-419715174110563\n",
    "12115428410534-13479808702945\n",
    "433405855667336-437096669641888\n",
    "485532499893097-491664846541474\n",
    "476951396635787-477940327871613\n",
    "93405994213523-97216189452539\n",
    "72206822427466-79146949214971\n",
    "326204386424004-330762376087721\n",
    "83596816559687-83977081220581\n",
    "154537462650505-154537462650505\n",
    "24747598258971-27912801163795\n",
    "515740263435366-515740263435366\n",
    "104044130542431-107961981060322\n",
    "164943741195430-165818543014747\n",
    "175023754421204-177774181016088\n",
    "515740263435367-522107388480339\n",
    "306562960361355-307295707308006\n",
    "87085548843772-87781822775167\n",
    "364317893246299-366838251329989\n",
    "497505569060219-499596001026913\n",
    "383092628166021-391214586599086\n",
    "14709285310818-16226245328327\n",
    "50795924941939-59305869430952\n",
    "86402429319437-87085548843772\n",
    "369246670112573-371332810982097\n",
    "427069728093328-427619318406186\n",
    "508894418256370-511365141996145\n",
    "168012963427099-168790686895784\n",
    "429057683979633-429470458932778\n",
    "294019513027683-301057928920460\n",
    "31689401124223-37053754943957\n",
    "85725281436986-86498280258826\n",
    "273929584127738-276734673978458\n",
    "205691130079223-208019881583469\n",
    "305883736321513-306562960361355\n",
    "110940853542246-118408321339437\n",
    "146495235254098-146495235254098\n",
    "20748523913351-24747598258970\n",
    "81347583055330-82070008227691\n",
    "208790047644351-210972459132194\n",
    "17643683798624-19000209178089\n",
    "302811454083038-302939011277575\n",
    "471346905712697-471346905712697\n",
    "85725281436986-86051125252015\n",
    "265088098018194-267638662803788\n",
    "503422300537863-508894418256369\n",
    "393740144790032-399091147175412\n",
    "167030614629233-167202593210283\n",
    "31689401124223-31689401124223\n",
    "282463235907380-289721798332242\n",
    "13921330771335-15240164412244\n",
    "83912506234540-83977081220581\n",
    "386567672073240-391214586599086\n",
    "304441952399986-304635442788465\n",
    "154537462650506-159845864095183\n",
    "16743850095214-17957826429903\n",
    "345618405179852-351338285762531\n",
    "122811772099834-127512665949023\n",
    "62005974637606-69683117530333\n",
    "305541167481338-305651241655026\n",
    "555082104474805-559517041232799\n",
    "166424154345753-166771486914483\n",
    "423571567463083-423877358791616\n",
    "10243185741232-11743782153710\n",
    "11277251601637-12468884018173\n",
    "167030614629233-167426194263208\n",
    "559517041232800-559517041232800\n",
    "494572295516804-496376955743620\n",
    "182655281468791-185338761628283\n",
    "427384137182626-427815309156367\n",
    "97216189452540-97216189452540\n",
    "536565187793325-539160358417727\n",
    "12906793712917-14539801376815\n",
    "185338761628285-188402522641289\n",
    "3799290744866-9199770770251\n",
    "429470458932778-429953338505420\n",
    "225414247715485-228267959693604\n",
    "536565187793325-539160358417727\n",
    "88583581137116-89047622016807\n",
    "\n",
    "417270233264984\n",
    "14224643536999\n",
    "249371968346974\n",
    "352302688530952\n",
    "435679439563325\n",
    "41642737069856\n",
    "53773188465390\n",
    "391278032181892\n",
    "126281452574122\n",
    "475817248421743\n",
    "209476665574491\n",
    "122675778286307\n",
    "428283171524715\n",
    "416534595621402\n",
    "444659639104379\n",
    "153576111137517\n",
    "168164605409982\n",
    "334835909359805\n",
    "528684717842206\n",
    "86059463891362\n",
    "151730456018022\n",
    "380316140337312\n",
    "43234422631780\n",
    "347593418072177\n",
    "464322080594664\n",
    "456527594969670\n",
    "215282174220231\n",
    "229700549082772\n",
    "458511100559549\n",
    "418264519127388\n",
    "372974584423704\n",
    "145770007270721\n",
    "266492398968408\n",
    "147022587387324\n",
    "127345928876632\n",
    "500359168832723\n",
    "275106075656032\n",
    "105778311533435\n",
    "192860201920562\n",
    "479341063665754\n",
    "68662427949054\n",
    "451664934680840\n",
    "511487613193432\n",
    "562134509163509\n",
    "531311854874517\n",
    "480875699214138\n",
    "198572401354507\n",
    "155941563326933\n",
    "150726712678876\n",
    "559919143310458\n",
    "506811095299167\n",
    "314058637804092\n",
    "356079539936085\n",
    "413118864146833\n",
    "431999117332139\n",
    "235676646485387\n",
    "73813973234506\n",
    "534573250945444\n",
    "146069441747676\n",
    "18718446804667\n",
    "276022874587480\n",
    "77894004624546\n",
    "15986643956169\n",
    "462900434169982\n",
    "269515610448569\n",
    "178328610322231\n",
    "74703310151746\n",
    "271696472959878\n",
    "195985271992762\n",
    "138055992787671\n",
    "454313083922677\n",
    "541291896975957\n",
    "428464920079091\n",
    "449473564854956\n",
    "298662992304284\n",
    "236429044858672\n",
    "331903572298671\n",
    "350848180579824\n",
    "286380519159668\n",
    "465800946203338\n",
    "562278452256171\n",
    "306793225368252\n",
    "397960837669751\n",
    "167456872134660\n",
    "204308952406833\n",
    "5332656550212\n",
    "207950041475572\n",
    "339653047908569\n",
    "344670347309194\n",
    "396284316332409\n",
    "109125679422499\n",
    "379659441324655\n",
    "553826430375453\n",
    "194428709355045\n",
    "279460434121196\n",
    "490452836622911\n",
    "333924531746098\n",
    "262754232568912\n",
    "140296433075947\n",
    "452295606060609\n",
    "78274836814650\n",
    "389087616105274\n",
    "513761114877622\n",
    "481286127383670\n",
    "33180677874883\n",
    "274949176929992\n",
    "522963509248107\n",
    "527763769859334\n",
    "432330087714050\n",
    "394838673802869\n",
    "469650785063626\n",
    "159007805688758\n",
    "455896978581450\n",
    "275657888187193\n",
    "354617190426279\n",
    "287924781523701\n",
    "320459050320540\n",
    "163528194321318\n",
    "25622522364457\n",
    "389534719909319\n",
    "432646896553908\n",
    "123792720051454\n",
    "66674775014163\n",
    "92298285076627\n",
    "444436681592575\n",
    "145268497459776\n",
    "528055477482525\n",
    "339599459403792\n",
    "225408485098248\n",
    "385945002718951\n",
    "100103153692052\n",
    "70563144830372\n",
    "295067398062001\n",
    "97507183647966\n",
    "179243409212528\n",
    "211975148830702\n",
    "276187280019874\n",
    "171276107798144\n",
    "278793993307426\n",
    "75656553315225\n",
    "441195078504292\n",
    "498098840491784\n",
    "400370477566556\n",
    "553789944431218\n",
    "312689836028119\n",
    "296142949686765\n",
    "458978825447458\n",
    "162900794111522\n",
    "428466055043971\n",
    "243673235069240\n",
    "486609706519567\n",
    "263538545120474\n",
    "102949075498185\n",
    "447106670676791\n",
    "558712689748779\n",
    "391354301848385\n",
    "547256147437840\n",
    "249070775242775\n",
    "512984460161286\n",
    "51038978027298\n",
    "354061276641946\n",
    "110171198975731\n",
    "497613228009801\n",
    "239652904266317\n",
    "470845109643047\n",
    "519473935178555\n",
    "463743336734996\n",
    "560117724347930\n",
    "328934262734465\n",
    "251948394549521\n",
    "235086705182584\n",
    "254115997695283\n",
    "32128499565446\n",
    "63080803275488\n",
    "167507524386821\n",
    "305780400227118\n",
    "461103732913106\n",
    "494807833009248\n",
    "328155384795138\n",
    "181646302185711\n",
    "480479356124914\n",
    "481652205004318\n",
    "93752760533196\n",
    "257228589210317\n",
    "157098513294570\n",
    "217760930009905\n",
    "205722130711021\n",
    "383076478305196\n",
    "474861433410895\n",
    "166091544432674\n",
    "72985490754119\n",
    "346582974740791\n",
    "451136239933969\n",
    "538748064148111\n",
    "288181602292539\n",
    "390581022159711\n",
    "467254408736518\n",
    "96113037577542\n",
    "540303653222027\n",
    "4436738480901\n",
    "243153888045300\n",
    "237105446680223\n",
    "11232529116767\n",
    "412777890144009\n",
    "402878756460992\n",
    "356269103259268\n",
    "472163548456870\n",
    "393659011377264\n",
    "59056447042791\n",
    "264787044039823\n",
    "204764924792990\n",
    "312459614842562\n",
    "66743414240907\n",
    "192814895677953\n",
    "102258921068235\n",
    "468272145066849\n",
    "159675974927063\n",
    "172030127029963\n",
    "109034286367895\n",
    "142474748763992\n",
    "366368626545260\n",
    "14335041104082\n",
    "497012041284177\n",
    "313667686080271\n",
    "456492752535990\n",
    "287039110331610\n",
    "521593250782070\n",
    "84605652812915\n",
    "84596447538067\n",
    "68279021896235\n",
    "295579605096812\n",
    "62294569866097\n",
    "345333169437312\n",
    "377475335674445\n",
    "349221307023812\n",
    "305959412133449\n",
    "452468477478921\n",
    "379691942070323\n",
    "20648297487357\n",
    "310964630747268\n",
    "316779622079844\n",
    "252132484492563\n",
    "316154875032559\n",
    "172675638722391\n",
    "438161243071050\n",
    "437791132740048\n",
    "533368843025734\n",
    "210500557562917\n",
    "263862548991265\n",
    "518594012305851\n",
    "326468732154814\n",
    "310774570149262\n",
    "371157800448208\n",
    "369642567515959\n",
    "407277194845282\n",
    "373262368331661\n",
    "98830446739071\n",
    "489191418701928\n",
    "89199964522682\n",
    "109821726420094\n",
    "488904007292128\n",
    "179434831567037\n",
    "294005784481659\n",
    "44049532468260\n",
    "382632111136335\n",
    "390980316453461\n",
    "132589783632537\n",
    "115532032484779\n",
    "354734769329072\n",
    "212817661928320\n",
    "64166375331091\n",
    "144194914018539\n",
    "554482955493711\n",
    "445603119608357\n",
    "249637642808387\n",
    "358162031541914\n",
    "53884762304177\n",
    "497779116573797\n",
    "139144319689582\n",
    "319043948021542\n",
    "293357438834275\n",
    "356773832342936\n",
    "425684600053583\n",
    "136504381647739\n",
    "516476422443162\n",
    "421628066903281\n",
    "185564796488638\n",
    "454978117360752\n",
    "110112938289945\n",
    "118829270869180\n",
    "535137465441529\n",
    "480118480569991\n",
    "403679437817032\n",
    "459142432667018\n",
    "190425432044222\n",
    "45787668028077\n",
    "17476114973935\n",
    "381227909127479\n",
    "28696436061200\n",
    "119739055949174\n",
    "270984309648368\n",
    "542421563231164\n",
    "350582192270523\n",
    "230113400587912\n",
    "400119591992161\n",
    "354108404019562\n",
    "470454168993106\n",
    "178027330059804\n",
    "561701596848914\n",
    "432749725896490\n",
    "280144282810756\n",
    "175471556886458\n",
    "158638537204813\n",
    "3423878569728\n",
    "23212379050071\n",
    "70816624264310\n",
    "152710267648008\n",
    "264313105255866\n",
    "162827149679053\n",
    "240727480999682\n",
    "411210917977834\n",
    "443159975931260\n",
    "38276838576587\n",
    "95497284983761\n",
    "97156613604225\n",
    "294030660612698\n",
    "514026854500690\n",
    "510528487992104\n",
    "238575580200042\n",
    "156744775091624\n",
    "482015938137898\n",
    "65499063442228\n",
    "533015673763384\n",
    "417550871890227\n",
    "91756875242250\n",
    "295395899041306\n",
    "500768176705488\n",
    "56218193108321\n",
    "242372569704393\n",
    "166038451410947\n",
    "150480134840041\n",
    "360513019313375\n",
    "398140942335468\n",
    "210259835509207\n",
    "499853924623735\n",
    "519242529240175\n",
    "183309644637083\n",
    "98470950346799\n",
    "418936723592169\n",
    "205190932271418\n",
    "33712896376095\n",
    "23201452974265\n",
    "494398705771843\n",
    "327173803026407\n",
    "369115283437346\n",
    "144434646008046\n",
    "110758729754683\n",
    "505430409791676\n",
    "19618143820210\n",
    "490904864361351\n",
    "241354935876373\n",
    "174511385663874\n",
    "290741388568852\n",
    "32155714822203\n",
    "114577527905614\n",
    "423840503262925\n",
    "196253819817563\n",
    "291975241251306\n",
    "500400623234330\n",
    "447969168935231\n",
    "358001613750219\n",
    "490491321668148\n",
    "84808639377922\n",
    "493283722615796\n",
    "302489878833229\n",
    "232935650440229\n",
    "495013765899131\n",
    "394815044374739\n",
    "296657336896227\n",
    "190412350358702\n",
    "534653572581888\n",
    "328850671281289\n",
    "389481353809004\n",
    "359937519271548\n",
    "338921108491694\n",
    "154330768901587\n",
    "179999444376275\n",
    "271913076648123\n",
    "327016994845206\n",
    "40940335739749\n",
    "464503244194793\n",
    "387530982203971\n",
    "61682191690249\n",
    "292226013020416\n",
    "235597159323192\n",
    "139581582922563\n",
    "539138260469324\n",
    "199645255445214\n",
    "416102095885854\n",
    "184408486698811\n",
    "72853573252794\n",
    "307230221187552\n",
    "208718183210142\n",
    "85475563358082\n",
    "332930474336381\n",
    "542569132071634\n",
    "222120659530537\n",
    "428486768848934\n",
    "50546456982748\n",
    "439048552637474\n",
    "93680673066572\n",
    "335577882881430\n",
    "149381316957894\n",
    "273917981119962\n",
    "284207372541459\n",
    "560134189006237\n",
    "439534807658822\n",
    "62951269623136\n",
    "345570090800037\n",
    "7795947193503\n",
    "201288246099159\n",
    "194190566077552\n",
    "168296899749644\n",
    "274697313348062\n",
    "478263730887817\n",
    "416883569615692\n",
    "419716106848812\n",
    "90222775151278\n",
    "166131575502577\n",
    "136725279026111\n",
    "406920589859872\n",
    "22799532405021\n",
    "92305725530387\n",
    "254114455649461\n",
    "101055054668723\n",
    "104990319099389\n",
    "553219565218379\n",
    "262811451047677\n",
    "294028780093422\n",
    "233344457904529\n",
    "456689490359781\n",
    "497828684797910\n",
    "54731808353017\n",
    "156378669504087\n",
    "308097151971544\n",
    "80946381658354\n",
    "97657004495501\n",
    "174175716540071\n",
    "174174962284120\n",
    "548988637995994\n",
    "123062560435724\n",
    "101608317560160\n",
    "391076366105052\n",
    "426499532499044\n",
    "6884879402707\n",
    "340463345319512\n",
    "345239944804516\n",
    "498597365044429\n",
    "390441014626557\n",
    "329675870060976\n",
    "351514802000195\n",
    "555213273068052\n",
    "249255158011198\n",
    "538949282947726\n",
    "196197988102626\n",
    "103943538950527\n",
    "181963498426569\n",
    "312811272853810\n",
    "485669870186874\n",
    "511199043594652\n",
    "506819339894425\n",
    "219934716316395\n",
    "526074244731736\n",
    "388712580961781\n",
    "456414040541168\n",
    "326943910622866\n",
    "441837859940234\n",
    "373222293363087\n",
    "194542551489050\n",
    "231242503734411\n",
    "532524032922054\n",
    "137488424122242\n",
    "227656157255778\n",
    "132378524937589\n",
    "542828317231154\n",
    "454252870742934\n",
    "135281837075949\n",
    "383876587828987\n",
    "238948305403770\n",
    "437445735682454\n",
    "379213990112929\n",
    "381460529073509\n",
    "34337867148608\n",
    "311337320147231\n",
    "201257847020697\n",
    "297350884838117\n",
    "198999601108724\n",
    "158288273072696\n",
    "524438984681493\n",
    "71291700184272\n",
    "512273856599242\n",
    "267567787286367\n",
    "268521511591152\n",
    "447882575482086\n",
    "253018550683872\n",
    "502335857889237\n",
    "390005102559579\n",
    "185270934624696\n",
    "208012073669107\n",
    "508404694483572\n",
    "408413247516419\n",
    "152817108360437\n",
    "524108395429341\n",
    "558380403261330\n",
    "131449982048331\n",
    "70204649139718\n",
    "86542239061964\n",
    "274289528913351\n",
    "275898557485501\n",
    "497158313254548\n",
    "149814803162433\n",
    "553708392302261\n",
    "254285377476261\n",
    "431354303697820\n",
    "489126583518036\n",
    "405061016298013\n",
    "109332816851646\n",
    "103030862536923\n",
    "434187088782275\n",
    "276544790949015\n",
    "341399050162106\n",
    "246082063500747\n",
    "77402687727500\n",
    "500136589963435\n",
    "373341401975844\n",
    "89218203965726\n",
    "217965731602965\n",
    "118113751656246\n",
    "429026024642265\n",
    "208370351528332\n",
    "389577558163516\n",
    "415836771180145\n",
    "61353149322936\n",
    "80442346951375\n",
    "37647604359448\n",
    "32510786750231\n",
    "139363735141481\n",
    "341384051874871\n",
    "479573452832838\n",
    "251923924949308\n",
    "502436727670457\n",
    "356820975286835\n",
    "77220754741864\n",
    "265255859527646\n",
    "187662036260970\n",
    "44159353458813\n",
    "205675009851157\n",
    "209162225970226\n",
    "126552717130865\n",
    "537694475681942\n",
    "271967190526864\n",
    "16129858311873\n",
    "406558243475209\n",
    "41584671315254\n",
    "189350044682815\n",
    "414813971884885\n",
    "166445521119759\n",
    "421414769392964\n",
    "258193897525780\n",
    "129000475023726\n",
    "160102967827398\n",
    "259361542157044\n",
    "306704714274888\n",
    "231679142407610\n",
    "163078963508226\n",
    "135755106055079\n",
    "131268611120761\n",
    "399384103588111\n",
    "244130745293657\n",
    "340208111307003\n",
    "408536333327485\n",
    "492123609486060\n",
    "107810837331359\n",
    "284910345787006\n",
    "185018969965357\n",
    "65970078275621\n",
    "470253520149753\n",
    "161643683287111\n",
    "132230548345331\n",
    "548647547302593\n",
    "247680336108197\n",
    "107089372500486\n",
    "110165466056755\n",
    "433447533808783\n",
    "304903085023282\n",
    "196255974272770\n",
    "528599869870149\n",
    "328787103268445\n",
    "161354610527288\n",
    "413829848422700\n",
    "365755468060296\n",
    "482517977627600\n",
    "307022105168555\n",
    "246006602083654\n",
    "122030441288830\n",
    "541872170429419\n",
    "400843086758761\n",
    "482534676551994\n",
    "185919863770600\n",
    "462353355457585\n",
    "562917909941012\n",
    "190869015740358\n",
    "515899382734125\n",
    "484425008732526\n",
    "508581145125899\n",
    "518623236886156\n",
    "69576212144565\n",
    "317195606578441\n",
    "398362177306622\n",
    "394080520843900\n",
    "141267354712397\n",
    "314772439140271\n",
    "542380947639293\n",
    "503065352812025\n",
    "374452106653404\n",
    "337188710156848\n",
    "529761545891872\n",
    "101621585847815\n",
    "164126361675919\n",
    "85526680823296\n",
    "53068597291337\n",
    "217621552435387\n",
    "176989738949355\n",
    "124662764591310\n",
    "554638051114105\n",
    "558224345352173\n",
    "357475309752342\n",
    "295643047559471\n",
    "496247539835523\n",
    "199933887457670\n",
    "353026401946126\n",
    "134655711483979\n",
    "335807764452577\n",
    "207739690903197\n",
    "520792015103503\n",
    "545735856820161\n",
    "535423775529173\n",
    "255201909892093\n",
    "522093028638616\n",
    "269932187893724\n",
    "361014686090466\n",
    "512556128316410\n",
    "22749448306174\n",
    "103561641284939\n",
    "447246981687804\n",
    "13699282413272\n",
    "417267623662228\n",
    "107475339404339\n",
    "510806875187339\n",
    "512504944693385\n",
    "386624808039169\n",
    "149893645529147\n",
    "8418829277187\n",
    "59714167225351\n",
    "494291496068490\n",
    "288799377906226\n",
    "158738238218326\n",
    "522407846964927\n",
    "353890049109841\n",
    "518429096774451\n",
    "87836682933837\n",
    "52625276776155\n",
    "264709383364198\n",
    "550249326945159\n",
    "522230185005266\n",
    "47840372059452\n",
    "152834422735457\n",
    "429338780274998\n",
    "3363809890131\n",
    "267216882821215\n",
    "71705146135946\n",
    "102160230432148\n",
    "406957054403535\n",
    "398167749122229\n",
    "36004367205148\n",
    "339892358252151\n",
    "54938444498399\n",
    "136631503675256\n",
    "113005072974716\n",
    "221156332882434\n",
    "230523892958867\n",
    "65055033069585\n",
    "537043019968191\n",
    "476603272598660\n",
    "300837101554756\n",
    "148954210296557\n",
    "504868993167456\n",
    "27424169294192\n",
    "386969796825838\n",
    "20486514139614\n",
    "255081411130076\n",
    "13451213140569\n",
    "155136186017734\n",
    "241322316420425\n",
    "258655342636806\n",
    "334036328465912\n",
    "132090285878237\n",
    "388520108093791\n",
    "79023610402621\n",
    "381766688079024\n",
    "386743531419885\n",
    "48320792489192\n",
    "247568916997206\n",
    "72968443167249\n",
    "120788362556618\n",
    "876823046701\n",
    "241281441786611\n",
    "76710409791576\n",
    "91230845975727\n",
    "443276654379811\n",
    "514373945848590\n",
    "239187798567826\n",
    "442678304173571\n",
    "260037506233019\n",
    "197377602965277\n",
    "182544728321319\n",
    "347166407894067\n",
    "13672850404311\n",
    "237795124309123\n",
    "367496114240733\n",
    "174810193224736\n",
    "492950541304214\n",
    "509215453821213\n",
    "424701168094531\n",
    "326352251795679\n",
    "534360199966256\n",
    "72245328877641\n",
    "107084674262434\n",
    "491992695505708\n",
    "459491221827267\n",
    "428245398422741\n",
    "9489060451602\n",
    "491041684615282\n",
    "125051209508764\n",
    "482233446988432\n",
    "448396520698779\n",
    "381781940651704\n",
    "360754780607448\n",
    "495420800081650\n",
    "11110405946214\n",
    "325596915022454\n",
    "463549159048137\n",
    "58884451871719\n",
    "451028129368881\n",
    "391844180352132\n",
    "126854306767525\n",
    "55828684133200\n",
    "76823273053826\n",
    "157103442162547\n",
    "297831711052286\n",
    "175635081401523\n",
    "132635950619001\n",
    "357700338496654\n",
    "284360316440540\n",
    "432719128139517\n",
    "381722437234285\n",
    "539383522220315\n",
    "319393675373641\n",
    "281714147327064\n",
    "107715113415816\n",
    "240120030661210\n",
    "172791660803233\n",
    "502297377234208\n",
    "535655069682621\n",
    "241425025638118\n",
    "115975496963469\n",
    "136367673850153\n",
    "436124321078925\n",
    "237066955400610\n",
    "180337819864308\n",
    "225842232818783\n",
    "108017353855468\n",
    "91841394485179\n",
    "81673967057812\n",
    "255797850268244\n",
    "283629339470153\n",
    "35464951337070\n",
    "472498651190775\n",
    "31296506513277\n",
    "536544210459283\n",
    "317859205061918\n",
    "19701340259734\n",
    "516056372604020\n",
    "327566984044775\n",
    "396240683128638\n",
    "31087758412921\n",
    "488377991676964\n",
    "392828650549956\n",
    "246919329604239\n",
    "371210101878345\n",
    "424682795377861\n",
    "4659994590307\n",
    "436851022257833\n",
    "22415833069678\n",
    "167835897459537\n",
    "169300722186317\n",
    "482692114126600\n",
    "56250741696209\n",
    "498070299617537\n",
    "241700711816876\n",
    "194606455201358\n",
    "165083964109101\n",
    "221870213534219\n",
    "50750412353656\n",
    "17115109803128\n",
    "308437767897249\n",
    "369755120734801\n",
    "311431717242784\n",
    "528878377997693\n",
    "346260851350547\n",
    "81270459848668\n",
    "528915874721365\n",
    "281314131914232\n",
    "209307057037354\n",
    "104588754711586\n",
    "519241764459210\n",
    "280949649453964\n",
    "152855614863362\n",
    "283614086688322\n",
    "404440903904106\n",
    "289696070008943\n",
    "550591902219243\n",
    "29517049333319\n",
    "272316706009884\n",
    "497813676542263\n",
    "424488409762048\n",
    "462791026073687\n",
    "510212146598334\n",
    "403390463695276\n",
    "86447168103904\n",
    "139976551789226\n",
    "394914711944661\n",
    "138028264431749\n",
    "127846112861729\n",
    "95227564036602\n",
    "33655502800504\n",
    "260773410170203\n",
    "351389224041523\n",
    "337225484116032\n",
    "113429999159969\n",
    "142324859911221\n",
    "271660547654325\n",
    "433891427456118\n",
    "394794516182229\n",
    "402733531351286\n",
    "545852051442338\n",
    "558346108836322\n",
    "416738443099575\n",
    "303841340474299\n",
    "161574617477273\n",
    "354844649557266\n",
    "448369944364581\n",
    "491521151084653\n",
    "22085035096921\n",
    "80319430505395\n",
    "58803155364631\n",
    "214120208818869\n",
    "236168261445080\n",
    "173108238265535\n",
    "240045538063686\n",
    "67925402608689\n",
    "539757991509483\n",
    "363048782889211\n",
    "48714895414947\n",
    "94787029698092\n",
    "375946034188233\n",
    "515296211999195\n",
    "339780591476678\n",
    "340227734341902\n",
    "177248448798641\n",
    "51302238860258\n",
    "151386766217259\n",
    "507749120111726\n",
    "293902391260032\n",
    "181631023544542\n",
    "373593799685082\n",
    "476561268997598\n",
    "312913925066489\n",
    "26037097727160\n",
    "144982437470825\n",
    "309549851622790\n",
    "322811308393950\n",
    "296495906208680\n",
    "311339547592957\n",
    "438680599006714\n",
    "429643622541649\n",
    "90266986693688\n",
    "348128645855160\n",
    "412875179671111\n",
    "497173275011290\n",
    "204126248360340\n",
    "505527979817527\n",
    "329634699915169\n",
    "389022234310062\n",
    "151975676526078\n",
    "277982498241758\n",
    "20177858742981\n",
    "90377215102103\n",
    "528874288252822\n",
    "196014629643597\n",
    "311892128787263\n",
    "148189548179827\n",
    "529225374799519\n",
    "378342314818775\n",
    "145614577369576\n",
    "57712111779633\n",
    "50826942726721\n",
    "451130613602896\n",
    "246228697367539\n",
    "83475847777934\n",
    "62569965586920\n",
    "500733026987925\n",
    "183926289261916\n",
    "342384746006324\n",
    "500512725421577\n",
    "440032944544871\n",
    "436409641122584\n",
    "322611105218158\n",
    "110302709696077\n",
    "476063737765137\n",
    "335070622918544\n",
    "464905953424623\n",
    "423765969231332\n",
    "438574195471629\n",
    "172445561218570\n",
    "455073744249756\n",
    "365120264938473\n",
    "31584345965667\n",
    "320275526407238\n",
    "229799236225423\n",
    "176642367241503\n",
    "322965240768016\n",
    "117986743562127\n",
    "479415201599494\n",
    "392931517266607\n",
    "333532124608404\n",
    "176805090007048\n",
    "5091162380344\n",
    "504358320170281\n",
    "119377058908335\n",
    "265894068257778\n",
    "167351876631132\n",
    "124704959044617\n",
    "373314403305604\n",
    "279254305601617\n",
    "287252887793925\n",
    "48771927621889\n",
    "208168954121578\n",
    "93145929830513\n",
    "373970354259011\n",
    "206999292157513\n",
    "78124421808241\n",
    "438860219622119\n",
    "212532497721950\n",
    "548704204888361\n",
    "139713687631528\n",
    "117854468902935\n",
    "413377837409901\n",
    "152446971058436\n",
    "170253946427765\n",
    "15442801965865\n",
    "440792688490779\n",
    "451377542795027\n",
    "143958052173350\n",
    "105764333303929\n",
    "56435158835677\n",
    "45145053792093\n",
    "406523883981013\n",
    "141269179434975\n",
    "287500579964733\n",
    "97800948546339\n",
    "479807405893491\n",
    "460736409451005\n",
    "133366013006983\n",
    "261846917771104\n",
    "41094746232105\n",
    "172392405513696\n",
    "148985142938343\n",
    "370717106576732\n",
    "466799240644811\n",
    "429903382916175\n",
    "197544706094109\n",
    "354535834828033\n",
    "188171237250860\n",
    "132048468564151\n",
    "426768605345187\n",
    "502618908371958\n",
    "271098480654350\n",
    "279823513545612\n",
    "58609737910842\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d95c77da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "ranges = []\n",
    "values = []\n",
    "for line in input_str.split():\n",
    "    if('-' in line):\n",
    "        start,end = line.split('-')\n",
    "        ranges.append([len(start),len(end),start,end])\n",
    "    else:\n",
    "        values.append(line)\n",
    "# print(ranges)\n",
    "# print(values)\n",
    "\n",
    "tot_count = 0\n",
    "for val in values:\n",
    "    for rng in ranges:\n",
    "        if(rng[0]<len(val)<rng[1]):\n",
    "            tot_count+=1\n",
    "            # print(val)\n",
    "            break\n",
    "        elif(rng[0]==len(val) and len(val)<rng[1] and rng[2]<=val):\n",
    "            tot_count+=1\n",
    "            # print(val)\n",
    "            break\n",
    "        elif(rng[0]<len(val) and len(val)==rng[1] and rng[3]>=val):\n",
    "            tot_count+=1\n",
    "            # print(val)\n",
    "            break\n",
    "        elif(rng[0]==len(val) and len(val)==rng[1] and rng[2]<=val and rng[3]>=val):\n",
    "            tot_count+=1\n",
    "            # print(val)\n",
    "            break\n",
    "\n",
    "print(tot_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "f8a30490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_overlaps(rng1,rng2):\n",
    "    start_len = min(rng1[0],rng2[0])\n",
    "    end_len = max(rng1[1],rng2[1])\n",
    "    if(rng1[0]==rng2[0]):\n",
    "        start = min(rng1[2],rng2[2])\n",
    "    elif(rng1[0]<rng2[0]):\n",
    "        start = rng1[2]\n",
    "    else:\n",
    "        start = rng2[2]\n",
    "    if(rng1[1]==rng2[1]):\n",
    "        end = max(rng1[3],rng2[3])\n",
    "    elif(rng1[1]>rng2[1]):\n",
    "        end = rng1[3]\n",
    "    else:\n",
    "        end = rng2[3]\n",
    "    return [start_len,end_len,start,end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "365f6d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, '9', '21']"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_overlaps([2,2,\"10\",\"20\"],[1,2,\"9\",\"21\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "252afc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def does_overlap(rng1,rng2):\n",
    "    # Any Endpoint overlap\n",
    "    if(rng1[2]==rng2[2] or rng1[2]==rng2[3] or rng1[3]==rng2[2] or rng1[3]==rng2[3]):\n",
    "        return True\n",
    "\n",
    "    # Smaller start first range\n",
    "    if(rng1[0]<rng2[0] or (rng1[0]==rng2[0] and rng1[2]<rng2[3])):\n",
    "        if(rng1[1]>rng2[0] or (rng1[1]==rng2[0] and rng1[3]>rng2[2])):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if(rng2[1]>rng1[0] or (rng2[1]==rng1[0] and rng2[3]>rng1[2])):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "print(does_overlap([3,3,\"101\",\"200\"],[1,3,\"9\",\"101\"]))\n",
    "print(does_overlap([2,2,\"10\",\"20\"],[2,2,\"21\",\"22\"]))\n",
    "print(does_overlap([2,2,\"10\",\"20\"],[2,2,\"20\",\"21\"]))\n",
    "print(does_overlap([2,2,\"10\",\"20\"],[2,2,\"20\",\"22\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "41fd0e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b73e1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_orig = ranges.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "f62f9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = ranges_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "31aa15f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "again\n",
      "again\n",
      "again\n",
      "again\n",
      "again\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    new_ranges = []\n",
    "    combined = []\n",
    "    for idx in range(len(ranges)):\n",
    "        rng1 = ranges[idx]\n",
    "        for idx2 in range(idx+1,len(ranges)):\n",
    "            rng2 = ranges[idx2]\n",
    "            if(does_overlap(rng1,rng2)):\n",
    "                new_ranges.append(combine_overlaps(rng1,rng2))\n",
    "                combined.append(idx)\n",
    "                combined.append(idx2)\n",
    "                break\n",
    "        if(idx not in combined):\n",
    "            new_ranges.append(rng1)\n",
    "    ranges = new_ranges\n",
    "    if(combined==[]):\n",
    "        break\n",
    "    else:\n",
    "        print(\"again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "fc784848",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"\n",
    "123 328  51 64 \n",
    " 45 64  387 23 \n",
    "  6 98  215 314\n",
    "*   +   *   +  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "62d444d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"\n",
    "91  99 31  33 125 61   44 4121  6  13 3  28 26  6 95  7459 912 4337 598  9668   59  387  4 1782 56 454 84 75 84 292 139 75 94 215 52 53    9 47 12  5161 445 66  61 2115 16 27 62  632 8938 2151  5 47  9  6  928 6834 98 3  791 5466 341 8   242 331 44 27 159 52 42  63  9   7 474 164 365 9  37   4  48 94 55 52  6  98 11 68 32 4   94 324 73   523    5 41 875 977 411 1  66 9995 21   2478 58  47 35 86 5  37 834 61  63  29 97 25 89  779 73 75 95  719 78  8 58 339 3  669 1953 14 131 76 91 45  7813 73 423  19  82 41 96  528 576 3  24 59  9985  65 631 4426 22  3 96  2 9813 52 67 64 36 73 884 321  1 81 1613 725 24   751 72 7182 44 178  2 812 61 47 23   1 44 215 75 256  51  72   47 214  2 678 54 211 6  756 18 59 22 797 34  4795 97 2488 56  849 236 67 584 4822 8     4 62 327 886 36 113 9   346 433 293 5981 332 46  9 717  2 39 55 97  99 38 42 64 4  41 837 71 31 96  44   57 92 91   2 97  6  8 91  8    73 6976 682   1  18 473  3   1   9258 9  198 69 35 442 363 7444 4678 8   54 35   317 13 194 968 264  8 42 44 94 29  234 395 54  4 5444 6   929 316 28 8  16 9      8 556 1      8  6 215 24 65 71  7 41  48 758 392  15 859 3   56 767 56 28 936   9 21 6927 57 7612 762 1   93 152 66 4  23 61 437    3 48 2498 56 98 637   5 7    5   6    8 87 24   68 18   2366  3 3852 396 17 457  274 26  19 98  786  3524 51 693 78 27  434  57 6699 68  19 793   27 85 4    3   94 1754 68 236 76 4  22  25 523 69 4   66 64   78   13  4882  8 65 11 6678 963 868 86 32  1 64  963  53  23 2228 275 1624 9   9   66 7  71   6 3   7955 9616 44   9 618 7  754   75 754 6363 32 3547  437 87   7 5     2 18  46 37 25 44 39 55 524 855 7  78 123 135 7638 7514    2 352 77 26  8   87  49 73  74 518 85 19 79   5 433 45 826 399 64 47  63  6 775 33  9  44  4 528  91 59 85  7 654   45 35 546 435 612 41 3444  96 772  278 276 5178  8 77  4 18 3797  894 8  764 7591 12 28 8  341 37 527  17 62 232   3 9885 49 537 75  61  2 9665 9   8  7  7197 826  4 22 78 38 883  8  39   1 636 32  1  96 9423  833 237 22  216 22 9  32  63  44  945 629 85 6   55 11 126 87 131 51 37 84 96 783 66 7  66  2  3786 963 43 56 175  846 746  6 24  24 65  14 697 746 285 67 11 279 489 641 384 96 97 661 726 27 42  64 7  463 81  49  8 54 1  97 42 564   4 468 319 4781 162 9  668 5658 94 567 424  6 4  2   942  5  3 2   2   51  81 68 6   81 8  41 3597 12 121 57 694   1 75 58 1  24 15 59  68 129 7   526 5679 127 22    2 61 379 32  492 8   394 6   293  4   3  8 1   13  32 945 9878 353 67 135  35 5   85 4  7  3479 59   4 4735 236 295 8   58 347   19 457  2 2   37 5515 3  1884  8 86   91 4   656 86 6899  42 1868 74 79 494  1 26 13 57 2766 669  55    9  99 1  95  19 486 797 92 4  5927 6771  84 66  53 63 299   6 375 669 87   51   67 34  68 169  3  62 671 17  9 741 695 93   873 817 511 783 63 857 61 479 51 92 84  4862 49 45 4757 94  81 717   5 198 7578 5   912 38 58  98 43 58  726  3 41 58 23 791 7882 17 7161 64 97  54 75 7  86 33 6  42 48  48 3  83 86 735 64 77 626 86 81 25  5 9  3   313 2659 96 27 13 682   11 389 498 776 27 6  371  9   3 71 623 26 71 776 36 49 523 88 6172 96      6 4  14 94 124  35   99 619 87 89 44  39  52 663 372 7  224 5784   66  9 847 46 396 8573 96 6339  2 72 3964 27 159 44 435 5167 34 57 28   6  42 189 51 825   44 9723 614 956 44  445 236 29 941 555  8 598  37 33 168 6    82 58  9 6689 413 94  239   2  921 49   236 61 82  2 456   66 41 9591 1  36 19  794 14 948 4429 8  13 12  2  41 13 31  6 31 79 7   788  6 753 222 59 3   58 37 1  58 54   64 4  32  96 398  236 325 333 4    2 319 1   81 13 37    7  58 29 63 2  8962 95   46 566  3 296 8246 44  9 257 949 855 122 92 26  77 372 81 28   357  8 817 58 826 81 49 219 584  4  91 6828 58  645 785 67 773  6  7283 3989   1 476 114  6265 9569 8   275 1   297 264 45  44 78 87  25   59 77 455 264 421 92 23\n",
    "736 17 35  85 558 29   45 2676 51 755 9  91 94  7 21  2858 456 9336 7975  794  289 9181 65 3176 21 999 25 59 56 225 385 85 65 745 96 661  97 12 67  7468 614 58  86 4865 59 84 787 581 2844 6825 45 114 86 9  38  1535 93 35 325 6241 323 54   27 716 84 76 778 98 464 32  65  9 987 838 113 19 693  6  83 49 53 964 2  49 5  75 72 3   75 921 493  146    3 73 561 129 647 6  61 7116 8674 3797 82  85 45 86 7  94 295 45  62  57 68 58 663 113 33 84 66  291 94 53 79 272 64 266 4297 43 239 64 34 23  298  95 822  752 46 63 996 871 613 1  44 82  2827  41 537 6518 15 72 67 67 7299 82 9  34 37 71 645 336 89 51 2285 182 953  681 62 3782 66 264  5 129 46 38 795  8 28 266 76 3534 79  21   15 638  4 748  4 158 29 195 68 13 69 219 964 5695 88 1896 94 9329 228 75 923 6229 8628 46 22 936 255 59 226 3   673 941 35   335 26  35 81 97  34 74 72 25  52 22 82 83 91 72 148 52 37 193 71  557 15 11  93 66 19  5 97  123 423 8727 588  68 778 182  289 434 9639 49 372 58 75 774  53  441 893  349 89 438  657 84 538 255 287  5 55 62 76 398 514 457 75 31 7664 5   579 275 88 53 89 8    228 738 511    4 18 942 52 18 98 14 69  61 79  648  68 147 6   53 967  1 74 715  96 96 6829 48 7433 312 94  67 727 17 72 71 96 996   39 63  861 92 89 245  49 45   1  48 1516 62 48  538 522  3278 37 9181 543 46 499  541 71  99 25  395   837 22 118 68 35  129 274 9924 24  37 518  756 74 679  2   65 3547 35 886 78 5  49 396  43 98 17  79 6727 71   52  8838 91 97 64 4587 977 892 26 28 52 989 999  913 95 2858 724 8177 656 78  63 4  29  85 9   9757 5336 17  18 441 4  651   56 766 8455 46 8534 2745 92  43 63   16 46  35 18 83 3  46 74 193 792 34 25 386 198 8598 517  2783 426 54 89  84  266 11 12 297 678 81 47 44   4 818 19 119 846 42 8  818  2 195 11  2  47 95 5497 26 99 69  7 744   33 79 422 428 417 79 1363 979 958  634 143 4939 66 42 63 85 6249  415 37 715 4373 67 99 14 363 62 5745 92 93 655 731 6534 64 538 88 268 83 8662 25  7  3  5727  88  3 93 97 18 483  8  55   9 951 616 53 63  471  679 642 23  444 81 4  859 71  41 7895 958 23 9   23 41 985 63 473 24 5  96 11 176 31 31 73  52 1118 616 34 11 195 4123 449 14 37 436 396 59 445 412 625 37 74 829 46  869 997 3  74 778 974 53 287 53 5  466 614 15  2 99 9   2 64 327  32 889 757 6419 688 3  711 7152 33 315 216  6 1  394 694 29 98 19  8   399 29 73 2   38 81 93  638 53 592 56  51 629 34 55 76 62 27 67  46  97 456 233 6482 583 568  24 71 557 28  232 88  275 275 344  8  43 43 65  43  36 986 5826 571 59 25  149 72  53 54 38 2671 77   6 9477 973 582 277 65 223  642 484  4 47  61 3571 9  4184  5 984  43 68 2125 16 2112 988 92   35 81 292 75 53 48 36 871  261  32 4925 533 1  75  91 758 797 22 74 4836 1453  83 493 34 44 981   7 364 163 44   142 322 33  28 976  13 13 582 68  3 599 128 16  3316 916 822 928 14 434 77 376 18  1 171 5984 21 54 8635 62  55 512   3 919 4559 3   699 37 49 486 64 58  357  8 17 58 21 84  4847 82 3411 86 919 18 45 9  42 5  82 21 82 989 9  47 67 162 57 33 61  26 54 36  6 4  23  942 7197 99 65 43 5243 312 959  27 511 46 88 215 96 365 32 353 33 91 257 19 33 465 24 1632 1537  269 42 52 31  68  68  182 242 75 35 59  38 277 328 742 7  983 6558   74  1 552 22 215 9437 36 181  54 23 671  22 653  6 771 4456 97 86 75 578  38  35 67 483 5588 5119 964  69 983 291 916 67 131 576 64 373  85 91 147 869  74 31 53 2962 544 192 456 588 2333 871  81  78 53 84 2143  61 13 898  85 68 94  768 96 222 8156 7  79 57 63  87 81 75  7 86 52 68 6434  4 571 341 24 9  552 14 93 56 28   75 81 99  34 123 1951 87  49  3    4 587 87  92 78 656 848 467 81 49 36 3726 46  942 926 21 154 8649 29  6 788 695 392 253 24 289 59 958 66 633  768  6 413 73 594 56 92 443 263 98 297 9628 257 781 485 84 778  44 8363 4237   1 227 9735 392  8156 9   983 24 5155 736  4 787 55 88  35   77 12 489 136 212 97 54\n",
    "347 87 49 416 415 279  86 26   36 884 9  92 76 56 915 6463 122 5629 1448  272  745 3736 54 7963  7 753 81 19 66 443 52  65 53 441 75 768  41 44 641 651  864 43 997 6264  5 68 867 577 7889 5    67 742 44 8  99  6826 98 59 633 4774 484 291  45 35  53 86 88   8 113 521 62  4 468 468  83 93 3139 96 81  5 66 699 1  87 1  94 16 536 19 268 5219 957 1848 91 16  729 117 71 97   76 7893 1529 91 312 33 53 11 19   3 915 399 86 99 14 488 485 24 64 996 317 64 47 74 643 77 331 29   27  36 31 76 37  256  21 4978 179 18 3  733 224 895 16  4 16  684   36 718 5393 11 34 16 78 53   61 9  85 52 57 336 874 39 96 78   39  893  362 46  168 88 392 97 471 28 16 549 64 21 133 21 5156 483 42 2887 837  4 64   4 285 34 311 5  78 77 949 461 7214 2  8721 12 6544 175 83  72 9962 6421 67 91 37  4   86 868 63  228 879 29   599 58  29 91 8   96 31 46 76   3 64 39 97 13 11 123 28 77 271 688 288 95 34  14 13 24 42 219 229 259 4835 251 771 474 642  395 414  599 51   2 38 51  57  82   79 477  445 34 774  426 92   7 857 742 87 88 72 26 982  32 18  59 66    2 838 341 759 16 88 84 858  769 191 5544 154 32 737 52 63 85 71 37 147 24  161 735 723 264 16 374  9 91 493 313 55 9368 73   51 789 583 15 827 96 19 85 44 529 4591 41  415 9  83 726 354 66  34 973 2255 85 9  3272 6752 7149 96 7156 375 82 796 8959 17 818 576 8985   49 81 874 76 82 6352 518 4637 667 97 373 8681 75 9884 86  26 8448 58 77  99 2  31 887  16 28 45  44 9821 7786 42  8737 77 4  54   83 321 176 35 55 43 193 6715 767 79  858 659 2919 767 73  45 48  2  86 318 2777 2459 768 38 484 99 4696  87 516 3546 55 3684 7952 34 396 35  134 32  79  5 82 6  52 23 833  88 62 11 761  42 5798 48   7158 814 5  419 797 614 47  3 564 827 36 85 332 35  77 69 966 892 34 4  935 68 118 36  7 721 29 4814 27 89 17 52   1   57 15 392 125 992  1 2924 729 4475 291 556  887 69 71 32 67 7458 4895 68 17  5566 82 83 15 39  66 4721 98 69 53  774 9315 58 336 82 361 65 641  29  9  47 3896  91 74 59 89  1 974  6 358  37 37  228 65 32  355 6584 897 62   34 72 8  432 35 792 8874 938 84 29  71 7  17  12 334 38 2  14 57 793 9  93 724 55 3361 484  7 15 374 8648 429 99 96 391 838 98  75 813 68  17  3 115 9    33 659 2  42 76  33  43 351 45 15 133 842 24 39 71 25  3 43 9732 37 48   69 4545 865 2  822 872  52 45  385  9 23 885  82 46 42 724 32  516 28 81 2  123 24 86  515 43 224 18  33 281 9  91 34 19 94 871 48   4 874 744 65   259 773 799 75 57  337 177 497  69 619 924  7 173 92 86 136  83 814 2575  24 98 1   256 96  76 96 61 2872 81  59  388  43 779 543 59 729 3618 636 12 438  2  169 38 9298 49 9252 51 26 1125 63  189 131 46   76 56 287 53 26 34 2  64    95 277 1836 998 87 295 49 141 519 71 73 2677 3189 679 573 37 92  31 592 545 398 424  961 549 85  36 8518 24 63 127 9  71 544 929 198 1896 679 743 375 99 9   84  97 82  2 433 172  53 19  616 74  46 634 326 21   575 77  291 12 35 964 44 482  25 11 87 84 85 8    539 46 5234 12 855 36 94 52 6  1  59 69 75 484 57 55 13 296 88 58 71  72 41 33  8 6  844 841 5556 43 47 28 1283 653 133  53 128  5 88 851 31 244 49  82 17  4 51  55  7  71 21  567 6141 9988 48 64 47  33 297 6944 656 3  29 9  557 271 779 469 22 536 281  6674 44 763 98 59  969  94 886  19 73 371  27 445  1 747 9838 86  1 37 855 625  34 85 718 8123 3215 639  34 731 245 296 94 45   66 39 99  192 22 678 8149 84 97 77 5987 715 521 92  695 2462 9519 76  73 24 19 2268 375 75 941  97 38 886 488 63 31   473 54 82 5  51  77 74 56  9 9  22 89 3127 73 587 325 38 47 621 71 12 85 62  379 53 617 17 867 7784 7   61  99  39 577 562 38 92 747 998 979 83 97 17 7271  7  113 166 84 389 1989 91  9  38 414 861 665 9  771 61 573  3 237  369 56 841 53 771 33 37 734 95  41 725  951 542  18 824 99 6768 34 6639 9878 145 49  5491 87   75   96  441 73 5182 281  8 579 78 92  82  595 62 472  37 416 89 6 \n",
    "583 7  47 289 449 428 984 5    18 633 56  8 18 51 113 31   129  672 3414  631 1949 5691 58  682  7 128 35 58 15 769 91  74 15 134 14 653 724 79 994 847  98  63 152 999   5 84 681 488 76   3    29 846 52 21 86  34   71 31  48  391 268 254  51 34  36 9  13   6 571 672 93 88  99 74    9 94 8249 51 45  8 6  661 23 12 7  55 82 745 7  67  8615 663 9478 29 35    9 144 93  8    5 8752 8935 69 222 68 66 58 28   3 513 574 38 64  6 869 53  27  9 119 552 66 87 93 664 48 288 88   76  58 13 14 826 258   9 1343 249 48 8  888 81  23  23  5 931 224  293 211 3154 17 51 83 62 9    57 9  67 98 82 345 517 81 32 69   8   669 1591 8     3 22  27 66 966 87 62 363 89 35 495 97 3842 292 71 8567  96 32 76   7 41  94  92 5   7 56 651 248   98 5  694  33 9424 62  13   6 1988 2861 76 6  5   3   5  348 237  73 114 5     41 8   13 83 5   15 26 44 428  8  9 34 32 28 64 866 23  2 479 587 626 21 63 343 67 91 41 645 729 317 8916  91 892 695 1635 813 713   68 23   1 69 62   8  61   59 35   949 43 7962   8  2   5 486 789 34 86 9  8  674  15 41   6 88    5 562 836 448  9 91 57 612 9111 291 6963 236 46 728  5 15 37 74 51 774 31   67 643 97  886  1 47   4 2  212 116 84 27   89   15 892 549 19 745 9  27 95 44 835 4235 2    93 5  76 167 568 53 856 298 2458 58 6  8675 6651 849  17 7246 611 2  139 9854 11 759 991 4911    5  9 795 76 36 7864 522 254  593 79 492 8884 44 9959 87 441 8627 76 65  65 34 75 191   8 62 922 58 5676 1269 524   24 84 9  52    3 7   265 4  31 15 496 9658 831 98   98 8     89 683 34 334 43  8 876 677 2769  981 994 73 571 12 9418 616  54  481 16 112  7638 22 787 45 5867 372 62  4 98 4  2  2   51  22 67 8  131   7 7699 47   4125 34  4  722 215 361 38  7 881   9  5  4 834 85  95 99   1 516 98 2  644 54 323 34 63 314 63 4445 36 88 43 41   2 9336  6 189 833 228  9 68   988 9776  93  81    7 45  5 18 8  47   9273 48 7    221  9 72 74 67  85 9981 16 98 38  946 118  57 322 29 138 13 839  296 99 61 6199  91 43 93 61  4  13 25 417 434 31  259 76 89   87 3886 789 166  85 7  92 979  6 733 2729  59 85 97 718 4  7   3  365 65 5  1  4   67 8  12 354 72   35 43   3  6 94  8164 691 16 92 628 493 11   6 88  38  92  8 491 4     2 998 4  92 76  3   33 177 96 65  92 935 15 74 33 71  2 55 4366 38 9    73  757  35 93  87 6     2 2   232 93 36 434   1 18 39 123 459 332 1  7  21 788 53 3    31 12 755 39   5 237 7  5  94 87 3  791 64   4 426 7   56    97 688 525  6 89  131 958 734  94 667 544 66 942 92 94 591 825 531 7594  81 41 1   587 435 72 53 12  564 558 55   83   6 825 271  1 1   8766 155 58 639  7    9 11 1918 98 7236 77 25 5818 44  979 383 76    1  9 4   34  5 11 5  69    46 648 6297 536 64 764 28 538 167 1  89 247  5412 462 479 59 22   1 255 619 5   1866 684 386 364 11 2854 84 27 236 2  92 52  577 714 3963 679 194 115 47 4   42  75 57  2 584 76    8 28  736  9 476   6 925 1      5 188 68  18  6 175 19 165   1 71 65 18 1  3    622 76 729  54 635  7 86 93 7  9  94 4  88 656 86  9 14 649 49 11 64  13 17 51 49 58 476 471   34 42  5 26 8447 531 953   8 521  7 21  38 58 696 22   9 33  3 4   31  9   2  9   22 7296 2324 46 77 51   7 194 3182 767 2  49 8  952 145 666 114 46 387 64   2619 55 375 78 57  7    47 267  52 51 63   54 7    7 794 35   2   9 15 344 583  25 41 52  8971 9185 8    83 278  16 71  86 15    4 24 73  636 65 894 9368 46  7 44 5336 463 188 66  379 6676 6954 1   49 57 45 3211 783 65 64   52 9  968 289 77 35    83 48 7  7  68 932  4 29 45 6  15 98 3782 29 32   49 43 36 399 71 45  2 622 355 62 484 44 651 1466 1   85  192 76 117 757 69 26 366 535 187 88 99 24 4423  4 1538   2 46 12  3    2  66   6 481   4 839 5  255 68 756  8 931 4442 28  65 94 715 82 65 92  6   73 517  713 249  24  18 33 3253 87  589 11   425 65  2818 4    4    596 824 96 4277   8  3 617 21 848 67 1239 31 99   87  69 61 4 \n",
    "+   +  *  +   *   *   +   +    +  *   +  *  +  *  +   +    +   +    +    +    +    +    *  +    *  *   +  +  *  *   *   +  +  *   *  +   +   +  +   +    *   +  *   +    *  *  *   *   +    +    *  *   *  +  *   +    +  *  *   +    +   +   *   *   *  *  +   *  *   *   +  *  *   +   +   +  +    *  *  +  *  +   +  +  *  *  *  *   +  *   +    +   +    +  *   *   *   *  *  +    +    +    *  *   *  *  *  +  *   +   +   *  *  +  *   +   *  *  *   *   +  *  *  *   +  *   +    *  +   +  +  *   +    *  +    *   *  *  *   +   *   *  *  +   +    +   *   +    *  +  *  *  +    *  *  *  *  *  +   *   *  +  +    +   +   +    +  +    *  +   +  *   +  +  *   *  *  *   *  +    +   +  +    *   +  +   *  +   *  *   *  +  *  *   *   +    *  +    +  +    *   *  *   +    +    *  +  +   *   *  +   +   *   +   *   +    *   +  *  *   +  *  +  *   *  *  *  +  *  +  *   *  *  +   +   *   *  *  *   +  *  +  +   +   +   +    +   *   +   +    *   +   +    *  *   +  *  +   *   +    +    *   +  +    *   +  +   *   +   +  *  *  *  +   *   *   +  +  +    +   +   *   +  *  *  +   +    *   +    *   +  +   *  *  *  *  *  +   *   *   *   +   +   *  *   +  *  *   *   *  +    *  +    *   +   +  +   *  *  +  +  *   +    +  +    *  *  *   *   *  +   *   +    *  *  +    +    +    +  +    *   *  *   +    *  *   *   +    +    +  *   *  *  +    +   +    +   *  *   +    *  +    +  *   +    *  +   +  *  +  +   *   +  *   +  +    +    *   +    +  *  *  +    *   *   +  +  *  *   +    *   +  +    +   +    *   *  +   *  *  *   *   +    +    *   *  *   *  +    *   *   +    *  +    +    *  +   *  +    +   *  +  +  +  +  +  *   *   *  *  *   +   +    +    +    *   +  *   *   *   *  +  *   *   *  +  *   +  *   +  *   *   +  +  *   *  +   +  *  *   +  +    +  +  +  *  +   +    *  *   +   *   *  +    *   +    *   *   +    *  *  *  *  +    +    *  +   +    *  +  *  +   *  +    *  +  *   *   +    +  *   *  *   *  +    +   +  *  +    *   *  *  +  *  *   +  *   *   +   +   +  *  +    +    +   +   *   *  *  *   +  *   +    +   *  +  *   +  *   *  +   *  +  *  *  *   *  +  +   +  +    *   *  +  *   +    *   *  +  *   *   +  +   +   *   +  *  *   *   *   *   *  +  *   *   *  +   *  *  +   *   *  +  *  +  +  +  +    +  *   +   +    *   *  *   +    +  +   +   *  *  *   *   *  *  +   *   *   *  +  *  +   +  *  +    *  +   *  +   +   *  *  *  *  *  *   +  *   *   *   +    *   +   *   +  *   *   *   *   *   +   *   *  +   *  *  *   +   +   +    +   +  *   *   +   *  +  +  +    +   +  +    +   *   +   *  *   +    +   +  +   +  +    *  +    *  +    *  *  +    *  +    *   +    +  +  +   *  *  *  +  +    *   +   +    *   *  *   +  +   *   *  +  +    +    *   *   *  *  +   *   *   +   +    *   *   *   +  +    *  +  *   *  *  +   *   *   +    *   *   *   *  *   +  *   *  *  +   +    *  *  +    +  *   *   *   *   +    *   *   *  *  *   +  *   *   *  +  *  *  *   +    *  +    +  *   *  *  *  +  *  *  *  *  *   +  *  *  +   *  +  +   *  +  +  +  *  *   *   +    *  *  *  +    +   *   *   *   *  *  +   *  *   *  *   *  +  *   *  *  *   *  +    +    +    *  *  *  *   *   +    +   *  +  *  *   *   +   *   +  *   +    +    *  +   +  *   +    *  +    *  +  +    *  +   +  *   +    *  +  +  +   *   +   *  *   +    +    +   *   +   *   *   +  *   +   *  +   +   +  *   +    +  *  *  +    *   *   *   *   +    +    +   *  +  +  +    +   +  +    +  *  +   +   *  +   +    +  +  +  *  *   *  *  *  *  *  *  +    *  +   +   +  +  *   *  *  *  *   *   *  *   *  +   +    +   *   +   *  +   *   *  *  +   +   +   *  *  +  +    +  +    +   *  *   +    *  +  +   *   *   +   +  +   *  +   *  *   +    *  *   +  *   +  +  *   *   *  *   +    +   *   +   *  +    *  +    +    +   +   +    +    +    +   *   +  +    +   +  *   *  *   *  +    *  *   +   +   +  + \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "6c00c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91  99 31  33 125 61   44 4121  6  13 3  28 26  6 95  7459 912 4337 598  9668   59  387  4 1782 56 454 84 75 84 292 139 75 94 215 52 53    9 47 12  5161 445 66  61 2115 16 27 62  632 8938 2151  5 47  9  6  928 6834 98 3  791 5466 341 8   242 331 44 27 159 52 42  63  9   7 474 164 365 9  37   4  48 94 55 52  6  98 11 68 32 4   94 324 73   523    5 41 875 977 411 1  66 9995 21   2478 58  47 35 86 5  37 834 61  63  29 97 25 89  779 73 75 95  719 78  8 58 339 3  669 1953 14 131 76 91 45  7813 73 423  19  82 41 96  528 576 3  24 59  9985  65 631 4426 22  3 96  2 9813 52 67 64 36 73 884 321  1 81 1613 725 24   751 72 7182 44 178  2 812 61 47 23   1 44 215 75 256  51  72   47 214  2 678 54 211 6  756 18 59 22 797 34  4795 97 2488 56  849 236 67 584 4822 8     4 62 327 886 36 113 9   346 433 293 5981 332 46  9 717  2 39 55 97  99 38 42 64 4  41 837 71 31 96  44   57 92 91   2 97  6  8 91  8    73 6976 682   1  18 473  3   1   9258 9  198 69 35 442 363 7444 4678 8   54 35   317 13 194 968 264  8 42 44 94 29  234 395 54  4 5444 6   929 316 28 8  16 9      8 556 1      8  6 215 24 65 71  7 41  48 758 392  15 859 3   56 767 56 28 936   9 21 6927 57 7612 762 1   93 152 66 4  23 61 437    3 48 2498 56 98 637   5 7    5   6    8 87 24   68 18   2366  3 3852 396 17 457  274 26  19 98  786  3524 51 693 78 27  434  57 6699 68  19 793   27 85 4    3   94 1754 68 236 76 4  22  25 523 69 4   66 64   78   13  4882  8 65 11 6678 963 868 86 32  1 64  963  53  23 2228 275 1624 9   9   66 7  71   6 3   7955 9616 44   9 618 7  754   75 754 6363 32 3547  437 87   7 5     2 18  46 37 25 44 39 55 524 855 7  78 123 135 7638 7514    2 352 77 26  8   87  49 73  74 518 85 19 79   5 433 45 826 399 64 47  63  6 775 33  9  44  4 528  91 59 85  7 654   45 35 546 435 612 41 3444  96 772  278 276 5178  8 77  4 18 3797  894 8  764 7591 12 28 8  341 37 527  17 62 232   3 9885 49 537 75  61  2 9665 9   8  7  7197 826  4 22 78 38 883  8  39   1 636 32  1  96 9423  833 237 22  216 22 9  32  63  44  945 629 85 6   55 11 126 87 131 51 37 84 96 783 66 7  66  2  3786 963 43 56 175  846 746  6 24  24 65  14 697 746 285 67 11 279 489 641 384 96 97 661 726 27 42  64 7  463 81  49  8 54 1  97 42 564   4 468 319 4781 162 9  668 5658 94 567 424  6 4  2   942  5  3 2   2   51  81 68 6   81 8  41 3597 12 121 57 694   1 75 58 1  24 15 59  68 129 7   526 5679 127 22    2 61 379 32  492 8   394 6   293  4   3  8 1   13  32 945 9878 353 67 135  35 5   85 4  7  3479 59   4 4735 236 295 8   58 347   19 457  2 2   37 5515 3  1884  8 86   91 4   656 86 6899  42 1868 74 79 494  1 26 13 57 2766 669  55    9  99 1  95  19 486 797 92 4  5927 6771  84 66  53 63 299   6 375 669 87   51   67 34  68 169  3  62 671 17  9 741 695 93   873 817 511 783 63 857 61 479 51 92 84  4862 49 45 4757 94  81 717   5 198 7578 5   912 38 58  98 43 58  726  3 41 58 23 791 7882 17 7161 64 97  54 75 7  86 33 6  42 48  48 3  83 86 735 64 77 626 86 81 25  5 9  3   313 2659 96 27 13 682   11 389 498 776 27 6  371  9   3 71 623 26 71 776 36 49 523 88 6172 96      6 4  14 94 124  35   99 619 87 89 44  39  52 663 372 7  224 5784   66  9 847 46 396 8573 96 6339  2 72 3964 27 159 44 435 5167 34 57 28   6  42 189 51 825   44 9723 614 956 44  445 236 29 941 555  8 598  37 33 168 6    82 58  9 6689 413 94  239   2  921 49   236 61 82  2 456   66 41 9591 1  36 19  794 14 948 4429 8  13 12  2  41 13 31  6 31 79 7   788  6 753 222 59 3   58 37 1  58 54   64 4  32  96 398  236 325 333 4    2 319 1   81 13 37    7  58 29 63 2  8962 95   46 566  3 296 8246 44  9 257 949 855 122 92 26  77 372 81 28   357  8 817 58 826 81 49 219 584  4  91 6828 58  645 785 67 773  6  7283 3989   1 476 114  6265 9569 8   275 1   297 264 45  44 78 87  25   59 77 455 264 421 92 23\n",
      "736 17 35  85 558 29   45 2676 51 755 9  91 94  7 21  2858 456 9336 7975  794  289 9181 65 3176 21 999 25 59 56 225 385 85 65 745 96 661  97 12 67  7468 614 58  86 4865 59 84 787 581 2844 6825 45 114 86 9  38  1535 93 35 325 6241 323 54   27 716 84 76 778 98 464 32  65  9 987 838 113 19 693  6  83 49 53 964 2  49 5  75 72 3   75 921 493  146    3 73 561 129 647 6  61 7116 8674 3797 82  85 45 86 7  94 295 45  62  57 68 58 663 113 33 84 66  291 94 53 79 272 64 266 4297 43 239 64 34 23  298  95 822  752 46 63 996 871 613 1  44 82  2827  41 537 6518 15 72 67 67 7299 82 9  34 37 71 645 336 89 51 2285 182 953  681 62 3782 66 264  5 129 46 38 795  8 28 266 76 3534 79  21   15 638  4 748  4 158 29 195 68 13 69 219 964 5695 88 1896 94 9329 228 75 923 6229 8628 46 22 936 255 59 226 3   673 941 35   335 26  35 81 97  34 74 72 25  52 22 82 83 91 72 148 52 37 193 71  557 15 11  93 66 19  5 97  123 423 8727 588  68 778 182  289 434 9639 49 372 58 75 774  53  441 893  349 89 438  657 84 538 255 287  5 55 62 76 398 514 457 75 31 7664 5   579 275 88 53 89 8    228 738 511    4 18 942 52 18 98 14 69  61 79  648  68 147 6   53 967  1 74 715  96 96 6829 48 7433 312 94  67 727 17 72 71 96 996   39 63  861 92 89 245  49 45   1  48 1516 62 48  538 522  3278 37 9181 543 46 499  541 71  99 25  395   837 22 118 68 35  129 274 9924 24  37 518  756 74 679  2   65 3547 35 886 78 5  49 396  43 98 17  79 6727 71   52  8838 91 97 64 4587 977 892 26 28 52 989 999  913 95 2858 724 8177 656 78  63 4  29  85 9   9757 5336 17  18 441 4  651   56 766 8455 46 8534 2745 92  43 63   16 46  35 18 83 3  46 74 193 792 34 25 386 198 8598 517  2783 426 54 89  84  266 11 12 297 678 81 47 44   4 818 19 119 846 42 8  818  2 195 11  2  47 95 5497 26 99 69  7 744   33 79 422 428 417 79 1363 979 958  634 143 4939 66 42 63 85 6249  415 37 715 4373 67 99 14 363 62 5745 92 93 655 731 6534 64 538 88 268 83 8662 25  7  3  5727  88  3 93 97 18 483  8  55   9 951 616 53 63  471  679 642 23  444 81 4  859 71  41 7895 958 23 9   23 41 985 63 473 24 5  96 11 176 31 31 73  52 1118 616 34 11 195 4123 449 14 37 436 396 59 445 412 625 37 74 829 46  869 997 3  74 778 974 53 287 53 5  466 614 15  2 99 9   2 64 327  32 889 757 6419 688 3  711 7152 33 315 216  6 1  394 694 29 98 19  8   399 29 73 2   38 81 93  638 53 592 56  51 629 34 55 76 62 27 67  46  97 456 233 6482 583 568  24 71 557 28  232 88  275 275 344  8  43 43 65  43  36 986 5826 571 59 25  149 72  53 54 38 2671 77   6 9477 973 582 277 65 223  642 484  4 47  61 3571 9  4184  5 984  43 68 2125 16 2112 988 92   35 81 292 75 53 48 36 871  261  32 4925 533 1  75  91 758 797 22 74 4836 1453  83 493 34 44 981   7 364 163 44   142 322 33  28 976  13 13 582 68  3 599 128 16  3316 916 822 928 14 434 77 376 18  1 171 5984 21 54 8635 62  55 512   3 919 4559 3   699 37 49 486 64 58  357  8 17 58 21 84  4847 82 3411 86 919 18 45 9  42 5  82 21 82 989 9  47 67 162 57 33 61  26 54 36  6 4  23  942 7197 99 65 43 5243 312 959  27 511 46 88 215 96 365 32 353 33 91 257 19 33 465 24 1632 1537  269 42 52 31  68  68  182 242 75 35 59  38 277 328 742 7  983 6558   74  1 552 22 215 9437 36 181  54 23 671  22 653  6 771 4456 97 86 75 578  38  35 67 483 5588 5119 964  69 983 291 916 67 131 576 64 373  85 91 147 869  74 31 53 2962 544 192 456 588 2333 871  81  78 53 84 2143  61 13 898  85 68 94  768 96 222 8156 7  79 57 63  87 81 75  7 86 52 68 6434  4 571 341 24 9  552 14 93 56 28   75 81 99  34 123 1951 87  49  3    4 587 87  92 78 656 848 467 81 49 36 3726 46  942 926 21 154 8649 29  6 788 695 392 253 24 289 59 958 66 633  768  6 413 73 594 56 92 443 263 98 297 9628 257 781 485 84 778  44 8363 4237   1 227 9735 392  8156 9   983 24 5155 736  4 787 55 88  35   77 12 489 136 212 97 54\n",
      "347 87 49 416 415 279  86 26   36 884 9  92 76 56 915 6463 122 5629 1448  272  745 3736 54 7963  7 753 81 19 66 443 52  65 53 441 75 768  41 44 641 651  864 43 997 6264  5 68 867 577 7889 5    67 742 44 8  99  6826 98 59 633 4774 484 291  45 35  53 86 88   8 113 521 62  4 468 468  83 93 3139 96 81  5 66 699 1  87 1  94 16 536 19 268 5219 957 1848 91 16  729 117 71 97   76 7893 1529 91 312 33 53 11 19   3 915 399 86 99 14 488 485 24 64 996 317 64 47 74 643 77 331 29   27  36 31 76 37  256  21 4978 179 18 3  733 224 895 16  4 16  684   36 718 5393 11 34 16 78 53   61 9  85 52 57 336 874 39 96 78   39  893  362 46  168 88 392 97 471 28 16 549 64 21 133 21 5156 483 42 2887 837  4 64   4 285 34 311 5  78 77 949 461 7214 2  8721 12 6544 175 83  72 9962 6421 67 91 37  4   86 868 63  228 879 29   599 58  29 91 8   96 31 46 76   3 64 39 97 13 11 123 28 77 271 688 288 95 34  14 13 24 42 219 229 259 4835 251 771 474 642  395 414  599 51   2 38 51  57  82   79 477  445 34 774  426 92   7 857 742 87 88 72 26 982  32 18  59 66    2 838 341 759 16 88 84 858  769 191 5544 154 32 737 52 63 85 71 37 147 24  161 735 723 264 16 374  9 91 493 313 55 9368 73   51 789 583 15 827 96 19 85 44 529 4591 41  415 9  83 726 354 66  34 973 2255 85 9  3272 6752 7149 96 7156 375 82 796 8959 17 818 576 8985   49 81 874 76 82 6352 518 4637 667 97 373 8681 75 9884 86  26 8448 58 77  99 2  31 887  16 28 45  44 9821 7786 42  8737 77 4  54   83 321 176 35 55 43 193 6715 767 79  858 659 2919 767 73  45 48  2  86 318 2777 2459 768 38 484 99 4696  87 516 3546 55 3684 7952 34 396 35  134 32  79  5 82 6  52 23 833  88 62 11 761  42 5798 48   7158 814 5  419 797 614 47  3 564 827 36 85 332 35  77 69 966 892 34 4  935 68 118 36  7 721 29 4814 27 89 17 52   1   57 15 392 125 992  1 2924 729 4475 291 556  887 69 71 32 67 7458 4895 68 17  5566 82 83 15 39  66 4721 98 69 53  774 9315 58 336 82 361 65 641  29  9  47 3896  91 74 59 89  1 974  6 358  37 37  228 65 32  355 6584 897 62   34 72 8  432 35 792 8874 938 84 29  71 7  17  12 334 38 2  14 57 793 9  93 724 55 3361 484  7 15 374 8648 429 99 96 391 838 98  75 813 68  17  3 115 9    33 659 2  42 76  33  43 351 45 15 133 842 24 39 71 25  3 43 9732 37 48   69 4545 865 2  822 872  52 45  385  9 23 885  82 46 42 724 32  516 28 81 2  123 24 86  515 43 224 18  33 281 9  91 34 19 94 871 48   4 874 744 65   259 773 799 75 57  337 177 497  69 619 924  7 173 92 86 136  83 814 2575  24 98 1   256 96  76 96 61 2872 81  59  388  43 779 543 59 729 3618 636 12 438  2  169 38 9298 49 9252 51 26 1125 63  189 131 46   76 56 287 53 26 34 2  64    95 277 1836 998 87 295 49 141 519 71 73 2677 3189 679 573 37 92  31 592 545 398 424  961 549 85  36 8518 24 63 127 9  71 544 929 198 1896 679 743 375 99 9   84  97 82  2 433 172  53 19  616 74  46 634 326 21   575 77  291 12 35 964 44 482  25 11 87 84 85 8    539 46 5234 12 855 36 94 52 6  1  59 69 75 484 57 55 13 296 88 58 71  72 41 33  8 6  844 841 5556 43 47 28 1283 653 133  53 128  5 88 851 31 244 49  82 17  4 51  55  7  71 21  567 6141 9988 48 64 47  33 297 6944 656 3  29 9  557 271 779 469 22 536 281  6674 44 763 98 59  969  94 886  19 73 371  27 445  1 747 9838 86  1 37 855 625  34 85 718 8123 3215 639  34 731 245 296 94 45   66 39 99  192 22 678 8149 84 97 77 5987 715 521 92  695 2462 9519 76  73 24 19 2268 375 75 941  97 38 886 488 63 31   473 54 82 5  51  77 74 56  9 9  22 89 3127 73 587 325 38 47 621 71 12 85 62  379 53 617 17 867 7784 7   61  99  39 577 562 38 92 747 998 979 83 97 17 7271  7  113 166 84 389 1989 91  9  38 414 861 665 9  771 61 573  3 237  369 56 841 53 771 33 37 734 95  41 725  951 542  18 824 99 6768 34 6639 9878 145 49  5491 87   75   96  441 73 5182 281  8 579 78 92  82  595 62 472  37 416 89 6 \n",
      "583 7  47 289 449 428 984 5    18 633 56  8 18 51 113 31   129  672 3414  631 1949 5691 58  682  7 128 35 58 15 769 91  74 15 134 14 653 724 79 994 847  98  63 152 999   5 84 681 488 76   3    29 846 52 21 86  34   71 31  48  391 268 254  51 34  36 9  13   6 571 672 93 88  99 74    9 94 8249 51 45  8 6  661 23 12 7  55 82 745 7  67  8615 663 9478 29 35    9 144 93  8    5 8752 8935 69 222 68 66 58 28   3 513 574 38 64  6 869 53  27  9 119 552 66 87 93 664 48 288 88   76  58 13 14 826 258   9 1343 249 48 8  888 81  23  23  5 931 224  293 211 3154 17 51 83 62 9    57 9  67 98 82 345 517 81 32 69   8   669 1591 8     3 22  27 66 966 87 62 363 89 35 495 97 3842 292 71 8567  96 32 76   7 41  94  92 5   7 56 651 248   98 5  694  33 9424 62  13   6 1988 2861 76 6  5   3   5  348 237  73 114 5     41 8   13 83 5   15 26 44 428  8  9 34 32 28 64 866 23  2 479 587 626 21 63 343 67 91 41 645 729 317 8916  91 892 695 1635 813 713   68 23   1 69 62   8  61   59 35   949 43 7962   8  2   5 486 789 34 86 9  8  674  15 41   6 88    5 562 836 448  9 91 57 612 9111 291 6963 236 46 728  5 15 37 74 51 774 31   67 643 97  886  1 47   4 2  212 116 84 27   89   15 892 549 19 745 9  27 95 44 835 4235 2    93 5  76 167 568 53 856 298 2458 58 6  8675 6651 849  17 7246 611 2  139 9854 11 759 991 4911    5  9 795 76 36 7864 522 254  593 79 492 8884 44 9959 87 441 8627 76 65  65 34 75 191   8 62 922 58 5676 1269 524   24 84 9  52    3 7   265 4  31 15 496 9658 831 98   98 8     89 683 34 334 43  8 876 677 2769  981 994 73 571 12 9418 616  54  481 16 112  7638 22 787 45 5867 372 62  4 98 4  2  2   51  22 67 8  131   7 7699 47   4125 34  4  722 215 361 38  7 881   9  5  4 834 85  95 99   1 516 98 2  644 54 323 34 63 314 63 4445 36 88 43 41   2 9336  6 189 833 228  9 68   988 9776  93  81    7 45  5 18 8  47   9273 48 7    221  9 72 74 67  85 9981 16 98 38  946 118  57 322 29 138 13 839  296 99 61 6199  91 43 93 61  4  13 25 417 434 31  259 76 89   87 3886 789 166  85 7  92 979  6 733 2729  59 85 97 718 4  7   3  365 65 5  1  4   67 8  12 354 72   35 43   3  6 94  8164 691 16 92 628 493 11   6 88  38  92  8 491 4     2 998 4  92 76  3   33 177 96 65  92 935 15 74 33 71  2 55 4366 38 9    73  757  35 93  87 6     2 2   232 93 36 434   1 18 39 123 459 332 1  7  21 788 53 3    31 12 755 39   5 237 7  5  94 87 3  791 64   4 426 7   56    97 688 525  6 89  131 958 734  94 667 544 66 942 92 94 591 825 531 7594  81 41 1   587 435 72 53 12  564 558 55   83   6 825 271  1 1   8766 155 58 639  7    9 11 1918 98 7236 77 25 5818 44  979 383 76    1  9 4   34  5 11 5  69    46 648 6297 536 64 764 28 538 167 1  89 247  5412 462 479 59 22   1 255 619 5   1866 684 386 364 11 2854 84 27 236 2  92 52  577 714 3963 679 194 115 47 4   42  75 57  2 584 76    8 28  736  9 476   6 925 1      5 188 68  18  6 175 19 165   1 71 65 18 1  3    622 76 729  54 635  7 86 93 7  9  94 4  88 656 86  9 14 649 49 11 64  13 17 51 49 58 476 471   34 42  5 26 8447 531 953   8 521  7 21  38 58 696 22   9 33  3 4   31  9   2  9   22 7296 2324 46 77 51   7 194 3182 767 2  49 8  952 145 666 114 46 387 64   2619 55 375 78 57  7    47 267  52 51 63   54 7    7 794 35   2   9 15 344 583  25 41 52  8971 9185 8    83 278  16 71  86 15    4 24 73  636 65 894 9368 46  7 44 5336 463 188 66  379 6676 6954 1   49 57 45 3211 783 65 64   52 9  968 289 77 35    83 48 7  7  68 932  4 29 45 6  15 98 3782 29 32   49 43 36 399 71 45  2 622 355 62 484 44 651 1466 1   85  192 76 117 757 69 26 366 535 187 88 99 24 4423  4 1538   2 46 12  3    2  66   6 481   4 839 5  255 68 756  8 931 4442 28  65 94 715 82 65 92  6   73 517  713 249  24  18 33 3253 87  589 11   425 65  2818 4    4    596 824 96 4277   8  3 617 21 848 67 1239 31 99   87  69 61 4 \n",
      "['+', '+', '*', '+', '*', '*', '+', '+', '+', '*', '+', '*', '+', '*', '+', '+', '+', '+', '+', '+', '+', '+', '*', '+', '*', '*', '+', '+', '*', '*', '*', '+', '+', '*', '*', '+', '+', '+', '+', '+', '*', '+', '*', '+', '*', '*', '*', '*', '+', '+', '*', '*', '*', '+', '*', '+', '+', '*', '*', '+', '+', '+', '*', '*', '*', '*', '+', '*', '*', '*', '+', '*', '*', '+', '+', '+', '+', '*', '*', '+', '*', '+', '+', '+', '*', '*', '*', '*', '+', '*', '+', '+', '+', '+', '*', '*', '*', '*', '*', '+', '+', '+', '*', '*', '*', '*', '*', '+', '*', '+', '+', '*', '*', '+', '*', '+', '*', '*', '*', '*', '+', '*', '*', '*', '+', '*', '+', '*', '+', '+', '+', '*', '+', '*', '+', '*', '*', '*', '*', '+', '*', '*', '*', '+', '+', '+', '*', '+', '*', '+', '*', '*', '+', '*', '*', '*', '*', '*', '+', '*', '*', '+', '+', '+', '+', '+', '+', '+', '*', '+', '+', '*', '+', '+', '*', '*', '*', '*', '*', '+', '+', '+', '+', '*', '+', '+', '*', '+', '*', '*', '*', '+', '*', '*', '*', '+', '*', '+', '+', '+', '*', '*', '*', '+', '+', '*', '+', '+', '*', '*', '+', '+', '*', '+', '*', '+', '*', '+', '*', '*', '+', '*', '+', '*', '*', '*', '*', '+', '*', '+', '*', '*', '*', '+', '+', '*', '*', '*', '*', '+', '*', '+', '+', '+', '+', '+', '+', '*', '+', '+', '*', '+', '+', '*', '*', '+', '*', '+', '*', '+', '+', '*', '+', '+', '*', '+', '+', '*', '+', '+', '*', '*', '*', '+', '*', '*', '+', '+', '+', '+', '+', '*', '+', '*', '*', '+', '+', '*', '+', '*', '+', '+', '*', '*', '*', '*', '*', '+', '*', '*', '*', '+', '+', '*', '*', '+', '*', '*', '*', '*', '+', '*', '+', '*', '+', '+', '+', '*', '*', '+', '+', '*', '+', '+', '+', '*', '*', '*', '*', '*', '+', '*', '+', '*', '*', '+', '+', '+', '+', '+', '*', '*', '*', '+', '*', '*', '*', '+', '+', '+', '*', '*', '*', '+', '+', '+', '+', '*', '*', '+', '*', '+', '+', '*', '+', '*', '+', '+', '*', '+', '+', '*', '+', '*', '+', '+', '+', '*', '+', '+', '*', '*', '+', '*', '*', '+', '+', '*', '*', '+', '*', '+', '+', '+', '+', '*', '*', '+', '*', '*', '*', '*', '+', '+', '*', '*', '*', '*', '+', '*', '*', '+', '*', '+', '+', '*', '+', '*', '+', '+', '*', '+', '+', '+', '+', '+', '*', '*', '*', '*', '*', '+', '+', '+', '+', '*', '+', '*', '*', '*', '*', '+', '*', '*', '*', '+', '*', '+', '*', '+', '*', '*', '+', '+', '*', '*', '+', '+', '*', '*', '+', '+', '+', '+', '+', '*', '+', '+', '*', '*', '+', '*', '*', '+', '*', '+', '*', '*', '+', '*', '*', '*', '*', '+', '+', '*', '+', '+', '*', '+', '*', '+', '*', '+', '*', '+', '*', '*', '+', '+', '*', '*', '*', '*', '+', '+', '+', '*', '+', '*', '*', '*', '+', '*', '*', '+', '*', '*', '+', '+', '+', '*', '+', '+', '+', '+', '*', '*', '*', '*', '+', '*', '+', '+', '*', '+', '*', '+', '*', '*', '+', '*', '+', '*', '*', '*', '*', '+', '+', '+', '+', '*', '*', '+', '*', '+', '*', '*', '+', '*', '*', '+', '+', '+', '*', '+', '*', '*', '*', '*', '*', '*', '+', '*', '*', '*', '+', '*', '*', '+', '*', '*', '+', '*', '+', '+', '+', '+', '+', '*', '+', '+', '*', '*', '*', '+', '+', '+', '+', '*', '*', '*', '*', '*', '*', '+', '*', '*', '*', '+', '*', '+', '+', '*', '+', '*', '+', '*', '+', '+', '*', '*', '*', '*', '*', '*', '+', '*', '*', '*', '+', '*', '+', '*', '+', '*', '*', '*', '*', '*', '+', '*', '*', '+', '*', '*', '*', '+', '+', '+', '+', '+', '*', '*', '+', '*', '+', '+', '+', '+', '+', '+', '+', '*', '+', '*', '*', '+', '+', '+', '+', '+', '+', '*', '+', '*', '+', '*', '*', '+', '*', '+', '*', '+', '+', '+', '+', '*', '*', '*', '+', '+', '*', '+', '+', '*', '*', '*', '+', '+', '*', '*', '+', '+', '+', '*', '*', '*', '*', '+', '*', '*', '+', '+', '*', '*', '*', '+', '+', '*', '+', '*', '*', '*', '+', '*', '*', '+', '*', '*', '*', '*', '*', '+', '*', '*', '*', '+', '+', '*', '*', '+', '+', '*', '*', '*', '*', '+', '*', '*', '*', '*', '*', '+', '*', '*', '*', '+', '*', '*', '*', '+', '*', '+', '+', '*', '*', '*', '*', '+', '*', '*', '*', '*', '*', '+', '*', '*', '+', '*', '+', '+', '*', '+', '+', '+', '*', '*', '*', '+', '*', '*', '*', '+', '+', '*', '*', '*', '*', '*', '+', '*', '*', '*', '*', '*', '+', '*', '*', '*', '*', '*', '+', '+', '+', '*', '*', '*', '*', '*', '+', '+', '*', '+', '*', '*', '*', '+', '*', '+', '*', '+', '+', '*', '+', '+', '*', '+', '*', '+', '*', '+', '+', '*', '+', '+', '*', '+', '*', '+', '+', '+', '*', '+', '*', '*', '+', '+', '+', '*', '+', '*', '*', '+', '*', '+', '*', '+', '+', '+', '*', '+', '+', '*', '*', '+', '*', '*', '*', '*', '+', '+', '+', '*', '+', '+', '+', '+', '+', '+', '+', '*', '+', '+', '*', '+', '+', '+', '+', '+', '*', '*', '*', '*', '*', '*', '*', '*', '+', '*', '+', '+', '+', '+', '*', '*', '*', '*', '*', '*', '*', '*', '*', '+', '+', '+', '*', '+', '*', '+', '*', '*', '*', '+', '+', '+', '*', '*', '+', '+', '+', '+', '+', '*', '*', '+', '*', '+', '+', '*', '*', '+', '+', '+', '*', '+', '*', '*', '+', '*', '*', '+', '*', '+', '+', '*', '*', '*', '*', '+', '+', '*', '+', '*', '+', '*', '+', '+', '+', '+', '+', '+', '+', '+', '*', '+', '+', '+', '+', '*', '*', '*', '*', '+', '*', '*', '+', '+', '+', '+']\n"
     ]
    }
   ],
   "source": [
    "mat_arr = []\n",
    "for line in input_str.split(\"\\n\"):\n",
    "    if(line ==''):\n",
    "        continue\n",
    "    try:\n",
    "        mat_arr.append(line)\n",
    "    except:\n",
    "        final_line = [x.strip() for x in line.split()]\n",
    "\n",
    "final_line = mat_arr[-1].split()\n",
    "mat_arr = mat_arr[:-1]\n",
    "for line in mat_arr:\n",
    "    print(line)\n",
    "print(final_line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "535cc24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*   +   *   +'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "cbe2e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9735, 1348, 673] 11756\n",
      "[9187, 977] 10164\n",
      "[3344, 1597] 5340368\n",
      "[42, 3818, 3569] 7429\n",
      "[1544, 2514, 5859] 22742388144\n",
      "[6224, 1972, 98] 1202825344\n",
      "[9, 4488, 4564] 9061\n",
      "[4225, 166, 27, 16] 4434\n",
      "[531, 6168] 6699\n",
      "[786, 1583, 3543] 4408335234\n",
      "[3995, 6] 4001\n",
      "[299, 8128] 2430272\n",
      "[2971, 6468] 9439\n",
      "[55, 6761] 371855\n",
      "[9291, 5111, 53] 14455\n",
      "[7263, 4841, 556, 983] 13643\n",
      "[9411, 1522, 2629] 13562\n",
      "[495, 3366, 3327, 7692] 14880\n",
      "[5713, 9944, 8741, 584] 24982\n",
      "[9, 6726, 6973, 8421] 22129\n",
      "[1, 279, 5844, 9959] 16083\n",
      "[935, 3176, 8839, 7161] 20111\n",
      "[655, 4548] 2978940\n",
      "[137, 7196, 8768, 2632] 18733\n",
      "[52, 6177] 321204\n",
      "[4971, 5952, 4938] 146102541696\n",
      "[8283, 4515] 12798\n",
      "[7515, 5998] 13513\n",
      "[8561, 4665] 39937065\n",
      "[2247, 9246, 2539] 52749659718\n",
      "[1359, 3821, 95] 493310205\n",
      "[7867, 5554] 13421\n",
      "[9651, 4535] 14186\n",
      "[2741, 1443, 5514] 21809320182\n",
      "[5971, 2654] 15847034\n",
      "[5676, 3665, 183] 9524\n",
      "[7, 942, 9714] 10663\n",
      "[4147, 7249] 11396\n",
      "[1669, 2749, 14] 4432\n",
      "[5768, 1454, 6617, 18] 13857\n",
      "[4689, 4168, 544] 10631801088\n",
      "[6546, 6833] 13379\n",
      "[91, 6895, 1672] 1049088040\n",
      "[2469, 1829, 1669, 554] 6521\n",
      "[15, 6955] 104325\n",
      "[2868, 7484] 21464112\n",
      "[6786, 2868, 771] 15005393208\n",
      "[6554, 3878, 2178] 55356945336\n",
      "[8277, 9886, 348, 849] 19360\n",
      "[2653, 18, 52, 15] 2738\n",
      "[462, 5579] 2577498\n",
      "[4178, 7144, 426] 12715091232\n",
      "[9845, 642] 6320490\n",
      "[6982, 1] 6983\n",
      "[9398, 2896, 8] 217732864\n",
      "[6163, 8584, 332, 456] 15535\n",
      "[9997, 8381] 18378\n",
      "[3353, 591] 1981623\n",
      "[736, 9234, 1538] 10452592512\n",
      "[564, 4273, 6479, 6141] 17457\n",
      "[3342, 4286, 1348] 8976\n",
      "[8522, 495, 14] 9031\n",
      "[2, 4245, 2751] 23355990\n",
      "[3733, 3154, 16] 188382112\n",
      "[4853, 4436] 21527908\n",
      "[2789, 766] 2136374\n",
      "[1781, 5783, 98] 7662\n",
      "[59, 2886] 170274\n",
      "[4415, 2617, 431] 4979797705\n",
      "[6356, 3227, 12] 246129744\n",
      "[9669, 523] 10192\n",
      "[8, 7948] 63584\n",
      "[494, 7869, 4789] 18616212654\n",
      "[1847, 6364, 488] 8699\n",
      "[31, 618, 5339] 5988\n",
      "[9199, 934] 10133\n",
      "[3638, 7912, 334, 99] 11983\n",
      "[4695, 61] 286395\n",
      "[4884, 8315] 40610460\n",
      "[94, 4958] 5052\n",
      "[5566, 536] 2983376\n",
      "[5966, 2696, 491] 9153\n",
      "[6212, 3] 6215\n",
      "[9481, 8972] 18453\n",
      "[1517, 1] 1517\n",
      "[6795, 8545] 58063275\n",
      "[3718, 2262] 8410116\n",
      "[4357, 34, 65] 9628970\n",
      "[9717, 459] 10176\n",
      "[3926, 2267, 418] 3720301156\n",
      "[7458, 3926, 311, 95] 11790\n",
      "[5196, 2456, 3673] 11325\n",
      "[19, 84, 47, 5388] 5538\n",
      "[4792, 1319] 6111\n",
      "[8513, 7665, 51] 3327859395\n",
      "[917, 722, 7999] 5295929926\n",
      "[4611, 1414, 1774] 11566398396\n",
      "[1679, 13] 21827\n",
      "[669, 6178] 4133082\n",
      "[97, 91, 917, 5665] 6770\n",
      "[2878, 1687, 795, 432] 5792\n",
      "[2318, 4759, 7923, 8795] 23795\n",
      "[5896, 8219] 48459224\n",
      "[32, 4812, 7522] 1158267648\n",
      "[3436, 5538] 19028568\n",
      "[8856, 6636] 58768416\n",
      "[5715, 18] 102870\n",
      "[3912, 7498] 11410\n",
      "[82, 39, 4533] 14496534\n",
      "[6495, 1511, 53] 8059\n",
      "[6635, 3297, 94] 10026\n",
      "[2583, 9768] 25230744\n",
      "[9696, 7894] 76540224\n",
      "[251, 5846] 6097\n",
      "[8648, 9686, 389] 32584401392\n",
      "[7145, 7183, 935] 15263\n",
      "[7322, 3347] 24506734\n",
      "[786, 5449] 4282914\n",
      "[9691, 5691, 69] 3805452189\n",
      "[7235, 1915, 9172] 127078289300\n",
      "[7966, 8446] 16412\n",
      "[548, 8377] 4590596\n",
      "[5779, 8943] 51681597\n",
      "[3266, 3746, 9234] 112972782024\n",
      "[3674, 478] 4152\n",
      "[6232, 6638, 9618] 397877577888\n",
      "[1428, 9298, 59, 37] 10822\n",
      "[1427, 4376] 6244552\n",
      "[12, 3335, 1968] 5315\n",
      "[7631, 6413] 14044\n",
      "[9371, 1464] 10835\n",
      "[4238, 5372, 6] 136599216\n",
      "[7222, 8955, 1868, 3] 18048\n",
      "[792, 3519] 2787048\n",
      "[4841, 2293, 3274, 83] 10491\n",
      "[1712, 9574, 299] 4900815712\n",
      "[8414, 2688] 22616832\n",
      "[4638, 13] 60294\n",
      "[9978, 6938, 638] 44167058232\n",
      "[5828, 2721, 814] 9363\n",
      "[5682, 7193, 635] 25952847510\n",
      "[3112, 63] 196056\n",
      "[24, 4445] 106680\n",
      "[5819, 9263, 1] 15083\n",
      "[9262, 9882, 8244, 57] 27445\n",
      "[2, 6439, 5163] 11604\n",
      "[6572, 3311, 1781] 38754367652\n",
      "[4653, 4531, 2195, 6834] 18213\n",
      "[2111, 2517] 5313387\n",
      "[735, 3241] 3976\n",
      "[9618, 6763] 65046534\n",
      "[676, 2782] 1880632\n",
      "[9759, 823, 19, 39] 10640\n",
      "[5865, 2217] 13002705\n",
      "[6999, 7] 48993\n",
      "[6386, 4457] 28462402\n",
      "[3359, 6728] 22599352\n",
      "[7758, 3172] 24608376\n",
      "[8633, 8434, 4565] 21632\n",
      "[3385, 2371, 1647] 13218550245\n",
      "[838, 1991] 1668458\n",
      "[8593, 1162] 9755\n",
      "[1276, 6289, 18, 35] 7618\n",
      "[7138, 289, 52] 7479\n",
      "[2986, 4596, 339] 7921\n",
      "[1, 7635, 5869, 1121] 14626\n",
      "[7648, 226] 7874\n",
      "[73, 171, 886, 2283] 3413\n",
      "[4682, 4682] 21921124\n",
      "[123, 7692, 8427] 16242\n",
      "[96, 2576] 2672\n",
      "[8149, 1276, 2916] 30320929584\n",
      "[6428, 1687] 8115\n",
      "[4316, 7862] 12178\n",
      "[2753, 3946, 593] 6441959434\n",
      "[68, 1849] 125732\n",
      "[4223, 4815] 20333745\n",
      "[2214, 1639, 5635] 20447983710\n",
      "[7729, 5617] 43413793\n",
      "[2353, 5518, 6354, 462] 14687\n",
      "[5742, 1989, 32] 7763\n",
      "[7247, 2121] 9368\n",
      "[28, 85, 4186, 7577] 11876\n",
      "[268, 1339, 4876] 1749762352\n",
      "[3, 2442] 2445\n",
      "[6767, 7446, 88] 14301\n",
      "[5, 4447] 22235\n",
      "[2124, 1581, 185] 3890\n",
      "[6239, 944] 5889616\n",
      "[713, 5919, 6512] 27482248464\n",
      "[1655, 88] 145640\n",
      "[517, 9387] 9904\n",
      "[2675, 2976] 7960800\n",
      "[7296, 9145, 7991] 533174862720\n",
      "[3942, 4664, 418] 7685133984\n",
      "[457, 762, 9919, 5548] 16686\n",
      "[9825, 78] 766350\n",
      "[2186, 4879, 8924, 861] 16850\n",
      "[5913, 6423] 12336\n",
      "[969, 8354, 4242, 9944] 23509\n",
      "[2216, 3272, 685] 4966765120\n",
      "[6781, 7533] 51081273\n",
      "[59, 827, 4326] 211078518\n",
      "[4691, 8299, 2268, 2928] 18186\n",
      "[8862, 648, 226, 811] 10547\n",
      "[467, 4676] 2183692\n",
      "[6296, 221] 6517\n",
      "[3935, 237, 76] 4248\n",
      "[8243, 85, 65] 45542575\n",
      "[3585, 696] 2495160\n",
      "[1283, 1264, 3688] 6235\n",
      "[9362, 33, 7] 9402\n",
      "[362, 4727, 6383] 10922423642\n",
      "[4981, 3471, 3194] 11646\n",
      "[2325, 959, 3] 6689025\n",
      "[5, 935, 8394, 1591] 10925\n",
      "[3258, 368, 2] 2397888\n",
      "[4321, 6593] 10914\n",
      "[898, 9113] 8183474\n",
      "[7985, 17, 7] 950215\n",
      "[391, 2465] 2856\n",
      "[3732, 9416] 35140512\n",
      "[5744, 5264] 11008\n",
      "[9274, 7562, 8] 561039904\n",
      "[95, 9238] 877610\n",
      "[326, 8249] 2689174\n",
      "[4833, 2294] 11086902\n",
      "[6893, 4372] 11265\n",
      "[4912, 138] 677856\n",
      "[4716, 1214] 5930\n",
      "[8118, 3426, 7836] 217936932048\n",
      "[7522, 1283] 9650726\n",
      "[337, 1772] 597164\n",
      "[9124, 6977, 319] 16420\n",
      "[4765, 4188, 87] 9040\n",
      "[526, 5582, 7786] 22860723752\n",
      "[9192, 2551] 23448792\n",
      "[9136, 1143] 10442448\n",
      "[3, 914, 2343] 6424506\n",
      "[9616, 7637] 17253\n",
      "[129, 6941] 895389\n",
      "[44, 8521] 8565\n",
      "[9926, 1714, 95] 11735\n",
      "[8127, 222, 399] 8748\n",
      "[423, 7251, 3397] 11071\n",
      "[6848, 9789, 7231, 6756] 30624\n",
      "[652, 8859, 2811] 12322\n",
      "[78, 679, 1812] 95967144\n",
      "[746, 1779, 8845] 11370\n",
      "[4161, 7846, 3223, 5] 15235\n",
      "[3238, 891, 953] 2749460274\n",
      "[1447, 311, 443] 2201\n",
      "[99, 265, 5396, 8998] 14758\n",
      "[9452, 913] 8629676\n",
      "[13, 97, 8221] 10366681\n",
      "[6536, 9889] 16425\n",
      "[3756, 5512] 20703072\n",
      "[47, 475, 2478] 3000\n",
      "[3, 6586, 3321] 65616318\n",
      "[7, 44, 4475, 4199] 8725\n",
      "[4843, 6975, 737, 8] 12563\n",
      "[8349, 444, 959] 3554970804\n",
      "[5834, 4943] 10777\n",
      "[3477, 5379, 846, 2] 9704\n",
      "[364, 152, 7768] 429787904\n",
      "[189, 3422] 3611\n",
      "[15, 93, 4875] 4983\n",
      "[9284, 6558, 8576] 522145231872\n",
      "[2277, 6848, 4729] 13854\n",
      "[83, 8574] 8657\n",
      "[4588, 2586] 11864568\n",
      "[4679, 422] 1974538\n",
      "[9728, 466] 4533248\n",
      "[2396, 9987, 824] 13207\n",
      "[25, 3131, 4425] 346366875\n",
      "[3414, 9581, 57] 1864443438\n",
      "[575, 4596] 5171\n",
      "[368, 4168] 4536\n",
      "[57, 46, 46, 4425] 4574\n",
      "[6585, 36, 82] 6703\n",
      "[9538, 2743, 9916] 22197\n",
      "[3274, 1754, 6598] 37889648408\n",
      "[281, 8869] 9150\n",
      "[8589, 381] 3272409\n",
      "[1885, 6947] 13095095\n",
      "[9886, 51, 82] 10019\n",
      "[9, 271, 261, 8891] 9432\n",
      "[5712, 5399, 6811] 210045028368\n",
      "[1556, 159, 146, 43] 1904\n",
      "[12, 53, 8446] 5371656\n",
      "[134, 6826] 6960\n",
      "[2977, 1432, 5278] 9687\n",
      "[255, 4225] 1077375\n",
      "[6161, 5835] 35949435\n",
      "[7983, 1857] 14824431\n",
      "[177, 7414] 1312278\n",
      "[4635, 1971] 9135585\n",
      "[17, 4647, 8174] 12838\n",
      "[7723, 5941, 8] 367058744\n",
      "[361, 9466, 2817] 9626325642\n",
      "[76, 1634, 5853] 726848952\n",
      "[8179, 5427, 973] 14579\n",
      "[3628, 68, 46] 3742\n",
      "[551, 6361] 3504911\n",
      "[7934, 6677, 774] 41002896132\n",
      "[5, 6194] 6199\n",
      "[2792, 841] 2348072\n",
      "[9742, 3191, 6532] 203058468104\n",
      "[31, 911, 9636] 272130276\n",
      "[2958, 1654] 4892532\n",
      "[6692, 9837, 226, 798] 17553\n",
      "[5478, 7839] 42942042\n",
      "[77, 64, 1351, 2315] 3807\n",
      "[7378, 6189, 2292] 104658317064\n",
      "[1955, 484, 39] 2478\n",
      "[9611, 3759] 13370\n",
      "[1787, 5224, 2775] 9786\n",
      "[6199, 676] 4190524\n",
      "[4712, 297] 1399464\n",
      "[2789, 3155] 5944\n",
      "[6944, 1644] 8588\n",
      "[4958, 3923, 7695] 149669550630\n",
      "[44, 52, 393, 3915] 4404\n",
      "[4642, 831] 5473\n",
      "[2, 484, 9619, 8153] 18258\n",
      "[5995, 62] 371690\n",
      "[9887, 8936] 88350232\n",
      "[6271, 3426, 7567] 162572802882\n",
      "[35, 456, 5948] 94930080\n",
      "[7465, 563] 4202795\n",
      "[8, 35, 5146] 5189\n",
      "[92, 479, 6838] 301336984\n",
      "[122, 524, 155, 8658] 9459\n",
      "[8685, 7258] 63035730\n",
      "[2496, 48] 119808\n",
      "[38, 526, 6377, 8825] 15766\n",
      "[1566, 8276, 255, 21] 10118\n",
      "[2378, 3214, 6749, 689] 13030\n",
      "[391, 3767] 4158\n",
      "[3977, 8112, 5854, 2166] 20109\n",
      "[3536, 9471, 6351] 212691535056\n",
      "[1482, 762] 1129284\n",
      "[4471, 5993, 7969] 213526988207\n",
      "[89, 2598, 7455, 4194] 14336\n",
      "[2711, 6171] 16729581\n",
      "[87, 1915, 9989] 1664217345\n",
      "[9259, 8579, 61] 4845410621\n",
      "[7384, 8999, 6581, 51] 23015\n",
      "[3, 58, 234, 4795] 5090\n",
      "[528, 1219] 1747\n",
      "[6187, 9179, 3845] 218359368685\n",
      "[7677, 8866] 68064282\n",
      "[2383, 7526] 17934458\n",
      "[67, 4138, 3256, 4924] 12385\n",
      "[255, 5712, 7482] 13449\n",
      "[6942, 6965, 9234, 947] 24088\n",
      "[6265, 8469, 73] 14807\n",
      "[1397, 9779] 13661263\n",
      "[7534, 9179, 3832] 265000373552\n",
      "[88, 768, 2588, 7614] 11058\n",
      "[8774, 5454] 47853396\n",
      "[4699, 789, 985, 49] 6522\n",
      "[3288, 67] 3355\n",
      "[4, 9624, 4561] 175580256\n",
      "[1388, 7546, 5442, 4787] 19163\n",
      "[6357, 8586] 54581202\n",
      "[2876, 3875, 66] 6817\n",
      "[7796, 6895] 14691\n",
      "[4523, 4] 18092\n",
      "[2437, 2915] 5352\n",
      "[381, 2989, 5671] 9041\n",
      "[5, 241, 3368] 4058440\n",
      "[6926, 9882] 16808\n",
      "[4149, 752, 2] 6240096\n",
      "[6745, 6948] 13693\n",
      "[6695, 4786, 227, 716] 12424\n",
      "[7771, 8172, 86, 69] 16098\n",
      "[1545, 3222, 4] 19911960\n",
      "[488, 887, 8332, 2874] 12581\n",
      "[978, 8174] 9152\n",
      "[6949, 57] 396093\n",
      "[1655, 1442] 2386510\n",
      "[64, 65, 788, 8733] 9650\n",
      "[9937, 672, 371] 2477413344\n",
      "[8812, 6976, 8265] 508070311680\n",
      "[8234, 665] 8899\n",
      "[3253, 2851] 6104\n",
      "[541, 1235] 668135\n",
      "[6914, 4899, 936] 31703898096\n",
      "[9969, 6976, 3915, 58] 20918\n",
      "[5978, 3163, 371] 7015021594\n",
      "[2979, 3598] 6577\n",
      "[22, 288, 2559, 8888] 11757\n",
      "[2768, 725, 549] 4042\n",
      "[182, 619, 2718, 4799] 8318\n",
      "[9676, 568, 673] 3698786464\n",
      "[9773, 834] 8150682\n",
      "[3, 6643, 6354] 13000\n",
      "[7444, 83] 617852\n",
      "[72, 1928] 138816\n",
      "[8, 887, 6566] 46592336\n",
      "[3936, 17, 87] 5821344\n",
      "[7922, 9777, 5576, 5779] 29054\n",
      "[952, 6349, 1358, 6691] 15350\n",
      "[4179, 4769, 84] 1674090684\n",
      "[137, 9883] 1353971\n",
      "[6445, 1487, 8141] 78021023815\n",
      "[7491, 92] 689172\n",
      "[7649, 5564, 4191, 68] 17472\n",
      "[6, 7581, 5676] 258178536\n",
      "[775, 5615, 4664] 20295979000\n",
      "[683, 3454, 6548, 3561] 14246\n",
      "[3451, 2656] 9165856\n",
      "[3831, 5561, 4382, 744] 14518\n",
      "[277, 4796, 3453, 7528] 16054\n",
      "[8932, 7242] 64685544\n",
      "[37, 498, 7367] 7902\n",
      "[5634, 355] 2000070\n",
      "[5, 18, 136, 2647] 2806\n",
      "[1433, 8627, 2] 10062\n",
      "[4376, 6592] 28846592\n",
      "[31, 7854] 7885\n",
      "[2889, 5328] 8217\n",
      "[4364, 4] 4368\n",
      "[3452, 962] 4414\n",
      "[5722, 543] 6265\n",
      "[518, 2935, 4331] 6584549230\n",
      "[87, 5982, 5282] 2748932388\n",
      "[7366, 427] 3145282\n",
      "[7218, 851] 6142518\n",
      "[1371, 2863, 3611] 14173799703\n",
      "[11, 394, 5827] 6232\n",
      "[7857, 6576, 3999, 8889] 27321\n",
      "[7544, 5187, 17, 4] 12752\n",
      "[274, 711, 852, 2385] 4222\n",
      "[3483, 5214, 264] 4794335568\n",
      "[7554, 74] 7628\n",
      "[2847, 6912, 92] 1810418688\n",
      "[8872, 491, 75] 326711400\n",
      "[8263, 7616, 641] 40338776128\n",
      "[4143, 9178] 38024454\n",
      "[71, 3237] 3308\n",
      "[258, 7968, 4741] 9746282304\n",
      "[568, 172, 8879] 867442784\n",
      "[883, 5165] 4560695\n",
      "[148, 9754] 9902\n",
      "[7438, 9433, 24] 1683903696\n",
      "[38, 5455] 5493\n",
      "[48, 3179, 3875] 591294000\n",
      "[4169, 5999] 10168\n",
      "[819, 216, 6961] 1231428744\n",
      "[3885, 9491, 9626] 354935021910\n",
      "[6439, 4248] 10687\n",
      "[4842, 7] 4849\n",
      "[896, 6134, 3854] 21181830656\n",
      "[65, 6284] 408460\n",
      "[7113, 7912, 5583] 20608\n",
      "[3133, 3164] 6297\n",
      "[6, 9273] 55638\n",
      "[73, 4421, 4714] 1521363362\n",
      "[926, 4593] 5519\n",
      "[5544, 2484, 8914, 745] 17687\n",
      "[9223, 1676] 10899\n",
      "[5988, 9998] 15986\n",
      "[8614, 5973] 14587\n",
      "[54, 7721] 416934\n",
      "[67, 54, 4412] 4533\n",
      "[9, 3, 4353, 5376] 9741\n",
      "[371, 5956] 2209676\n",
      "[5431, 4298, 6229] 145400046302\n",
      "[4418, 3223, 5853] 13494\n",
      "[6492, 1192, 2728] 21110529792\n",
      "[47, 1919] 90193\n",
      "[3126, 4398, 462, 434] 8420\n",
      "[979, 9728, 6998] 66646936576\n",
      "[7949, 7547, 2877, 56] 18429\n",
      "[262, 7399, 8413] 16308920194\n",
      "[215, 7458, 6361] 10199672670\n",
      "[54, 198, 738, 8977] 9967\n",
      "[664, 8695] 5773480\n",
      "[747, 7215] 5389605\n",
      "[631, 4328] 2730968\n",
      "[1868, 857] 1600876\n",
      "[3674, 7247, 945, 798] 12664\n",
      "[49, 8482, 9197, 4553] 22281\n",
      "[8364, 788] 6590832\n",
      "[7717, 617, 45] 8379\n",
      "[745, 5352, 9762, 1361] 17220\n",
      "[168, 2729] 458472\n",
      "[2987, 8932] 11919\n",
      "[8117, 454] 3685118\n",
      "[3336, 4697, 13] 8046\n",
      "[3668, 7265] 26648020\n",
      "[5549, 2779, 7428, 511] 16267\n",
      "[1991, 7286] 14506426\n",
      "[6969, 2398] 9367\n",
      "[2653, 3538, 25] 234657850\n",
      "[779, 374, 3146] 916574516\n",
      "[9691, 8531, 8318, 545] 27085\n",
      "[4655, 9487] 14142\n",
      "[5533, 3332, 7862] 144943486072\n",
      "[7882, 5829] 45944178\n",
      "[231, 6663, 1818] 2798180154\n",
      "[861, 2353] 2025933\n",
      "[9868, 6643, 6619, 52] 23182\n",
      "[9222, 599, 6] 9827\n",
      "[8799, 9] 8808\n",
      "[7346, 71] 521566\n",
      "[7536, 1781, 9299, 7769] 26385\n",
      "[8, 2899, 6811] 157960712\n",
      "[74, 4343] 321382\n",
      "[2959, 2393] 7080887\n",
      "[7986, 8791] 16777\n",
      "[31, 8814] 273234\n",
      "[849, 8871, 3343] 25177734297\n",
      "[2, 8865] 8867\n",
      "[34, 3551, 9587] 1157476858\n",
      "[4, 33, 1974] 260568\n",
      "[6933, 3571, 61] 10565\n",
      "[3622, 2125, 689] 6436\n",
      "[1567, 356] 1923\n",
      "[9638, 6329] 60998902\n",
      "[9, 443, 2758, 3157] 6367\n",
      "[63, 8658, 3788, 3946] 16455\n",
      "[2687, 3498, 7279] 13464\n",
      "[2261, 2326, 6] 4593\n",
      "[24, 1438, 6445] 222429840\n",
      "[2877, 212] 609924\n",
      "[9489, 2] 18978\n",
      "[3849, 2537, 929] 9071604177\n",
      "[673, 3156] 3829\n",
      "[77, 4493, 4123] 1426397203\n",
      "[782, 9887, 4972, 5549] 21190\n",
      "[699, 2535, 9889] 13123\n",
      "[8288, 5345] 44299360\n",
      "[6929, 97] 7026\n",
      "[7, 5271, 5318] 196218246\n",
      "[1474, 11] 1485\n",
      "[1917, 287, 65] 35761635\n",
      "[8613, 732] 6304716\n",
      "[1433, 3736, 1345] 6514\n",
      "[5236, 1485] 7775460\n",
      "[3525, 7] 3532\n",
      "[8911, 464] 4134704\n",
      "[9154, 617] 5648018\n",
      "[717, 8796, 3637] 22937584284\n",
      "[6398, 61] 390278\n",
      "[7391, 132] 7523\n",
      "[6773, 6325, 44] 13142\n",
      "[2557, 252] 2809\n",
      "[313, 713, 8163, 6815] 16004\n",
      "[9644, 6183, 364] 21704902128\n",
      "[43, 3473] 149339\n",
      "[511, 6156] 6667\n",
      "[1139, 7974, 554] 5031641844\n",
      "[488, 8161, 4246, 6384] 19279\n",
      "[7446, 4429, 6991] 230551532994\n",
      "[191, 6496] 1240736\n",
      "[2399, 4762] 7161\n",
      "[436, 2392, 4618] 4816167616\n",
      "[6384, 5939, 683] 25895655408\n",
      "[1591, 4981] 6572\n",
      "[64, 947, 7556] 8567\n",
      "[7488, 4118, 623] 12229\n",
      "[2663, 8288, 55] 1213901920\n",
      "[6319, 7772] 14091\n",
      "[17, 1438] 24446\n",
      "[2814, 7219, 9951] 202147260966\n",
      "[4494, 86, 9] 3478356\n",
      "[68, 463, 1932] 60827088\n",
      "[3969, 8959, 4798] 170608584258\n",
      "[9324, 6] 55944\n",
      "[9749, 7422] 17171\n",
      "[6777, 6766, 18] 825357276\n",
      "[7933, 273, 64] 138605376\n",
      "[2543, 7333] 18647819\n",
      "[4231, 2857, 717] 7805\n",
      "[6549, 4356] 28527444\n",
      "[7516, 55] 413380\n",
      "[441, 6639, 3632] 10712\n",
      "[8689, 1143, 425] 4220898975\n",
      "[4121, 9545] 39334945\n",
      "[37, 8294] 8331\n",
      "[5973, 4913] 29345349\n",
      "[1927, 51] 1978\n",
      "[9, 7232] 7241\n",
      "[4645, 2435] 7080\n",
      "[5394, 6273, 4736, 26] 16429\n",
      "[333, 4278] 4611\n",
      "[4849, 688, 89] 296913968\n",
      "[37, 1567, 9793] 11397\n",
      "[464, 7457, 8145, 1957] 18023\n",
      "[168, 6863, 2855] 3291769320\n",
      "[9329, 3] 27987\n",
      "[678, 6128, 8127] 33765929568\n",
      "[5786, 617, 552, 82] 7037\n",
      "[935, 4322] 5257\n",
      "[5342, 615, 75] 6032\n",
      "[4232, 2183, 4652] 11067\n",
      "[9, 6693] 60237\n",
      "[4123, 36] 148428\n",
      "[2384, 983, 454] 1063936288\n",
      "[96, 498, 2421] 115743168\n",
      "[241, 5968] 1438288\n",
      "[943, 3829] 3610747\n",
      "[2171, 922, 43] 3136\n",
      "[2834, 25, 9] 637650\n",
      "[5353, 1913, 962] 9851158018\n",
      "[8221, 198] 1627758\n",
      "[6787, 831] 7618\n",
      "[6222, 1] 6222\n",
      "[17, 8328, 1838] 10183\n",
      "[8825, 143] 8968\n",
      "[4983, 136] 677688\n",
      "[3, 565, 9313, 7851] 17732\n",
      "[1541, 2332] 3593612\n",
      "[1527, 2925, 1245] 5697\n",
      "[5513, 7689] 42389457\n",
      "[6, 953, 4135] 5094\n",
      "[622, 283, 1917] 2822\n",
      "[7397, 54] 399438\n",
      "[5595, 851] 4761345\n",
      "[1739, 644] 1119916\n",
      "[2618, 4297] 11249546\n",
      "[1293, 574] 742182\n",
      "[5687, 9779, 11] 611744903\n",
      "[6446, 8684] 15130\n",
      "[1, 29, 9744] 282576\n",
      "[7484, 572, 646] 2765427808\n",
      "[5277, 234, 634] 782874612\n",
      "[5665, 6456, 78, 92] 12291\n",
      "[152, 2859, 7397] 3214499496\n",
      "[2576, 2678, 838] 6092\n",
      "[75, 292, 2495] 54640500\n",
      "[677, 1156] 1833\n",
      "[3558, 7579, 97] 2615709954\n",
      "[3231, 2833, 71] 649893033\n",
      "[4219, 9375, 2278] 90102018750\n",
      "[8847, 893, 74] 584627454\n",
      "[32, 9769, 4594] 1436121152\n",
      "[6266, 716, 597] 7579\n",
      "[2395, 9424, 3444] 77732733120\n",
      "[6, 4876] 29256\n",
      "[19, 474, 3332] 3825\n",
      "[499, 8322] 4152678\n",
      "[1689, 564] 952596\n",
      "[15, 1439, 3361] 72547185\n",
      "[8, 3382, 2635] 6025\n",
      "[9985, 4813, 5641] 20439\n",
      "[9527, 8855, 7279, 8654] 34315\n",
      "[35, 5728, 3141] 8904\n",
      "[6594, 7981] 14575\n",
      "[1211, 35, 5] 211925\n",
      "[125, 3458, 5967] 2579235750\n",
      "[5794, 263, 5] 6062\n",
      "[8577, 5362] 45989874\n",
      "[4595, 463] 5058\n",
      "[7361, 812] 8173\n",
      "[322, 4685, 7776, 9124] 21907\n",
      "[5785, 9715, 8] 15508\n",
      "[55, 4695] 4750\n",
      "[49, 743, 3788, 5783] 10363\n",
      "[29, 374, 6336] 6739\n",
      "[2578, 9872, 5295] 134757834720\n",
      "[8252, 747, 731] 9730\n",
      "[565, 8591] 4853915\n",
      "[3271, 422, 739] 1020087518\n",
      "[38, 667, 1416, 9286] 11407\n",
      "[4461, 5835, 7465] 17761\n",
      "[15, 2428] 2443\n",
      "[2446, 733, 89] 3268\n",
      "[36, 7127] 7163\n",
      "[53, 551, 176, 5199] 5979\n",
      "[3931, 81] 318411\n",
      "[1491, 8129, 8891, 4488] 22999\n",
      "[49, 8598] 421302\n",
      "[8997, 6822, 453, 26] 16298\n",
      "[9457, 1317] 12454869\n",
      "[4622, 865] 3998030\n",
      "[215, 6118, 5221, 6558] 18112\n",
      "[8164, 6634] 54159976\n",
      "[62, 8119, 9187, 9299] 26667\n",
      "[913, 4838, 2813] 12425285422\n",
      "[1947, 8266, 6, 8] 10227\n",
      "[737, 4561] 5298\n",
      "[785, 9169] 9954\n",
      "[4224, 998, 427] 5649\n",
      "[753, 1534] 1155102\n",
      "[252, 6365] 1603980\n",
      "[1431, 3841] 5496471\n",
      "[5325, 76] 5401\n",
      "[2866, 7749, 61, 6] 10682\n",
      "[62, 6694, 9156] 3799996368\n",
      "[26, 5374, 5278] 10678\n",
      "[416, 982, 239, 9567] 11204\n",
      "[595, 9393, 9386] 52456805310\n",
      "[1186, 74] 87764\n",
      "[9727, 5596, 54] 2939343768\n",
      "[1942, 9198] 11140\n",
      "[4715, 8543, 6818] 20076\n",
      "[7751, 9916, 7797] 599268968052\n",
      "[9271, 221] 2048891\n",
      "[4778, 439] 5217\n",
      "[5422, 9864, 2377, 767] 18430\n",
      "[6135, 7414, 7581, 1392] 22522\n",
      "[64, 8876, 4392] 2494937088\n",
      "[6454, 6977, 339] 15265020162\n",
      "[5335, 3479] 18560465\n",
      "[6492, 3422] 22215624\n",
      "[29, 983, 9111] 10123\n",
      "[52, 95, 6725] 33221500\n",
      "[3356, 7641, 5459] 139986206964\n",
      "[6135, 669, 938] 7742\n",
      "[8441, 7428, 46, 6] 15921\n",
      "[5196, 1468, 214] 1632333792\n",
      "[353, 6248, 7296] 16091649024\n",
      "[3383, 4356, 4] 58945392\n",
      "[6231, 8861] 15092\n",
      "[1982, 6758, 9615, 84] 18439\n",
      "[3128, 344] 1076032\n",
      "[6162, 2337] 8499\n",
      "[6512, 7823, 1276] 65003747776\n",
      "[1692, 78] 131976\n",
      "[79, 9312] 735648\n",
      "[7555, 4942, 194] 12691\n",
      "[6195, 9227, 5897] 337079979705\n",
      "[9117, 3691, 84] 2826671148\n",
      "[313, 8389, 7196, 3663] 19561\n",
      "[8966, 1177, 7699] 81247408418\n",
      "[5871, 1249, 1234] 9048772686\n",
      "[7931, 8271, 3855] 252877595355\n",
      "[6194, 3497] 21660418\n",
      "[8494, 53, 74] 33313468\n",
      "[6784, 1742] 8526\n",
      "[43, 7797, 9675] 3243746925\n",
      "[5185, 1827] 9472995\n",
      "[9, 2122] 19098\n",
      "[8145, 4738, 134] 13017\n",
      "[4517, 8976, 682, 24] 14199\n",
      "[425, 9138] 3883650\n",
      "[4512, 5498] 24806976\n",
      "[48, 7667, 5313, 7566] 20594\n",
      "[967, 4249] 5216\n",
      "[4, 8547, 1566] 53538408\n",
      "[756, 113, 7246] 619011288\n",
      "[39, 22, 5365] 4603170\n",
      "[1921, 911, 89] 155752759\n",
      "[74, 555, 757, 8955] 10341\n",
      "[5371, 78, 8] 3351504\n",
      "[9626, 1998, 291] 5596729668\n",
      "[3311, 8728] 28898408\n",
      "[543, 8956] 4863108\n",
      "[491, 9867, 8645] 41882405565\n",
      "[4641, 3449] 8090\n",
      "[5541, 8886, 25] 1230933150\n",
      "[73, 252, 6751] 124191396\n",
      "[17, 3811] 64787\n",
      "[4186, 1775] 5961\n",
      "[5581, 8848] 49380688\n",
      "[2281, 315] 718515\n",
      "[7883, 94, 1] 741002\n",
      "[74, 8856, 8432, 2792] 20154\n",
      "[1847, 7266] 13420302\n",
      "[7357, 1422, 6139, 114] 15032\n",
      "[6815, 4624] 11439\n",
      "[9986, 7153, 955] 68215514390\n",
      "[513, 4867] 2496771\n",
      "[7498, 5546] 41583908\n",
      "[7959, 23] 183057\n",
      "[8467, 62] 8529\n",
      "[3519, 3] 10557\n",
      "[6859, 294] 2016546\n",
      "[4264, 219] 933816\n",
      "[4878, 8258] 40282524\n",
      "[946, 4885, 8946] 41341344660\n",
      "[3958, 76] 4034\n",
      "[845, 3759] 3176355\n",
      "[8611, 6734] 57986474\n",
      "[7126, 3694, 5269] 16089\n",
      "[6584, 4789] 31530776\n",
      "[7351, 7381] 14732\n",
      "[6676, 2114, 6] 8796\n",
      "[8271, 6623] 54778833\n",
      "[8541, 1417] 9958\n",
      "[2335, 5631] 7966\n",
      "[4, 5689] 5693\n",
      "[9465, 8] 75720\n",
      "[3284, 347, 46] 52419208\n",
      "[3984, 1447, 3211] 18510926928\n",
      "[275, 615, 5953, 9764] 16607\n",
      "[9944, 6932] 68931808\n",
      "[264, 7575] 1999800\n",
      "[1422, 3386] 4814892\n",
      "[6518, 8224, 2484, 337] 17563\n",
      "[365, 1153, 1231] 2749\n",
      "[3919, 8535, 9933] 332245589445\n",
      "[4, 925, 8738] 32330600\n",
      "[7515, 7122, 6181] 330818431230\n",
      "[24, 7657] 183768\n",
      "[6882, 881] 6063042\n",
      "[328, 7153, 1518] 8999\n",
      "[935, 9618] 8992830\n",
      "[326, 649, 3546] 750241404\n",
      "[7342, 1292] 9485864\n",
      "[63, 258, 3329] 54109566\n",
      "[2313, 6373] 14740749\n",
      "[79, 1143] 1222\n",
      "[7254, 751, 67] 364999518\n",
      "[3153, 6951] 21916503\n",
      "[43, 9379] 403297\n",
      "[54, 267, 3512] 50636016\n",
      "[822, 8419] 6920418\n",
      "[61, 165, 7362, 2272] 9860\n",
      "[9167, 6512, 349, 716] 16744\n",
      "[92, 293, 682, 6984] 8051\n",
      "[4444, 286] 1270984\n",
      "[1567, 4247] 6655049\n",
      "[9345, 4171] 38977995\n",
      "[1, 263, 4837] 1272131\n",
      "[21, 3699, 5874] 456286446\n",
      "[63, 191, 9848, 9242] 19344\n",
      "[6267, 1456, 9267] 16990\n",
      "[8732, 75] 654900\n",
      "[8324, 9599] 17923\n",
      "[4598, 49] 225302\n",
      "[59, 3355, 9872] 1954113040\n",
      "[221, 5774, 2715] 3464486610\n",
      "[6376, 6276, 3896] 16548\n",
      "[3741, 7461, 2294] 64029212694\n",
      "[7724, 26] 7750\n",
      "[2953, 2838, 4367] 36598141338\n",
      "[5626, 7584, 851, 48] 14109\n",
      "[62, 66, 6771, 6449] 13348\n",
      "[45, 9145] 411525\n",
      "[8573, 4567, 7235] 20375\n",
      "[4297, 6288] 10585\n",
      "[3255, 9197, 65] 1945855275\n",
      "[8997, 546, 739, 37] 10319\n",
      "[9394, 6647] 62441918\n",
      "[6182, 3886, 3167, 9] 13244\n",
      "[515, 2492] 1283380\n",
      "[7275, 2331] 9606\n",
      "[3636, 9773, 611, 4] 14024\n",
      "[2225, 7274] 16184650\n",
      "[1647, 554, 935] 3136\n",
      "[4, 4617] 4621\n",
      "[4777, 3749, 5174] 92661026302\n",
      "[5493, 1485, 653, 768] 8399\n",
      "[3982, 476] 1895432\n",
      "[58, 7619] 7677\n",
      "[2731, 8575] 11306\n",
      "[583, 754, 6854] 8191\n",
      "[65, 4328, 2853] 802605960\n",
      "[1, 8332, 9545] 17878\n",
      "[5684, 1751] 9952684\n",
      "[8475, 2812, 538] 12821454600\n",
      "[588, 519, 4827, 4831] 10765\n",
      "[9539, 7121, 2118, 3955] 22733\n",
      "[6968, 163, 449] 7580\n",
      "[9, 5638, 6943] 352301706\n",
      "[4972, 4837, 318] 10127\n",
      "[422, 4941, 5156] 10750785912\n",
      "[2927, 3191, 666] 6220477962\n",
      "[2698, 9746] 12444\n",
      "[9141, 4355, 11] 437899605\n",
      "[55, 576, 5664] 6295\n",
      "[632, 8494] 5368208\n",
      "[5397, 9793, 83] 15273\n",
      "[16, 3893, 7526] 11435\n",
      "[3926, 3125] 7051\n",
      "[1168, 6479, 8784] 66472674048\n",
      "[6889, 613, 946, 98] 8546\n",
      "[8784, 2446] 11230\n",
      "[539, 8177] 4407403\n",
      "[574, 9374] 5380676\n",
      "[6255, 6993, 8683, 9276] 31207\n",
      "[4574, 1416, 3453] 22364335152\n",
      "[9151, 4928, 218] 9830955904\n",
      "[2496, 3526, 96] 844886016\n",
      "[563, 897, 2859] 1443826449\n",
      "[226, 9346, 2367, 1326] 13265\n",
      "[4896, 9759, 115, 94] 14864\n",
      "[2871, 316, 6] 3193\n",
      "[6774, 1839] 12457386\n",
      "[8525, 2347] 10872\n",
      "[814, 2495] 3309\n",
      "[4223, 5122, 6461, 381] 16187\n",
      "[37, 6678, 6153] 12868\n",
      "[4176, 1355] 5531\n",
      "[9896, 5944, 981, 1] 16822\n",
      "[1895, 572] 2467\n",
      "[3639, 688] 2503632\n",
      "[1989, 9486, 68] 11543\n",
      "[7742, 9688, 4889] 22319\n",
      "[1967, 4637] 9120979\n",
      "[9233, 4215, 82] 13530\n",
      "[48, 414, 2578, 9633] 12673\n",
      "[8754, 48] 8802\n",
      "[1787, 392] 2179\n",
      "[1557, 27] 1584\n",
      "[656, 2318] 1520608\n",
      "[9, 4873, 1772] 77714604\n",
      "[187, 3144] 587928\n",
      "[3752, 1569] 5886888\n",
      "[4, 6795] 27180\n",
      "[3896, 16] 62336\n",
      "[7521, 9225] 69381225\n",
      "[7689, 898] 6904722\n",
      "[633, 7417, 8328, 8472] 24850\n",
      "[72, 6439] 463608\n",
      "[7553, 5782, 317] 13652\n",
      "[233, 2424, 2159] 4816\n",
      "[5234, 9483] 14717\n",
      "[3943, 76] 4019\n",
      "[563, 5529, 8219] 25584325113\n",
      "[3177, 7411] 23544747\n",
      "[1914, 325] 622050\n",
      "[558, 8652] 4827816\n",
      "[5266, 4822, 2] 50785304\n",
      "[33, 6775, 4595] 1027327125\n",
      "[4856, 132] 640992\n",
      "[3964, 2918, 74] 855954448\n",
      "[9314, 6474] 60298836\n",
      "[3186, 9265, 8371] 20822\n",
      "[171, 2974, 3586, 6146] 12877\n",
      "[3871, 27, 5] 3903\n",
      "[3468, 3915, 3] 40731660\n",
      "[4391, 99, 2] 4492\n",
      "[37, 2496] 92352\n",
      "[3551, 1871, 9777] 15199\n",
      "[1857, 765, 27] 38356335\n",
      "[8936, 1289] 11518504\n",
      "[1792, 3826] 6856192\n",
      "[3673, 7546, 676] 11895\n",
      "[895, 493, 7885] 9273\n",
      "[491, 5678, 8797] 14966\n",
      "[2888, 9138] 26390544\n",
      "[6499, 3979] 25859521\n",
      "[2312, 674] 2986\n",
      "[8374, 9724, 6272, 2613] 26983\n",
      "[94, 5674] 5768\n",
      "[1, 915, 4413, 6238] 11567\n",
      "[591, 626, 6662] 7879\n",
      "[284, 3146] 893464\n",
      "[2131, 9582, 649] 13252088058\n",
      "[8813, 269, 448, 699] 10229\n",
      "[4292, 491] 2107372\n",
      "[6, 9696] 9702\n",
      "[27, 583, 7886] 8496\n",
      "[9644, 4918, 9541] 452521920872\n",
      "[838, 596, 5214] 2604121872\n",
      "[1268, 2563, 2359] 6190\n",
      "[9295, 24] 9319\n",
      "[2272, 6875, 915] 10062\n",
      "[7566, 7918] 59907588\n",
      "[3957, 7575, 2836] 14368\n",
      "[86, 1638] 140868\n",
      "[2629, 8333, 371] 8127666547\n",
      "[4, 3734, 5664, 7892] 17294\n",
      "[52, 8668] 450736\n",
      "[848, 1146, 7315] 7108775520\n",
      "[5759, 8334] 14093\n",
      "[8577, 2971, 6415] 163468742805\n",
      "[8538, 1632] 10170\n",
      "[4936, 9275] 14211\n",
      "[2479, 1432, 934] 3315632752\n",
      "[5296, 865, 43] 196984720\n",
      "[947, 4813] 4557911\n",
      "[275, 9921, 1757] 4793579175\n",
      "[69, 8697, 2251, 8813] 19830\n",
      "[5252, 8544, 729] 14525\n",
      "[67, 4812, 5184] 1671342336\n",
      "[748, 8821, 5548] 15117\n",
      "[6893, 7493] 51649249\n",
      "[7763, 7772, 3865, 83] 19483\n",
      "[6438, 447] 2877786\n",
      "[786, 2365, 8638, 3399] 15188\n",
      "[3491, 9281, 837, 978] 14587\n",
      "[14, 42, 1155] 1211\n",
      "[4246, 7295, 67] 11608\n",
      "[1952, 1748, 4391, 518] 8609\n",
      "[6384, 297, 62, 5] 6748\n",
      "[9874, 515, 65, 96] 10550\n",
      "[8995, 69, 6] 9070\n",
      "[2948, 7842, 5314] 122850199824\n",
      "[1279, 436] 1715\n",
      "[554, 2112, 9587, 7527] 19780\n",
      "[272, 638, 4618] 5528\n",
      "[4, 5483] 5487\n",
      "[756, 4871, 4797] 17664837372\n",
      "[7572, 8581] 64975332\n",
      "[8898, 7824, 8] 556943616\n",
      "[2386, 5527] 13187422\n",
      "[1, 52, 5793, 9759] 15605\n",
      "[7163, 7221] 51724023\n",
      "[4449, 5879, 592] 15484157232\n",
      "[21, 6338, 4677] 11036\n",
      "[424, 2116, 1269] 3809\n",
      "[9986, 2791] 12777\n",
      "[2564, 34] 2598\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "cur_pos = 0\n",
    "cur_val = final_line[cur_pos]\n",
    "tot = 0\n",
    "values = []\n",
    "\n",
    "for idx in range(len(mat_arr[0])):\n",
    "    num_str = \"\"\n",
    "    for col_idx in range(len(mat_arr)):\n",
    "        if(mat_arr[col_idx][idx]!=' '):\n",
    "            num_str += mat_arr[col_idx][idx]\n",
    "    if(num_str):\n",
    "        values.append(int(num_str))\n",
    "    else:\n",
    "        if(cur_val=='+'):\n",
    "            my_sum = sum(values)\n",
    "            print(values,my_sum)\n",
    "            tot += my_sum\n",
    "            values = []\n",
    "            cur_pos += 1\n",
    "            cur_val = final_line[cur_pos] \n",
    "        else:\n",
    "            my_prod = math.prod(values)\n",
    "            tot += my_prod\n",
    "            print(values,my_prod)\n",
    "            values = []\n",
    "            cur_pos += 1\n",
    "            cur_val = final_line[cur_pos] \n",
    "\n",
    "if(values!=[]):\n",
    "    if(cur_val=='+'):\n",
    "        my_sum = sum(values)\n",
    "        print(values,my_sum)\n",
    "        tot += my_sum\n",
    "\n",
    "    else:\n",
    "        my_prod = math.prod(values)\n",
    "        tot += my_prod\n",
    "        print(values,my_prod)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "31ff7464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10695785245101"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2422fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for j in range(len(mat_arr[0])):\n",
    "    if(final_line[j]=='*'):\n",
    "        sub_tot = 1\n",
    "        for i in range(len(mat_arr)):\n",
    "            sub_tot *= mat_arr[i][j]\n",
    "        \n",
    "    elif(final_line[j]=='+'):\n",
    "        sub_tot = 0\n",
    "        for i in range(len(mat_arr)):\n",
    "            sub_tot += mat_arr[i][j]\n",
    "    tot += sub_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "2dcb9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str=\"\"\"......................................................................S......................................................................\n",
    ".............................................................................................................................................\n",
    "......................................................................^......................................................................\n",
    ".............................................................................................................................................\n",
    ".....................................................................^.^.....................................................................\n",
    ".............................................................................................................................................\n",
    "....................................................................^...^....................................................................\n",
    ".............................................................................................................................................\n",
    "...................................................................^.^.^.^...................................................................\n",
    ".............................................................................................................................................\n",
    "..................................................................^.^.^...^..................................................................\n",
    ".............................................................................................................................................\n",
    ".................................................................^.^.^.^.^.^.................................................................\n",
    ".............................................................................................................................................\n",
    "................................................................^.^.^.^.^...^................................................................\n",
    ".............................................................................................................................................\n",
    "...............................................................^.^.^...^.^.^.^...............................................................\n",
    ".............................................................................................................................................\n",
    "..............................................................^.^.^.^.^.^...^.^..............................................................\n",
    ".............................................................................................................................................\n",
    ".............................................................^.^.......^...^.^.^.............................................................\n",
    ".............................................................................................................................................\n",
    "............................................................^.^.^.^.^...^.^.^.^.^............................................................\n",
    ".............................................................................................................................................\n",
    "...........................................................^.^.^.^.^.^.^.^...^.^.^...........................................................\n",
    ".............................................................................................................................................\n",
    "..........................................................^.....^.^.^.^.......^.^.^..........................................................\n",
    ".............................................................................................................................................\n",
    ".........................................................^...^.^.^.^.^...^.^.^.....^.........................................................\n",
    ".............................................................................................................................................\n",
    "........................................................^.....^.^.....^.^.^.^.....^.^........................................................\n",
    ".............................................................................................................................................\n",
    ".......................................................^...^.^.^.......^...^...^.^.^.^.......................................................\n",
    ".............................................................................................................................................\n",
    "......................................................^.^.^.^.^.^.^.^.^.^.^.^.^...^.^.^......................................................\n",
    ".............................................................................................................................................\n",
    ".....................................................^.^.^.^...^...^...........^.^.^.^.^.....................................................\n",
    ".............................................................................................................................................\n",
    "....................................................^.^...^.^.....^.^...^.^.^.^.^...^...^....................................................\n",
    ".............................................................................................................................................\n",
    "...................................................^.^...^...^...^...^.^.^.^.^...^.^.^.^.^...................................................\n",
    ".............................................................................................................................................\n",
    "..................................................^.....^.^.....^.^.^.^.^.^...^.^.....^.^.^..................................................\n",
    ".............................................................................................................................................\n",
    ".................................................^.^.^...^.^.^.....^.^.^.^.^.....^.^.^...^.^.................................................\n",
    ".............................................................................................................................................\n",
    "................................................^...^...^...^.^.^.........^.^.^.^.^.^.......^................................................\n",
    ".............................................................................................................................................\n",
    "...............................................^.^.^.^...^.^.^.......^.^.........^.^.^.^.....^...............................................\n",
    ".............................................................................................................................................\n",
    "..............................................^.^.^...^.^.^.^.^.^...^.^.....^.......^.^.^...^.^..............................................\n",
    ".............................................................................................................................................\n",
    ".............................................^.^.^.^.^.^...^.^.^.....^.^.^.^.^.^.^.....^.^.^.^.^.............................................\n",
    ".............................................................................................................................................\n",
    "............................................^.^.^...^.^.^.^.^.^.^...^.^.^.^...^.^.^.^.^.^...^.^.^............................................\n",
    ".............................................................................................................................................\n",
    "...........................................^.^.^.^.^.^.^.^.^.^...^.^.............^.^.^.........^.^...........................................\n",
    ".............................................................................................................................................\n",
    "..........................................^.^.^.....^.^.^.^...^.^.^.^.^.^...^.^.^.^.^.^...^.^.^...^..........................................\n",
    ".............................................................................................................................................\n",
    ".........................................^.^...^.^.^.^.^.^.......^.^...^.^.^.^...^...^.^.^...^.^.^.^.........................................\n",
    ".............................................................................................................................................\n",
    "........................................^.^.^.^.^.^...^...^.^.^.....^.^.^...^.^.^.^.^.^...^.^.^...^.^........................................\n",
    ".............................................................................................................................................\n",
    ".......................................^.^.^.^.^.^.^.^.^.^.^.^.^.^...^.^.^.^.......^...^.^...^.^.^...^.......................................\n",
    ".............................................................................................................................................\n",
    "......................................^.^.^.^...^.^...^.^.^.^.^.^.^.^.^.....^.^...^.^.....^.^.^...^...^......................................\n",
    ".............................................................................................................................................\n",
    ".....................................^.^.^.^.^.^.^.^...^.^.^...^.....^.^...^.^.^.^.....^.^...^...^.^.^.^.....................................\n",
    ".............................................................................................................................................\n",
    "....................................^...^.^.^.....^.^.^.^.^...^...^...^.^.^.^.^.^.^...^.^.^.^.^...^...^.^....................................\n",
    ".............................................................................................................................................\n",
    "...................................^...^...^...^.^.^.....^.^...^.^.^.^.^.....^.^.^.^.^.^.....^...^.^.^...^...................................\n",
    ".............................................................................................................................................\n",
    "..................................^.^.^.^.^...^.....^.....^.......^.^.....^.^...^...^.^.^...^.....^.^.^.^.^..................................\n",
    ".............................................................................................................................................\n",
    ".................................^.^.....^.^.^.^.......^.......^.^.^.^.^.^...^.^...^.^.^...^...^.^...^.....^.................................\n",
    ".............................................................................................................................................\n",
    "................................^.^.^.^.^...^.^.^...^.^.^.^.^.^.^.^...^.^.^.^.....^.^.^.....^.^.^.^...^.....^................................\n",
    ".............................................................................................................................................\n",
    "...............................^.^...^.^.^...^...^.^.....^.....^.^.^.^...^.....^...^...^...^.^.^.^.^.....^.^.^...............................\n",
    ".............................................................................................................................................\n",
    "..............................^.^.....^.^.^.^...^.^.^.^.^...^.^.^.^.^.^.^.^.^.^.^.^.......^.^.^.....^...^...^.^..............................\n",
    ".............................................................................................................................................\n",
    ".............................^.^.^.^.........^.....^.^.^...^...^.^.^.^.^...^...^.^.^.^.^.^.^...^.^.^.^...^.^...^.............................\n",
    ".............................................................................................................................................\n",
    "............................^.^.^.^.^.^.^.^...^.^.....^.^...^.^.^.^.^.....^.^.^.^...^.^.^.^.^...^...^...^...^.^.^............................\n",
    ".............................................................................................................................................\n",
    "...........................^.^...^.^.^.^.^.^...^.^.^.....^...^.^.^.^.^...^...^.^...^.^.......^.^.^...^.^.^.^.^.^.^...........................\n",
    ".............................................................................................................................................\n",
    "..........................^.^...^.^.^.^.^.^.^.........^.^...^.^.^.^.^.^.^.......^.^.^...^.^...^...^.^.^.^.^...^.^.^..........................\n",
    ".............................................................................................................................................\n",
    ".........................^.....^.^.^.^.^.^...^.^.^.^.....^.^.^...^.^.....^.^.^.^.^.^...^...^.^.....^.^.....^.^.^.^.^.........................\n",
    ".............................................................................................................................................\n",
    "........................^...^...^.^.^.^.^.^.....^.^.^.^.^.^.^.^.^.^.....^.^...^...^...^.^.^.^.^.^.......^.^.^.^.^...^........................\n",
    ".............................................................................................................................................\n",
    ".......................^.^.^...^.^.......^.^.^.^.^.^...^.^.......^.^.^...^.^...^.^.^.^.^...^.^.^.^...^.^.^.^.^.^.^.^.^.......................\n",
    ".............................................................................................................................................\n",
    "......................^.^.^.^...^.^.^.^.^.^.^...^.......^.^...^...^...^...^...^...^.....^...^.^.^.^...^.^.^...^.^.^.^.^......................\n",
    ".............................................................................................................................................\n",
    ".....................^.^.^...^.^...^.^...^.....^...^.^.^.^.....^.^...^.^.^.^.....^...^.......^.^.^...^.....^.^.^.....^.^.....................\n",
    ".............................................................................................................................................\n",
    "....................^.^.^.^.^.^.^.^...^.^.^.^.^.^.^.....^...^.^.^.^.^...^.^.^.^.^.^.^...^.^.......^...^.^.^.^.^.^.^.....^....................\n",
    ".............................................................................................................................................\n",
    "...................^.^.....^.....^...^.^...^...^...^.^.^...^.......^.^...^...^.^.^.^.^.^.^.^...^.^.^.^.^...^.^...^...^.^.^...................\n",
    ".............................................................................................................................................\n",
    "..................^...^.^.^.^.^.^.^.^.^.^.^.^.....^...^...^...^.^.^.^.^.^.^.^.^...^.....^...^...^.^.^.^.^.....^...^.^.^.^.^..................\n",
    ".............................................................................................................................................\n",
    ".................^.^.^.^.....^...^.^.^.^.^.^.^.^.^.^...^.^.^.^.^.^.^.....^.^.^...^.^.^...^.......^.....^.^...^...^.......^.^.................\n",
    ".............................................................................................................................................\n",
    "................^.^...^.....^.^...^.^...^.^.^...^.^.^.^...^.^.^.^.....^.^...^.^...^.^...^.^.....^.^.^.....^.^.^.^.^.^...^...^................\n",
    ".............................................................................................................................................\n",
    "...............^.^.....^.^.^.^.^.^.^.^...^.^...^.^...^.^.^...^.^.....^.^...^.^.^.^.^.........^.^...^.^.^...^.^.^.....^...^.^.^...............\n",
    ".............................................................................................................................................\n",
    "..............^.^.^.^.^.^.^.^.^.^.^...^.^.^.^.^.^.^.^.....^.^.^...^.^.^.^.^.^.^.^...^.^.^.^.^.^.^.^.........^.^.^.^.^...^.^.^.^..............\n",
    ".............................................................................................................................................\n",
    ".............^.^.^.^.^.^...^.^.^.^...^.^.^.^.^.........^.^...^.^.^.....^.^...^.^.^...^.^.^...^.^...^...^...^...^.^.^.^.^.^...^.^.............\n",
    ".............................................................................................................................................\n",
    "............^.^.....^.^...^.^.^.^.......^.^.^.^.^.....^.^.^.^.^.^.^.^.^.^.^...^.^.^.^.^...^.^.^...^.^...^.^.^...^.^.^.^.^.^.^...^............\n",
    ".............................................................................................................................................\n",
    "...........^.^.^...^.^.^.^.^...^...^.^.^.....^.^...^.^.^...^.^.^...^.^.^.^...^...^.^.....^...^.^.....^.^.^.^.^.^.^.^...^.......^.^...........\n",
    ".............................................................................................................................................\n",
    "..........^.^.^.^.^.^...^...^.^.^.^.^.^.....^.^.^.^.^...^...^.^.^...^.^.^.^.^...^.^.^.^.....^.^.^.^.^.^.^.^.^.^.^.....^.^.^.......^..........\n",
    ".............................................................................................................................................\n",
    ".........^.^.^.^.^...^.^...^...^.....^.^...^.^...^.^.^.^.^.^.........^.^.^.^.^...^.^.^...^.^.^.^.^...^.....^.^.^.^.^.^.^.^.^.^.^...^.........\n",
    ".............................................................................................................................................\n",
    "........^...^.....^.^.......^...^.^.^.^.....^.^.^.^.......^.^...^.^.^.^.^.^.^.^.^.^.^.....^...^.^.....^...^.^.^.^.^...^...^.....^.^.^........\n",
    ".............................................................................................................................................\n",
    ".......^.^.^.^.^.^...^.^.^...^.^...^...^.......^.^.^.^.^.^...^.^.^.^.^...^.^.^.^.^.^.^.^.^.^.^...^.^.^.^.^.^.^.^.^.....^.^.^.^...^.^.^.......\n",
    ".............................................................................................................................................\n",
    "......^.^.^.^.......^.^.^.^.....^.^.^...^.^.^.^.^...^...^...^.^.^.........^.....^.^.^.^.^.^.....^.......^.^.......^.....^.^.^.^.^.....^......\n",
    ".............................................................................................................................................\n",
    ".....^.^.^.^.....^.^.^...^...^.......^.^...^.....^.^.^.^.^...^...^.^.^.^...^.^.^.^.^.^.^.^.^...^.......^...^.........^.^.^.^...^.^...^.^.....\n",
    ".............................................................................................................................................\n",
    "....^.^.^.^.^.^.^.^.^.^...^.^...^.^.^...^.^.^.^...^.^...^.^.^.^...^...^.^.^.^.^.^.^...^.^.^...^.......^.^.^.^.^.^.^.^.^.^.^.^...^.^.^...^....\n",
    ".............................................................................................................................................\n",
    "...^...^.^.^.^...^.^...^.^.....^.^.^.^.^.^.^.^.^.....^.^.^...^...^.^.^.^.^...^...^.^.^.^...^.^.^.^.^...^...^.^.^.^.^...^.^.^.^.....^.....^...\n",
    ".............................................................................................................................................\n",
    "..^.^...^...^.^.^.^...^.^.^...^.^.^.^.^.....^...^...^.^.^.....^.^.....^.^.^...^.....^.^...^.^.^.^...^.......^.^.....^.^.......^.^.......^.^..\n",
    ".............................................................................................................................................\n",
    ".^...^.^.^.^.^.^.....^.^.^.........^.^...^.^.^.^...^.^.^.^...^.^.........^.^...^.....^...^.^.^.^.^.^.^...^...^.^.^.........^.^.^.^.^.^.^.^.^.\n",
    ".............................................................................................................................................\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "effbcdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58097428661390.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "grid_array = [line for line in input_str.split()]\n",
    "value_array = np.zeros([len(grid_array),len(grid_array[0])])\n",
    "\n",
    "row_len = len(grid_array[0])\n",
    "\n",
    "for idx in range(row_len):\n",
    "    if(grid_array[0][idx]=='S'):\n",
    "        value_array[0][idx]=1\n",
    "\n",
    "num_splits = 0\n",
    "for row in range(1,len(grid_array)):\n",
    "    for col in range(row_len):\n",
    "        if(grid_array[row-1][col]!='^'):\n",
    "            value_array[row][col] += value_array[row-1][col]\n",
    "        if(col>0  and value_array[row-1][col-1]>0 and grid_array[row-1][col-1]=='^'):\n",
    "            value_array[row][col]+= value_array[row-1][col-1]\n",
    "        if(col<row_len-1 and value_array[row-1][col+1]>0 and grid_array[row-1][col+1]=='^'):\n",
    "            value_array[row][col]+= value_array[row-1][col+1]\n",
    "        if(value_array[row][col]>0 and grid_array[row][col]=='^'):\n",
    "            num_splits +=1\n",
    "\n",
    "print(sum(value_array[-1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "0cba3d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  2.,  0., 10.,  0., 11.,  0., 11.,  0.,  2.,  1.,  1.,\n",
       "        0.,  1.])"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_array[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "931a3fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  2.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  2.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  3.  0.  3.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  3.  0.  3.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  4.  0.  3.  3.  1.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  4.  0.  3.  3.  1.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  5.  0.  4.  3.  4.  0.  2.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  5.  0.  4.  3.  4.  0.  2.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  1.  5.  4.  0.  7.  4.  0.  2.  1.  0.  1.  0.]\n",
      " [ 0.  1.  0.  1.  5.  4.  0.  7.  4.  0.  2.  1.  0.  1.  0.]\n",
      " [ 1.  0.  2.  0. 10.  0. 11.  0. 11.  0.  2.  1.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(value_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "ad1cda2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......S.......\n",
      "...............\n",
      ".......^.......\n",
      "...............\n",
      "......^.^......\n",
      "...............\n",
      ".....^.^.^.....\n",
      "...............\n",
      "....^.^...^....\n",
      "...............\n",
      "...^.^...^.^...\n",
      "...............\n",
      "..^...^.....^..\n",
      "...............\n",
      ".^.^.^.^.^...^.\n",
      "...............\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "2c3c35ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranges_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "0a91c3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2315424623146"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "209270512762890-206955088139744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ebe7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"162,817,812\n",
    "57,618,57\n",
    "906,360,560\n",
    "592,479,940\n",
    "352,342,300\n",
    "466,668,158\n",
    "542,29,236\n",
    "431,825,988\n",
    "739,650,466\n",
    "52,470,668\n",
    "216,146,977\n",
    "819,987,18\n",
    "117,168,530\n",
    "805,96,715\n",
    "346,949,466\n",
    "970,615,88\n",
    "941,993,340\n",
    "862,61,35\n",
    "984,92,344\n",
    "425,690,689\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401c19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrDist(node1,node2):\n",
    "    return (node1[0]-node2[0])**2 + (node1[1]-node2[1])**2 + (node1[2]-node2[2])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daf063fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([162, 817, 812], [425, 690, 689], 100427), ([162, 817, 812], [431, 825, 988], 103401), ([906, 360, 560], [805, 96, 715], 103922), ([431, 825, 988], [425, 690, 689], 107662), ([862, 61, 35], [984, 92, 344], 111326), ([52, 470, 668], [117, 168, 530], 114473), ([819, 987, 18], [941, 993, 340], 118604), ([906, 360, 560], [739, 650, 466], 120825), ([346, 949, 466], [425, 690, 689], 123051), ([906, 360, 560], [984, 92, 344], 124564), ([592, 479, 940], [425, 690, 689], 135411), ([352, 342, 300], [542, 29, 236], 138165), ([352, 342, 300], [117, 168, 530], 138401), ([352, 342, 300], [466, 668, 158], 139436), ([542, 29, 236], [862, 61, 35], 143825), ([592, 479, 940], [431, 825, 988], 147941), ([739, 650, 466], [425, 690, 689], 149925), ([162, 817, 812], [52, 470, 668], 153245), ([819, 987, 18], [970, 615, 88], 166085), ([805, 96, 715], [984, 92, 344], 169698), ([466, 668, 158], [739, 650, 466], 169717), ([162, 817, 812], [346, 949, 466], 170996), ([739, 650, 466], [941, 993, 340], 174329), ([57, 618, 57], [466, 668, 158], 179982), ([52, 470, 668], [425, 690, 689], 187970), ([466, 668, 158], [346, 949, 466], 188225), ([739, 650, 466], [970, 615, 88], 197470), ([970, 615, 88], [941, 993, 340], 207229), ([216, 146, 977], [117, 168, 530], 210094), ([542, 29, 236], [984, 92, 344], 210997), ([57, 618, 57], [352, 342, 300], 222250), ([52, 470, 668], [216, 146, 977], 227353), ([352, 342, 300], [52, 470, 668], 241808), ([592, 479, 940], [805, 96, 715], 242683), ([739, 650, 466], [346, 949, 466], 243850), ([466, 668, 158], [819, 987, 18], 245970), ([592, 479, 940], [216, 146, 977], 253634), ([906, 360, 560], [592, 479, 940], 257157), ([466, 668, 158], [970, 615, 88], 261725), ([352, 342, 300], [739, 650, 466], 272189), ([592, 479, 940], [739, 650, 466], 275526), ([352, 342, 300], [425, 690, 689], 277754), ([466, 668, 158], [425, 690, 689], 284126), ([542, 29, 236], [117, 168, 530], 286382), ([906, 360, 560], [970, 615, 88], 291905), ([431, 825, 988], [346, 949, 466], 295085), ([542, 29, 236], [805, 96, 715], 303099), ([162, 817, 812], [592, 479, 940], 315528), ([739, 650, 466], [819, 987, 18], 320673), ([970, 615, 88], [862, 61, 35], 321389), ([970, 615, 88], [984, 92, 344], 339261), ([906, 360, 560], [542, 29, 236], 347033), ([52, 470, 668], [346, 949, 466], 356681), ([906, 360, 560], [425, 690, 689], 356902), ([57, 618, 57], [346, 949, 466], 360363), ([466, 668, 158], [941, 993, 340], 364374), ([592, 479, 940], [52, 470, 668], 365665), ([906, 360, 560], [862, 61, 35], 366962), ([346, 949, 466], [941, 993, 340], 371837), ([431, 825, 988], [52, 470, 668], 372066), ([739, 650, 466], [805, 96, 715], 373273), ([906, 360, 560], [352, 342, 300], 374840), ([739, 650, 466], [984, 92, 344], 386273), ([117, 168, 530], [425, 690, 689], 392629), ([57, 618, 57], [52, 470, 668], 395250), ([352, 342, 300], [346, 949, 466], 396041), ([431, 825, 988], [739, 650, 466], 397973), ([352, 342, 300], [862, 61, 35], 409286), ([216, 146, 977], [805, 96, 715], 418065), ([466, 668, 158], [542, 29, 236], 420181), ([216, 146, 977], [425, 690, 689], 422561), ([819, 987, 18], [346, 949, 466], 425877), ([57, 618, 57], [117, 168, 530], 429829), ([352, 342, 300], [805, 96, 715], 437950), ([906, 360, 560], [466, 668, 158], 450068), ([906, 360, 560], [941, 993, 340], 450314), ([352, 342, 300], [984, 92, 344], 463860), ([805, 96, 715], [862, 61, 35], 466874), ([466, 668, 158], [52, 470, 668], 470700), ([542, 29, 236], [739, 650, 466], 477350), ([941, 993, 340], [425, 690, 689], 479866), ([162, 817, 812], [216, 146, 977], 480382), ([162, 817, 812], [739, 650, 466], 480534), ([592, 479, 940], [352, 342, 300], 485969), ([592, 479, 940], [117, 168, 530], 490446), ([805, 96, 715], [425, 690, 689], 497912), ([352, 342, 300], [970, 615, 88], 501397), ([162, 817, 812], [117, 168, 530], 502750), ([592, 479, 940], [346, 949, 466], 506092), ([431, 825, 988], [216, 146, 977], 507387), ([466, 668, 158], [117, 168, 530], 510185), ([117, 168, 530], [805, 96, 715], 512753), ([352, 342, 300], [216, 146, 977], 515241), ([162, 817, 812], [352, 342, 300], 523869), ([57, 618, 57], [425, 690, 689], 540032), ([466, 668, 158], [862, 61, 35], 540394), ([162, 817, 812], [466, 668, 158], 542333), ([739, 650, 466], [52, 470, 668], 545173), ([739, 650, 466], [862, 61, 35], 547811), ([542, 29, 236], [970, 615, 88], 548484), ([57, 618, 57], [542, 29, 236], 614187), ([162, 817, 812], [57, 618, 57], 620651), ([542, 29, 236], [52, 470, 668], 621205), ([739, 650, 466], [117, 168, 530], 623304), ([906, 360, 560], [431, 825, 988], 625034), ([57, 618, 57], [739, 650, 466], 633429), ([466, 668, 158], [984, 92, 344], 634696), ([346, 949, 466], [970, 615, 88], 643816), ([542, 29, 236], [425, 690, 689], 655819), ([592, 479, 940], [984, 92, 344], 658649), ([906, 360, 560], [117, 168, 530], 660285), ([592, 479, 940], [466, 668, 158], 663121), ([970, 615, 88], [425, 690, 689], 663851), ([117, 168, 530], [346, 949, 466], 666498), ([542, 29, 236], [216, 146, 977], 669046), ([906, 360, 560], [346, 949, 466], 669357), ([805, 96, 715], [970, 615, 88], 689715), ([819, 987, 18], [425, 690, 689], 693686), ([906, 360, 560], [819, 987, 18], 694462), ([906, 360, 560], [216, 146, 977], 695785), ([592, 479, 940], [542, 29, 236], 700616), ([431, 825, 988], [941, 993, 340], 708228), ([52, 470, 668], [805, 96, 715], 709094), ([352, 342, 300], [431, 825, 988], 712874), ([352, 342, 300], [819, 987, 18], 713638), ([466, 668, 158], [431, 825, 988], 714774), ([57, 618, 57], [819, 987, 18], 718326), ([431, 825, 988], [117, 168, 530], 740009), ([431, 825, 988], [805, 96, 715], 745846), ([592, 479, 940], [941, 993, 340], 745997), ([466, 668, 158], [805, 96, 715], 752354), ([906, 360, 560], [52, 470, 668], 753080), ([352, 342, 300], [941, 993, 340], 772322), ([739, 650, 466], [216, 146, 977], 788666), ([984, 92, 344], [425, 690, 689], 789110), ([117, 168, 530], [984, 92, 344], 792061), ([117, 168, 530], [862, 61, 35], 811499), ([941, 993, 340], [984, 92, 344], 813666), ([162, 817, 812], [906, 360, 560], 825889), ([57, 618, 57], [970, 615, 88], 834539), ([819, 987, 18], [862, 61, 35], 859614), ([162, 817, 812], [941, 993, 340], 860601), ([592, 479, 940], [970, 615, 88], 887284), ([216, 146, 977], [346, 949, 466], 922830), ([819, 987, 18], [984, 92, 344], 934526), ([542, 29, 236], [346, 949, 466], 937716), ([162, 817, 812], [805, 96, 715], 942699), ([57, 618, 57], [862, 61, 35], 958758), ([805, 96, 715], [941, 993, 340], 963730), ([941, 993, 340], [862, 61, 35], 967890), ([216, 146, 977], [984, 92, 344], 993429), ([805, 96, 715], [346, 949, 466], 1000291), ([57, 618, 57], [941, 993, 340], 1002170), ([466, 668, 158], [216, 146, 977], 1005745), ([862, 61, 35], [425, 690, 689], 1014326), ([57, 618, 57], [906, 360, 560], 1040374), ([542, 29, 236], [819, 987, 18], 1042017), ([57, 618, 57], [431, 825, 988], 1049486), ([592, 479, 940], [862, 61, 35], 1066649), ([57, 618, 57], [592, 479, 940], 1085235), ([162, 817, 812], [819, 987, 18], 1090985), ([57, 618, 57], [216, 146, 977], 1094465), ([162, 817, 812], [542, 29, 236], 1097120), ([542, 29, 236], [941, 993, 340], 1099313), ([52, 470, 668], [984, 92, 344], 1116484), ([431, 825, 988], [819, 987, 18], 1117688), ([117, 168, 530], [970, 615, 88], 1122782), ([431, 825, 988], [970, 615, 88], 1144621), ([346, 949, 466], [984, 92, 344], 1156377), ([592, 479, 940], [819, 987, 18], 1159677), ([52, 470, 668], [941, 993, 340], 1171434), ([52, 470, 668], [970, 615, 88], 1200149), ([542, 29, 236], [431, 825, 988], 1211441), ([162, 817, 812], [970, 615, 88], 1217844), ([57, 618, 57], [984, 92, 344], 1218374), ([52, 470, 668], [862, 61, 35], 1224070), ([346, 949, 466], [862, 61, 35], 1240561), ([431, 825, 988], [984, 92, 344], 1257834), ([57, 618, 57], [805, 96, 715], 1264952), ([52, 470, 668], [819, 987, 18], 1278078), ([819, 987, 18], [805, 96, 715], 1279886), ([216, 146, 977], [862, 61, 35], 1311905), ([117, 168, 530], [941, 993, 340], 1395701), ([162, 817, 812], [984, 92, 344], 1420333), ([819, 987, 18], [117, 168, 530], 1425709), ([216, 146, 977], [970, 615, 88], 1578798), ([216, 146, 977], [941, 993, 340], 1648803), ([162, 817, 812], [862, 61, 35], 1665265), ([431, 825, 988], [862, 61, 35], 1677666), ([216, 146, 977], [819, 987, 18], 1990571)]\n"
     ]
    }
   ],
   "source": [
    "nodes = []\n",
    "for line in input_str.split():\n",
    "    nodes.append(list(map(int,line.split(','))))\n",
    "\n",
    "edges = []\n",
    "for idx1 in range(len(nodes)):\n",
    "    for idx2 in range(idx1+1,len(nodes)):\n",
    "        edges.append((nodes[idx1],nodes[idx2],sqrDist(nodes[idx1],nodes[idx2])))\n",
    "\n",
    "sorted_edges = sorted(edges,key=lambda x: x[2])\n",
    "\n",
    "print(sorted_edges)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "368ded21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([162, 817, 812], [425, 690, 689], 100427),\n",
       " ([162, 817, 812], [431, 825, 988], 103401),\n",
       " ([906, 360, 560], [805, 96, 715], 103922),\n",
       " ([431, 825, 988], [425, 690, 689], 107662),\n",
       " ([862, 61, 35], [984, 92, 344], 111326),\n",
       " ([52, 470, 668], [117, 168, 530], 114473),\n",
       " ([819, 987, 18], [941, 993, 340], 118604),\n",
       " ([906, 360, 560], [739, 650, 466], 120825),\n",
       " ([346, 949, 466], [425, 690, 689], 123051),\n",
       " ([906, 360, 560], [984, 92, 344], 124564)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_edges[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43b6318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135411"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrDist([592,479,940],[425,690,689])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b08eaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_edges = sorted_edges[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7c8eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(node,searched_nodes,connected_edges):\n",
    "    total_size = 1\n",
    "    for edge in connected_edges:\n",
    "        if(edge[0]==node or edge[1]==node):\n",
    "            if(edge[0] not in searched_nodes):\n",
    "                searched_nodes.append(edge[0])\n",
    "                total_size += dfs(edge[0],searched_nodes,connected_edges)\n",
    "            if(edge[1] not in searched_nodes):\n",
    "                searched_nodes.append(edge[1])\n",
    "                total_size += dfs(edge[1],searched_nodes,connected_edges)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6536fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93612, 76992, 69452]\n",
      "[58345, 5062, 87052]\n",
      "[999, 1]\n"
     ]
    }
   ],
   "source": [
    "searched_nodes = []\n",
    "part_sizes = []\n",
    "for node in nodes:\n",
    "    if(node not in searched_nodes):\n",
    "        print(node)\n",
    "        searched_nodes.append(node)\n",
    "        part_sizes.append(dfs(node,searched_nodes,connected_edges))\n",
    "\n",
    "\n",
    "part_sizes.sort(reverse=True)\n",
    "print(part_sizes[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6af0f007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6281\n"
     ]
    }
   ],
   "source": [
    "for edge_idx in range(len(sorted_edges)):\n",
    "    if(sorted_edges[edge_idx][0]==[58345, 5062, 87052] or sorted_edges[edge_idx][1]==[58345, 5062, 87052]):\n",
    "        print(edge_idx)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b81d7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([64572, 18666, 90042], [58345, 5062, 87052], 232784445)\n"
     ]
    }
   ],
   "source": [
    "print(sorted_edges[edge_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a39733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3767453340"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58345*64572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f4971481",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"98139,50134\n",
    "98139,51344\n",
    "97752,51344\n",
    "97752,52552\n",
    "97690,52552\n",
    "97690,53768\n",
    "97716,53768\n",
    "97716,55028\n",
    "98110,55028\n",
    "98110,56140\n",
    "97156,56140\n",
    "97156,57477\n",
    "97912,57477\n",
    "97912,58631\n",
    "97393,58631\n",
    "97393,59810\n",
    "97068,59810\n",
    "97068,60999\n",
    "96805,60999\n",
    "96805,62191\n",
    "96547,62191\n",
    "96547,63241\n",
    "95790,63241\n",
    "95790,64439\n",
    "95574,64439\n",
    "95574,65656\n",
    "95388,65656\n",
    "95388,66774\n",
    "94904,66774\n",
    "94904,67836\n",
    "94290,67836\n",
    "94290,69244\n",
    "94501,69244\n",
    "94501,70268\n",
    "93788,70268\n",
    "93788,71148\n",
    "92809,71148\n",
    "92809,72346\n",
    "92489,72346\n",
    "92489,73328\n",
    "91753,73328\n",
    "91753,74320\n",
    "91051,74320\n",
    "91051,75306\n",
    "90348,75306\n",
    "90348,76613\n",
    "90136,76613\n",
    "90136,77644\n",
    "89480,77644\n",
    "89480,78337\n",
    "88364,78337\n",
    "88364,79295\n",
    "87628,79295\n",
    "87628,80165\n",
    "86784,80165\n",
    "86784,81228\n",
    "86171,81228\n",
    "86171,82441\n",
    "85705,82441\n",
    "85705,83098\n",
    "84624,83098\n",
    "84624,84064\n",
    "83873,84064\n",
    "83873,84825\n",
    "82918,84825\n",
    "82918,85335\n",
    "81744,85335\n",
    "81744,86744\n",
    "81365,86744\n",
    "81365,86949\n",
    "79956,86949\n",
    "79956,88350\n",
    "79514,88350\n",
    "79514,88946\n",
    "78431,88946\n",
    "78431,89218\n",
    "77134,89218\n",
    "77134,90171\n",
    "76314,90171\n",
    "76314,91035\n",
    "75418,91035\n",
    "75418,91538\n",
    "74296,91538\n",
    "74296,91669\n",
    "72975,91669\n",
    "72975,92779\n",
    "72193,92779\n",
    "72193,92918\n",
    "70903,92918\n",
    "70903,93286\n",
    "69742,93286\n",
    "69742,93717\n",
    "68615,93717\n",
    "68615,94951\n",
    "67809,94951\n",
    "67809,95446\n",
    "66686,95446\n",
    "66686,95710\n",
    "65481,95710\n",
    "65481,95839\n",
    "64241,95839\n",
    "64241,95966\n",
    "63013,95966\n",
    "63013,96113\n",
    "61801,96113\n",
    "61801,97201\n",
    "60813,97201\n",
    "60813,96716\n",
    "59464,96716\n",
    "59464,97458\n",
    "58368,97458\n",
    "58368,97772\n",
    "57181,97772\n",
    "57181,97368\n",
    "55897,97368\n",
    "55897,97883\n",
    "54733,97883\n",
    "54733,97638\n",
    "53493,97638\n",
    "53493,97722\n",
    "52286,97722\n",
    "52286,98001\n",
    "51081,98001\n",
    "51081,97675\n",
    "49866,97675\n",
    "49866,97707\n",
    "48657,97707\n",
    "48657,98136\n",
    "47423,98136\n",
    "47423,97634\n",
    "46238,97634\n",
    "46238,98098\n",
    "44972,98098\n",
    "44972,97622\n",
    "43799,97622\n",
    "43799,97855\n",
    "42531,97855\n",
    "42531,97299\n",
    "41385,97299\n",
    "41385,96972\n",
    "40209,96972\n",
    "40209,96335\n",
    "39110,96335\n",
    "39110,96563\n",
    "37804,96563\n",
    "37804,95651\n",
    "36799,95651\n",
    "36799,95762\n",
    "35501,95762\n",
    "35501,94989\n",
    "34481,94989\n",
    "34481,95417\n",
    "33034,95417\n",
    "33034,94438\n",
    "32104,94438\n",
    "32104,93632\n",
    "31130,93632\n",
    "31130,93574\n",
    "29830,93574\n",
    "29830,93411\n",
    "28554,93411\n",
    "28554,92731\n",
    "27526,92731\n",
    "27526,91888\n",
    "26595,91888\n",
    "26595,91570\n",
    "25371,91570\n",
    "25371,90514\n",
    "24589,90514\n",
    "24589,89701\n",
    "23674,89701\n",
    "23674,89384\n",
    "22423,89384\n",
    "22423,88761\n",
    "21369,88761\n",
    "21369,87707\n",
    "20642,87707\n",
    "20642,87225\n",
    "19472,87225\n",
    "19472,85980\n",
    "18936,85980\n",
    "18936,85790\n",
    "17482,85790\n",
    "17482,84618\n",
    "16907,84618\n",
    "16907,83563\n",
    "16247,83563\n",
    "16247,82768\n",
    "15333,82768\n",
    "15333,82271\n",
    "14078,82271\n",
    "14078,80864\n",
    "13842,80864\n",
    "13842,80408\n",
    "12492,80408\n",
    "12492,79557\n",
    "11593,79557\n",
    "11593,78479\n",
    "10986,78479\n",
    "10986,77474\n",
    "10289,77474\n",
    "10289,76312\n",
    "9830,76312\n",
    "9830,75465\n",
    "8887,75465\n",
    "8887,74377\n",
    "8322,74377\n",
    "8322,73361\n",
    "7631,73361\n",
    "7631,71962\n",
    "7666,71962\n",
    "7666,71126\n",
    "6622,71126\n",
    "6622,70096\n",
    "5936,70096\n",
    "5936,68996\n",
    "5389,68996\n",
    "5389,67683\n",
    "5367,67683\n",
    "5367,66513\n",
    "5025,66513\n",
    "5025,65515\n",
    "4188,65515\n",
    "4188,64224\n",
    "4215,64224\n",
    "4215,63167\n",
    "3489,63167\n",
    "3489,61910\n",
    "3462,61910\n",
    "3462,60708\n",
    "3257,60708\n",
    "3257,59625\n",
    "2484,59625\n",
    "2484,58265\n",
    "3125,58265\n",
    "3125,57194\n",
    "2142,57194\n",
    "2142,55886\n",
    "2721,55886\n",
    "2721,54690\n",
    "2552,54690\n",
    "2552,53529\n",
    "1870,53529\n",
    "1870,52300\n",
    "1984,52300\n",
    "1984,51075\n",
    "2287,51075\n",
    "2287,50126\n",
    "94997,50126\n",
    "94997,48641\n",
    "1738,48641\n",
    "1738,47438\n",
    "2142,47438\n",
    "2142,46228\n",
    "2242,46228\n",
    "2242,45035\n",
    "2503,45035\n",
    "2503,43802\n",
    "2400,43802\n",
    "2400,42582\n",
    "2469,42582\n",
    "2469,41477\n",
    "3203,41477\n",
    "3203,40123\n",
    "2614,40123\n",
    "2614,39130\n",
    "3748,39130\n",
    "3748,37771\n",
    "3311,37771\n",
    "3311,36688\n",
    "3965,36688\n",
    "3965,35618\n",
    "4607,35618\n",
    "4607,34321\n",
    "4547,34321\n",
    "4547,33197\n",
    "5019,33197\n",
    "5019,31962\n",
    "5208,31962\n",
    "5208,31031\n",
    "6138,31031\n",
    "6138,29690\n",
    "6123,29690\n",
    "6123,28824\n",
    "7136,28824\n",
    "7136,27785\n",
    "7761,27785\n",
    "7761,26487\n",
    "7917,26487\n",
    "7917,25366\n",
    "8421,25366\n",
    "8421,24655\n",
    "9592,24655\n",
    "9592,23544\n",
    "10102,23544\n",
    "10102,22385\n",
    "10560,22385\n",
    "10560,21358\n",
    "11223,21358\n",
    "11223,20681\n",
    "12341,20681\n",
    "12341,19804\n",
    "13179,19804\n",
    "13179,18387\n",
    "13383,18387\n",
    "13383,17846\n",
    "14610,17846\n",
    "14610,16742\n",
    "15209,16742\n",
    "15209,16240\n",
    "16429,16240\n",
    "16429,14832\n",
    "16758,14832\n",
    "16758,14652\n",
    "18243,14652\n",
    "18243,13592\n",
    "18921,13592\n",
    "18921,13025\n",
    "20023,13025\n",
    "20023,11804\n",
    "20605,11804\n",
    "20605,11323\n",
    "21765,11323\n",
    "21765,10506\n",
    "22675,10506\n",
    "22675,10187\n",
    "23921,10187\n",
    "23921,9541\n",
    "24939,9541\n",
    "24939,8539\n",
    "25750,8539\n",
    "25750,7925\n",
    "26800,7925\n",
    "26800,7268\n",
    "27831,7268\n",
    "27831,7118\n",
    "29114,7118\n",
    "29114,6182\n",
    "30015,6182\n",
    "30015,5471\n",
    "31038,5471\n",
    "31038,5830\n",
    "32500,5830\n",
    "32500,5118\n",
    "33520,5118\n",
    "33520,4516\n",
    "34595,4516\n",
    "34595,3842\n",
    "35659,3842\n",
    "35659,3852\n",
    "36935,3852\n",
    "36935,3660\n",
    "38140,3660\n",
    "38140,3437\n",
    "39332,3437\n",
    "39332,2972\n",
    "40472,2972\n",
    "40472,2852\n",
    "41686,2852\n",
    "41686,2524\n",
    "42863,2524\n",
    "42863,2771\n",
    "44119,2771\n",
    "44119,2721\n",
    "45326,2721\n",
    "45326,2485\n",
    "46515,2485\n",
    "46515,2257\n",
    "47712,2257\n",
    "47712,2068\n",
    "48919,2068\n",
    "48919,2423\n",
    "50133,2423\n",
    "50133,2070\n",
    "51349,2070\n",
    "51349,2501\n",
    "52542,2501\n",
    "52542,1823\n",
    "53804,1823\n",
    "53804,2662\n",
    "54947,2662\n",
    "54947,2141\n",
    "56231,2141\n",
    "56231,2160\n",
    "57466,2160\n",
    "57466,2742\n",
    "58606,2742\n",
    "58606,3176\n",
    "59759,3176\n",
    "59759,3160\n",
    "61007,3160\n",
    "61007,3713\n",
    "62122,3713\n",
    "62122,3596\n",
    "63418,3596\n",
    "63418,4576\n",
    "64391,4576\n",
    "64391,4917\n",
    "65550,4917\n",
    "65550,5332\n",
    "66685,5332\n",
    "66685,5802\n",
    "67798,5802\n",
    "67798,5698\n",
    "69158,5698\n",
    "69158,5988\n",
    "70371,5988\n",
    "70371,7040\n",
    "71222,7040\n",
    "71222,7085\n",
    "72570,7085\n",
    "72570,8251\n",
    "73325,8251\n",
    "73325,8772\n",
    "74424,8772\n",
    "74424,9591\n",
    "75344,9591\n",
    "75344,10037\n",
    "76498,10037\n",
    "76498,10972\n",
    "77326,10972\n",
    "77326,11171\n",
    "78680,11171\n",
    "78680,12095\n",
    "79510,12095\n",
    "79510,12791\n",
    "80513,12791\n",
    "80513,13793\n",
    "81258,13793\n",
    "81258,14467\n",
    "82284,14467\n",
    "82284,15132\n",
    "83330,15132\n",
    "83330,16459\n",
    "83729,16459\n",
    "83729,17146\n",
    "84756,17146\n",
    "84756,17950\n",
    "85674,17950\n",
    "85674,18854\n",
    "86486,18854\n",
    "86486,19790\n",
    "87261,19790\n",
    "87261,20559\n",
    "88254,20559\n",
    "88254,21754\n",
    "88691,21754\n",
    "88691,22539\n",
    "89690,22539\n",
    "89690,23885\n",
    "89867,23885\n",
    "89867,24583\n",
    "91032,24583\n",
    "91032,25801\n",
    "91371,25801\n",
    "91371,27020\n",
    "91675,27020\n",
    "91675,27977\n",
    "92449,27977\n",
    "92449,29020\n",
    "93074,29020\n",
    "93074,30116\n",
    "93597,30116\n",
    "93597,31248\n",
    "94036,31248\n",
    "94036,32343\n",
    "94564,32343\n",
    "94564,33526\n",
    "94865,33526\n",
    "94865,34739\n",
    "95057,34739\n",
    "95057,35811\n",
    "95668,35811\n",
    "95668,37049\n",
    "95744,37049\n",
    "95744,38096\n",
    "96509,38096\n",
    "96509,39350\n",
    "96482,39350\n",
    "96482,40433\n",
    "97222,40433\n",
    "97222,41595\n",
    "97659,41595\n",
    "97659,42878\n",
    "97375,42878\n",
    "97375,44100\n",
    "97379,44100\n",
    "97379,45229\n",
    "98259,45229\n",
    "98259,46460\n",
    "98267,46460\n",
    "98267,47709\n",
    "97813,47709\n",
    "97813,48914\n",
    "98189,48914\n",
    "98189,50134\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0b3389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [[94997,48641],\n",
    "[1738,48641],\n",
    "[1738,47438],\n",
    "[2142,47438],\n",
    "[2142,46228],\n",
    "[2242,46228],\n",
    "[2242,45035],\n",
    "[2503,45035],\n",
    "[2503,43802],\n",
    "[2400,43802],\n",
    "[2400,42582],\n",
    "[2469,42582],\n",
    "[2469,41477],\n",
    "[3203,41477],\n",
    "[3203,40123],\n",
    "[2614,40123],\n",
    "[2614,39130],\n",
    "[3748,39130],\n",
    "[3748,37771],\n",
    "[3311,37771],\n",
    "[3311,36688],\n",
    "[3965,36688],\n",
    "[3965,35618],\n",
    "[4607,35618]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6988748",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [[5367,67683],\n",
    "[5367,66513],\n",
    "[5025,66513],\n",
    "[5025,65515],\n",
    "[4188,65515],\n",
    "[4188,64224],\n",
    "[4215,64224],\n",
    "[4215,63167],\n",
    "[3489,63167],\n",
    "[3489,61910],\n",
    "[3462,61910],\n",
    "[3462,60708],\n",
    "[3257,60708],\n",
    "[3257,59625],\n",
    "[2484,59625],\n",
    "[2484,58265],\n",
    "[3125,58265],\n",
    "[3125,57194],\n",
    "[2142,57194],\n",
    "[2142,55886],\n",
    "[2721,55886],\n",
    "[2721,54690],\n",
    "[2552,54690],\n",
    "[2552,53529],\n",
    "[1870,53529],\n",
    "[1870,52300],\n",
    "[1984,52300],\n",
    "[1984,51075],\n",
    "[2287,51075],\n",
    "[2287,50126]]#,\n",
    "#[94997,50126]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b38a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for line in input_str.split():\n",
    "    points.append(list(map(int,line.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "257ed423",
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangles_areas = [] \n",
    "for idx1 in range(len(points)):\n",
    "    for idx2 in range(idx1+1,len(points)):\n",
    "        rectangles_areas.append([(1+abs(points[idx1][0]-points[idx2][0]))*((1+abs(points[idx1][1]-points[idx2][1]))),points[idx1],points[idx2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e0dcd783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1474477524, [5025, 66513], [94997, 50126]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rectangles_areas)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55391713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1573741098, [5367, 67683], [94997, 50126]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rectangles_areas)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[94997,50126],[94997,66774],[5367,66774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3faa5127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot([point[0] for point in points],[point[1] for point in points],marker='o',linestyle='-',color='green',markerfacecolor='red')\n",
    "plt.plot([94997,94997,5367,5367],[50126,66774,66774,50126],marker='o',linestyle='-',color='green',markerfacecolor='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "52264028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429660000000.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "122760*1000000*3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2471609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "plt.scatter(\n",
      "    x: \u001b[33m'float | ArrayLike'\u001b[39m,\n",
      "    y: \u001b[33m'float | ArrayLike'\u001b[39m,\n",
      "    s: \u001b[33m'float | ArrayLike | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    c: \u001b[33m'ArrayLike | Sequence[ColorType] | ColorType | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    *,\n",
      "    marker: \u001b[33m'MarkerType | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    cmap: \u001b[33m'str | Colormap | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    norm: \u001b[33m'str | Normalize | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    vmin: \u001b[33m'float | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    vmax: \u001b[33m'float | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    alpha: \u001b[33m'float | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    linewidths: \u001b[33m'float | Sequence[float] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    edgecolors: \u001b[33m\"Literal['face', 'none'] | ColorType | Sequence[ColorType] | None\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    colorizer: \u001b[33m'Colorizer | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    plotnonfinite: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    data=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **kwargs,\n",
      ") -> \u001b[33m'PathCollection'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "A scatter plot of *y* vs. *x* with varying marker size and/or color.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x, y : float or array-like, shape (n, )\n",
      "    The data positions.\n",
      "\n",
      "s : float or array-like, shape (n, ), optional\n",
      "    The marker size in points**2 (typographic points are 1/72 in.).\n",
      "    Default is ``rcParams['lines.markersize'] ** 2``.\n",
      "\n",
      "    The linewidth and edgecolor can visually interact with the marker\n",
      "    size, and can lead to artifacts if the marker size is smaller than\n",
      "    the linewidth.\n",
      "\n",
      "    If the linewidth is greater than 0 and the edgecolor is anything\n",
      "    but *'none'*, then the effective size of the marker will be\n",
      "    increased by half the linewidth because the stroke will be centered\n",
      "    on the edge of the shape.\n",
      "\n",
      "    To eliminate the marker edge either set *linewidth=0* or\n",
      "    *edgecolor='none'*.\n",
      "\n",
      "c : array-like or list of :mpltype:`color` or :mpltype:`color`, optional\n",
      "    The marker colors. Possible values:\n",
      "\n",
      "    - A scalar or sequence of n numbers to be mapped to colors using\n",
      "      *cmap* and *norm*.\n",
      "    - A 2D array in which the rows are RGB or RGBA.\n",
      "    - A sequence of colors of length n.\n",
      "    - A single color format string.\n",
      "\n",
      "    Note that *c* should not be a single numeric RGB or RGBA sequence\n",
      "    because that is indistinguishable from an array of values to be\n",
      "    colormapped. If you want to specify the same RGB or RGBA value for\n",
      "    all points, use a 2D array with a single row.  Otherwise,\n",
      "    value-matching will have precedence in case of a size matching with\n",
      "    *x* and *y*.\n",
      "\n",
      "    If you wish to specify a single color for all points\n",
      "    prefer the *color* keyword argument.\n",
      "\n",
      "    Defaults to `None`. In that case the marker color is determined\n",
      "    by the value of *color*, *facecolor* or *facecolors*. In case\n",
      "    those are not specified or `None`, the marker color is determined\n",
      "    by the next color of the ``Axes``' current \"shape and fill\" color\n",
      "    cycle. This cycle defaults to :rc:`axes.prop_cycle`.\n",
      "\n",
      "marker : `~.markers.MarkerStyle`, default: :rc:`scatter.marker`\n",
      "    The marker style. *marker* can be either an instance of the class\n",
      "    or the text shorthand for a particular marker.\n",
      "    See :mod:`matplotlib.markers` for more information about marker\n",
      "    styles.\n",
      "\n",
      "cmap : str or `~matplotlib.colors.Colormap`, default: :rc:`image.cmap`\n",
      "    The Colormap instance or registered colormap name used to map scalar data\n",
      "    to colors.\n",
      "\n",
      "    This parameter is ignored if *c* is RGB(A).\n",
      "\n",
      "norm : str or `~matplotlib.colors.Normalize`, optional\n",
      "    The normalization method used to scale scalar data to the [0, 1] range\n",
      "    before mapping to colors using *cmap*. By default, a linear scaling is\n",
      "    used, mapping the lowest value to 0 and the highest to 1.\n",
      "\n",
      "    If given, this can be one of the following:\n",
      "\n",
      "    - An instance of `.Normalize` or one of its subclasses\n",
      "      (see :ref:`colormapnorms`).\n",
      "    - A scale name, i.e. one of \"linear\", \"log\", \"symlog\", \"logit\", etc.  For a\n",
      "      list of available scales, call `matplotlib.scale.get_scale_names()`.\n",
      "      In that case, a suitable `.Normalize` subclass is dynamically generated\n",
      "      and instantiated.\n",
      "\n",
      "    This parameter is ignored if *c* is RGB(A).\n",
      "\n",
      "vmin, vmax : float, optional\n",
      "    When using scalar data and no explicit *norm*, *vmin* and *vmax* define\n",
      "    the data range that the colormap covers. By default, the colormap covers\n",
      "    the complete value range of the supplied data. It is an error to use\n",
      "    *vmin*/*vmax* when a *norm* instance is given (but using a `str` *norm*\n",
      "    name together with *vmin*/*vmax* is acceptable).\n",
      "\n",
      "    This parameter is ignored if *c* is RGB(A).\n",
      "\n",
      "alpha : float, default: None\n",
      "    The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
      "\n",
      "linewidths : float or array-like, default: :rc:`lines.linewidth`\n",
      "    The linewidth of the marker edges. Note: The default *edgecolors*\n",
      "    is 'face'. You may want to change this as well.\n",
      "\n",
      "edgecolors : {'face', 'none', *None*} or :mpltype:`color` or list of :mpltype:`color`, default: :rc:`scatter.edgecolors`\n",
      "    The edge color of the marker. Possible values:\n",
      "\n",
      "    - 'face': The edge color will always be the same as the face color.\n",
      "    - 'none': No patch boundary will be drawn.\n",
      "    - A color or sequence of colors.\n",
      "\n",
      "    For non-filled markers, *edgecolors* is ignored. Instead, the color\n",
      "    is determined like with 'face', i.e. from *c*, *colors*, or\n",
      "    *facecolors*.\n",
      "\n",
      "colorizer : `~matplotlib.colorizer.Colorizer` or None, default: None\n",
      "    The Colorizer object used to map color to data. If None, a Colorizer\n",
      "    object is created from a *norm* and *cmap*.\n",
      "\n",
      "    This parameter is ignored if *c* is RGB(A).\n",
      "\n",
      "plotnonfinite : bool, default: False\n",
      "    Whether to plot points with nonfinite *c* (i.e. ``inf``, ``-inf``\n",
      "    or ``nan``). If ``True`` the points are drawn with the *bad*\n",
      "    colormap color (see `.Colormap.set_bad`).\n",
      "\n",
      "Returns\n",
      "-------\n",
      "`~matplotlib.collections.PathCollection`\n",
      "\n",
      "Other Parameters\n",
      "----------------\n",
      "data : indexable object, optional\n",
      "    If given, the following parameters also accept a string ``s``, which is\n",
      "    interpreted as ``data[s]`` if ``s`` is a key in ``data``:\n",
      "\n",
      "    *x*, *y*, *s*, *linewidths*, *edgecolors*, *c*, *facecolor*, *facecolors*, *color*\n",
      "**kwargs : `~matplotlib.collections.PathCollection` properties\n",
      "    Properties:\n",
      "    agg_filter: a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array and two offsets from the bottom left corner of the image\n",
      "    alpha: array-like or float or None\n",
      "    animated: bool\n",
      "    antialiased or aa or antialiaseds: bool or list of bools\n",
      "    array: array-like or None\n",
      "    capstyle: `.CapStyle` or {'butt', 'projecting', 'round'}\n",
      "    clim: (vmin: float, vmax: float)\n",
      "    clip_box: `~matplotlib.transforms.BboxBase` or None\n",
      "    clip_on: bool\n",
      "    clip_path: Patch or (Path, Transform) or None\n",
      "    cmap: `.Colormap` or str or None\n",
      "    color: :mpltype:`color` or list of RGBA tuples\n",
      "    edgecolor or ec or edgecolors: :mpltype:`color` or list of :mpltype:`color` or 'face'\n",
      "    facecolor or facecolors or fc: :mpltype:`color` or list of :mpltype:`color`\n",
      "    figure: `~matplotlib.figure.Figure` or `~matplotlib.figure.SubFigure`\n",
      "    gid: str\n",
      "    hatch: {'/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*'}\n",
      "    hatch_linewidth: unknown\n",
      "    in_layout: bool\n",
      "    joinstyle: `.JoinStyle` or {'miter', 'round', 'bevel'}\n",
      "    label: object\n",
      "    linestyle or dashes or linestyles or ls: str or tuple or list thereof\n",
      "    linewidth or linewidths or lw: float or list of floats\n",
      "    mouseover: bool\n",
      "    norm: `.Normalize` or str or None\n",
      "    offset_transform or transOffset: `.Transform`\n",
      "    offsets: (N, 2) or (2,) array-like\n",
      "    path_effects: list of `.AbstractPathEffect`\n",
      "    paths: unknown\n",
      "    picker: None or bool or float or callable\n",
      "    pickradius: float\n",
      "    rasterized: bool\n",
      "    sizes: `numpy.ndarray` or None\n",
      "    sketch_params: (scale: float, length: float, randomness: float)\n",
      "    snap: bool or None\n",
      "    transform: `~matplotlib.transforms.Transform`\n",
      "    url: str\n",
      "    urls: list of str or None\n",
      "    visible: bool\n",
      "    zorder: float\n",
      "\n",
      "See Also\n",
      "--------\n",
      "plot : To plot scatter plots when markers are identical in size and\n",
      "    color.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      ".. note::\n",
      "\n",
      "    This is the :ref:`pyplot wrapper <pyplot_interface>` for `.axes.Axes.scatter`.\n",
      "\n",
      "* The `.plot` function will be faster for scatterplots where markers\n",
      "  don't vary in size or color.\n",
      "\n",
      "* Any or all of *x*, *y*, *s*, and *c* may be masked arrays, in which\n",
      "  case all masks will be combined and only unmasked points will be\n",
      "  plotted.\n",
      "\n",
      "* Fundamentally, scatter works with 1D arrays; *x*, *y*, *s*, and *c*\n",
      "  may be input as N-D arrays, but within scatter they will be\n",
      "  flattened. The exception is *c*, which will be flattened only if its\n",
      "  size matches the size of *x* and *y*.\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "@_copy_docstring_and_deprecators(Axes.scatter)\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m scatter(\n",
      "    x: float | ArrayLike,\n",
      "    y: float | ArrayLike,\n",
      "    s: float | ArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    c: ArrayLike | Sequence[ColorType] | ColorType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    marker: MarkerType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    cmap: str | Colormap | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    norm: str | Normalize | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    vmin: float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    vmax: float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    alpha: float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    linewidths: float | Sequence[float] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    *,\n",
      "    edgecolors: Literal[\u001b[33m\"face\"\u001b[39m, \u001b[33m\"none\"\u001b[39m] | ColorType | Sequence[ColorType] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    colorizer: Colorizer | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    plotnonfinite: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    data=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **kwargs,\n",
      ") -> PathCollection:\n",
      "    __ret = gca().scatter(\n",
      "        x,\n",
      "        y,\n",
      "        s=s,\n",
      "        c=c,\n",
      "        marker=marker,\n",
      "        cmap=cmap,\n",
      "        norm=norm,\n",
      "        vmin=vmin,\n",
      "        vmax=vmax,\n",
      "        alpha=alpha,\n",
      "        linewidths=linewidths,\n",
      "        edgecolors=edgecolors,\n",
      "        colorizer=colorizer,\n",
      "        plotnonfinite=plotnonfinite,\n",
      "        **({\u001b[33m\"data\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n",
      "        **kwargs,\n",
      "    )\n",
      "    sci(__ret)\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "\u001b[31mFile:\u001b[39m      /opt/homebrew/anaconda3/envs/test_env/lib/python3.12/site-packages/matplotlib/pyplot.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "??plt.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "43917d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "points = [\n",
    "[6622,71126],\n",
    "[6622,70096],\n",
    "[5936,70096],\n",
    "[5936,68996],\n",
    "[5389,68996],\n",
    "[5389,67683],\n",
    "[5367,67683],\n",
    "[5367,66513],\n",
    "[5025,66513],\n",
    "[5025,65515],\n",
    "[4188,65515],\n",
    "[4188,64224],\n",
    "[4215,64224],\n",
    "[4215,63167],\n",
    "[3489,63167],\n",
    "[3489,61910],\n",
    "[3462,61910],\n",
    "[3462,60708],\n",
    "[3257,60708],\n",
    "[3257,59625],\n",
    "[2484,59625],\n",
    "[2484,58265],\n",
    "[3125,58265],\n",
    "[3125,57194],\n",
    "[2142,57194],\n",
    "[2142,55886],\n",
    "[2721,55886],\n",
    "[2721,54690],\n",
    "[2552,54690],\n",
    "[2552,53529],\n",
    "[1870,53529],\n",
    "[1870,52300],\n",
    "[1984,52300],\n",
    "[1984,51075],\n",
    "[2287,51075],\n",
    "[2287,50126]]#,\n",
    "#[94997,50126]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "055fb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [[88691,21754],\n",
    "[88691,22539],\n",
    "[89690,22539],\n",
    "[89690,23885],\n",
    "[89867,23885],\n",
    "[89867,24583],\n",
    "[91032,24583],\n",
    "[91032,25801],\n",
    "[91371,25801],\n",
    "[91371,27020],\n",
    "[91675,27020],\n",
    "[91675,27977],\n",
    "[92449,27977],\n",
    "[92449,29020],\n",
    "[93074,29020],\n",
    "[93074,30116],\n",
    "[93597,30116],\n",
    "[93597,31248],\n",
    "[94036,31248],\n",
    "[94036,32343],\n",
    "[94564,32343],\n",
    "[94564,33526],\n",
    "[94865,33526],\n",
    "[94865,34739],\n",
    "[95057,34739],\n",
    "[95057,35811]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9e0e7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [\n",
    "[97156,56140],\n",
    "[97156,57477],\n",
    "[97912,57477],\n",
    "[97912,58631],\n",
    "[97393,58631],\n",
    "[97393,59810],\n",
    "[97068,59810],\n",
    "[97068,60999],\n",
    "[96805,60999],\n",
    "[96805,62191],\n",
    "[96547,62191],\n",
    "[96547,63241],\n",
    "[95790,63241],\n",
    "[95790,64439],\n",
    "[95574,64439],\n",
    "[95574,65656],\n",
    "[95388,65656],\n",
    "[95388,66774],\n",
    "[94904,66774],\n",
    "[94904,67836],\n",
    "[94290,67836],\n",
    "[94290,69244],\n",
    "[94501,69244],\n",
    "[94501,70268],\n",
    "[93788,70268],\n",
    "[93788,71148],\n",
    "[92809,71148],\n",
    "[92809,72346],\n",
    "[92489,72346],\n",
    "[92489,73328],\n",
    "[91753,73328],\n",
    "[91753,74320],\n",
    "[91051,74320],\n",
    "[91051,75306],\n",
    "[90348,75306],\n",
    "[90348,76613],\n",
    "[90136,76613],\n",
    "[90136,77644],\n",
    "[89480,77644],\n",
    "[89480,78337]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "440e3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnNum(x)->int:\n",
    "    return \"asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f30db40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdf'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnNum(\"asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "[5367, 67683], [94997, 50126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8bd946af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot([point[0] for point in points[:]],[point[1] for point in points[:]],marker='o',linestyle='-',color='green',markerfacecolor='red')\n",
    "plt.plot([94997,94997],[66513,50126],marker='o',linestyle='-',color='green',markerfacecolor='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "7631,73361\n",
    "7631,71962\n",
    "7666,71962\n",
    "7666,71126\n",
    "6622,71126\n",
    "6622,70096\n",
    "5936,70096\n",
    "5936,68996\n",
    "5389,68996\n",
    "5389,67683\n",
    "5367,67683\n",
    "5367,66513\n",
    "5025,66513\n",
    "5025,65515\n",
    "4188,65515\n",
    "4188,64224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7130d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAP4RJREFUeJzt3Qt4VNW58PF3AiSA4SYQCCSQIIZbIgJWLkIqRwoS24IYL6A93q2IlYJFGtojnJ6niUehQq1ilVbopwbBQ1ERoQjEoEQRIkIAESQpSUhI5Zoot5D9Pe+ie5iRYBIyyWT2/H/PM+7svdfsywKzX9Ze71ouy7IsAQAAcJgQf18AAABAXSDIAQAAjkSQAwAAHIkgBwAAOBJBDgAAcCSCHAAA4EgEOQAAwJEIcgAAgCM1liBWUVEhBw4ckBYtWojL5fL35QAAgGrQcYxLS0ulU6dOEhJy8faaoA5yNMCJjo7292UAAIBLkJ+fL1FRURfdH9RBjrbg2JXUsmVLf18OAACohuPHj5tGCvs5fjFBHeTYr6g0wCHIAQAgsFTV1YSOxwAAwJEIcgAAgCMR5AAAAEciyAEAAI5EkAMAAByJIAcAADgSQQ4AAHAkghwAAOBIQT0YIAAA8L2zFWdlw/4NUlRaJJEtImVYl2HSKKSR1DeCHAAA4DPLdi2Tx1dOlryyAve2mPAomZM0T8b1Gif1iddVAADAZwFO8pJkScgukKwFIqWpYpYJ2YVmu+6vTy5L5ysP4gm+WrVqJceOHWPuKgAAavmKqvuzMSbAWZ4uEuIRXVS4RMaOd0lO/yjZMyW31q+uqvv8piUHAADUmvbB0VdUMzK9Axyl6ymZluSW5Zty9YUgBwAA1Jp2MlbxJZXvt7fb5eoDQQ4AAKg1zaJSORGV77e32+XqA0EOAACoNU0T1yyq1ESX6YPjSdfTEl0SGx5tytUXghwAAFBr2plY08RXxJ3rZJwVJVIaKmap67p9dtLceh0vh3FyAACAT+g4OG/e9qZMffcxGRJX6N4eGx4lbybNrfdxcghyAACAz2ggMyJ2hLT631ZmfeWElTLyipF+GfGY11UAAMCnPAOaxK6JfglwFEEOAABwJIIcAADgSAQ5AADAkQhyAACAIxHkAAAARyLIAQDAx7NxZ+RlSPr2dLPU9WBz1uOeM/+Z6bc6YJwcAAB8ZNmuZfL4yslmNm6bTnWgIwHX90B4/qwDHQzQlvR6kt/qoEYtOTExMeJyuS74TJo0yew/efKk+blt27YSHh4ut9xyixw8eNDrGPv375ebbrpJmjdvLhERETJt2jQpLy/3KpORkSH9+/eXsLAw6d69uyxcuPCCa3n++efN9TRt2lQGDhwomzZturQaAADARw/35CXJkpBdIFkLREpTxSwTsgvNdt0fLHVw1WeFDaMOrBooKSmxioqK3J81a9ZYeoj169eb/Q8//LAVHR1trV271tq8ebM1aNAga8iQIe7vl5eXW/Hx8daIESOszz77zFq5cqXVrl07KyUlxV1m3759VvPmza2pU6daO3futJ577jmrUaNG1qpVq9xlFi9ebIWGhlp//etfrR07dlgPPvig1bp1a+vgwYM1uR3r2LFj5vp1CQDApSo/W27FzI6yfjJBrLMusSw5/9H1n0xwWbGzo005pyqvxzqo7vO7RkHOd02ePNm64oorrIqKCuvo0aNWkyZNrKVLl7r379q1y1xEVlaWWdegJiQkxCouLnaXmT9/vtWyZUvr1KlTZv2JJ56w+vTp43We22+/3Ro1apR7/dprr7UmTZrkXj979qzVqVMnKy0trUbXT5ADAPCF9bnrLZklVlaU98Pd/myMErNfyznV+nqsg+o+vy+54/Hp06fl1Vdflfvuu8+8stqyZYucOXNGRowY4S7Ts2dP6dKli2RlZZl1XSYkJEiHDh3cZUaNGiXHjx+XHTt2uMt4HsMuYx9Dz6vn8iwTEhJi1u0yF3Pq1ClzLs8PAAC1VVRaZJbxJZXvt7fb5ZyoqAHWwSUHOcuXL5ejR4/KPffcY9aLi4slNDRUWrdu7VVOAxrdZ5fxDHDs/fa+7yujAcmJEyfk66+/lrNnz1Zaxj7GxaSlpUmrVq3cn+jo6Eu9fQAA3CJbRJplTkTl++3tdjknimyAdXDJQc5f/vIXGT16tHTq1EkCRUpKihw7dsz9yc/P9/clAQAcYFiXYSaDKDXRJRUu7326npboktjwaFPOqYY1wDq4pCDnn//8p7z//vvywAMPuLd17NjRvErS1h1Pml2l++wy3822sterKtOyZUtp1qyZtGvXTho1alRpGfsYF6PZWnoczw8AALWls2xrivSKOJGx412SFSVSGipmqeu6fXbSXL/Nxh2sdXBJQc4rr7xi0r81Fdw2YMAAadKkiaxdu9a9bffu3SZlfPDgwWZdl9u3b5eSkvMv7NasWWOCjd69e7vLeB7DLmMfQ1+J6bk8y1RUVJh1uwwAAPVNx4B587Y35fOrI2XIAyItZ4hZ5vSPMtuDYZyccf+ug+39OzeMOqhpj2bNZOrSpYs1ffr0C/ZpCrnuW7dunUkhHzx4sPl8N4V85MiR1tatW01aePv27StNIZ82bZrJznr++ecrTSEPCwuzFi5caNLMH3roIZNC7pm1VR1kVwEAfK3oeJHJIrIziZycNn4xes96769ve71O6qDOUshXr15tDrx79+4L9p04ccJ65JFHrDZt2phA5eabbzbj6XjKy8uzRo8ebTVr1syMkfP4449bZ86c8Sqj4+5cffXVZiycbt26Wa+88soF59LxczSg0jKaUv7xxx/X9FYIcgAAPldSVuIOclA3qvv8dul/JEhpxpZmWWknZPrnAAB84V/f/EsiZp9LJbJmBu0jtkE8v5mgEwAAOBJBDgAAcCSCHAAA4EgEOQAAwJEIcgAAgCMR5AAA/OpsxVnJyMuQ9O3pZqnrgczz+p1wP4Gssb8vAAAQvJbtWiaPr5wseWUF7m06/5FODxCIIwTr/UxZ8Qv3+vBFwwP6fgIdLTkAAL8FBMlLkiUhu0CyFoiUpopZJmQXmu26PxDvp+/WA464HydgMEAGAwSAeqevcLo/G2MCnOXpIiGW94zVY8aLZPVpJY9dN1VCXA3/3+MVVoXM+2iODNlxXN6q5H50gkqdv2nPlFxHT9LZ0J7fvK4CANS7Dfs3mFdU6ZneAYHS9RmZIkPijsnMjJkSSH5zkftJybRkSFy+ue/rY6731+UFHYIcAEC9KyotMsv4ksr329v/I+Y/pPvl3aWh23t4r6zLW1fl/dj3jfpBkAMAqHeRLSLNMidCZND5Psduul391w//KyBaPjSLSoOcqu7Hvm/Uj4b/ohMA4DjDugwzWUepiS7TZ8WTrqcluiQ2PNqUCwROux+nIMgBANQ77XyradUr4s51ys2KEikNFbPUdd0+O2luwHTSddr9OAXZVWRXAUCDGidHWzw0IAjEcWWcdj+B/vwmyCHIAQC/p5M3+Z8mYoklb976poztOTagWzz0fjSLSjsZax8cfUUVyPfTEJFCDgAICBoAuFwu0X9zD4keEvABgV5/IHSWDgb0yQEAAI5EkAMAAByJIAcAADgSQQ4AAHAkghwAAOBIBDkAAMCRCHIAAIAjEeQAAABHIsgBAACORJADAPD7NAj2DEMb8zeadcAXCHIAAH6d0LL7szFm3iqVvDTZrOt2oLYIcgAAfqGBTPKSZEnILpCsBSKlqWKWCdmFZjuBDmqLWciZhRwA6p2+ktIWGw1wlqeLhHg8iSpcImPHuySnf5TsmZIb8BN2wn/Pb1pyAAD1bsP+DZJXViAzMr0DHKXrKZmW5Jblm3LApSLIAQDUu6LSIrOML6l8v73dLgdcCoIcAEC9i2wRaZY5EZXvt7fb5YBLQZADAKh3w7oMk5jwKElNdJk+OJ50PS3RJbHh0aYccKkIcgAA9U47E89Jmicr4kTGjBfJihIpDT231E7Hun120lw6HaNWGtfu6wAAXJpxvcbJm7e9KQ8su1uGxJW5t8eGR8mbSXPNfqA2aMkBAPiNBjI3xN1ofr4r4S5Zf/d6kzZOgANfoCUHAOBXB0oPmOWYnmPk+pjr/X05cBBacgAAfpV/LN8so1pG+ftS4DAEOQAAv458bLfkRLeM9vflwGEIcgAAflNcVixnrbPSyNVIOoZ39PflwGEIcgAAflNwvMAsO7XoRLo4fI4gBwDgN/nH6Y+DukOQAwDwe0tOdCv648D3SCEHgCDu9KuzfOskmDpHlE6hUJ+vjPT8G/dvND9bFZZZ55UVfMllWdZ3JrkPHsePH5dWrVrJsWPHpGXLlv6+HACoN8t2LZPHV06WvLJzLSlK55LSqRbqYyA+f58fwfH85nUVAAQZDTCSlyRLQnaBZC0QKU0Vs0zILjTbdb+Tz4/gQUsOLTkAgoi+Eur+bIwJMJani4RY3rN/6+SYOf2jzNQKdfHqyN/nR3A9v+mTAwBBRPvg6Cui9EzvAEPpekqmJUPi8qXfn/tJ66atfX7+oyePVuv8ep1M8YDaIsgBgCCinYxVfEnl++3t20u21+l1VHV++zqB2iDIAYAgollUKidCZND5Pr9uul3N+uEs6RPRx+fn31GyQ2Z9MKvK89vXCdQGfXLokwMgiJzvE1Moy9MtP/bJ8c/54QxkVwEALqCBg6Zpr4gTGTNeJCtKpDT03FIDDN0+O2lunQUYnufX89X3+RFcaMmhJQdAENI07QeW3SNHykvd22LDo02A4a9xcurz/AiO5zdBDkEOgCA1fc10eXrj03LjFTfK9KHT/TLisT9HXEbgIoUcAPC9Qlzneiz0bNfTL+naGtCQJo66RJ8cAADgSAQ5AADAkQhyAACAIxHkAAAARyLIARCwNDsnIy9D0renm6Wuo/oqrAqz/OLrL6g/OBLZVQACUmXjrMSER5mB5hhnpXr19/Km+ebnVV+tMh/qD05DSw6AgHxAJy9JloTsAslaIFKaKmapUwXodt2Pquvvuh2l1B8cjcEAGQwQCCjn5z4qkOXpwtxHNUT9wQkYDBCAI+kIufqKKj3T+wGtdD0l05IhcfnS54U+0jKMf7x81/FTx6tVf1rPDNSHQEeQAyCg6BQAKr6k8v329t2HdtfjVQWequrPrmcgkBHkAAgoOseRyokQGXS+z7Gbblep/5EqCR0S6vnqGr7tB7fLjHUzqqw/u56BQEafHPrkAAHap6RQlqdb9CmpIeoPwfT8JrsKQEDRB6+mOa+IO/dAzooSKQ0Vs9R13T47aS4P6Iug/hBMahzkFBYWyl133SVt27aVZs2aSUJCgmzevNm9/5577hGXy+X1ufHGG72OcfjwYbnzzjtN9NW6dWu5//77payszKvMtm3bZNiwYdK0aVOJjo6Wp59++oJrWbp0qfTs2dOU0etYuXJlTW8HQADScVzevO1N2d6/swx5QKTlDDFLbYHQ7Yzz8v2oPwSLGvXJOXLkiFx33XUyfPhwee+996R9+/ayZ88eadOmjVc5DWpeeeUV93pYWJjXfg1wioqKZM2aNXLmzBm599575aGHHpLXX3/d3Qw1cuRIGTFihLz44ouyfft2ue+++0xApOXUxo0bZfz48ZKWliY//vGPzXfHjh0r2dnZEh8fX5s6ARAA9EE8pscYCU8Ll5PlJ+XVm1+VO+LvoAWihvWnWVTayVj74AzrMoz6Q/D2yfn1r38tH330kWzYsOGiZbQl5+jRo7J8+fJK9+/atUt69+4tn376qVxzzTVm26pVqyQpKUkKCgqkU6dOMn/+fPnNb34jxcXFEhoa6j63HvOLL74w67fffrt88803smLFCvexBw0aJFdffbUJjKqDPjlA4GuR1kLKTpfJ3l/slSsuv8LflwMgUPvkvP322yYwufXWWyUiIkL69esnL7/88gXlMjIyzP4ePXrIxIkT5dChQ+59WVlZpkXGDnCUttiEhITIJ5984i6TmJjoDnDUqFGjZPfu3aY1yS6j3/OkZXT7xZw6dcpUjOcHAAA4U42CnH379plWliuvvFJWr15tApjHHntMFi1a5PWq6m9/+5usXbtW/vd//1c++OADGT16tJw9e27iN22d0QDIU+PGjeXyyy83++wyHTp08Cpjr1dVxt5fGX21pZGf/dG+PgAAwJlq1CenoqLCtMCkpqaadW3JycnJMa+H7r77brPtjjvucJfXzsBXXXWVXHHFFaZ154YbbhB/SklJkalTp7rXtSWHQAcAAGeqUUtOZGSk6U/jqVevXrJ///6Lfqdbt27Srl072bt3r1nv2LGjlJR4D7VZXl5uMq50n13m4MGDXmXs9arK2Psrox2g9d2d5wcAADhTjYIczazSfjGevvzyS+natetFv6OdibVPjgZIavDgwaZj8pYtW9xl1q1bZ1qJBg4c6C6TmZlpMq9smomlfXzsTC4to6/EPGkZ3Q4AAFCjIGfKlCny8ccfm9dV2jKjadsvvfSSTJo0yezXsW6mTZtmyuTl5ZkgZMyYMdK9e3fTKdhu+dF+Ow8++KBs2rTJZGs9+uij5jWXZlapCRMmmE7HOn7Ojh075I033pB58+Z5vWqaPHmyycqaM2eOybiaNWuWGa9HjwUAACBWDb3zzjtWfHy8FRYWZvXs2dN66aWX3Pu+/fZba+TIkVb79u2tJk2aWF27drUefPBBq7i42OsYhw4dssaPH2+Fh4dbLVu2tO69916rtLTUq8znn39uDR061Jync+fO1lNPPXXBtSxZssSKi4uzQkNDrT59+ljvvvtuje7l2LFjmj5vlgACU3hquCWzxNp7aK+/LwVAPanu85u5qxgnBwhojJMDBJ/jzF0FAACCWY1SyAGgoc2oXV5Rbn7emL9R8o7mSck3JUxRAMAgyAEQkJbtWiaPr5xs5q1S9/3ff0q5R0wTEx5lZttmskkgePG6CkBABjjJS5IlIbtA0t7XSfhERu8VyVogUpp6bpmQXWjKaFkAwYmOx3Q8BgLuFVX3Z2NMgPN/i0XifiGSUCKyfLFIiMdvswqXyNjxLsnpHyV7puTy6gpwEDoeA3CkDfs3SF5ZgczIFPmoi0heG5EZG7wDHKXrKZmW5Jblm+8ACD4EOQACSlFpkVnGl4gUhYv758rY2+3vAAguBDkAAopmTqmcCJHIMnH/XBl7u/0dAMGFIAdAQNHUcM2cSk10yXX7RWKOiKQOO9cHx5OupyW6JDY82nwHQPAhyAEQULQDsaaGr4gTueUOlzy0RczPY+4QyYoSKQ09t9ROx7p9dtJcOh0DQYrsKrKrgIAeJ0c7IavGZ8VrnBxtwdEAh3FygOB9fhPkEOQAAZ1OrplT2rF484HN8oeP/yD9OvaTP4z6AyMeAw5W3ec3Ix4DCFgaxFwfc735+dsz35pl55ad3dsABDf65AAAAEciyAEAAI5EkAMAAByJIAcAADgSQQ4AAHAkghwgQFOnM/IyJH17ulnqerCrsCrMsvB4IXUCwCCFHAjwQfCUTnOgowAH68B3Wie/+cd08/NnxZ/J8EXDg75OANCSAwTcwzx5SbIkZBdI1gKR0lQxy4TsQrNd9wdrnQzMOUKdAPDCiMeMeIwAoa9fuj8bYwKc5ekiIZb3ZJRjxot81jdC3rhjWdCM9Kt1clv6OBmwraTSOtH5q3L6R8meKblBUydAMDjOiMeAs+j0BfqKKj3T+2GudH1GpsiQuBIZ+spQCTb/d5E6Scm0ZEhcvqk7RkEGgg9BDhAgdH4mFV9S+X57e8RlERIeGi7BoOx0mZR8U1Jlndh1ByC4EOQAASKyRaRZ5kSIDDrf59hNt6s3kt8ImlYLzaLSTsZV1YlddwCCCx2PgQChs2prxlBqosv0N/Gk62mJLokNjzblggV1AuD7EOQAAUI7zmpK9Iq4c52Ms6JESkPPLbWDrW6fnTQ3qDrYetaJ1gF1AsAT2VVkVyHAaEr0pLd/LsUnv3Zv09YKfZgH65gwlY0dFOx1AjhZdZ/fBDkEOQhA7+15T5JeT5KurbrKwrELzeuYYG+t0HRyzaLSTsbaB4c6AZyLFHLAweyHd5tmbYKmk3F16oS6AOCJPjkAAMCRCHIAAIAjEeQAAABHIsgBAACORJADAAAciSAHAAA4EkEOAABwJIIcAADgSAwGCATgiL77j+03246cOGJm4mZ0XwC4EEEOEKBzMzU+K/LPY/+U4YuGm5m4daJK5mkCgPN4XQUEQICTvCRZErILJGuBSGmqmOWNe3XyOZG090USsgtNGS0LADiHCTqZoBMN/BVV92djTICzPF0kxOP/1gqXyNg7RHIiRHY/J3LLHS7J6R8le6bk8uoKgKNV9/lNSw7QgGkfHH1FNSPTO8BRup6yQSS3jchHXURSMi3JLcs33wEAEOQADZp2MlbxJZXvt7cXhXv8/O/vAECwI8gBGrDIFpFmqa+kKmNvjyzz+Pnf3wGAYEeQAzRgmhqumVOpiS7TB8eTrqcNE4k9InLdfpG0RJfEhkeb7wAACHKABk07EGtq+Io4kbHjXZIVJVIaKmY55g4x2x/ccq7Tsf48O2kunY4B4N/IriK7CgE8Tk75v+MZbcHRAIdxcgAEg+PVfH4T5BDkIIDSybvN6yb7j++XOT+aI3079pWSb0pMHxxGPAYQTI5X8/nNiMdAgNAg5rLQy8zPAzoNkB/G/NDflwQADRp9cgAAgCMR5AAAAEciyAEAAI5EkAMAAByJIAcAADgSQQ4AAHAkghwAAOBIBDlAHQ/gl5GXIenb081S12tzrG9Of2N+/qz4s1odCwCCAUEOUIdTMXR/NkaGLxouE5ZNMEtd1+2Xeiwd7VhNWT3lko8FAMGCIAeoAxp8JC9JloTsAslaIFKaKmaZkF1ottckOPHlsQAgmDB3FXNXwcf0NZK2smhQsjxdJMTj/7AK17nZxHP6R8meKblVzjfly2MBgFMwdxXgJxv2bzCzhadnegclStdTMi0ZEpcvnf/QWZo2bvq9xzpZflIOfnOwymPpOa+Pub4O7gYAAhdBDuBjRaVFZhlfUvl+e7sGL9VV1bHscwIAziPIAXwsskWkWeZEiAwquHC/blfzk+ab2cS/z5YDW2TiyolVHss+JwDgPPrk0CcHPna+H02hLE+3fNQnp/bHAoBge36TXQX4mAYbc5LmyYo4kTHjRbKiREpDzy01KNHts5PmViso8TyWfrc2xwKAYENLDi05qCOa2j3prZ9L8amv3dtiw6NNUDKu17gaH+vxlZNNh+baHgsAguX5TZBDkIM69M7ud+Sni38qsa1j5a9j/irDugy75FYXfXWlWVTayVj74NTmWAAQyEghBxoAOwhp27xtrVO89VikiQNA9dW4T05hYaHcdddd0rZtW2nWrJkkJCTI5s2b3fu1YejJJ5+UyMhIs3/EiBGyZ88er2McPnxY7rzzThN9tW7dWu6//34pKyvzKrNt2zYZNmyYNG3aVKKjo+Xpp5++4FqWLl0qPXv2NGX0OlauXFnT2wEAAA5VoyDnyJEjct1110mTJk3kvffek507d8qcOXOkTZs27jIajPzxj3+UF198UT755BO57LLLZNSoUXLy5El3GQ1wduzYIWvWrJEVK1ZIZmamPPTQQ17NUCNHjpSuXbvKli1b5JlnnpFZs2bJSy+95C6zceNGGT9+vAmQPvvsMxk7dqz55OTk1L5WAABA4LNqYPr06dbQoUMvur+iosLq2LGj9cwzz7i3HT161AoLC7PS09PN+s6dO7UPkPXpp5+6y7z33nuWy+WyCgsLzfoLL7xgtWnTxjp16pTXuXv06OFev+2226ybbrrJ6/wDBw60fv7zn1f7fo4dO2auRZdAXXj3y3ctmSXWNS9d4+9LAQDHqO7zu0YtOW+//bZcc801cuutt0pERIT069dPXn75Zff+3NxcKS4uNq+obNoxaODAgZKVlWXWdamvqPQ4Ni0fEhJiWn7sMomJiRIaGuouo61Bu3fvNq1JdhnP89hl7PNU5tSpU6aVyPMDAACcqUZBzr59+2T+/Ply5ZVXyurVq2XixIny2GOPyaJFi8x+DXBUhw4dvL6n6/Y+XWqA5Klx48Zy+eWXe5Wp7Bie57hYGXt/ZdLS0kzQZX+0rw8AAHCmGgU5FRUV0r9/f0lNTTWtONqP5sEHHzT9bwJBSkqKSTezP/n5+f6+pICl6cwZeRmSvj3dLHUdF7Lr5dC3h6gnAGjIQY5mTPXu3dtrW69evWT//v3m544dO5rlwYPeEw/qur1PlyUl3rMNlpeXm4wrzzKVHcPzHBcrY++vTFhYmMno8vyg5nRgOp1qYPii4TJh2QSz1HXdjvO0Ph76+33m59yjudQTADTkIEczq7RfjKcvv/zSZEGp2NhYE2SsXbvWvV/7vWhfm8GDB5t1XR49etRkTdnWrVtnWom0745dRjOuzpw54y6jmVg9evRwZ3JpGc/z2GXs86Bu6AM6eUmyJGQXSNYCkdJUMUudW0m38wD3rqdrtn9NPQGAv9SkN/OmTZusxo0bW7///e+tPXv2WK+99prVvHlz69VXX3WXeeqpp6zWrVtbb731lrVt2zZrzJgxVmxsrHXixAl3mRtvvNHq16+f9cknn1gffvihdeWVV1rjx4/3ysjq0KGD9bOf/czKycmxFi9ebM7z5z//2V3mo48+Mtcye/Zsa9euXdbMmTOtJk2aWNu3b6/2/ZBdVTPlZ8utmNlR1k8miHXWJTpUtvuj6z+Z4LJiZ0ebcsGMegKAulXd53eNp3XQcW20b4sO8KctN1OnTjX9cjyCJpk5c6YZ00ZbbIYOHSovvPCCxMXFucvoq6lHH31U3nnnHZNVdcstt5ixdcLDw70GA5w0aZJ8+umn0q5dO/nFL34h06dPv2AwwN/+9reSl5dnOkPrGD1JSUnVvhemdagZ7VOir1y0RWLQ+SmU3HTSyCEPiNzW+zaJbhW8nbrzj+XLkp1Lqqyn9XevZwRjALgEzF1VDQQ5NaOdjLUPjr56CT994X6dHbvlDH9cWcNUVT29Pu51GZ8w3h+XBgABjbmr4HM6KaTKiai8hUK3qzv63CFdWnWRYLX/2H5ZvGNxlfVk1ycAoG4Q5KDadNbrmPAoSU0slOXploR4tAFWuETSEl0SGx4lr457Nahnx9Y08Y//+WGV9aT1CQBoQBN0Inhp4DInaZ6siBMZO95l+pboqxdd6rpun500N6gDHEU9AUDDQJ8c+uTUmKY/P75ysuSVnX8XExsebR7c43qN8+u1NSTUEwDUDToeVwNBTu1eydz42o3y/r73ZeI1E+W50c/RMnGRetqwf4MUlRaZPjj6iop6AoDaoeMx6pQ+qDuGnxtduvvl3XlwX4TWC2niAOAf9MkBAACORJADAAAciSAHAAA4EkEOAABwJIIcAADgSAQ5AADAkQhyAACAIxHkAAAARyLIAQAAjkSQAwAAHIlpHXDJczIVlxWbn/ce3mvWnT61A/NQAUBgYYJOJuj0yezaMeFRMidpnmNn1w7GewaAQH9+87oKNX7YJy9JloTsAslaIFKaKmaZkF1otut+pwnGewYAJ6Alh5acGr2u6f5sjHnYL08XCfH4m1PhEhk73iU5/aNkz5Rcx7zGCcZ7BgCnPL/pk4Nq0/4o+romPdP7Ya90PSXTkiFx+dLnhT7SMswZQePxU8erdc9aN9fHXO+vywQAVIIgB9WmHW5VfEnl++3tuw/tFqep6p7tugEANBwEOag2zShSOREig873v3XT7Sr1P1IloUOCOMH2g9tlxroZVd6zXTcAgIaDPjn0ybmE/imFsjzdCor+KcF4zwDQ0JFdBZ/Th7imTK+IO/dwz4oSKQ0Vs9R13T47aa6jHvbBeM8A4BS05NCS45MxY2LDo83D3qljxgTjPQNAoD+/CXIIci5JMI7+q/fc40895KsjX8kzI56RKYOnOP6eAaAhIoUcdUof7sGWMq33HB4abn7u27EvAQ4ANHD0yQEAAI5EkAMAAByJIAcAADgSQQ4AAHAkghwAAOBIBDkBnM6ckZch6dvTzVLXUbe0jstOl5mfPy/+nDoHgAaOICdAB6bTqQaGLxouE5ZNMEtd1+2o2zrXMXLUtPenUecA0MAR5AQYfagmL0mWhOwCyVogUpoqZqlzK+l2Hrq+R50DQGBixOMAGvH4/GSRBbI8XZgssh5Q5wDQ8DDisQPpNAo6d1J6pvfDVul6SqYlQ+Ly5Uf/70fSIbyDvy7TUQ6WHaxWneufTbCNAA0ADR1BTgDReaJUfEnl++3t6/PW1+NVBYeq6tz+swEANBwEOQFEJ8JUOREig85Phu2m29WjP3hUrmx7ZT1fnTPtObRH/vTpn6qsc/vPBgDQcBDkBBCd6TsmPEpSEwtlebp1Qf+QtESXxIZHydwb59I/xId9clbsWl5lneufDQCgYSG7KoBo4DInaZ6siDvX4TUrSqQ0VMxS13X77CQCHF+izgEgcJFdFUDZVTZNWZ6y4lHZ/+35fiCx4dHmYTuu1zi/XptTaZ0/vnKy6YRso84BoGE/vwlyAjDIUQeOH5DOz3Y2P6+/e715XUJrQt2/utIsKu1krH1wqHMA8A9SyB3Ofri6xEXqcj3WOXUNAIGDPjkAAMCRCHIAAIAjEeQAAABHIsgBAACORJADAAAciSAHAAA4EkEOAABwJIIcAADgSAQ5AADAkQhyAniKAWWJJRl5Ge51J9B70XtK357uuHsDANQfpnUIQPYEnbbhi4ZLTHiUmS070CeLrGwiTKfcGwCgftGSE4BBQPKSZOm7tUiyFoiUpopZJmQXmu26P9DvLSG7wHH3BgCof8xCHkCzkOtrm+7PxpggYHm6SIjHn1yFS2TseJfk9I+SPVNyA252bCffGwDAt5iF3IE27N9gXuOkZ3oHAUrXUzItGRKXL4P+Mkgub3a5BJLDJw5X6960DpgJHABQHQQ5AaSotMgs40sq329v33xgswSqqu7NrgMAAKpCkBNAIltEmmVOhMig8/1y3XS7mjF0hvRq30sCya5/7ZLUD1OrvDe7DgAAqApBTgAZ1mWYyTRKTSyU5enWBf1W0hJdEhseJb8b/ruA7JPz+ta/VXlvWgcAAFQH2VUBRAMXTaVeEXeuI25WlEhpqJilruv22UlzAy7Acfq9AQD8g+yqAMqu+r6xZGLDo00QEOhjyei9TX5nkhScKHbcvQEA6vf5TZATgEGO/XpHM420I672U9HXOE5p5dD+Ob1f6C3NmzSXdye866h7AwDUHinkDqcPfaemUtsBTWijUMfeIwCg7tEnBwAAOBJBDgAAcCSCHAAA4Eg1CnJmzZolLpfL69OzZ0/3/uuvv/6C/Q8//LDXMfbv3y833XSTNG/eXCIiImTatGlSXl7uVSYjI0P69+8vYWFh0r17d1m4cOEF1/L8889LTEyMNG3aVAYOHCibNm2q+d0DAADHqnHH4z59+sj7779//gCNvQ/x4IMPyu9+9zv3ugYztrNnz5oAp2PHjrJx40YpKiqS//zP/5QmTZpIamqqKZObm2vKaHD02muvydq1a+WBBx6QyMhIGTVqlCnzxhtvyNSpU+XFF180Ac7cuXPNvt27d5vACQAAoMavqzSo0SDF/rRr185rvwY1nvs9U7v+8Y9/yM6dO+XVV1+Vq6++WkaPHi3/8z//Y1plTp8+bcpo4BIbGytz5syRXr16yaOPPirJycny7LPPuo/zhz/8wQRT9957r/Tu3dt8R8/717/+tXa1AQAAgjfI2bNnj3Tq1Em6desmd955p3n95ElbXzTwiY+Pl5SUFPn222/d+7KysiQhIUE6dOjg3qYtMJrvvmPHDneZESNGeB1Ty+h2pcHQli1bvMqEhISYdbvMxZw6dcqcy/MDAACcqUavq/TVkPaP6dGjh3nV9N///d8ybNgwycnJkRYtWsiECROka9euJgjatm2bTJ8+3bxCWrZsmfl+cXGxV4Cj7HXd931lNCA5ceKEHDlyxLz2qqzMF1988b3Xn5aWZq4ZDXugQv2+On32tGTkZTAYIACg7oMcfb1ku+qqq0zQo0HNkiVL5P7775eHHnrIvV9bbLQfzQ033CBfffWVXHHFFeJv2rKkfXlsGjhFR0f79ZqcprIpJ3RSUZ2XqjrTMtjTOqhvz3wrwxcNr9H3AQDwSQp569atJS4uTvbu3Vvpfg2ClL1f++gcPHjQq4y9rvu+r4z27WnWrJl5FdaoUaNKy9jHuBjN1tLjeH7gOxqgJC9JloTsAslaIFKaKmaZkF1otuv+6ny/3+fFl/R9AAB8FuSUlZWZVhptsanM1q1bzdLeP3jwYNm+fbuUlJS4y6xZs8YEG9qB2C6jGVWetIxuV6GhoTJgwACvMhUVFWbdLoP6p6+YtAXnx19asjxdZFCBSPjpc8vl6Zb8+EuRX638pftVlK+/DwBArV5X/epXv5Kf/OQn5hXVgQMHZObMmaZVZfz48SbYef311yUpKUnatm1r+uRMmTJFEhMTzastNXLkSBPM/OxnP5Onn37a9L/57W9/K5MmTTKtLEpTx//0pz/JE088Iffdd5+sW7fOvA5799133dehr5zuvvtuueaaa+Taa681KeTffPONybaCf2gfHH1FlZ4pEvKdKV91PSXTkiFx+TLujXHSuWXnC75feLywWt/X8zCfFQDA50FOQUGBCWgOHTok7du3l6FDh8rHH39sfj558qQZP8cOOLSvyy233GKCGJsGRCtWrJCJEyeaVpfLLrvMBCue4+po+rgGNBogzZs3T6KiomTBggXuMXLU7bffLv/617/kySefNIGSpqOvWrXqgs7IqD/ayVjFn2+k82Jvf/vLt7/3OFV93z4PAABVcVmW9Z1/NweP6k7VjqppFpR2EtY+NPqK6buyokSGPCByd9+7JbZ17AX7c4/myqLPF1X5/fV3r6clBwCC3PFqPr9rPOIxUBlN89YsqNTEQtOHxvOVU4VLJC3RJbHhUfKXn/6l0nRw7WvzwVdrq/y+ngcAgOpggk74hAYumua9Ik5k7HiXaXkpDT3XAqPrun120tyLjndT2+8DAPBdvK7idZVPaZr3Y+88IoUnzqf4x4ZHmwCluuPkfHecnZp8HwDgfMer+fwmyCHI8bnsA9ky4OUB0jqstfz9jr9f0ojHtRkxGQDgbPTJgd/YAUmzJs0uqZOwfp/OxQCA2qJPDgAAcCSCHAAA4EgEOQAAwJEIcgAAgCMR5AAAAEciyAEAAI5EkAMAAByJIMfHdCA7nawyfXu6Wep6sLHv+cSZE0FbBwAA/2MwQB+qbEoCnbRS52QKlikJ7Gkd1NFTR83M5MFWBwCAhoGWHB8+3JOXJEtCdoFkLRApTRWzTMguNNt1f7DUQf/PDwZtHQAAGg7mrvLB3FX6Oqb7szEmwFmeLhLiUaMVrnOzaOf07yxfTP7KsXMwaR30mHuFJHz2fXUQJXum5Dq2DgAA9YO5q+qRTiapr6jSM70f7krXUzItGRJXIGG/DxOn+/46yDd1xbxUAID6wOsqH9DZslV8SeX7L7bdiaqqA7uuAACoa7Tk+EBki0izzIkQGXS+z7Gbbldv3fGWDO0yVJzow/0fypjFY6qsA7uuAACoawQ5PjCsyzCTQZSaWCjL060L+qOkJbokNjxKbrryJsf2R9F7q04daF0BAFAfeF3lAxq4aIr0irhzHWyzokRKQ8UsdV23z06a69gAR1EHAICGhuwqH2RXfd84ObHh0ebhHixjxFAHAICG8vwmyPFhkGOnUkc8EyGHTx6Wl3/ystx79b1B13qhdaBZVNrJWPvg6CuqYKsDAEDdIYXcT/RhHtb4XKr4Dzr9ICgf7nrPpIkDAPyNPjkAAMCRCHIAAIAjEeQAAABHIsgBAACORJADAAAciSAHAAA4EkEOAABwJIIcAADgSAwGWAej/Z4qP2V+/vTApxIfEX/RAQEZGRgAgLpDS46P523q/myMmdJBPfjOg2Zdt1+s7PBFw2XCsglmebGyAACg5ghyfESDk+QlyZKQXSBZC0RKU8UsE7ILzXbP4KUmZQEAwKVhgk4fTNCpr520FUaDluXpIiEeNVrhEhkzXuTThLYyJ2me2Tb13cfk2pzD8lYlZceOd0lO/yjZMyWXV1cAAFSCCTrrkfarySsrkPRM76BF6fqMTJEhcYfkrr/f5d7+m4uUTcm0ZEhcvjkmk1wCAHDpeF3lA9pxWMWXVL7f3t6nfR/zqU5Z+5gAAODSEOT4gGZGqZyIyvfb2/+U9CfzqU5Z+5gAAODSEOT4gKZ+x4RHSWqiy/Sr8aTraYkuiQ2PNuVqUhYAAFw6ghwf0A7C2ql4Rdy5jsNZUSKloWKWuq7bZyfNNeVqUhYAAFw6sqt8kF1l09Tvx1dONp2Qbdoqo0HLuF7jLig7ZcUvZP+3B6osCwAAav78JsjxYZBT01GMi0uLJfIP5/rerL97PSMeAwBQDaSQ+4kGKdVN/fYMaEgXBwDAt+iTAwAAHIkgBwAAOBJBDgAAcCSCHAAA4EgEOQAAwJEIcgAAgCMR5AAAAEciyPEjHTjQlpGX4bVel+fUc6VvT6+3cwIA4A8MBugn9rQOtuGLhpuJO3Veq7qa1qGyaSfq+pwAAPgLLTl+oMFG8pJk6bv1gGQtEClNFbNMyC4023V/XZ0zIbug3s4JAIA/MXeVj+euqoq+Hur+bIwJNpani4R41H6F69xM5Dn9o2TPlFyfzWPlj3MCAFBXmLuqgdLJO/V1UXqmd7ChdD0l05Ihcfky4KUB0qZZG5+c88iJI9U6p14bc2gBAJyCIKee6ezkKr6k8v329s8Pfu7zc1d1TvvaAABwAoKcehbZItIscyJEBp3v/+um29WTiU9Kn4g+PjnnjpId8rvM31V5TvvaAABwAoKcejasyzCT0ZSaWCjL060L+sekJbokNjxKnvzhk77rk9PrrPwt+69VnlOvDQAApyC7qp5p4KIp2yviznX4zYoSKQ0Vs9R13T47aa5POwB7nnPMeKmXcwIA4G9kV9VzdtX3jVkTGx5tgo26HCfnkbcekoOnDtXbOQEA8NfzmyDHT0GOndqtGU3a4Vf7w+jrorpuTXkj5w254//ukJ7tesr8m+bXyzkBAPAlUsgDgAYX9Z2yHeI694Yy4rII0sUBAI5GnxwAAOBIBDkAAMCRCHIAAIAjEeQEmQqrwixLvimRjLwM0/kZAAAnIsgJIppCPnnFJPPzF19/IcMXDTcTdzIDOQDAiQhygoQGMslLkuUH2w9J1gKR0lQxy4TsQrOdQAcAENRBzqxZs8Tlcnl9evbs6d5/8uRJmTRpkrRt21bCw8PllltukYMHD3odY//+/XLTTTdJ8+bNJSIiQqZNmybl5eVeZTIyMqR///4SFhYm3bt3l4ULF15wLc8//7zExMRI06ZNZeDAgbJp06aa332Q0FdSOvDgj7+05K30c/NXhZ8+t9RpHn78pcivVv6SV1cAgOBuyenTp48UFRW5Px9++KF735QpU+Sdd96RpUuXygcffCAHDhyQcePOj6R79uxZE+CcPn1aNm7cKIsWLTIBzJNPPukuk5uba8oMHz5ctm7dKr/85S/lgQcekNWrV7vLvPHGGzJ16lSZOXOmZGdnS9++fWXUqFFSUnKRabaDnA44qCMrz8gUr3mrlK6nZFqSW5ZvygEA4BhWDcycOdPq27dvpfuOHj1qNWnSxFq6dKl7265du/SRamVlZZn1lStXWiEhIVZxcbG7zPz5862WLVtap06dMutPPPGE1adPH69j33777daoUaPc69dee601adIk9/rZs2etTp06WWlpaTW5HevYsWPm+nTpZK9ve92SWWKVhooOb33B53iomP1aDgCAhq66z+8at+Ts2bNHOnXqJN26dZM777zTvH5SW7ZskTNnzsiIESPcZfVVVpcuXSQrK8us6zIhIUE6dOjgLqMtMDo8844dO9xlPI9hl7GPoa1Aei7PMiEhIWbdLnMxp06dMufy/AQDnTJC5URUvt/ebpcDAMAJahTkaN8Xfb20atUqmT9/vnm1NGzYMCktLZXi4mIJDQ2V1q1be31HAxrdp3TpGeDY++1931dGA5ITJ07I119/bV57VVbGPsbFpKWlmbku7E90dLQEA52fKiY8SlITXVLh8t6n62mJLjNRp5YDAMApajR31ejRo90/X3XVVSbo6dq1qyxZskSaNWsmDV1KSorpy2PTwCkYAh2dI2tO0jxJLkuWseNdpg9OfMm5FhwNcFbEibyZNJeJOgEAjlKrCTq11SYuLk727t0rP/rRj8yrpKNHj3q15mh2VceOHc3PuvxuFpSdfeVZ5rsZWbqus4xqINWoUSPzqayMfYyL0Wwt/QSjcb3GyZu3vWmyrIbEFbi3x4ZHmQBH9wMA4CS1GienrKxMvvrqK4mMjJQBAwZIkyZNZO3ate79u3fvNn12Bg8ebNZ1uX37dq8sqDVr1pgApnfv3u4ynsewy9jH0Fdiei7PMhUVFWbdLoPKaSCzd0qerL97vbw+7nWz3DMllwAHAOBMNenN/Pjjj1sZGRlWbm6u9dFHH1kjRoyw2rVrZ5WUlJj9Dz/8sNWlSxdr3bp11ubNm63Bgwebj628vNyKj4+3Ro4caW3dutVatWqV1b59eyslJcVdZt++fVbz5s2tadOmmeys559/3mrUqJEpa1u8eLEVFhZmLVy40Nq5c6f10EMPWa1bt/bK2qqOYMmuAgDASar7/K5RkKOp3JGRkVZoaKjVuXNns7537173/hMnTliPPPKI1aZNGxOo3HzzzVZRUZHXMfLy8qzRo0dbzZo1MwGSBk5nzpzxKrN+/Xrr6quvNufp1q2b9corr1xwLc8995wJqLSMppR//PHHVk0R5AAAEHiq+/x26X8kSGnHY82yOnbsmHllBgAAnPP8Zu4qAADgSAQ5AADAkQhyAACAIxHkAAAARyLIAQAAjkSQAwAAHIkgBwAAOFKt5q4KdPYQQZpvDwAAAoP93K5qqL+gDnJKS0vNMhhmIgcAwInPcR0U8GKCesRjndjzwIED0qJFC3G5XH6NSDXQys/PZ+Tlekbd+w917z/Uvf9Q976hoYsGOJ06dZKQkIv3vAnqlhytmKioKGko9C88f+n9g7r3H+ref6h7/6Hua+/7WnBsdDwGAACORJADAAAciSCnAQgLC5OZM2eaJeoXde8/1L3/UPf+Q93Xr6DueAwAAJyLlhwAAOBIBDkAAMCRCHIAAIAjEeQAAABHIsjxkbS0NPnBD35gRk+OiIiQsWPHyu7du73KnDx5UiZNmiRt27aV8PBwueWWW+TgwYNeZfbv3y833XSTNG/e3Bxn2rRpUl5e7lUmIyND+vfvb3rnd+/eXRYuXCjBbP78+XLVVVe5B9caPHiwvPfee+791Hv9eOqpp8zI4b/85S/d26j7ujNr1ixT356fnj17uvdT93WnsLBQ7rrrLlO3zZo1k4SEBNm8ebN7v+bzPPnkkxIZGWn2jxgxQvbs2eN1jMOHD8udd95pfme1bt1a7r//fikrK/Mqs23bNhk2bJg0bdrUjJL89NNP19s9OoZmV6H2Ro0aZb3yyitWTk6OtXXrVispKcnq0qWLVVZW5i7z8MMPW9HR0dbatWutzZs3W4MGDbKGDBni3l9eXm7Fx8dbI0aMsD777DNr5cqVVrt27ayUlBR3mX379lnNmze3pk6dau3cudN67rnnrEaNGlmrVq2ygtXbb79tvfvuu9aXX35p7d6925oxY4bVpEkT82ehqPe6t2nTJismJsa66qqrrMmTJ7u3U/d1Z+bMmVafPn2soqIi9+df//qXez91XzcOHz5sde3a1brnnnusTz75xNTR6tWrrb1797rLPPXUU1arVq2s5cuXW59//rn105/+1IqNjbVOnDjhLnPjjTdaffv2tT7++GNrw4YNVvfu3a3x48e79x87dszq0KGDdeedd5rfZenp6VazZs2sP//5z/V+z4GMIKeOlJSUaGq+9cEHH5j1o0ePmgfv0qVL3WV27dplymRlZZl1/SUTEhJiFRcXu8vMnz/fatmypXXq1Cmz/sQTT5hfbJ5uv/12E2ThvDZt2lgLFiyg3utBaWmpdeWVV1pr1qyxfvjDH7qDHOq+7oMcfUhWhrqvO9OnT7eGDh160f0VFRVWx44drWeeecbrzyMsLMwEKkoDRv2z+PTTT91l3nvvPcvlclmFhYVm/YUXXjC/x+w/C/vcPXr0qKM7cyZeV9WRY8eOmeXll19ullu2bJEzZ86YZkubNi136dJFsrKyzLoutdmzQ4cO7jKjRo0yE7rt2LHDXcbzGHYZ+xjB7uzZs7J48WL55ptvzGsr6r3u6SsRfeXx3fqh7uuevgLRCQq7detmXn3o6ydF3dedt99+W6655hq59dZbzSu+fv36ycsvv+zen5ubK8XFxV71pnMsDRw40Kvu9RWVHsem5XU+xU8++cRdJjExUUJDQ73qXrtBHDlypJ7uNvAR5NTR7ObaL+G6666T+Ph4s03/0utfVv2L7Ul/weg+u4znLxx7v73v+8roL6YTJ05IsNq+fbvpd6D9Bh5++GH5+9//Lr1796be65gGlNnZ2aZP2ndR93VLH5raP2bVqlWmX5o+XLX/hs7MTN3XnX379pn6vvLKK2X16tUyceJEeeyxx2TRokVedVdZvXnWqwZInho3bmz+UVyTPx9ULahnIa/Lf9nm5OTIhx9+6O9LCRo9evSQrVu3mha0N998U+6++2754IMP/H1Zjpafny+TJ0+WNWvWmI6RqF+jR492/6wd7zXo6dq1qyxZssR0dkXd/SNWW2BSU1PNurbk6O/7F1980fzeQcNCS46PPfroo7JixQpZv369REVFubd37NhRTp8+LUePHvUqr9kOus8u893sB3u9qjLaQz+Yf7Hpv1o182PAgAGmVaFv374yb9486r0O6SuRkpISk3mj/wrVjwaWf/zjH83P+q9O6r7+aKtNXFyc7N27l7/3dUgzprSV2FOvXr3crwrtuqus3jzrVf/f8aRZbZpxVZM/H1SNIMdHtBO3Bjj6mmTdunUSGxvrtV8fvk2aNJG1a9e6t+m7Vf0fQ/uOKF3qaxfPv/z6r2T9hWL/T6VlPI9hl7GPgfP/2jp16hT1XoduuOEGU2/agmZ/9F+42jfE/pm6rz+afvzVV1+ZhzB/7+uOdkP47vAgX375pWlFU/q7X4MQz3rT13va18az7jUA1X8o2PS5ob+3tEXOLpOZmWn6VnnWvbZat2nTps7v0zH83fPZKSZOnGhSBjMyMrxSOr/99luvlE5NK1+3bp1J6Rw8eLD5fDelc+TIkSYNXdM027dvX2lK57Rp00y2xPPPPx/0KZ2//vWvTRZbbm6utW3bNrOuWQr/+Mc/zH7qvf54Zlcp6r7uPP744+b3jf69/+ijj0wquKaAa2anou7rbriExo0bW7///e+tPXv2WK+99pqpo1dffdUrhbx169bWW2+9ZX4njRkzptIU8n79+pk09A8//NBkKHqmkGtGlqaQ/+xnPzMp5IsXLzbnIYW8ZghyfETjxco+OnaOTf+CP/LIIyYtUP+y3nzzzSYQ8pSXl2eNHj3ajIegv7D0F9mZM2e8yqxfv966+uqrrdDQUKtbt25e5whG9913nxm3QutDf0nfcMMN7gBHUe/+C3Ko+7qjqdyRkZGmTjp37mzWPcdqoe7rzjvvvGMCRE0L79mzp/XSSy9dkEb+X//1XyZI0TL6O0nH8PJ06NAhE9SEh4ebtP17773XDMfgScfY0XR1PYb+GWvwhJpx6X/83ZoEAADga/TJAQAAjkSQAwAAHIkgBwAAOBJBDgAAcCSCHAAA4EgEOQAAwJEIcgAAgCMR5AAAAEciyAEAAI5EkAMAAByJIAcAADgSQQ4AABAn+v/mY5bQ3PsOLAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot([point[0] for point in points[2:]],[point[1] for point in points[2:]],marker='o',linestyle='-',color='green',markerfacecolor='red')\n",
    "plt.plot([point[0] for point in points[:2]],[point[1] for point in points[:2]],marker='o',linestyle='-',color='green',markerfacecolor='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9b8e65e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot([point[0] for point in points[:]],[point[1] for point in points[:]],marker='o',linestyle='-',color='green',markerfacecolor='red')\n",
    "\n",
    "\n",
    "plt.plot([5367,5367],[66513,50126],marker='o',linestyle='-',color='green',markerfacecolor='magenta',alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bf150",
   "metadata": {},
   "outputs": [],
   "source": [
    "[5367, 67683], [94997, 50126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb17a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fcd2b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"[###.] (0,3) (0,2,3) (1,3) (0,1,3) {117,15,2,128}\n",
    "[...##..] (2,3) (5,6) (0,1,3,4,5) (0,1,2,6) (2,3,4,5,6) (0,1,5) {12,12,13,13,2,31,19}\n",
    "[.###.#..#.] (0,1,3,7,8) (0,1,2,3,4,6,7,9) (0,1,3,5,6,8,9) (3,8) (1,6,7,9) (2,8) (1,3,5) (0,6,9) (4,8) (0,1,3,6,7,8,9) (0,2,5,6,8) {51,33,24,38,16,22,58,25,54,44}\n",
    "[#.##] (0,1,2,3) (0,2,3) {9,1,9,9}\n",
    "[##.###] (0,1,4,5) (0,1,3,5) (0,1,4) (2,3) (0,1,3,4,5) (1,3) {43,59,16,39,38,25}\n",
    "[##.##.####] (2,6,8) (2,5,6,7,8,9) (0,1,6,7,8,9) (0,1,2,5,6,7,8,9) (3,4) (0,1,3,4,5,6,7,9) (3,4,7,8,9) (1,2,4) {24,40,67,26,42,34,62,64,81,64}\n",
    "[##...#..#] (1,4,5,6,7) (0,2,3,4,5,6,8) (1,2,4,7,8) (0,2,5,6,8) (0,1,5,7) (1,3,6) (3,5) (0,1,2,6) (2,3,7) {44,44,44,36,12,42,46,36,27}\n",
    "[##...] (2,3) (1,4) (0,1,3,4) (0,1,3) (0,1,4) (0,3,4) {32,32,0,21,27}\n",
    "[##.#...] (0,1,3,4,6) (0,4,6) (1,4,5) (0,1,2,3,4) (0,1,4) (0,2) (0,1,2,5) (2,4) {87,53,62,21,73,18,25}\n",
    "[###.#..#..] (0,1,3,5,6,7,8,9) (7,9) (0,4,8) (0,1,2,6,7,9) (2,4,7) (0,1,2,3,4,5,7,8,9) (1,2,3,4,5,7,9) (0,1,5,9) (0,1,2,3,4,7,8,9) {190,192,169,50,50,45,147,196,48,203}\n",
    "[..##...#.#] (6) (1,2,3,4,5,8,9) (5,6) (1,5,8,9) (0,2,3,5,6,7,8,9) (0,1,2,3,6,7,8,9) (2,3,7,9) (1,2,3,4,5,7,8,9) (0,1,6) (1,3,4,6,7,8) (2,4,5,9) (0,1,2,8) {29,70,55,43,37,57,36,32,57,63}\n",
    "[.#...##] (3,4,5) (1,2,3,4,6) (0,2,3,4,5,6) (1,5,6) (0,2,3,5,6) (0,2,6) {161,25,177,164,148,157,186}\n",
    "[.####] (1,2,4) (2) (2,3) (1,3,4) (0,1) (4) {15,43,31,21,32}\n",
    "[.#.....#] (1,7) (2,3) (0,2,3,4,5,6,7) (1,4,5,7) (0,1,2,4,5) (0,3,6) {35,23,19,31,21,21,30,31}\n",
    "[.##...#.] (1,3,4,5,7) (2,6) (0,1,3,4,7) (0,1,4,7) (1,2,4,5,7) (1,3,5,7) (0,2) (0,1,2,3,5) (0,1,2,3,4,5,6) {65,216,59,183,62,184,20,202}\n",
    "[##...###] (1,2,3,4,5,7) (2,7) (3,4,7) (1,3) (0,1,2,3,6,7) (4,5) (0,5,7) (0,1,4,5,7) (0,1,3,5,6,7) {49,63,35,69,44,57,29,84}\n",
    "[#####] (0,1,2,3) (0,3,4) (0,3) (0,1,2) (1,2) {31,138,138,22,0}\n",
    "[.######] (0,2,3,5,6) (0,2,3,4,5,6) (3,5,6) (1,2,6) (0,2,4,5) (1) (0,2,3,4,5) {40,8,43,219,35,237,221}\n",
    "[##...] (0,2,4) (1,2,3,4) (2,3) (1,2,3) (0,1,2) (0,1,4) {31,34,62,33,21}\n",
    "[..#.#....#] (3,4,5) (0,5,6,7) (0,1,2,3,4,6,8) (1,3,4,8) (6,9) (2,7) (3,4,5,6,7) (1,3,6,8,9) (1,3,4,5,6,7,8,9) (2,3,5,6,7,9) {28,52,36,101,81,72,90,60,52,45}\n",
    "[###.#.#] (0,5,6) (1,2,5,6) (0,2,5,6) (3,6) (0,1,2,3,5) (0,2,3,4,5,6) {34,21,23,25,2,41,36}\n",
    "[.##.#....] (0,4,6,8) (1,5) (0,1,2,6,8) (0,1,4,6,7) (0,5,6) (0,2,3,6,7,8) (2,4,7,8) (0,1,3,5,6,7,8) {45,23,17,19,19,30,45,31,34}\n",
    "[.####...] (0,3,4,7) (0,4,5,6,7) (1,3,4,5,6,7) (0,1,2,3,5,7) (2,6) (4,6) (0,3,7) {45,11,25,44,47,18,50,51}\n",
    "[.#....] (0,4,5) (1,2,4,5) (0,2,4) (1,2,3,4) (0,1,3,4) {18,23,21,20,34,9}\n",
    "[#.##] (1,3) (0,2,3) {155,5,155,160}\n",
    "[##..] (1,2,3) (0,1) (0,3) {144,37,19,145}\n",
    "[#.#.##..##] (0,1,2,3,6,8) (0,1,2,6,8,9) (1,2,3,5,6,7,8,9) (0,1,3,5,7,8,9) (1,2,3,5,6,7) (1,2,4,5,6,7,8,9) (0,1,2,3,4,5,6,7,8) (2,3,5,7,8,9) (1,3,4,5,6,7,8,9) (0,1,3,4,5,6,8,9) {60,91,78,95,42,82,88,66,106,78}\n",
    "[#.##.##] (1,2,3,5) (0,6) (2,3,4,5) (1,2,4,5) (2) (0,3,5) (1,2,6) (0,1,2,4,5) (0,2,3,4,5) {55,40,81,33,48,54,33}\n",
    "[.#####..] (0,1,3,5) (2,3,4,5,6,7) (0,1,2,3,4,7) (0,2) (1,2,3,4,5) (3,6) (1,2,5,7) (0,1,2,4,7) {30,45,48,46,30,30,16,27}\n",
    "[####.] (2,3,4) (0,1,2,4) (3,4) (0,3,4) {115,110,114,17,127}\n",
    "[###..#] (1,4,5) (2,3,4,5) (3,5) (0,3,5) (1,3,4) {13,22,19,63,41,53}\n",
    "[###.] (0,1) (0,2) (0,2,3) (2,3) (0,1,3) {38,20,37,37}\n",
    "[.#..] (0) (2) (3) (0,1) {199,15,15,19}\n",
    "[..#..#] (2,3,4,5) (1,2,3,4) (4) (0,1,2) (0) (3,4,5) (1,2,3,4,5) {7,20,21,30,45,17}\n",
    "[#.#..] (2,4) (1,3,4) (0,4) (0,1) {25,23,16,6,30}\n",
    "[..#.#..] (0,1,2,4,5,6) (0,2,3,5,6) (0,1,3,5,6) (0,5) (0,3,4,5,6) (0,1,2,3,5,6) {51,19,23,26,18,51,37}\n",
    "[##..##] (1,2,4,5) (0,1,4,5) (0,3) (1,2,3,4) (3,5) (0,2,3,4) (2,5) {23,12,25,40,28,26}\n",
    "[....###..] (2,3,4,5) (4,5,6,7) (0,1,3,7) (3,5,6) (3,4,8) (0,2,4,5,7,8) (4,5,6) (0,1,3,4,5,7,8) (0,1,2,3,4,5,6) {24,18,13,37,59,48,32,18,31}\n",
    "[.##...] (0,1,3,5) (4,5) (3,5) (1,2,3,5) (2,3,5) {2,11,19,41,3,44}\n",
    "[.###] (0,3) (1,2) (1,3) (2) (0,1) (3) {11,21,22,30}\n",
    "[.#.#.] (1) (1,3,4) (1,2,3,4) (0,2,3) (2,4) (0,2,4) {22,40,54,25,54}\n",
    "[#####.] (1,3,4,5) (1,3,5) (0,1,2,3,4) (1,2) {169,215,185,199,180,30}\n",
    "[#.#######] (1,5) (4,5) (5,7) (0,1,3,6,8) (0,1,2,3,4,6,8) (1,5,7) (0,2,4,5) (1,2,4,5,7,8) (2,4) (0,1,2,3,4,7,8) (0,1,4,5,6) {40,73,52,7,76,284,25,232,21}\n",
    "[##.##.###.] (4,8,9) (0,5,6,8,9) (0,1,3,6,7,9) (0,7) (0,1,3,4,5,7,8,9) (1,6) (1,2,3) (0,2,3,4,5,6,7,8) {225,217,19,215,31,40,233,213,43,211}\n",
    "[...#####.#] (0,1,3,5,6,8,9) (3,4,5,6,7) (0,3,4,5,6,7,8,9) (0,1,2,4,5,7,9) (1,9) (0,2,4,5,6) (0,2,3,4,8,9) (1,2,4,5,7,8,9) (2,9) {46,50,51,43,60,69,50,43,53,85}\n",
    "[.#..#] (2,3,4) (2,3) (1,2,3) (1,4) (0,1,2) (0,2,4) (4) {31,36,185,154,63}\n",
    "[.#.##.#] (3) (0,1,4,5) (3,6) (0,1,2,3) (0,1,2,4,5) (0,3,5,6) (6) (0,4) (4,5) {47,28,24,53,31,46,48}\n",
    "[.....#..#] (0,2,3) (0,1,2,3,4,5,6,8) (4,8) (0,1,2,3,7) (5,6,7) (1,2) (1,3,4,5,6,8) (0,1,2,4,5,6,7,8) (0,3,4,5,7) {52,56,51,51,56,56,52,46,52}\n",
    "[.#.......] (2,3,4,5,6,7,8) (0,1,3) (0,2,5,6,7,8) (1,3,4,5,7) (1,2,3,4,5,8) (3,6,7) (0,4,7) (3,5) (2,3,4,7,8) (1,2,3,5,7,8) {23,16,32,65,57,42,30,78,32}\n",
    "[##.#] (1,2,3) (0,2) (3) (0,3) (1,2) {13,20,29,29}\n",
    "[##.#] (1,3) (0,3) (0,1,2) (3) {10,11,6,180}\n",
    "[##..] (0,1,3) (2) (0,2) (2,3) {5,4,7,4}\n",
    "[#..#] (1) (0,3) (1,2) (0,1) (2,3) {31,42,19,23}\n",
    "[#..#.###.#] (0,4) (4,7) (0,2,3,4,6,7,8,9) (3) (0,6,8,9) (0,1,2,3,4,5,6,7,8) (0,1,2,6,8) (0,1,5,6,7,8,9) (6) (3,4,9) (1,3,5,6,7) (0,2,8) {75,58,45,69,72,41,79,69,59,38}\n",
    "[.#####] (0,1,3) (3) (0,2) (1,2,3,5) (1,2,3,4,5) (2,3) (0,2,4,5) (0,3) {49,54,68,91,21,41}\n",
    "[.####.##.] (2,3,4,5,8) (0,1,5,8) (1,2,3,4,6,7) (0,4,6,7) (0,3,7) (1,3,5) (0,1,2,3,5,6,7) {24,38,32,54,30,41,23,30,19}\n",
    "[#..##....#] (2,3,4,5,6,9) (1,2,3,4,6,7,8) (2,4,9) (0,2,4,6,8) (1,9) (1,2,3,4,8) (5,6) (3,4,5,8) (2,3,4,5,7,8,9) (0,1,3,5,6,9) {39,45,96,92,110,77,79,30,73,77}\n",
    "[.##.#] (0,1,2,3) (0,1,2,4) (1,2,4) {21,200,200,10,190}\n",
    "[..#.#####] (2,4) (1,2,4,5,6,8) (0,1,2,3,5) (0,2,3,6) (5,8) (4,5,6) (0,1,2,3,4,5,7) {30,31,39,30,32,54,19,13,18}\n",
    "[.#..#] (0,1,3,4) (1,4) (0,2,4) {7,21,4,3,25}\n",
    "[##.###.#.] (6) (0,5) (0,2,3,4,7,8) (1,2,5,8) (0,3,4,5,6,8) (0,1,7) (1,3,4,5,7,8) {22,38,18,28,28,42,14,32,40}\n",
    "[#.##....] (0,1,3,4,5,7) (1,2,5,6) (2,4,7) (1,4,5,7) (1,2,6,7) (1,2,3,4,5,6) (3,4,5) (0,5,6) (0,5) {23,44,44,23,41,62,38,42}\n",
    "[..#....#] (0,1,2,3,4,5,7) (2,3,4,5,6,7) (2,7) (0,2,3,4,6,7) (4,5,6) (0,1,6) (1,2,3,4,6,7) {11,11,22,20,38,24,36,22}\n",
    "[#.#.###.] (1,3) (0,1,2,5,6,7) (0,1,2,3,5,7) (0,2,5,6,7) (1,3,4) (2,3,4,5) (0,1,3,6,7) (2,4,5,6,7) {37,46,56,62,29,56,30,44}\n",
    "[#.##] (1) (2,3) (2) (0,2) (1,2,3) {19,3,55,17}\n",
    "[....##] (1,2,4,5) (2,5) (4) (0,1,2,5) (2,3,5) (0,1,3,5) (0,2) (0,2,3) {53,23,69,30,2,42}\n",
    "[.#.#....] (2,3,5) (3,7) (1,2,4,5,6,7) (0,5) (0,6,7) (0,1,4,5,6,7) (1,2,5,7) (1,2,4,7) (1,5,7) (6) {20,31,19,10,16,44,34,35}\n",
    "[#.#.#.#..#] (3,6,7,8,9) (1,3,4,5,6,8,9) (1,2,3,4,7,9) (0,1,2,3,4,5,7,8,9) (2,3,4,8) (0,3,5,6,9) (1,3) (0,1,4,6,7,8) (5,7) (0,1,2,5,6) (7,9) (0,1,2,3,4,6,8,9) (4,7,9) {53,76,67,83,58,35,58,45,42,72}\n",
    "[#.#..##] (1,2,3,4,5) (0,1,2,6) (2,3) (0,4,5) (0,1,2,3,4) {49,44,59,41,46,35,18}\n",
    "[..##..##] (1,4,6,7) (0,1,3,5,7) (1,3,7) (1,2,5,6,7) (1,3,6,7) (1,2) (1,2,4,5,6,7) (3) (0,1,2,4,6,7) (0,5,6) {42,95,32,54,30,35,68,82}\n",
    "[####.####] (1,5,8) (4,5,6,7,8) (0,2,4,5,6,7,8) (0,2,4,7,8) (1,2,6) (0,1,2,3,4,5,8) (0,1,2) (1,4) {26,65,45,12,40,32,23,12,40}\n",
    "[.###] (0,2,3) (0,1) (2,3) {27,10,26,26}\n",
    "[##.#.#.] (1,2,3,4,5) (1,3) (0,1,2,3,4) (0,1,2,3,5,6) (1,2,3,5) (0,1,2,6) {32,52,49,43,24,25,17}\n",
    "[#.#..#] (1,3,5) (1,2,5) (1,4) (0,2,4) (0,2,3,5) (0,1,2,3) {32,53,41,42,14,31}\n",
    "[.###.#..] (0,4,5,7) (2,6) (0,2,3,4,5) (0,1,2,7) (0,1,2,3,6) (3,4,5,7) (3,7) (2,4,6,7) {48,15,51,48,58,41,36,61}\n",
    "[#.#.#.] (1,2) (3,5) (0,1,3) (2,4,5) (2) (1,2,4) {3,28,39,11,9,12}\n",
    "[#..###] (0,3,5) (4) (2,3,5) (0,3) (3,4,5) (0,3,4,5) (1,3,4) (0) {40,12,17,82,64,62}\n",
    "[..#.##.] (0,3,4) (2,4,5) (2,3,4,5,6) (0,1,3,4,5,6) (1,2,3,5,6) {26,14,15,41,40,28,28}\n",
    "[.#..] (1) (2,3) (0,3) (1,2) (0,2) (0,2,3) {41,154,46,34}\n",
    "[###.#...] (4,5) (6,7) (1,4,7) (1,2,3,4,5,6) (0,1,3,5,6) (2,7) (0,6) (0,2,3,4,6) (2) {36,29,20,20,26,13,147,138}\n",
    "[#..####.##] (0,1,3,4,6,8,9) (0,5,7,8) (2,8) (0,1,3,6) (0,1,2) (0,3,4,5,6,7,8,9) (2,3,5,8) (0,1,2,4,5,7,8,9) (0,1,2,4,5,7) (1,3,4,7) (2,3,6,7,8,9) {70,53,51,66,64,60,45,48,67,47}\n",
    "[....#..#..] (0,1,2,3,5,6,7,8) (3,4,7) (0,3,4,6,7,8) (2,6) (0,2,3,4,5,8,9) (0,7,8,9) (2,8,9) (1,3,7,9) (5,8) (3) (0,1,3,4,5,7,8,9) {44,19,35,63,37,45,12,57,73,54}\n",
    "[...##..#] (4,7) (3,4,5,7) (0,2,7) (0,1,5,6,7) (0,1,2,3,4,6,7) (1,6,7) {22,33,14,16,32,16,33,63}\n",
    "[###..] (0,2,3) (2) (1,4) (0,3,4) (1,2,3) {31,5,199,36,12}\n",
    "[#....#] (0,2,4) (0,2,3,4) (0,2,3) (1,4,5) (2,4,5) (0,1,3,5) (0,1,2,4) (0,3) {48,38,41,21,57,30}\n",
    "[####..#] (3,4) (0,2,4,6) (3,4,6) (2,4) (0,1,3,5) (3,4,5,6) (3,6) {28,19,15,70,46,28,45}\n",
    "[##.###.##.] (1,2,4,6) (5,6,9) (2,4,7,9) (1,2,3,6,7,8,9) (0,2,3,4,5,6,7,9) (0,1,2,4,5,6,7,8) (0,2,4,9) (1,2,5,7) (3,6,7,8,9) {28,23,71,16,59,166,175,45,7,203}\n",
    "[.#...#.] (0,1,3,5) (1,2,6) (3,4,5,6) (2,5,6) (0,2,3,4,6) {36,23,23,49,29,37,36}\n",
    "[##.##..#] (0,1,2,4,5,6,7) (2,3) (0,1,2,4,7) (1,4,5) (0,2,7) (1,2,4,6) (6) {32,34,51,10,34,6,22,32}\n",
    "[######] (0,1,3,4) (2,5) (3,4) (0,1,5) (0,1,2,4,5) {29,29,18,26,39,21}\n",
    "[#...#..#] (0,2,3,4,6,7) (1,5) (1,7) (3,4,5,6) (0,4,6) (3,4) {25,8,16,23,32,10,30,19}\n",
    "[.###] (0,2,3) (1,2,3) {6,1,7,7}\n",
    "[.##.#...] (0,2,3) (2,5,7) (0,1,3,4,5,6,7) (1,3,4,5,6) (3,7) (1,6) (1,2,5,6) (3,5,6,7) {22,37,42,50,17,44,37,35}\n",
    "[###..] (0,2,3,4) (2,3) (0,1) (0,1,4) (0,1,3,4) (4) {30,24,6,11,17}\n",
    "[##.##.###.] (0,5,8) (1,2,3,4,6,7,8,9) (1,2) (0,1,3,4,5,7,8,9) (0,3,4,7,8,9) (0,1,3,4,5,6,7,8) (1,4,9) (3,4,7,9) {25,47,29,53,55,19,26,53,38,42}\n",
    "[..#..#..#] (3,4,6) (0,1,2,3,5,6,8) (7) (0,2,3,4,6,8) (0,2,3,4,7,8) (0,1,2,3,4,5,6,7) (1,2,3,4,5,6,8) (1,7) (0,5,7) {54,47,52,72,53,51,63,46,46}\n",
    "[#.##.] (2,3) (0,2,3,4) (1,4) (1,2,3) (0,1) (2,3,4) {4,25,40,40,39}\n",
    "[#..#.#.] (1,2,4,6) (2,3,4) (2,3,6) (3,4,6) (0,1,3,5,6) (1,2,3,5,6) (4,5,6) (0,1,2,4,6) (4,5) {6,28,50,34,45,24,49}\n",
    "[.##.#] (0,1,3,4) (0,1,2) (1,2,4) {10,19,10,9,18}\n",
    "[##.#######] (0,4,9) (0,6,9) (2,4,5) (1,3,5,6,7,8) (0,2,3,4,5,6,7,8) (0,5,6) (1,2,7,8) (2,3) (1,2,4,6,7) (1,2,5,6,8) (1,2,5,7,9) (0,1,4,5,6,7,8,9) {41,84,89,36,54,86,81,68,66,32}\n",
    "[####.#####] (1,2,3,4,6,7,8,9) (1,4,6,9) (2,3,4,6,8,9) (3,7,8) (0,2,3,5,7) (0,1,3,4,5,8) (2,4,5,6,9) (0,2,5,7) {37,35,60,65,56,50,45,55,48,45}\n",
    "[##.#] (0,1,3) (0,2,3) {26,11,15,26}\n",
    "[.#..#.] (0,2,5) (0,1,3,5) (1,5) (0,3,4,5) {178,35,151,27,10,196}\n",
    "[#.#..#] (1,2,5) (0,2,4,5) (0,3,4,5) (0,1,2,5) (0,1,2,3) (1,4) {32,36,32,6,34,34}\n",
    "[###.#..] (0,1,2,3) (0,3,4,5) (0,2,4,6) (0,1,2,4) (0,2,3,4,5) (1,4,6) {45,46,43,17,50,2,37}\n",
    "[..##.#.] (0,1,4,5) (0,2,3,5,6) (1,2,3,4) (0,1,3,4,6) (2,5) (3,6) (2,5,6) (1,2) {28,57,78,48,37,55,48}\n",
    "[##..###] (2,3) (0,1) (0,1,5,6) (0,4,6) (0,3,6) (1,2,3,4,6) (1,2,3,6) {36,29,24,37,6,10,41}\n",
    "[......##..] (0,1,3,6,7,8,9) (1,3,6) (0,1,3,4,6,8,9) (0,3,5,7,9) (5,6) (0,3,4,5,7) (1,8) (0,1,2,5,6) (0,1,2,3,5,6,8,9) {81,83,16,82,30,47,70,46,64,61}\n",
    "[#.###..#] (1,4,5,7) (1,3,6) (1,7) (0,1,2,3,4,6) (0,2,3,4,5) (0,1,3,7) (1,3,5,6,7) (0,2,4,5,6,7) {47,77,36,50,53,49,50,70}\n",
    "[########] (0,1,2,5,6,7) (0,2,3,5) (0,2,4,6) (5,6) (1,2,4,7) (0,1,2,5,6) {33,30,37,5,6,42,39,13}\n",
    "[#.#.] (1,3) (1,2) (0,2) (2,3) {16,20,53,19}\n",
    "[#.....##] (1,2,3,5,6,7) (5,7) (1,4) (1,5,7) (3,4,6,7) (0,1,4,6,7) (0,1,3,5,6,7) (0,1,2,3,4,5,7) (3,7) (0,2,6,7) {31,49,23,45,48,41,48,88}\n",
    "[.#..##...] (0,2,4,5,8) (0,1,2,3,4,7) (0,2,4,5,6,8) (1,2,3,5,6,7) (7,8) (0,3,4,6) (0,3,4,5,7,8) (4,6) {199,6,195,12,214,192,200,24,207}\n",
    "[#.#..] (0,2) (0,1,2,3,4) (0,1,3) {159,143,143,143,127}\n",
    "[.##..] (3,4) (0,1,3,4) (2,3,4) (1,2) (0,1,3) {30,48,30,61,43}\n",
    "[#.#.] (0,1) (0,2) (1,3) (1,2) (0,3) {43,25,17,31}\n",
    "[#.##.####] (0,1,2,3,4,5,8) (0,1,2,3,5,7,8) (0,2,3,4,5,6,8) (1,2,4,5) (2,3,4,7) (1,4,5,7) (0,1,8) (0,1,7,8) (2,4,5,6,7,8) (1,2,3,4,6) {24,47,48,37,50,41,8,40,24}\n",
    "[......####] (1,8) (0,3,4,6,7,8,9) (0,1,2,3,4,5,7,8) (2,5,7) (1,5,6) (2,3,4,6,7,9) (3,8) (3,5,6,7,8) (0,1,2,3,5,9) (0,1,2,4,5,7,9) (0,3,6) {55,63,49,241,53,62,47,72,245,43}\n",
    "[#...#.#.##] (1,3,4,7) (3,7,9) (1,2,3,4,5,6,8,9) (4,5,9) (2,3,4) (0,4,5,6,7,9) (0,1,5,9) (2,5,6) (0,1,4,5,6,7,8,9) (2,3,5,6,9) (1,6) (0,2,3,4,5,6,7,8,9) (5) {57,61,52,57,81,113,101,74,39,93}\n",
    "[#..#..##..] (1,5,6) (0,1,2,3,6,7,8) (0,3,4,5,7) (1,6,9) (8) (0,1,2,3,4,5,9) (1,2,4,6,7,9) (2,4,5,6,7,8,9) (0,1,2,3,5,8,9) (0,1,3,4,6,7,9) (0,1,2,3,4,5,7,8,9) {73,93,54,73,66,63,61,70,46,78}\n",
    "[..#..##.] (0,1) (0,1,2,3,4,7) (0) (0,1,3,5) (4) (5,6) (3,4) (0,5,6) (1,2,4,5,7) (1,4,5,6,7) {54,59,19,27,57,76,41,31}\n",
    "[..###.#] (2) (0,1,2,4,5,6) (0,1,3) (2,4,5) (4,5) (0,1,2,3,5) (0,3,6) (2,3,4,6) {69,49,58,59,62,67,50}\n",
    "[.#.#.] (0,2,4) (1,3) (0,3) (0,1,2) {22,27,15,22,3}\n",
    "[.####.#.#.] (0,3,4) (0,1,3,6,7,8,9) (2,4,9) (3,7,9) (0,1,2,6,7,9) (0,1,2,3,4,5,6) (0,3,4,5,6,8) (0,4,5,7) {95,52,50,71,75,50,68,72,36,70}\n",
    "[###..##.#.] (8,9) (0,1,2,3,5,6,7,9) (2,6) (6) (0,1,5,6,9) (2,4,6,7,8,9) (0,1,2,3,6,7,8,9) (2,8) (4,7) (1,2,3,4,7,8) (0,3,4,6) (0,1,3,4,5,6,7,9) (3,5,7) {40,56,208,54,49,39,215,74,53,55}\n",
    "[#..#] (2) (0,2,3) (0,1,2) {32,13,49,19}\n",
    "[...#.#.] (0,4,6) (0,1,2,3,6) (0,1,2,3,4,6) (2,5) (0,1,2,5) (1,3,4,5,6) (0,1,2,4,5) {66,55,51,23,34,36,38}\n",
    "[#.#..#..#] (0,3,4,5,6,7,8) (1,2,3,4,7) (1,3,6,7,8) (2,7) (1,2,4,5,6,7,8) (0,2,5,8) (0,2,8) (1,3,7) (0,5) (0,2,3,4,6,7) {60,25,74,57,53,32,42,80,38}\n",
    "[###.] (0,1,2) (0,3) (0,1) (1,2,3) (3) (0) {22,13,9,32}\n",
    "[..##] (1) (1,2,3) (0,2,3) {10,16,21,21}\n",
    "[..##.##.##] (1,3,5,7,8,9) (4,5,8) (0,4,6) (1,5,6,7,8,9) (2,9) (5,6) (4,7,8,9) (1,8) (0,3,4,7,8,9) (4,5) {9,8,14,12,52,52,19,29,49,43}\n",
    "[##....####] (0,3,5,9) (1,3) (6,9) (0,2,3,4,5,6,7,9) (2,3,5,6,8,9) (0,1,3,4,5,6,8,9) (0,1,2,3,4,6,7,9) (0,2,3,6,7) (2,3,6,8,9) (0,9) (1,2,3,4,5,6,7) (1,3,4,8,9) (1,3,4,5,6,7,8,9) {51,76,57,126,76,73,102,58,60,121}\n",
    "[##.##] (1,2) (0,3,4) (2,3,4) (0,1,3,4) {12,23,27,19,19}\n",
    "[#.###..##] (2,3,7,8) (0,8) (1,2,4,6,7) (2,5,6) (0,1,3) (1,2,3,4) (2,5) (0,2,4,8) {42,37,80,38,41,24,19,29,46}\n",
    "[#.#.##.] (0,2,5) (1,5) (0,4,6) (1,3,6) (0,3) (0,4,5,6) {57,23,11,23,26,40,29}\n",
    "[#...#..#] (4) (0,1,2,4,5) (2,3,4,5,6,7) (1,3,5) (0,4,7) (1,2,3,4,5,6) (6,7) (3) {23,30,26,31,52,42,23,32}\n",
    "[###.#] (1,2,3) (0,4) (0,1,2) (1,2) (1,2,4) {15,161,161,6,13}\n",
    "[.#.....] (2,3,4,5,6) (1,5) (1,3,4) (0,1,2,5,6) (0,1,3,6) (1,5,6) (1,3) (1,2,3,4,5) {24,100,34,54,29,64,39}\n",
    "[.###] (2,3) (1,2,3) (2) (3) (0,1,3) (0,2) {136,136,56,150}\n",
    "[.##...] (0,2,3,4,5) (0,4,5) (3,4) (0,1,5) {42,17,9,15,31,42}\n",
    "[#.##] (0,2) (0,1) (2) (3) (1,2,3) (0,2,3) {34,15,53,30}\n",
    "[##..###..] (1,3,4,5,6,7,8) (0,4,6) (0,2,4,6,7) (0,1,2,3,4,5,7) (0,3,4,5,6,7) (2,3,4,6,8) (5,7) (3,4,6,8) (4,8) (0,3,8) (0,1,2,3,4) {166,28,59,178,202,132,168,150,62}\n",
    "[#.#.....] (0,3,4,7) (0,1,2,3,4,6,7) (0,1,4,5,6,7) (2,3,4,5,6) (0,1,3,4,5,7) (0,1,3,6,7) (0,1,2,4,5,6) {47,29,34,43,61,38,46,35}\n",
    "[..###.#..] (6,8) (2,3,4,5,6,7,8) (0,1,2,5,7,8) (1,4,5) (0,1,4,5,6,7,8) (0,3,6,7) (1,2,5,7,8) (0,3,5) (0,1,2,8) (2,3,5,8) (1,8) {33,207,46,30,45,55,44,40,230}\n",
    "[.#.#....] (1,3) (0,2,4,6,7) (4,6,7) (0,3,4,5,7) (0,2,3,4,5) (1,2) (0,2,3,4,6,7) {49,22,64,42,58,20,38,38}\n",
    "[#.#..#..] (4,7) (0,1,3,4,7) (0,1,2,3,6) (0,2,3,6) (0,2,4,6) (1,5,6,7) {62,47,43,44,55,16,59,53}\n",
    "[##.###.] (1,4,6) (0,1,3,4,5) (2,3,4,5) (4,6) (0,1,3,5) (2,3,6) (2,5) {12,27,24,27,47,35,27}\n",
    "[..#..#.] (0,1) (0,2) (1,4) (2,3) (0,3,4,5) (0,2,3,4,6) (2,3,6) (4,5) (0,4,6) {67,32,35,25,76,17,43}\n",
    "[#.##] (1,3) (0,2,3) {10,14,10,24}\n",
    "[#..#.#.##] (0,1,2,3,4,5,7) (6,8) (0,1,3,5,6,7,8) (0,1,2,5,7) (4,6) (1,2,3,4,5,6,8) (0,1,5,6,7,8) (3,4,6,8) (1,3) (0,2,4,5,6,7) (3,6) {39,64,40,62,57,58,96,39,75}\n",
    "[#..#####.] (0,4,8) (0,1,4,8) (3,7,8) (1,6,8) (1,2,3,4,5,6,7,8) (1,2,8) (0,1,3,4) (0,2,3,6,7,8) (5,7,8) (0,7) (0,1,4,5,6,7,8) {54,52,31,55,41,36,36,75,85}\n",
    "[##.##] (3,4) (2,3) (2,3,4) (0,1,3,4) (1,2,3) (0,1,4) (4) {18,18,26,50,57}\n",
    "[.#.####] (1,4,5) (1,3) (1) (0,2,4,6) (1,2,3,6) (2) (0,1,4) (1,3,4,5,6) (0,4,5,6) {33,46,13,32,50,34,47}\n",
    "[..##.##] (2,5,6) (0,2,3) (1,2,4,5,6) (2,4) (0,1,2,5,6) (0,1,3,4,5) {27,40,63,14,30,60,53}\n",
    "[####...#.] (4,6,7,8) (2,4,5,6,8) (2,5,6,7,8) (1,2,4,5,8) (0,1,2,4,5,7) (1,4,6,7) (0,3,5,8) {2,36,45,2,50,47,53,45,53}\n",
    "[##..#] (0) (0,3,4) (0,1,2) (1,2,3) (2,3) (0,2,4) (0,1,2,4) {52,27,42,33,29}\n",
    "[.......##] (0,1,2,4,6,8) (0,5) (2,7) (3,7,8) (0,1,2,5,6,7) (2,3,5,6,7,8) (7,8) (1,2,4,7) (1,2,5,6) (1,4,7) {35,58,56,9,32,50,39,60,13}\n",
    "[##.##.] (0,1) (0,3,4,5) (0,1,3,4) (1,4) (1,2,4,5) (0,1,2,4,5) (0,1,2) (1,5) {50,79,32,25,69,49}\n",
    "[####..##.] (0,1,2,3,7,8) (0,1,2,3,4,7,8) (1,2,3,5,6,7,8) (1,4) (0,1,2,3,4,5,7,8) (1,3) (0,1,4,5,8) (2,3) (0,1,2,5,6) {71,99,64,64,36,48,23,39,54}\n",
    "[##.###] (0,4) (0,1,2,4) (0,4,5) (0,1,3,5) (0,1,2,3,5) (2,3,4) (1,2,4) {40,19,12,26,33,23}\n",
    "[.#..#.] (0,1) (2,5) (1,2,3,5) (0,5) (3,4,5) (0) (0,1,2,3,4) {147,38,41,22,11,36}\n",
    "[##.###.] (0,2,5,6) (0,1,2,3,4) (2,3,4) (1,3) (0,1,3,6) {41,46,29,48,18,11,25}\n",
    "[###...#.#] (1,2,3,5,7,8) (2,3,4) (0,2,3,4,5,7) (0,1,2,5) (0,2,3,4,6,7,8) (1,2,3,5,6,8) (0,2,7,8) {197,37,229,50,32,47,26,178,186}\n",
    "[.###.] (1,2,3) (4) (0,1,2,4) (1,4) (0,1,3) (0) (0,3) {42,43,31,29,33}\n",
    "[.#..##.##.] (5,6,7,9) (4,7,8) (1,2,4,5,6,8,9) (1,2,4,5,7,9) (0,2,3,5,6,7,9) (0,1,2,3,7,8,9) (0,2,3,4,5,8,9) (2,3,4,5,6,7,8,9) (6) (1,2,3,4,6,7,8,9) (0,1,3,4,5,6,7,9) (0,1,2,3,4,6,7,8,9) (0,1,2,5) {55,62,69,54,48,47,67,78,53,75}\n",
    "[###..#] (0,2,4,5) (0,2,3) (0,3,5) (0,1,2,5) {58,13,41,25,20,50}\n",
    "[#.###.####] (0,1,2,3,5,8) (2,5,9) (2,6,7,9) (0,1,5) (1,2,3,4,5,6,7,8) (3,5,7,9) (1,4,6,7,8,9) (1,3) (0,5) (6,7) (0,3,4,5,6,9) (3,8) {42,229,30,234,30,66,49,52,37,44}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae061399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_state(val):\n",
    "    if(val == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34a9c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValid(buttons_presses,buttons,values):\n",
    "    final_state = [0]*len(values)\n",
    "    for button in buttons_presses:\n",
    "        for idx in buttons[button]:\n",
    "            final_state[idx] = flip_state(final_state[idx])\n",
    "    if(final_state == values):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ac435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa467657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "my_set = np.array(range(len(buttons)))\n",
    "min_len = 2*len(buttons)\n",
    "final_range = []\n",
    "for k in range(min_len):\n",
    "    for subset in itertools.combinations(range(len(buttons)),k):\n",
    "        if(isValid(list(subset),buttons,on_off) and len(my_set[list(subset)]) < min_len):\n",
    "            final_range = list(subset)\n",
    "            min_len = len(final_range)\n",
    "print(final_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9fc76659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "7\n",
      "10\n",
      "4\n",
      "6\n",
      "10\n",
      "9\n",
      "5\n",
      "7\n",
      "10\n",
      "10\n",
      "7\n",
      "5\n",
      "8\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "5\n",
      "10\n",
      "7\n",
      "9\n",
      "8\n",
      "6\n",
      "4\n",
      "4\n",
      "10\n",
      "7\n",
      "8\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "9\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "9\n",
      "10\n",
      "10\n",
      "5\n",
      "7\n",
      "9\n",
      "9\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "10\n",
      "6\n",
      "9\n",
      "10\n",
      "5\n",
      "9\n",
      "5\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "7\n",
      "8\n",
      "9\n",
      "4\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "8\n",
      "10\n",
      "10\n",
      "8\n",
      "5\n",
      "6\n",
      "7\n",
      "10\n",
      "7\n",
      "8\n",
      "6\n",
      "8\n",
      "4\n",
      "8\n",
      "5\n",
      "10\n",
      "9\n",
      "5\n",
      "7\n",
      "5\n",
      "10\n",
      "10\n",
      "4\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "10\n",
      "8\n",
      "8\n",
      "4\n",
      "8\n",
      "9\n",
      "5\n",
      "5\n",
      "4\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "8\n",
      "7\n",
      "5\n",
      "10\n",
      "10\n",
      "4\n",
      "7\n",
      "9\n",
      "4\n",
      "4\n",
      "10\n",
      "10\n",
      "5\n",
      "9\n",
      "7\n",
      "8\n",
      "5\n",
      "7\n",
      "4\n",
      "6\n",
      "4\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "4\n",
      "9\n",
      "9\n",
      "5\n",
      "7\n",
      "7\n",
      "9\n",
      "5\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "9\n",
      "5\n",
      "10\n",
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for line in input_str.split('\\n'):\n",
    "    on_off = []\n",
    "    \n",
    "    for character in line.split(']')[0][1:]:\n",
    "        if(character == '.'):\n",
    "            on_off.append(0)\n",
    "        else:\n",
    "            on_off.append(1)\n",
    "        buttons = []\n",
    "    for mystr in line.split(']')[1].split():\n",
    "        if(mystr[0] == '('):\n",
    "            buttons.append(list(map(int,mystr[1:-1].split(','))))\n",
    "        else:\n",
    "            braces= list(map(int,mystr[1:-1].split(',')))\n",
    "    equations = []\n",
    "    for val in range(len(on_off)):\n",
    "        equation = []\n",
    "        for idx,button in enumerate(buttons):\n",
    "            if(val in button):\n",
    "                equation.append(idx)\n",
    "        equation.append(on_off[val])\n",
    "        equations.append(equation)\n",
    "    my_set = np.array(range(len(buttons)))\n",
    "    min_len = 2*len(buttons)\n",
    "    final_range = []\n",
    "    for k in range(min_len):\n",
    "        for subset in itertools.combinations(range(len(buttons)),k):\n",
    "            if(isValid(list(subset),buttons,on_off) and len(my_set[list(subset)]) < min_len):\n",
    "                final_range = list(subset)\n",
    "                min_len = len(final_range)\n",
    "    print(len(on_off))\n",
    "    tot+=min_len\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d49a8a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8369a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str=\"\"\"[.#..##.##.] (5,6,7,9) (4,7,8) (1,2,4,5,6,8,9) (1,2,4,5,7,9) (0,2,3,5,6,7,9) (0,1,2,3,7,8,9) (0,2,3,4,5,8,9) (2,3,4,5,6,7,8,9) (6) (1,2,3,4,6,7,8,9) (0,1,3,4,5,6,7,9) (0,1,2,3,4,6,7,8,9) (0,1,2,5) {55,62,69,54,48,47,67,78,53,75}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c6215c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "idx_check = -1\n",
    "for line in input_str.split('\\n'):\n",
    "    for character in line.split(']')[0][1:]:\n",
    "        if(character == '.'):\n",
    "            on_off.append(0)\n",
    "        else:\n",
    "            on_off.append(1)\n",
    "        buttons = []\n",
    "    for mystr in line.split(']')[1].split():\n",
    "        if(mystr[0] == '('):\n",
    "            buttons.append(list(map(int,mystr[1:-1].split(','))))\n",
    "        else:\n",
    "            braces= list(map(int,mystr[1:-1].split(',')))\n",
    "    print(len(buttons)-len(braces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c870953d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buttons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "32570374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDocstring:\u001b[39m\n",
      "array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n",
      "      like=None)\n",
      "\n",
      "Create an array.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "object : array_like\n",
      "    An array, any object exposing the array interface, an object whose\n",
      "    ``__array__`` method returns an array, or any (nested) sequence.\n",
      "    If object is a scalar, a 0-dimensional array containing object is\n",
      "    returned.\n",
      "dtype : data-type, optional\n",
      "    The desired data-type for the array. If not given, NumPy will try to use\n",
      "    a default ``dtype`` that can represent the values (by applying promotion\n",
      "    rules when necessary.)\n",
      "copy : bool, optional\n",
      "    If ``True`` (default), then the array data is copied. If ``None``,\n",
      "    a copy will only be made if ``__array__`` returns a copy, if obj is\n",
      "    a nested sequence, or if a copy is needed to satisfy any of the other\n",
      "    requirements (``dtype``, ``order``, etc.). Note that any copy of\n",
      "    the data is shallow, i.e., for arrays with object dtype, the new\n",
      "    array will point to the same objects. See Examples for `ndarray.copy`.\n",
      "    For ``False`` it raises a ``ValueError`` if a copy cannot be avoided.\n",
      "    Default: ``True``.\n",
      "order : {'K', 'A', 'C', 'F'}, optional\n",
      "    Specify the memory layout of the array. If object is not an array, the\n",
      "    newly created array will be in C order (row major) unless 'F' is\n",
      "    specified, in which case it will be in Fortran order (column major).\n",
      "    If object is an array the following holds.\n",
      "\n",
      "    ===== ========= ===================================================\n",
      "    order  no copy                     copy=True\n",
      "    ===== ========= ===================================================\n",
      "    'K'   unchanged F & C order preserved, otherwise most similar order\n",
      "    'A'   unchanged F order if input is F and not C, otherwise C order\n",
      "    'C'   C order   C order\n",
      "    'F'   F order   F order\n",
      "    ===== ========= ===================================================\n",
      "\n",
      "    When ``copy=None`` and a copy is made for other reasons, the result is\n",
      "    the same as if ``copy=True``, with some exceptions for 'A', see the\n",
      "    Notes section. The default order is 'K'.\n",
      "subok : bool, optional\n",
      "    If True, then sub-classes will be passed-through, otherwise\n",
      "    the returned array will be forced to be a base-class array (default).\n",
      "ndmin : int, optional\n",
      "    Specifies the minimum number of dimensions that the resulting\n",
      "    array should have.  Ones will be prepended to the shape as\n",
      "    needed to meet this requirement.\n",
      "like : array_like, optional\n",
      "    Reference object to allow the creation of arrays which are not\n",
      "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "    the ``__array_function__`` protocol, the result will be defined\n",
      "    by it. In this case, it ensures the creation of an array object\n",
      "    compatible with that passed in via this argument.\n",
      "\n",
      "    .. versionadded:: 1.20.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "out : ndarray\n",
      "    An array object satisfying the specified requirements.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "empty_like : Return an empty array with shape and type of input.\n",
      "ones_like : Return an array of ones with shape and type of input.\n",
      "zeros_like : Return an array of zeros with shape and type of input.\n",
      "full_like : Return a new array with shape of input filled with value.\n",
      "empty : Return a new uninitialized array.\n",
      "ones : Return a new array setting values to one.\n",
      "zeros : Return a new array setting values to zero.\n",
      "full : Return a new array of given shape filled with value.\n",
      "copy: Return an array copy of the given object.\n",
      "\n",
      "\n",
      "Notes\n",
      "-----\n",
      "When order is 'A' and ``object`` is an array in neither 'C' nor 'F' order,\n",
      "and a copy is forced by a change in dtype, then the order of the result is\n",
      "not necessarily 'C' as expected. This is likely a bug.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> np.array([1, 2, 3])\n",
      "array([1, 2, 3])\n",
      "\n",
      "Upcasting:\n",
      "\n",
      ">>> np.array([1, 2, 3.0])\n",
      "array([ 1.,  2.,  3.])\n",
      "\n",
      "More than one dimension:\n",
      "\n",
      ">>> np.array([[1, 2], [3, 4]])\n",
      "array([[1, 2],\n",
      "       [3, 4]])\n",
      "\n",
      "Minimum dimensions 2:\n",
      "\n",
      ">>> np.array([1, 2, 3], ndmin=2)\n",
      "array([[1, 2, 3]])\n",
      "\n",
      "Type provided:\n",
      "\n",
      ">>> np.array([1, 2, 3], dtype=complex)\n",
      "array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
      "\n",
      "Data-type consisting of more than one element:\n",
      "\n",
      ">>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
      ">>> x['a']\n",
      "array([1, 3])\n",
      "\n",
      "Creating an array from sub-classes:\n",
      "\n",
      ">>> np.array(np.asmatrix('1 2; 3 4'))\n",
      "array([[1, 2],\n",
      "       [3, 4]])\n",
      "\n",
      ">>> np.array(np.asmatrix('1 2; 3 4'), subok=True)\n",
      "matrix([[1, 2],\n",
      "        [3, 4]])\n",
      "\u001b[31mType:\u001b[39m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "??np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "94b6f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_matrix[:,-1]=braces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fd823917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        55.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        62.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        69.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        54.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        48.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        47.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        67.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        78.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        53.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        75.]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e3742f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_matrix = np.zeros((10,14))\n",
    "for val in range(10):\n",
    "    for idx, button in enumerate(buttons):\n",
    "        if(val in button):\n",
    "            my_matrix[val,idx] = 1\n",
    "        else:\n",
    "            my_matrix[val,idx] = 0\n",
    "my_matrix[:,-1]=braces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "dcaffb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "536d347b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   0. ,   0. ,  -1.5,  -7. ,  -1. ,   0. , -49.5],\n",
       "       [  0. ,   0. ,   1. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,  -1. ,  -6. ,  -1. ,   0. , -46. ],\n",
       "       [  0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   1. ,   0. ,   1. ,   2. ,   0. ,   0. ,  18. ],\n",
       "       [  0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   2. ,   0. ,   1. ,  19. ],\n",
       "       [  0. ,   1. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,  -0.5,  -2. ,   0. ,   0. ,  -4.5],\n",
       "       [  1. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   3. ,   0. ,   0. ,  25. ],\n",
       "       [  0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   1. ,   2.5,   9. ,   3. ,   0. , 119.5],\n",
       "       [  0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   0. ,   0. ,   0. ,   1. ,   3. ,   1. ,   0. ,  42. ],\n",
       "       [  0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   0.5,   4. ,   1. ,   0. ,  38.5],\n",
       "       [  0. ,   0. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   0. ,   1. ,   2. ,   1. ,   0. ,  47. ]])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "167dac25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(209.0)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(my_matrix[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad387ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize 209-2*x9-9*x10-3*x11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 x9 + 7.0 x10 + 1.0 x11 + -49.5>=0\n",
      "1.0 x9 + 6.0 x10 + 1.0 x11 + -46.0>=0\n",
      "-1.0 x9 + -2.0 x10 + -0.0 x11 + 18.0>=0\n",
      "-0.0 x9 + -2.0 x10 + -0.0 x11 + 19.0>=0\n",
      "0.5 x9 + 2.0 x10 + -0.0 x11 + -4.5>=0\n",
      "-0.0 x9 + -3.0 x10 + -0.0 x11 + 25.0>=0\n",
      "-2.5 x9 + -9.0 x10 + -3.0 x11 + 119.5>=0\n",
      "-1.0 x9 + -3.0 x10 + -1.0 x11 + 42.0>=0\n",
      "-0.5 x9 + -4.0 x10 + -1.0 x11 + 38.5>=0\n",
      "-1.0 x9 + -2.0 x10 + -1.0 x11 + 47.0>=0\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(my_matrix[:,0])):\n",
    "    if(j==1)\n",
    "    for i in range(9,12):\n",
    "        print(f\"{-my_matrix[j,i]} x{i} + \",end='')\n",
    "    print(f\"{my_matrix[j,-1]}>=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432814f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "11aa7461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.8"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "119.5/2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5356c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x10<=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "acf58fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-3.0)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-sum(my_matrix[:,11])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "b9486434",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_matrix[0,:] = my_matrix[0,:]-my_matrix[6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_column(my_matrix,col,base_row):\n",
    "    for row in range(len(my_matrix[:,0])):\n",
    "        if(my_matrix[row,col] == 1 and row != base_row):\n",
    "            my_matrix[row,:-1] = my_matrix[base_row,:-1]\n",
    "            my_matrix[row,-1] = 0\n",
    "    return my_matrix\n",
    "zero_column(my_matrix,0,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9cd4d829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0., 78.])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix[7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f246cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "fixed_rows = []\n",
    "for col in range(len(my_matrix[0,:])):\n",
    "    for row in range(len(my_matrix[:,0])):\n",
    "        if(my_matrix[row,col] == 1 and row not in fixed_rows):\n",
    "            fixed_rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6339ef0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 4 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x732ba13b\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 1e+02]\n",
      "Presolve removed 4 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 128 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.280000000000e+02, best bound 1.280000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 21 nonzeros (Min)\n",
      "Model fingerprint: 0xf2f98cb5\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 3e+01]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 42 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.200000000000e+01, best bound 4.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 11 columns and 48 nonzeros (Min)\n",
      "Model fingerprint: 0x2493e3d1\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 8 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2 rows, 4 columns, 6 nonzeros\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Found heuristic solution: objective 90.0000000\n",
      "Found heuristic solution: objective 80.0000000\n",
      "\n",
      "Root relaxation: cutoff, 0 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "Explored 1 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 80 90 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.000000000000e+01, best bound 8.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 2 columns and 7 nonzeros (Min)\n",
      "Model fingerprint: 0x7d237f1d\n",
      "Model has 2 linear objective coefficients\n",
      "Variable types: 0 continuous, 2 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 9e+00]\n",
      "Presolve removed 4 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 9 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.000000000000e+00, best bound 9.000000000000e+00, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 6 columns and 20 nonzeros (Min)\n",
      "Model fingerprint: 0x1d09ba83\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 6 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 75 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.500000000000e+01, best bound 7.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 8 columns and 41 nonzeros (Min)\n",
      "Model fingerprint: 0xe830c444\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 10 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 101 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.010000000000e+02, best bound 1.010000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 9 columns and 38 nonzeros (Min)\n",
      "Model fingerprint: 0x235b75d4\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 9 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 80 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.000000000000e+01, best bound 8.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 6 columns and 17 nonzeros (Min)\n",
      "Model fingerprint: 0xed5038fc\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 3e+01]\n",
      "Presolve removed 5 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 32 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.200000000000e+01, best bound 3.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 8 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0xad429b35\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 9e+01]\n",
      "Presolve removed 7 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 101 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.010000000000e+02, best bound 1.010000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 9 columns and 50 nonzeros (Min)\n",
      "Model fingerprint: 0x3801ac64\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 2e+02]\n",
      "Presolve removed 10 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 219 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.190000000000e+02, best bound 2.190000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 12 columns and 59 nonzeros (Min)\n",
      "Model fingerprint: 0x68958815\n",
      "Model has 12 linear objective coefficients\n",
      "Variable types: 0 continuous, 12 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 7e+01]\n",
      "Presolve removed 3 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 7 rows, 9 columns, 30 nonzeros\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 9.100000e+01, 8 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      91.0000000   91.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (8 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 91 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.100000000000e+01, best bound 9.100000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 25 nonzeros (Min)\n",
      "Model fingerprint: 0x3f9e657c\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 2e+02]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 186 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.860000000000e+02, best bound 1.860000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 6 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0xcea4797b\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+01]\n",
      "Presolve removed 5 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 59 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.900000000000e+01, best bound 5.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 6 columns and 23 nonzeros (Min)\n",
      "Model fingerprint: 0x3ca2152c\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+01]\n",
      "Presolve removed 8 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 54 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.400000000000e+01, best bound 5.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 9 columns and 39 nonzeros (Min)\n",
      "Model fingerprint: 0x78c1b733\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 2e+02]\n",
      "Presolve removed 8 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 243 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.430000000000e+02, best bound 2.430000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 9 columns and 35 nonzeros (Min)\n",
      "Model fingerprint: 0xfb601463\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 8e+01]\n",
      "Presolve removed 8 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 90 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.000000000000e+01, best bound 9.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 5 columns and 14 nonzeros (Min)\n",
      "Model fingerprint: 0xaee19c44\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 1e+02]\n",
      "Presolve removed 5 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 138 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.380000000000e+02, best bound 1.380000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 7 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0x13f8cf02\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [8e+00, 2e+02]\n",
      "Presolve removed 7 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 245 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.450000000000e+02, best bound 2.450000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 6 columns and 18 nonzeros (Min)\n",
      "Model fingerprint: 0x28a2aec1\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 5 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 64 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.400000000000e+01, best bound 6.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 10 columns and 46 nonzeros (Min)\n",
      "Model fingerprint: 0xfd7fba33\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 1e+02]\n",
      "Presolve removed 10 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 127 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.270000000000e+02, best bound 1.270000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 24 nonzeros (Min)\n",
      "Model fingerprint: 0xc8a77478\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 4e+01]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 50 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.000000000000e+01, best bound 5.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 8 columns and 36 nonzeros (Min)\n",
      "Model fingerprint: 0x50dfb3ae\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+01]\n",
      "Presolve removed 9 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 59 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.900000000000e+01, best bound 5.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 7 columns and 28 nonzeros (Min)\n",
      "Model fingerprint: 0x84e4fb0e\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 8 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 88 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.800000000000e+01, best bound 8.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 5 columns and 18 nonzeros (Min)\n",
      "Model fingerprint: 0xfca1d461\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [9e+00, 3e+01]\n",
      "Presolve removed 6 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 34 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.400000000000e+01, best bound 3.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 2 columns and 5 nonzeros (Min)\n",
      "Model fingerprint: 0x05b14f76\n",
      "Model has 2 linear objective coefficients\n",
      "Variable types: 0 continuous, 2 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+00, 2e+02]\n",
      "Presolve removed 4 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 160 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.600000000000e+02, best bound 1.600000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 3 columns and 7 nonzeros (Min)\n",
      "Model fingerprint: 0x20f6a693\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 1e+02]\n",
      "Presolve removed 4 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 163 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.630000000000e+02, best bound 1.630000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 10 columns and 72 nonzeros (Min)\n",
      "Model fingerprint: 0xdb04f0af\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 1e+02]\n",
      "Presolve removed 10 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 108 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.080000000000e+02, best bound 1.080000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 9 columns and 31 nonzeros (Min)\n",
      "Model fingerprint: 0x8eaa220c\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 8e+01]\n",
      "Presolve removed 7 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 101 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.010000000000e+02, best bound 1.010000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 8 columns and 34 nonzeros (Min)\n",
      "Model fingerprint: 0xb8071335\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 8 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 69 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.900000000000e+01, best bound 6.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 4 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0xea2b6d70\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 1e+02]\n",
      "Presolve removed 5 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 127 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.270000000000e+02, best bound 1.270000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 5 columns and 15 nonzeros (Min)\n",
      "Model fingerprint: 0x4a8ebb7e\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 6e+01]\n",
      "Presolve removed 6 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 69 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.900000000000e+01, best bound 6.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 5 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0xe0d729a3\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+01]\n",
      "Presolve removed 4 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 57 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.700000000000e+01, best bound 5.700000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 4 columns and 5 nonzeros (Min)\n",
      "Model fingerprint: 0x0bacdcbc\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 2e+02]\n",
      "Presolve removed 4 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 233 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.330000000000e+02, best bound 2.330000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 7 columns and 21 nonzeros (Min)\n",
      "Model fingerprint: 0xfe51af15\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [7e+00, 4e+01]\n",
      "Presolve removed 6 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 52 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.200000000000e+01, best bound 5.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 4 columns and 9 nonzeros (Min)\n",
      "Model fingerprint: 0xddf9a4e4\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 3e+01]\n",
      "Presolve removed 5 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 47 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.700000000000e+01, best bound 4.700000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 29 nonzeros (Min)\n",
      "Model fingerprint: 0x20146e01\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 51 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.100000000000e+01, best bound 5.100000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 7 columns and 22 nonzeros (Min)\n",
      "Model fingerprint: 0x33c110e3\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 4e+01]\n",
      "Presolve removed 6 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 49 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.900000000000e+01, best bound 4.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 9 columns and 41 nonzeros (Min)\n",
      "Model fingerprint: 0x4a0ff1a4\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 6e+01]\n",
      "Presolve removed 9 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 64 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.400000000000e+01, best bound 6.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 5 columns and 15 nonzeros (Min)\n",
      "Model fingerprint: 0xbbe22021\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 4e+01]\n",
      "Presolve removed 6 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 44 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.400000000000e+01, best bound 4.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 6 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x8bcf7399\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 3e+01]\n",
      "Presolve removed 4 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 52 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.200000000000e+01, best bound 5.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 6 columns and 16 nonzeros (Min)\n",
      "Model fingerprint: 0x447c3c2b\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 5 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.04 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 69 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.900000000000e+01, best bound 6.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 4 columns and 14 nonzeros (Min)\n",
      "Model fingerprint: 0xf3a47f8d\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 2e+02]\n",
      "Presolve removed 6 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 215 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.150000000000e+02, best bound 2.150000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 11 columns and 45 nonzeros (Min)\n",
      "Model fingerprint: 0x055e50fd\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [7e+00, 3e+02]\n",
      "Found heuristic solution: objective 313.0000000\n",
      "Presolve removed 9 rows and 11 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 307 313 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.070000000000e+02, best bound 3.070000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 8 columns and 37 nonzeros (Min)\n",
      "Model fingerprint: 0x3463c9fe\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 2e+02]\n",
      "Presolve removed 10 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 249 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.490000000000e+02, best bound 2.490000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 9 columns and 49 nonzeros (Min)\n",
      "Model fingerprint: 0xa4389dfc\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 8e+01]\n",
      "Presolve removed 10 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 106 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.060000000000e+02, best bound 1.060000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 7 columns and 17 nonzeros (Min)\n",
      "Model fingerprint: 0xea19b39d\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 2e+02]\n",
      "Presolve removed 5 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 185 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.850000000000e+02, best bound 1.850000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 9 columns and 25 nonzeros (Min)\n",
      "Model fingerprint: 0x530e28b2\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 7 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 84 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.400000000000e+01, best bound 8.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 9 columns and 42 nonzeros (Min)\n",
      "Model fingerprint: 0xfc5a6bb8\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+01, 6e+01]\n",
      "Presolve removed 9 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 95 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.500000000000e+01, best bound 9.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 10 columns and 46 nonzeros (Min)\n",
      "Model fingerprint: 0xcaf2c061\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 1 rows and 0 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 8 rows, 10 columns, 34 nonzeros\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 8.800000e+01, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      88.0000000   88.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (7 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 88 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.800000000000e+01, best bound 8.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 5 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x71f780fb\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 3e+01]\n",
      "Presolve removed 4 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 38 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.800000000000e+01, best bound 3.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 4 columns and 8 nonzeros (Min)\n",
      "Model fingerprint: 0xbbdadcc2\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 2e+02]\n",
      "Presolve removed 4 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 186 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.860000000000e+02, best bound 1.860000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 4 columns and 8 nonzeros (Min)\n",
      "Model fingerprint: 0x85159a06\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 7e+00]\n",
      "Presolve removed 4 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 11 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.100000000000e+01, best bound 1.100000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 5 columns and 9 nonzeros (Min)\n",
      "Model fingerprint: 0xdc56b8cc\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+01]\n",
      "Presolve removed 4 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 65 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.500000000000e+01, best bound 6.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 12 columns and 50 nonzeros (Min)\n",
      "Model fingerprint: 0x0b11598e\n",
      "Model has 12 linear objective coefficients\n",
      "Variable types: 0 continuous, 12 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 8e+01]\n",
      "Found heuristic solution: objective 189.0000000\n",
      "Presolve removed 10 rows and 12 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.05 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 132 189 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.320000000000e+02, best bound 1.320000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 8 columns and 23 nonzeros (Min)\n",
      "Model fingerprint: 0x248b1e71\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 9e+01]\n",
      "Presolve removed 4 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2 rows, 4 columns, 6 nonzeros\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Found heuristic solution: objective 122.0000000\n",
      "Found heuristic solution: objective 121.0000000\n",
      "Found heuristic solution: objective 118.0000000\n",
      "Found heuristic solution: objective 117.0000000\n",
      "\n",
      "Root relaxation: objective 1.040000e+02, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     104.0000000  104.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 5: 104 117 118 ... 122\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.040000000000e+02, best bound 1.040000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 7 columns and 32 nonzeros (Min)\n",
      "Model fingerprint: 0x4a517d56\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 9 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 64 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.400000000000e+01, best bound 6.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 10 columns and 47 nonzeros (Min)\n",
      "Model fingerprint: 0xe1947fe6\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 1e+02]\n",
      "Presolve removed 10 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 140 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.400000000000e+02, best bound 1.400000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 3 columns and 11 nonzeros (Min)\n",
      "Model fingerprint: 0x8899692f\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 2e+02]\n",
      "Presolve removed 5 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 200 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+02, best bound 2.000000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 7 columns and 29 nonzeros (Min)\n",
      "Model fingerprint: 0x8cca4ad0\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 9 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 62 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.200000000000e+01, best bound 6.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 3 columns and 9 nonzeros (Min)\n",
      "Model fingerprint: 0x0ec00104\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+00, 2e+01]\n",
      "Presolve removed 5 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 25 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.500000000000e+01, best bound 2.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 7 columns and 28 nonzeros (Min)\n",
      "Model fingerprint: 0x2f68dff3\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 4e+01]\n",
      "Presolve removed 9 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 66 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.600000000000e+01, best bound 6.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 9 columns and 35 nonzeros (Min)\n",
      "Model fingerprint: 0xd43a01c4\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 8 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 93 93 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.300000000000e+01, best bound 9.300000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 7 columns and 33 nonzeros (Min)\n",
      "Model fingerprint: 0x3388f15e\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 4e+01]\n",
      "Presolve removed 8 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 41 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.100000000000e+01, best bound 4.100000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 8 columns and 36 nonzeros (Min)\n",
      "Model fingerprint: 0xaa270d76\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 6e+01]\n",
      "Presolve removed 8 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 82 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.200000000000e+01, best bound 8.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 5 columns and 9 nonzeros (Min)\n",
      "Model fingerprint: 0xf7d461df\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+00, 6e+01]\n",
      "Presolve removed 4 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 55 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.500000000000e+01, best bound 5.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 8 columns and 23 nonzeros (Min)\n",
      "Model fingerprint: 0xa9fa8705\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 7e+01]\n",
      "Presolve removed 6 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 74 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.400000000000e+01, best bound 7.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 10 columns and 34 nonzeros (Min)\n",
      "Model fingerprint: 0xec346a4b\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 4e+01]\n",
      "Presolve removed 8 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 62 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.200000000000e+01, best bound 6.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 13 columns and 64 nonzeros (Min)\n",
      "Model fingerprint: 0xd2abad6d\n",
      "Model has 13 linear objective coefficients\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 8e+01]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 10 rows, 13 columns, 64 nonzeros\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.010435e+02, 10 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  101.04348    0   10          -  101.04348      -     -    0s\n",
      "H    0     0                     141.0000000  101.04348  28.3%     -    0s\n",
      "H    0     0                     108.0000000  101.04348  6.44%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "\n",
      "Explored 1 nodes (10 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 108 141 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.080000000000e+02, best bound 1.080000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 5 columns and 19 nonzeros (Min)\n",
      "Model fingerprint: 0x94db57c6\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 7 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 79 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.900000000000e+01, best bound 7.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 10 columns and 39 nonzeros (Min)\n",
      "Model fingerprint: 0xe8f95d6a\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 1e+02]\n",
      "Presolve removed 8 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 105 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.050000000000e+02, best bound 1.050000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 8 columns and 35 nonzeros (Min)\n",
      "Model fingerprint: 0xd0f64346\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 6e+01]\n",
      "Presolve removed 9 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 77 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.700000000000e+01, best bound 7.700000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 3 columns and 7 nonzeros (Min)\n",
      "Model fingerprint: 0x5567fd24\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 3e+01]\n",
      "Presolve removed 4 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 36 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.600000000000e+01, best bound 3.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 26 nonzeros (Min)\n",
      "Model fingerprint: 0x0e906fe2\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 52 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.200000000000e+01, best bound 5.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 6 columns and 19 nonzeros (Min)\n",
      "Model fingerprint: 0x096f440e\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 6 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 65 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.500000000000e+01, best bound 6.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 8 columns and 30 nonzeros (Min)\n",
      "Model fingerprint: 0xde095ea1\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 8 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 93 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.300000000000e+01, best bound 9.300000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 6 columns and 14 nonzeros (Min)\n",
      "Model fingerprint: 0xd7671ae6\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+00, 4e+01]\n",
      "Presolve removed 6 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 50 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.000000000000e+01, best bound 5.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 8 columns and 20 nonzeros (Min)\n",
      "Model fingerprint: 0xdeadf1c0\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 8e+01]\n",
      "Presolve removed 6 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 89 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.900000000000e+01, best bound 8.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 5 columns and 22 nonzeros (Min)\n",
      "Model fingerprint: 0xe393726d\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 4e+01]\n",
      "Presolve removed 7 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 41 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.100000000000e+01, best bound 4.100000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 6 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0xbc850553\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 2e+02]\n",
      "Presolve removed 4 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 195 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.950000000000e+02, best bound 1.950000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 9 columns and 28 nonzeros (Min)\n",
      "Model fingerprint: 0xc03c30a1\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 1e+02]\n",
      "Presolve removed 8 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 177 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.770000000000e+02, best bound 1.770000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 11 columns and 56 nonzeros (Min)\n",
      "Model fingerprint: 0x6b7ebc77\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 7e+01]\n",
      "Presolve removed 10 rows and 11 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 96 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.600000000000e+01, best bound 9.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 11 columns and 48 nonzeros (Min)\n",
      "Model fingerprint: 0xac0fe531\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 7e+01]\n",
      "Presolve removed 2 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 8 rows, 9 columns, 31 nonzeros\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.160000e+02, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     116.0000000  116.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (7 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 116 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.160000000000e+02, best bound 1.160000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 6 columns and 24 nonzeros (Min)\n",
      "Model fingerprint: 0x9966a343\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 6e+01]\n",
      "Presolve removed 8 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 63 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.300000000000e+01, best bound 6.300000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 5 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0x96aa2020\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+00, 2e+02]\n",
      "Presolve removed 5 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 211 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.110000000000e+02, best bound 2.110000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 8 columns and 26 nonzeros (Min)\n",
      "Model fingerprint: 0x405fcdda\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 6 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 68 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.800000000000e+01, best bound 6.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 7 columns and 21 nonzeros (Min)\n",
      "Model fingerprint: 0x726c5eae\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 7e+01]\n",
      "Presolve removed 7 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 85 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.500000000000e+01, best bound 8.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 9 columns and 47 nonzeros (Min)\n",
      "Model fingerprint: 0xf33ab93c\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [7e+00, 2e+02]\n",
      "Presolve removed 10 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 223 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.230000000000e+02, best bound 2.230000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 5 columns and 19 nonzeros (Min)\n",
      "Model fingerprint: 0x2fcfdf24\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 7 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 56 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.600000000000e+01, best bound 5.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 7 columns and 25 nonzeros (Min)\n",
      "Model fingerprint: 0x3fd1ef4c\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 5e+01]\n",
      "Presolve removed 8 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 58 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.800000000000e+01, best bound 5.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 5 columns and 16 nonzeros (Min)\n",
      "Model fingerprint: 0xbce41542\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+01]\n",
      "Presolve removed 6 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 47 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.700000000000e+01, best bound 4.700000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 6 columns and 19 nonzeros (Min)\n",
      "Model fingerprint: 0xbdfce113\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [8e+00, 3e+01]\n",
      "Presolve removed 8 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 40 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.000000000000e+01, best bound 4.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 2 columns and 6 nonzeros (Min)\n",
      "Model fingerprint: 0x6d8d4909\n",
      "Model has 2 linear objective coefficients\n",
      "Variable types: 0 continuous, 2 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 7e+00]\n",
      "Presolve removed 4 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 7 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.000000000000e+00, best bound 7.000000000000e+00, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 8 columns and 30 nonzeros (Min)\n",
      "Model fingerprint: 0xcc1574ad\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 8 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 80 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.000000000000e+01, best bound 8.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 6 columns and 16 nonzeros (Min)\n",
      "Model fingerprint: 0xb2919470\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 3e+01]\n",
      "Presolve removed 5 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 30 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.000000000000e+01, best bound 3.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 8 columns and 42 nonzeros (Min)\n",
      "Model fingerprint: 0x33ef3c84\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 10 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 74 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.400000000000e+01, best bound 7.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 9 columns and 43 nonzeros (Min)\n",
      "Model fingerprint: 0x35be5db4\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+01, 7e+01]\n",
      "Presolve removed 9 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 103 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.030000000000e+02, best bound 1.030000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 6 columns and 16 nonzeros (Min)\n",
      "Model fingerprint: 0xc5649065\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 4e+01]\n",
      "Presolve removed 3 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2 rows, 4 columns, 6 nonzeros\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Found heuristic solution: objective 65.0000000\n",
      "\n",
      "Root relaxation: objective 5.200000e+01, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      52.0000000   52.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 52 65 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.200000000000e+01, best bound 5.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 9 columns and 33 nonzeros (Min)\n",
      "Model fingerprint: 0x7eda1a78\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 5e+01]\n",
      "Presolve removed 3 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 4 rows, 6 columns, 14 nonzeros\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Found heuristic solution: objective 70.0000000\n",
      "\n",
      "Root relaxation: objective 6.400000e+01, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      64.0000000   64.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 64 70 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.400000000000e+01, best bound 6.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 3 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x4e494ff6\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [9e+00, 2e+01]\n",
      "Presolve removed 5 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 19 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.900000000000e+01, best bound 1.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 12 columns and 55 nonzeros (Min)\n",
      "Model fingerprint: 0xf1b7a3cd\n",
      "Model has 12 linear objective coefficients\n",
      "Variable types: 0 continuous, 12 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 9e+01]\n",
      "Presolve removed 1 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 9 rows, 11 columns, 44 nonzeros\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.372727e+02, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  137.27273    0    8          -  137.27273      -     -    0s\n",
      "H    0     0                     138.0000000  137.27273  0.53%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "\n",
      "Explored 1 nodes (7 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 138 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.380000000000e+02, best bound 1.380000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 8 columns and 41 nonzeros (Min)\n",
      "Model fingerprint: 0x409d1ca6\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 6e+01]\n",
      "Presolve removed 10 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 98 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.800000000000e+01, best bound 9.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 2 columns and 6 nonzeros (Min)\n",
      "Model fingerprint: 0xd71cfe0c\n",
      "Model has 2 linear objective coefficients\n",
      "Variable types: 0 continuous, 2 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 3e+01]\n",
      "Presolve removed 4 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 26 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.600000000000e+01, best bound 2.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 4 columns and 13 nonzeros (Min)\n",
      "Model fingerprint: 0xf74e1b44\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 2e+02]\n",
      "Presolve removed 6 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 196 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.960000000000e+02, best bound 1.960000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 6 columns and 21 nonzeros (Min)\n",
      "Model fingerprint: 0x30dff9a5\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 4e+01]\n",
      "Presolve removed 6 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 53 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.300000000000e+01, best bound 5.300000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 24 nonzeros (Min)\n",
      "Model fingerprint: 0x9882f19c\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+01]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 65 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.500000000000e+01, best bound 6.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 8 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0x570d4fe2\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 8e+01]\n",
      "Presolve removed 7 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 112 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.120000000000e+02, best bound 1.120000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 7 columns and 23 nonzeros (Min)\n",
      "Model fingerprint: 0x5d5e0c1d\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 4e+01]\n",
      "Presolve removed 7 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 60 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.000000000000e+01, best bound 6.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 9 columns and 44 nonzeros (Min)\n",
      "Model fingerprint: 0x2c90fdca\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 10 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 114 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.140000000000e+02, best bound 1.140000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 8 columns and 35 nonzeros (Min)\n",
      "Model fingerprint: 0x6b709ce4\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 8e+01]\n",
      "Presolve removed 8 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 94 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.400000000000e+01, best bound 9.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 6 columns and 25 nonzeros (Min)\n",
      "Model fingerprint: 0x25f911c8\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+00, 4e+01]\n",
      "Presolve removed 8 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 48 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.800000000000e+01, best bound 4.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 4 columns and 8 nonzeros (Min)\n",
      "Model fingerprint: 0x3c3dd816\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 4 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 54 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.400000000000e+01, best bound 5.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 10 columns and 41 nonzeros (Min)\n",
      "Model fingerprint: 0x941426a9\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 9e+01]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 8 rows, 10 columns, 37 nonzeros\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 8.800000e+01, 5 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   88.00000    0    6          -   88.00000      -     -    0s\n",
      "H    0     0                      88.0000000   88.00000  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  Mod-K: 1\n",
      "\n",
      "Explored 1 nodes (5 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 88 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.800000000000e+01, best bound 8.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 8 columns and 37 nonzeros (Min)\n",
      "Model fingerprint: 0xf6838382\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 2e+02]\n",
      "Presolve removed 9 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 233 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.330000000000e+02, best bound 2.330000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 3 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x001c39e7\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+02, 2e+02]\n",
      "Presolve removed 5 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 159 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.590000000000e+02, best bound 1.590000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 5 columns and 14 nonzeros (Min)\n",
      "Model fingerprint: 0xf92fc9b3\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 6e+01]\n",
      "Presolve removed 5 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 79 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.900000000000e+01, best bound 7.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 5 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x4e2d9562\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+01]\n",
      "Presolve removed 4 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 58 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.800000000000e+01, best bound 5.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 10 columns and 51 nonzeros (Min)\n",
      "Model fingerprint: 0xac7cce86\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [8e+00, 5e+01]\n",
      "Presolve removed 9 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 66 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.600000000000e+01, best bound 6.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 11 columns and 52 nonzeros (Min)\n",
      "Model fingerprint: 0x6fea2809\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 2e+02]\n",
      "Presolve removed 10 rows and 11 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 283 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.830000000000e+02, best bound 2.830000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 13 columns and 59 nonzeros (Min)\n",
      "Model fingerprint: 0x841ea7d7\n",
      "Model has 13 linear objective coefficients\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 1e+02]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 10 rows, 13 columns, 45 nonzeros\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.343333e+02, 9 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  134.33333    0    7          -  134.33333      -     -    0s\n",
      "H    0     0                     138.0000000  134.33333  2.66%     -    0s\n",
      "H    0     0                     136.0000000  134.33333  1.23%     -    0s\n",
      "H    0     0                     135.0000000  134.33333  0.49%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "\n",
      "Explored 1 nodes (9 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 3: 135 136 138 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.350000000000e+02, best bound 1.350000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 11 columns and 62 nonzeros (Min)\n",
      "Model fingerprint: 0xb298f429\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+01, 9e+01]\n",
      "Presolve removed 2 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 8 rows, 10 columns, 46 nonzeros\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.030000e+02, 9 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     103.0000000  103.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (9 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 103 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.030000000000e+02, best bound 1.030000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 10 columns and 31 nonzeros (Min)\n",
      "Model fingerprint: 0x0a0c4c68\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 8 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 114 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.140000000000e+02, best bound 1.140000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 8 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0xb4f42bc6\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+01, 7e+01]\n",
      "Presolve removed 7 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 111 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.110000000000e+02, best bound 1.110000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 4 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x5cdb6b7e\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+00, 3e+01]\n",
      "Presolve removed 5 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 37 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.700000000000e+01, best bound 3.700000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 8 columns and 39 nonzeros (Min)\n",
      "Model fingerprint: 0x5c902d03\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 1e+02]\n",
      "Presolve removed 10 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 127 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.270000000000e+02, best bound 1.270000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 13 columns and 57 nonzeros (Min)\n",
      "Model fingerprint: 0x381f2911\n",
      "Model has 13 linear objective coefficients\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 2e+02]\n",
      "Presolve removed 2 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 8 rows, 11 columns, 40 nonzeros\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 2.570000e+02, 9 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     257.0000000  257.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (9 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 257 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.570000000000e+02, best bound 2.570000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 3 columns and 7 nonzeros (Min)\n",
      "Model fingerprint: 0x8af35c2e\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 4 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 49 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.900000000000e+01, best bound 4.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 7 columns and 30 nonzeros (Min)\n",
      "Model fingerprint: 0xcdb78108\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 7e+01]\n",
      "Presolve removed 7 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 70 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.000000000000e+01, best bound 7.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 10 columns and 44 nonzeros (Min)\n",
      "Model fingerprint: 0x67f086c1\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 1 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 8 rows, 9 columns, 34 nonzeros\n",
      "Variable types: 0 continuous, 9 integer (1 binary)\n",
      "Found heuristic solution: objective 103.0000000\n",
      "\n",
      "Root relaxation: infeasible, 3 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 infeasible    0       103.00000  103.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (3 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 103 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.030000000000e+02, best bound 1.030000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 6 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0xfed9de64\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [9e+00, 3e+01]\n",
      "Presolve removed 4 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 36 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.600000000000e+01, best bound 3.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 3 columns and 7 nonzeros (Min)\n",
      "Model fingerprint: 0x35471866\n",
      "Model has 3 linear objective coefficients\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 2e+01]\n",
      "Presolve removed 4 rows and 3 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 26 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.600000000000e+01, best bound 2.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 10 columns and 36 nonzeros (Min)\n",
      "Model fingerprint: 0x4ff1a013\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [8e+00, 5e+01]\n",
      "Presolve removed 10 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 88 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.800000000000e+01, best bound 8.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 13 columns and 70 nonzeros (Min)\n",
      "Model fingerprint: 0xecd71b15\n",
      "Model has 13 linear objective coefficients\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+01, 1e+02]\n",
      "Presolve removed 1 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 9 rows, 12 columns, 49 nonzeros\n",
      "Variable types: 0 continuous, 12 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.435000e+02, 11 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  143.50000    0    6          -  143.50000      -     -    0s\n",
      "H    0     0                     147.0000000  143.50000  2.38%     -    0s\n",
      "H    0     0                     145.0000000  143.50000  1.03%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "\n",
      "Explored 1 nodes (11 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 145 147 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.450000000000e+02, best bound 1.450000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 4 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0x7f97777e\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 3e+01]\n",
      "Presolve removed 5 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 39 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.900000000000e+01, best bound 3.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 8 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0x18b496c6\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 9 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 107 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.070000000000e+02, best bound 1.070000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 17 nonzeros (Min)\n",
      "Model fingerprint: 0xdf59cb5b\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 6e+01]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 80 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.000000000000e+01, best bound 8.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 8 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0x15e13ab3\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 8 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 76 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.600000000000e+01, best bound 7.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 5 columns and 13 nonzeros (Min)\n",
      "Model fingerprint: 0x2eb7ef7a\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+00, 2e+02]\n",
      "Presolve removed 5 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 161 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.610000000000e+02, best bound 1.610000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 8 columns and 29 nonzeros (Min)\n",
      "Model fingerprint: 0xc26ade44\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 1e+02]\n",
      "Presolve removed 7 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 100 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000000000000e+02, best bound 1.000000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 6 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0xd241b1de\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+01, 2e+02]\n",
      "Presolve removed 4 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 171 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.710000000000e+02, best bound 1.710000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 4 columns and 13 nonzeros (Min)\n",
      "Model fingerprint: 0x87df301b\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [9e+00, 4e+01]\n",
      "Presolve removed 6 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 48 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.800000000000e+01, best bound 4.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 6 columns and 12 nonzeros (Min)\n",
      "Model fingerprint: 0x5e4b916a\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 2 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2 rows, 4 columns, 6 nonzeros\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Found heuristic solution: objective 98.0000000\n",
      "Found heuristic solution: objective 96.0000000\n",
      "Found heuristic solution: objective 79.0000000\n",
      "Found heuristic solution: objective 76.0000000\n",
      "\n",
      "Root relaxation: objective 5.300000e+01, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      53.0000000   53.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 5: 53 76 79 ... 98\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.300000000000e+01, best bound 5.300000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 11 columns and 49 nonzeros (Min)\n",
      "Model fingerprint: 0x9e61d320\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 2e+02]\n",
      "Presolve removed 7 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2 rows, 3 columns, 5 nonzeros\n",
      "Variable types: 0 continuous, 3 integer (0 binary)\n",
      "Found heuristic solution: objective 225.0000000\n",
      "Found heuristic solution: objective 223.0000000\n",
      "Found heuristic solution: objective 221.0000000\n",
      "Found heuristic solution: objective 219.0000000\n",
      "Found heuristic solution: objective 217.0000000\n",
      "\n",
      "Root relaxation: objective 2.150000e+02, 0 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     215.0000000  215.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 6: 215 217 219 ... 225\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.150000000000e+02, best bound 2.150000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 7 columns and 39 nonzeros (Min)\n",
      "Model fingerprint: 0xc5c9ed36\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 6e+01]\n",
      "Presolve removed 8 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 64 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.400000000000e+01, best bound 6.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 11 columns and 47 nonzeros (Min)\n",
      "Model fingerprint: 0xab87e13b\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 2e+02]\n",
      "Presolve removed 1 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 8 rows, 10 columns, 35 nonzeros\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 2.440000e+02, 9 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     244.0000000  244.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (9 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 244 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.440000000000e+02, best bound 2.440000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 7 columns and 28 nonzeros (Min)\n",
      "Model fingerprint: 0xa000270e\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 8 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 80 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.000000000000e+01, best bound 8.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 8 rows, 6 columns and 24 nonzeros (Min)\n",
      "Model fingerprint: 0x43c0e4cb\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 8 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 96 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.600000000000e+01, best bound 9.600000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 7 columns and 23 nonzeros (Min)\n",
      "Model fingerprint: 0xb64b1290\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 7 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 62 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.200000000000e+01, best bound 6.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 9 columns and 25 nonzeros (Min)\n",
      "Model fingerprint: 0xab7aa9cc\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 7 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 102 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.020000000000e+02, best bound 1.020000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 2 columns and 5 nonzeros (Min)\n",
      "Model fingerprint: 0x658ae603\n",
      "Model has 2 linear objective coefficients\n",
      "Variable types: 0 continuous, 2 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 2e+01]\n",
      "Presolve removed 4 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 24 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.400000000000e+01, best bound 2.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 11 columns and 50 nonzeros (Min)\n",
      "Model fingerprint: 0xfb09bcc3\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 1e+02]\n",
      "Presolve removed 7 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2 rows, 4 columns, 6 nonzeros\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Found heuristic solution: objective 123.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 123 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.230000000000e+02, best bound 1.230000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 11 columns and 46 nonzeros (Min)\n",
      "Model fingerprint: 0xf81c37a2\n",
      "Model has 11 linear objective coefficients\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 8e+01]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 9 rows, 11 columns, 40 nonzeros\n",
      "Variable types: 0 continuous, 11 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.050000e+02, 8 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     105.0000000  105.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (8 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 105 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.050000000000e+02, best bound 1.050000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 7 columns and 18 nonzeros (Min)\n",
      "Model fingerprint: 0x3e241c57\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 6e+01]\n",
      "Presolve removed 5 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 57 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.700000000000e+01, best bound 5.700000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 9 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0x2455fab1\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 7 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 65 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.500000000000e+01, best bound 6.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 6 columns and 23 nonzeros (Min)\n",
      "Model fingerprint: 0x68062090\n",
      "Model has 6 linear objective coefficients\n",
      "Variable types: 0 continuous, 6 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 6e+01]\n",
      "Presolve removed 7 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 70 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.000000000000e+01, best bound 7.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 7 columns and 33 nonzeros (Min)\n",
      "Model fingerprint: 0xe9660a07\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+01]\n",
      "Presolve removed 9 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 72 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.200000000000e+01, best bound 7.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 7 columns and 19 nonzeros (Min)\n",
      "Model fingerprint: 0x0f514681\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 5e+01]\n",
      "Presolve removed 2 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 3 rows, 5 columns, 9 nonzeros\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Found heuristic solution: objective 67.0000000\n",
      "Found heuristic solution: objective 66.0000000\n",
      "Found heuristic solution: objective 65.0000000\n",
      "\n",
      "Root relaxation: objective 6.400000e+01, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      64.0000000   64.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 4: 64 65 66 67 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.400000000000e+01, best bound 6.400000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 10 columns and 38 nonzeros (Min)\n",
      "Model fingerprint: 0x57a04e43\n",
      "Model has 10 linear objective coefficients\n",
      "Variable types: 0 continuous, 10 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [9e+00, 6e+01]\n",
      "Presolve removed 9 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 89 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.900000000000e+01, best bound 8.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 8 columns and 26 nonzeros (Min)\n",
      "Model fingerprint: 0x31e9aadf\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 0 continuous, 8 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 8e+01]\n",
      "Presolve removed 6 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 83 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.300000000000e+01, best bound 8.300000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 9 columns and 44 nonzeros (Min)\n",
      "Model fingerprint: 0x61734f05\n",
      "Model has 9 linear objective coefficients\n",
      "Variable types: 0 continuous, 9 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 1e+02]\n",
      "Presolve removed 9 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 104 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.040000000000e+02, best bound 1.040000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 7 columns and 24 nonzeros (Min)\n",
      "Model fingerprint: 0xdec0fb8e\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 4e+01]\n",
      "Presolve removed 6 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 50 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.000000000000e+01, best bound 5.000000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 7 columns and 19 nonzeros (Min)\n",
      "Model fingerprint: 0x07f8277d\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 1e+02]\n",
      "Presolve removed 6 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 177 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.770000000000e+02, best bound 1.770000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 7 rows, 5 columns and 18 nonzeros (Min)\n",
      "Model fingerprint: 0x159e0819\n",
      "Model has 5 linear objective coefficients\n",
      "Variable types: 0 continuous, 5 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 5e+01]\n",
      "Presolve removed 7 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 59 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.900000000000e+01, best bound 5.900000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 9 rows, 7 columns and 36 nonzeros (Min)\n",
      "Model fingerprint: 0xc9f10eb5\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 2e+02]\n",
      "Presolve removed 9 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 229 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.290000000000e+02, best bound 2.290000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 5 rows, 7 columns and 16 nonzeros (Min)\n",
      "Model fingerprint: 0xe233309c\n",
      "Model has 7 linear objective coefficients\n",
      "Variable types: 0 continuous, 7 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 4e+01]\n",
      "Presolve removed 5 rows and 7 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 62 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.200000000000e+01, best bound 6.200000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 13 columns and 79 nonzeros (Min)\n",
      "Model fingerprint: 0x04b45805\n",
      "Model has 13 linear objective coefficients\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+01, 8e+01]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 10 rows, 13 columns, 69 nonzeros\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 9.450000e+01, 14 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   94.50000    0    7          -   94.50000      -     -    0s\n",
      "H    0     0                      98.0000000   94.50000  3.57%     -    0s\n",
      "H    0     0                      95.0000000   94.50000  0.53%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "\n",
      "Explored 1 nodes (14 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 2: 95 98 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.500000000000e+01, best bound 9.500000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 6 rows, 4 columns and 14 nonzeros (Min)\n",
      "Model fingerprint: 0x0530b4a4\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 6e+01]\n",
      "Presolve removed 6 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 58 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.800000000000e+01, best bound 5.800000000000e+01, gap 0.0000%\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 10 rows, 12 columns and 48 nonzeros (Min)\n",
      "Model fingerprint: 0x5cd3f455\n",
      "Model has 12 linear objective coefficients\n",
      "Variable types: 0 continuous, 12 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 2e+02]\n",
      "Presolve removed 7 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 3 rows, 4 columns, 9 nonzeros\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Found heuristic solution: objective 291.0000000\n",
      "Found heuristic solution: objective 287.0000000\n",
      "\n",
      "Root relaxation: objective 2.782000e+02, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  278.20000    0    3  287.00000  278.20000  3.07%     -    0s\n",
      "H    0     0                     279.0000000  278.20000  0.29%     -    0s\n",
      "     0     0  278.20000    0    3  279.00000  278.20000  0.29%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 14 (of 14 available processors)\n",
      "\n",
      "Solution count 3: 279 287 291 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.790000000000e+02, best bound 2.790000000000e+02, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "idx_check = -1\n",
    "for line in input_str.split('\\n'):\n",
    "    for character in line.split(']')[0][1:]:\n",
    "        if(character == '.'):\n",
    "            on_off.append(0)\n",
    "        else:\n",
    "            on_off.append(1)\n",
    "        buttons = []\n",
    "    for mystr in line.split(']')[1].split():\n",
    "        if(mystr[0] == '('):\n",
    "            buttons.append(list(map(int,mystr[1:-1].split(','))))\n",
    "        else:\n",
    "            braces= list(map(int,mystr[1:-1].split(',')))\n",
    "    m = gp.Model()\n",
    "\n",
    "    x=m.addVars(len(buttons),vtype=gp.GRB.INTEGER,lb=0)\n",
    "\n",
    "    expr = x[0]\n",
    "    for val in x:\n",
    "        if(val != 0):\n",
    "            expr += x[val]\n",
    "\n",
    "    m.setObjective(expr,gp.GRB.MINIMIZE)\n",
    "    for val in range(len(braces)):\n",
    "        construct = None\n",
    "        for idx,button in enumerate(buttons):\n",
    "            if(val in button):\n",
    "                if(construct is None):\n",
    "                    construct = x[idx]\n",
    "                else:\n",
    "                    construct += x[idx]\n",
    "        m.addConstr(construct==braces[val])\n",
    "\n",
    "    m.optimize()\n",
    "    tot+=m.ObjVal\n",
    "\n",
    "    if m.status == gp.GRB.OPTIMAL:\n",
    "        pass\n",
    "        # print(\"Optimal solution found!\")\n",
    "        # print(\"Objective value:\", m.objVal)\n",
    "        # for v in m.getVars():\n",
    "        #     print(f\"{v.varName} = {v.x}\") # Access variable name and value\n",
    "    else:\n",
    "        print(\"Optimal solution not found.\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b5249b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16386.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "164b0b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3], [0, 2, 3], [1, 3], [0, 1, 3]]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1bf13cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[117, 15, 2, 128]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "braces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ddfb8f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gurobipy\n",
      "  Downloading gurobipy-13.0.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (16 kB)\n",
      "Downloading gurobipy-13.0.0-cp312-cp312-macosx_10_13_universal2.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gurobipy\n",
      "Successfully installed gurobipy-13.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab65b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m gp.TempConstr(lhs, sense, rhs)\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Gurobi temporary constraint object.  Objects of this class are created\n",
      "as intermediate results when building constraints using overloaded\n",
      "operators.\n",
      "\u001b[31mFile:\u001b[39m           /opt/homebrew/anaconda3/envs/test_env/lib/python3.12/site-packages/gurobipy/_core.cpython-312-darwin.so\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d30329",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = x[0]\n",
    "for val in x:\n",
    "    if(val != 0):\n",
    "        expr += x[val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "77d23432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.LinExpr: <gurobi.Var *Awaiting Model Update*> + <gurobi.Var *Awaiting Model Update*> + <gurobi.Var *Awaiting Model Update*> + <gurobi.Var *Awaiting Model Update*>>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "019f228f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3], [0, 2, 3], [1, 3], [0, 1, 3]]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411b295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (mac64[arm] - Darwin 24.6.0 24G309)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 14 physical cores, 14 logical processors, using up to 14 threads\n",
      "\n",
      "Optimize a model with 4 rows, 4 columns and 10 nonzeros (Min)\n",
      "Model fingerprint: 0x732ba13b\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 0 continuous, 4 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 1e+02]\n",
      "Presolve removed 4 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 14 available processors)\n",
      "\n",
      "Solution count 1: 128 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.280000000000e+02, best bound 1.280000000000e+02, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "\n",
    "m = gp.Model()\n",
    "\n",
    "x=m.addVars(len(buttons),vtype=gp.GRB.INTEGER,lb=0)\n",
    "\n",
    "expr = x[0]\n",
    "for val in x:\n",
    "    if(val != 0):\n",
    "        expr += x[val]\n",
    "\n",
    "m.setObjective(expr,gp.GRB.MINIMIZE)\n",
    "for val in range(len(braces)):\n",
    "    construct = None\n",
    "    for idx,button in enumerate(buttons):\n",
    "        if(val in button):\n",
    "            if(construct is None):\n",
    "                construct = x[idx]\n",
    "            else:\n",
    "                construct += x[idx]\n",
    "    m.addConstr(construct==braces[val])\n",
    "\n",
    "m.optimize()\n",
    "m.ObjVal\n",
    "\n",
    "if m.status == gp.GRB.OPTIMAL:\n",
    "    print(\"Optimal solution found!\")\n",
    "    print(\"Objective value:\", m.objVal)\n",
    "    for v in m.getVars():\n",
    "        print(f\"{v.varName} = {v.x}\") # Access variable name and value\n",
    "else:\n",
    "    print(\"Optimal solution not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "233e5e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution found!\n",
      "Objective value: 128.0\n",
      "C0 = 111.0\n",
      "C1 = 2.0\n",
      "C2 = 11.0\n",
      "C3 = 4.0\n"
     ]
    }
   ],
   "source": [
    "if m.status == gp.GRB.OPTIMAL:\n",
    "    print(\"Optimal solution found!\")\n",
    "    print(\"Objective value:\", m.objVal)\n",
    "    for v in m.getVars():\n",
    "        print(f\"{v.varName} = {v.x}\") # Access variable name and value\n",
    "else:\n",
    "    print(\"Optimal solution not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "72983c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = m.getVars()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e3bd1d5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Unable to retrieve attribute 'BarX'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[184]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m m.getVars():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m != \u001b[32m0\u001b[39m:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mprint\u001b[39m(v.varName, \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m, v.x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/gurobipy/var.pxi:128\u001b[39m, in \u001b[36mgurobipy._core.Var.__getattr__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/gurobipy/var.pxi:156\u001b[39m, in \u001b[36mgurobipy._core.Var.getAttr\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/gurobipy/_attrutil.pyx:119\u001b[39m, in \u001b[36mgurobipy._attrutil._getattr\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: Unable to retrieve attribute 'BarX'"
     ]
    }
   ],
   "source": [
    "for v in m.getVars():\n",
    "    if v.x != 0:\n",
    "        print(v.varName, \"=\", v.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "22fdac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lru-cache\n",
      "  Downloading lru_cache-0.2.3.tar.gz (2.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: lru-cache\n",
      "  Building wheel for lru-cache (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lru-cache: filename=lru_cache-0.2.3-py3-none-any.whl size=3281 sha256=97c8cb6d089d35b3aad1ed725593b0438e90731dd3d306d371a4d7bc4e3f47ac\n",
      "  Stored in directory: /Users/david.howard/Library/Caches/pip/wheels/49/42/6d/3a1af1e060fd4a2a2fb5b90bda09966ea85dd6359484d57785\n",
      "Successfully built lru-cache\n",
      "Installing collected packages: lru-cache\n",
      "Successfully installed lru-cache-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lru-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "49eee90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"svy: npd tiy oux als\n",
    "clh: nlj\n",
    "qjt: efj hsv\n",
    "kwg: bqs tiq rir\n",
    "twr: lyq ibs\n",
    "kol: yil\n",
    "gzb: coh rsy\n",
    "fft: aya pvu\n",
    "gmj: fda\n",
    "rhn: xty you wkd ltb\n",
    "iyo: gxf vmy vsx lss\n",
    "olz: qlq\n",
    "ohd: tmu cea apx\n",
    "cmw: fsc zcz\n",
    "kow: vop jul\n",
    "pbx: lqf rxr\n",
    "ava: fau gqy kkj\n",
    "jto: yur hlx\n",
    "pkn: hrm ujq hir\n",
    "efj: oeb\n",
    "sgs: chu ajq\n",
    "qya: cvf vid\n",
    "vlw: nrp ilm tfo\n",
    "rxe: thu\n",
    "psq: djx xtd ygh\n",
    "obl: ttw kdb uef hbk\n",
    "ngc: tfs skn bcy tea qmb\n",
    "hat: skz lvr fmt xij\n",
    "egk: lau esm\n",
    "imr: lau cvo wwx esm\n",
    "oxy: jmn pbs\n",
    "txd: vzm uvc ljo\n",
    "tsv: gyz ibs lyq\n",
    "cpj: ahl lmq\n",
    "mla: pzo\n",
    "cvf: wom oxy\n",
    "faz: hqg val ybz\n",
    "qmk: pxp\n",
    "ptr: nvm hzi\n",
    "gvl: ico mpt syt kab tvw gqm gmj aeb ajw rdd nrr fte xpm gsg bap ioe kkm rup cqj\n",
    "pzo: ttq zpu sbi vlw dpf\n",
    "ffg: ljo vzm mbe\n",
    "chu: kzg kcn wze ikl mgs\n",
    "mkx: ibl cqj rup kkm syt lgf ajw tvw kab fte\n",
    "yfq: rxd iox dpe rkv\n",
    "mvn: out\n",
    "one: you xty\n",
    "gzl: jkz lmd\n",
    "vuh: xhv fuj uoq xgu\n",
    "bss: yno\n",
    "rkv: juo\n",
    "mqd: out\n",
    "vzm: qjt hgr xoz flp vpo yiq zzj toq xbn\n",
    "had: hjw\n",
    "ybz: ltb wkd you\n",
    "iox: mqd juo\n",
    "ltb: xee msy ewx boj owr oah rjx avv dzn gvs xuo jmy bvd\n",
    "sfs: mbe ljo\n",
    "tmu: qku ujy\n",
    "skn: wff\n",
    "agr: kwg klr tbk\n",
    "alq: obv pzd\n",
    "mle: ikn nhi pzo wxj\n",
    "ahl: gzo ike jwz knm\n",
    "vsx: lau\n",
    "rqc: rjf wfq wyx dfy ddd\n",
    "joh: bni rwy\n",
    "ikl: yur\n",
    "yno: glh iag dac\n",
    "yiq: cvf vid\n",
    "fyy: mma qdl\n",
    "wzr: wwx esm lau\n",
    "wxu: jhm\n",
    "jct: bjc als oux npd\n",
    "klr: tiq fyy\n",
    "iva: buq jbt bvp\n",
    "pvu: vqv mbe vzm uvc\n",
    "wwx: oeo ohd hxi vyk tiw awf bsz xqr\n",
    "cea: ujy rsj lot\n",
    "dzn: gte lvr fmt skz\n",
    "hrm: btf txd xly uxa\n",
    "knm: jto adq\n",
    "tiu: nhi\n",
    "oeo: rqc qlq gjw\n",
    "ajq: kcn kzg\n",
    "cjv: thu yur\n",
    "ugu: whf\n",
    "uxa: uvc vzm mbe ljo vqv\n",
    "xty: avv eiy wxu ccn dzn xuo gvs oah owr boj ewx msy xee avb\n",
    "avv: had iyh eoi\n",
    "oeb: esm wwx cvo\n",
    "ujq: xam btf txd uxa\n",
    "vqo: cuq ssj sfs\n",
    "ucb: fsp pno\n",
    "val: ltb xty\n",
    "qdl: nye uqk tpn\n",
    "xly: vqv vzm\n",
    "aml: hpw iyo muw yyr\n",
    "fda: mnf yil\n",
    "xbn: tou fxx efj\n",
    "cka: bgs oix ghq zmz\n",
    "ear: ilm nrp yno\n",
    "gte: ubh\n",
    "prp: lyq gyz\n",
    "ykt: doe jwp wrx\n",
    "bqk: whf\n",
    "rfu: ocm wzj\n",
    "vcz: rbg wnr svy jct\n",
    "hir: xly btf\n",
    "vno: wkd you\n",
    "zfd: jkz ieb\n",
    "psi: rxe\n",
    "wep: lky xvc\n",
    "tiq: mma qdl\n",
    "jbt: fjz hhx sqs\n",
    "wze: thu hlx yur\n",
    "jwz: jto adq\n",
    "rtz: xty wkd\n",
    "bwe: yur thu hlx\n",
    "ysw: skg hzc\n",
    "lss: cvo lau esm\n",
    "aeb: zfe ven rsy\n",
    "fmt: ubh zva rkf\n",
    "okm: ipn bar avg qyh\n",
    "zwa: klr kwg\n",
    "dac: wuv xgu xhv\n",
    "lzd: ieb jkz\n",
    "pbs: esm wwx lau cvo\n",
    "lpi: ahl han lmq\n",
    "cjl: yyr tzj hpw iyo\n",
    "lot: fib bno\n",
    "bqs: txz\n",
    "tga: oxy\n",
    "owr: lvr gte skz\n",
    "rgt: aml cjl\n",
    "wwu: yur hlx\n",
    "qku: bef\n",
    "hhx: wwm vdq siz\n",
    "qoc: vqo skg hzc\n",
    "aya: mbe vzm uvc\n",
    "ipn: hqg val\n",
    "ssf: dvu qmk lxw\n",
    "toa: lmd ieb\n",
    "qyh: ybz\n",
    "npd: vpc\n",
    "psm: nmd njl\n",
    "jes: cvo\n",
    "bsz: gjw zmx rqc\n",
    "zmz: orv bzm\n",
    "ibs: zlm ugu psm\n",
    "iyh: hjw yru ksu\n",
    "lqf: jes urs\n",
    "rdd: rbp ucb\n",
    "aaj: lmq han\n",
    "mjc: out\n",
    "uwe: qfc ewu pme\n",
    "eaa: cjl cpw\n",
    "uju: rgt eaa\n",
    "xuo: zwa\n",
    "kzg: yur hlx\n",
    "bdt: aml\n",
    "djx: iup cfp lmx gdr\n",
    "hlx: lzd toa aiw knp plo ava qoc agx zgk cka bsn\n",
    "mlw: qll\n",
    "wzj: egk gws rvl\n",
    "qmb: tsd\n",
    "ibl: xww\n",
    "ioe: svy wnr jct\n",
    "gxf: cvo lau\n",
    "gjw: wyx dfy rjf\n",
    "bjc: bwe cjv vpc\n",
    "cfp: rhn vdd\n",
    "jmn: cvo esm\n",
    "gqm: xww lay\n",
    "rjx: nkn clh\n",
    "flp: tga\n",
    "shn: ffg aya\n",
    "wff: vqv uvc vzm mbe\n",
    "xlx: rer\n",
    "kmw: iva\n",
    "ddd: ymr wau ojn\n",
    "fau: pkn ahb hcv nup\n",
    "xij: ubh\n",
    "tvw: ejp\n",
    "irc: you xty wkd ltb\n",
    "msy: had eoi\n",
    "ccn: agr zwa\n",
    "fib: wxj\n",
    "sus: zcz fsc clu\n",
    "als: cjv dje bwe\n",
    "wuv: one dgu rtz\n",
    "tzj: gxf vmy lyc vsx lss\n",
    "zlm: njl whf nmd\n",
    "jhw: vzm ljo vqv\n",
    "mor: rfu rer ysr\n",
    "xam: uvc vzm mbe ljo vqv\n",
    "uhp: apx\n",
    "fxx: oeb wzr\n",
    "nye: out\n",
    "bvp: ppi\n",
    "syt: coh rsy zfe ven\n",
    "gvs: jfo bcs fvt\n",
    "eck: out\n",
    "vhk: irc\n",
    "hqs: ykt\n",
    "fxj: njl whf\n",
    "ijr: btu ykt ray onr\n",
    "zup: dpe iox rkv rxd\n",
    "plo: vqo elj\n",
    "ttq: okm\n",
    "rwy: hlx thu\n",
    "azy: lgf ico syt kab tvw vcz gsg ibl gzb bap rup cqj aeb xpm nrr fte\n",
    "apy: rvl gws\n",
    "fuj: rtz one\n",
    "gqy: pkn ahb wqd hcv\n",
    "lyc: lau wwx\n",
    "adq: yur thu\n",
    "grj: wwx esm cvo\n",
    "zqt: bni\n",
    "buq: sqs mid\n",
    "gzo: vav jto\n",
    "yye: clh iva\n",
    "qlq: wfq wyx ddd\n",
    "ewx: agr\n",
    "wfq: ymr ojn eez\n",
    "egm: xam\n",
    "bap: kfj nnl jve\n",
    "nlj: mid hhx\n",
    "wzv: djx\n",
    "lmq: knm ike\n",
    "vav: hlx thu\n",
    "eet: xtd\n",
    "qkw: han\n",
    "wwm: mvn wbx mjc\n",
    "glh: xgu wuv uoq xhv\n",
    "fsp: ajq chu sxs\n",
    "svr: dcv ihi mkx azy gvl\n",
    "bar: hqg luj\n",
    "ujy: bef bno ifr\n",
    "pzd: pnx grj\n",
    "iqw: ocm\n",
    "xvc: qmb tea bcy skn\n",
    "xxd: clh nkn iva\n",
    "bef: nhi ikn\n",
    "kdb: ikn pzo wxj\n",
    "avb: fvt bcs jsg\n",
    "szw: xty ltb wkd\n",
    "hgr: vid\n",
    "btf: uvc vqv ljo\n",
    "qbs: han\n",
    "lvr: zva\n",
    "iup: gjg vdd\n",
    "prz: wqz vlc qgt vkv khf\n",
    "fjz: siz\n",
    "cvo: drk iwj prp dit awf\n",
    "vof: lau cvo esm wwx\n",
    "zfe: nut ywg\n",
    "emg: okk obl\n",
    "hoz: vqv mbe vzm uvc\n",
    "onr: doe\n",
    "eoi: ksu\n",
    "oux: vpc cjv\n",
    "fom: rwy rxe bni\n",
    "vss: wxj\n",
    "btu: jwp wrx doe\n",
    "jhm: tbk klr kwg\n",
    "lgf: kfj jve\n",
    "vqv: flp mor uld pbx qya mul vpo kvt bqv xoz toq uju\n",
    "doe: out\n",
    "rxm: mvn\n",
    "ozo: okm gco dul\n",
    "vkv: out\n",
    "hcv: hir ujq hrm\n",
    "pua: wcz alq mlw\n",
    "knp: siu fau\n",
    "qll: rly vrl grj\n",
    "rir: mma\n",
    "pbd: jmn pbs imr\n",
    "wcz: qll obv pzd\n",
    "cwa: huq obl okk\n",
    "siz: ntc mvn mjc\n",
    "vyk: sus twc cmw\n",
    "lxw: onq yam prz\n",
    "jul: ang\n",
    "muw: gxf lyc vmy vsx\n",
    "kab: jct svy wnr rbg\n",
    "mnf: psi hsq fom zqt joh\n",
    "iag: wuv fuj xhv\n",
    "rvl: wwx esm cvo\n",
    "ggp: mlw\n",
    "orv: vqv uvc vzm mbe\n",
    "boj: jsg fvt jfo\n",
    "fvc: wxj pzo ikn nhi\n",
    "ikn: wzv zpu ear ttq eet dpf ztc mjy ozo uwe agw psq kow bss xzs vgd vlw vnu\n",
    "fes: ljo mbe uvc vzm\n",
    "vdd: you xty wkd ltb\n",
    "qfc: hzi ere\n",
    "ahb: egm hrm\n",
    "agx: dty\n",
    "xhv: dgu rtz\n",
    "wli: qmk lxw tfx\n",
    "siu: hcv wqd\n",
    "ven: nut xrc wwu\n",
    "rjt: hsv\n",
    "xtd: gdr iup tkk cfp\n",
    "ygh: iup cfp gdr lmx\n",
    "esc: hrl ghq\n",
    "mul: iqw\n",
    "yru: hqs amc ijr\n",
    "yam: qgt vlc\n",
    "dfq: thu hlx\n",
    "ilm: dac glh iag vuh\n",
    "apx: ujy lot rsj\n",
    "onq: wqz\n",
    "hxi: apo cmw twc sus\n",
    "xqr: ibs\n",
    "lge: cxr jes\n",
    "reg: rxd\n",
    "dvi: dab\n",
    "njl: ikn nhi wxj\n",
    "zgk: siu fau kkj\n",
    "fvt: ssf\n",
    "ysr: apy xbl\n",
    "tiw: sus\n",
    "kkm: ucb rbp\n",
    "gws: cvo lau wwx\n",
    "rer: ocm apy\n",
    "dgu: xty you wkd ltb\n",
    "uld: tou\n",
    "ztc: vop\n",
    "vop: bly vhk\n",
    "jkz: fft shn opy\n",
    "ljo: toq zzj uju flp xlx dsn bqv rjt kvt\n",
    "wqd: ujq hir\n",
    "rup: qbs cpj qkw\n",
    "hsv: wzr vof\n",
    "gco: bar qyh\n",
    "awf: sus apo cmw twc\n",
    "zpu: jvz\n",
    "rbg: tiy npd als bjc\n",
    "apo: zcz clu fsc\n",
    "sjg: xvc lky\n",
    "kkj: ahb pkn\n",
    "mxx: lxw\n",
    "pme: hzi\n",
    "kwq: odg\n",
    "hpw: vmy\n",
    "skz: rkf\n",
    "dul: faz ipn bar\n",
    "bni: yur thu\n",
    "pnx: esm wwx lau\n",
    "dsn: lge lqf\n",
    "lau: bsz dit twr iwj prp vyk drk emg olz tiw tsv uhp cwa nmb ckp\n",
    "tbk: bqs fyy rir\n",
    "zmx: ddd wyx wfq rjf\n",
    "lmx: rhn\n",
    "hoc: out\n",
    "ghq: hoz qyk orv\n",
    "xuc: qmk dvu\n",
    "oix: hoz qyk bzm\n",
    "zcz: mle uhy omr\n",
    "lay: uep\n",
    "iwj: apx\n",
    "wqz: out\n",
    "mpt: cfl ucb rbp\n",
    "zue: rxd\n",
    "bly: irc szw\n",
    "wrx: out\n",
    "rsy: xrc wwu ywg nut\n",
    "ssj: ljo mbe vzm uvc\n",
    "pno: ajq\n",
    "gsg: qkw lpi\n",
    "mog: vqo\n",
    "tfx: prz pxp nub\n",
    "bcy: hiu\n",
    "xpm: ejp fda kol dvi\n",
    "skg: sfs trj\n",
    "bvd: had iyh uim eoi\n",
    "jvz: vhk ang\n",
    "rkf: zue tmg reg\n",
    "fte: qbs cpj qkw aaj lpi\n",
    "epz: yur\n",
    "dit: apo cmw twc sus\n",
    "thu: ivz zfd toa itr cka zgk ava gzl\n",
    "jmy: had iyh uim\n",
    "agw: tfo ilm\n",
    "ifr: ikn pzo\n",
    "yur: ivz knp plo aiw bsn cka itr zfd irl ysw mog hxy zgk esc\n",
    "ytk: apy xbl wzj\n",
    "vmy: lau cvo\n",
    "rbp: pno seh qxm\n",
    "yil: zqt psi\n",
    "mgs: yur thu\n",
    "oah: jsg\n",
    "avg: hqg ybz\n",
    "leu: lyq\n",
    "wkd: avv xuo kmw boj oah\n",
    "juo: out\n",
    "uhy: wxj ikn nhi\n",
    "wyx: ymr\n",
    "qxm: sxs chu ajq\n",
    "elj: yzu trj ssj cuq\n",
    "ico: nnl kfj\n",
    "jwp: out\n",
    "nub: qgt wqz khf\n",
    "dje: yur hlx\n",
    "wbx: out\n",
    "ppi: rxm\n",
    "vpc: yur hlx\n",
    "ray: jwp\n",
    "eez: bxs khd vss\n",
    "txz: tpn nye\n",
    "tkk: rhn\n",
    "hbk: pzo nhi\n",
    "tfo: dac iag glh vuh\n",
    "amc: ykt onr ray\n",
    "rjf: ojn\n",
    "dpf: dul\n",
    "xrc: yur thu\n",
    "hrl: hoz bzm orv qyk\n",
    "ike: jto vav\n",
    "xww: epz ztl uep dfq\n",
    "rxd: juo hoc\n",
    "yyr: lyc gxf lss vsx\n",
    "tsd: vqv ljo uvc\n",
    "hsq: rwy\n",
    "ojn: bxs khd\n",
    "jsg: xuc mxx\n",
    "nrr: kol fda bvf dvi\n",
    "tpn: out\n",
    "bob: nrp\n",
    "okk: kdb ttw\n",
    "dfy: eez ojn ymr\n",
    "tfs: tsd jhw wff fes\n",
    "nhi: eet ear zpu wzv ttq uwe hja mjy ztc sbi bob agw psq kow vlw vnu vgd xzs bss\n",
    "aiw: wep sjg dty\n",
    "lky: tea qmb skn\n",
    "trj: uvc vqv\n",
    "bsn: bgs oix zmz\n",
    "sqs: siz vdq wwm\n",
    "djo: pbs imr\n",
    "lyq: zlm ugu psm fxj\n",
    "dvu: pxp prz onq\n",
    "mma: uqk eck\n",
    "bwj: mlw alq\n",
    "mbe: mul qjt yiq clx xbn kvt bqv xoz hgr dsn xlx\n",
    "rsj: bno fib\n",
    "ajw: cfl\n",
    "ihi: aeb rdd ajw nrr xpm bap ioe gzb ibl vcz gsg cqj kkm rup syt ico gqm tvw kab\n",
    "han: nzn gzo ike jwz\n",
    "kve: gdr lmx\n",
    "wom: jmn\n",
    "bvf: dab mnf\n",
    "bno: wxj ikn pzo\n",
    "nnl: ztl\n",
    "uqk: out\n",
    "wxj: eet zpu ttq kow vnu uwe ozo mjy xzs bss ztc\n",
    "cfl: fsp sgs qxm seh pno\n",
    "luj: wkd xty\n",
    "tli: nvm\n",
    "nup: hir egm\n",
    "vrl: esm wwx\n",
    "dty: lky xvc ngc\n",
    "omr: ikn pzo\n",
    "bgs: bzm\n",
    "vgd: pme ewu ptr tli\n",
    "rxr: urs cxr\n",
    "hdc: odg wcz\n",
    "dpe: mqd\n",
    "esm: iwj ohd vyk tiw leu twr xqr dit oeo nmb hxi awf cwa\n",
    "wnr: npd bjc\n",
    "irl: lmd jkz ieb\n",
    "nvm: xty\n",
    "toq: lge lqf rxr\n",
    "lmd: shn opy\n",
    "uep: thu\n",
    "vnu: ptr qfc ewu pme\n",
    "tmg: rkv\n",
    "cxr: esm lau\n",
    "urs: wwx lau\n",
    "jve: uep\n",
    "zva: reg tmg\n",
    "hxy: siu\n",
    "whf: wxj nhi pzo\n",
    "bqv: pua kwq\n",
    "dcv: ibl gsg rup gmj ajw syt fte xpm gqm\n",
    "ksu: hqs ijr\n",
    "dab: joh zqt fom hsq psi\n",
    "uoq: one dgu\n",
    "mjy: djx kve ygh\n",
    "ocm: egk rvl\n",
    "wau: vss bxs\n",
    "xgu: dgu\n",
    "tea: jhw fes hiu\n",
    "ivz: sjg\n",
    "rly: cvo lau\n",
    "hzi: xty wkd\n",
    "eiy: lvr fmt xij\n",
    "khd: nhi ikn wxj\n",
    "huq: uef kdb tiu\n",
    "odg: pzd qll\n",
    "gyz: fxj bqk\n",
    "tou: wzr\n",
    "xzs: vop jul jvz\n",
    "xee: clh\n",
    "bzm: ljo uvc mbe\n",
    "hqg: you wkd\n",
    "uef: pzo ikn nhi wxj\n",
    "khf: out\n",
    "vpo: bwj ggp hdc\n",
    "cuq: vzm ljo\n",
    "coh: ywg xrc wwu\n",
    "nut: thu\n",
    "qgt: out\n",
    "cpw: hpw yyr\n",
    "nzn: adq vav\n",
    "zzj: eaa rgt bdt\n",
    "qyk: vzm mbe ljo\n",
    "gdr: rhn vdd gjg\n",
    "sxs: wze ikl\n",
    "clx: eaa bdt fay\n",
    "pxp: khf qgt wqz\n",
    "ewu: nvm ere hzi\n",
    "ywg: hlx yur\n",
    "seh: ajq sxs\n",
    "bcs: xuc wli\n",
    "xbl: gws\n",
    "ejp: yil\n",
    "ckp: zmx gjw\n",
    "fay: aml\n",
    "ere: you ltb\n",
    "opy: aya ffg\n",
    "ymr: bxs\n",
    "xoz: rfu ytk ysr\n",
    "nrp: vuh iag\n",
    "obv: vrl\n",
    "uim: yru\n",
    "twc: clu\n",
    "vlc: out\n",
    "ntc: out\n",
    "vid: pbd djo\n",
    "jfo: wli mxx\n",
    "mid: wwm rxm\n",
    "fsc: mla\n",
    "ubh: reg zue yfq zup\n",
    "hja: djx kve xtd\n",
    "you: xxd avb jmy ccn ewx owr rjx yye msy hat\n",
    "itr: fau siu kkj\n",
    "ttw: wxj ikn nhi\n",
    "sbi: tli ptr pme ewu\n",
    "nmd: nhi\n",
    "hiu: mbe vzm uvc ljo\n",
    "nmb: okk huq\n",
    "clu: fvc uhy\n",
    "nkn: buq jbt\n",
    "tiy: vpc bwe\n",
    "ztl: hlx\n",
    "kfj: dfq uep epz\n",
    "drk: cea apx\n",
    "kvt: pua kwq ggp bwj hdc\n",
    "gjg: xty you ltb\n",
    "uvc: flp pbx mor qjt qya mul zzj xlx dsn rjt toq yiq\n",
    "vdq: ntc\n",
    "yzu: vzm mbe vqv\n",
    "bxs: nhi ikn pzo wxj\n",
    "hzc: cuq ssj\n",
    "hjw: ijr amc hqs\n",
    "kcn: thu\n",
    "cqj: ucb cfl rbp\n",
    "ieb: opy shn fft\n",
    "ang: vno\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "720cf266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "af34cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11315"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_dict = {}\n",
    "for line in input_str.split('\\n'):\n",
    "    input = line.split(':')[0]\n",
    "    edge_dict[input] = line.split(':')[1].split()\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def count_paths(start_point):\n",
    "    if start_point == 'fft':\n",
    "        return 1\n",
    "    elif start_point == 'out':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(count_paths(edge) for edge in edge_dict[start_point])\n",
    "\n",
    "count_paths('svr')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b0676657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384151614084875"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8281*4099825*11315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b3246238",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"0:\n",
    "#..\n",
    "##.\n",
    ".##\n",
    "\n",
    "1:\n",
    "###\n",
    ".##\n",
    "##.\n",
    "\n",
    "2:\n",
    "###\n",
    "###\n",
    "#..\n",
    "\n",
    "3:\n",
    "..#\n",
    ".##\n",
    "###\n",
    "\n",
    "4:\n",
    "###\n",
    ".#.\n",
    "###\n",
    "\n",
    "5:\n",
    "###\n",
    "..#\n",
    "###\n",
    "\n",
    "42x45: 51 48 40 49 56 48\n",
    "40x47: 38 43 52 44 61 48\n",
    "49x41: 48 45 53 62 51 51\n",
    "50x44: 42 38 32 45 34 32\n",
    "45x41: 46 49 42 48 51 48\n",
    "50x37: 42 43 44 45 51 58\n",
    "48x37: 46 57 51 33 41 44\n",
    "41x36: 45 32 52 41 27 33\n",
    "37x49: 51 49 42 51 38 50\n",
    "45x35: 41 37 38 63 36 31\n",
    "36x42: 30 38 27 44 46 46\n",
    "44x35: 29 39 32 46 46 43\n",
    "42x49: 37 34 43 35 36 39\n",
    "40x46: 34 41 35 21 35 29\n",
    "45x44: 29 37 38 39 34 33\n",
    "44x39: 31 26 31 23 26 45\n",
    "35x50: 44 40 50 57 30 50\n",
    "47x50: 39 35 49 37 36 43\n",
    "50x48: 37 38 41 42 44 54\n",
    "49x35: 47 53 35 43 46 41\n",
    "39x35: 23 19 22 24 28 27\n",
    "50x49: 38 48 43 43 44 40\n",
    "44x49: 44 31 33 38 38 40\n",
    "50x39: 36 33 37 35 37 30\n",
    "37x36: 23 28 23 25 19 26\n",
    "37x40: 31 42 46 39 35 33\n",
    "47x44: 55 45 61 47 64 46\n",
    "50x50: 59 75 68 62 60 59\n",
    "37x37: 41 27 30 37 36 42\n",
    "47x47: 52 54 70 57 60 46\n",
    "35x49: 34 28 25 33 30 25\n",
    "48x44: 34 45 36 32 38 38\n",
    "42x35: 43 42 37 37 34 35\n",
    "40x43: 42 45 44 57 44 34\n",
    "47x42: 64 40 44 59 44 58\n",
    "36x44: 43 53 33 42 30 44\n",
    "45x38: 27 33 28 33 25 33\n",
    "42x46: 43 44 57 59 49 45\n",
    "48x46: 50 58 51 64 65 51\n",
    "47x46: 46 36 37 28 35 43\n",
    "37x47: 34 28 28 30 35 25\n",
    "42x36: 29 24 28 29 25 32\n",
    "37x43: 41 37 34 40 46 47\n",
    "37x36: 24 30 41 40 36 32\n",
    "37x43: 56 25 44 44 35 46\n",
    "41x36: 29 18 30 26 28 24\n",
    "45x36: 37 44 33 47 47 41\n",
    "41x50: 56 55 46 61 48 52\n",
    "44x41: 49 45 38 50 57 40\n",
    "47x39: 33 42 22 28 36 33\n",
    "48x47: 58 60 56 62 48 64\n",
    "43x43: 34 35 30 28 36 33\n",
    "39x48: 58 47 52 33 49 50\n",
    "40x39: 45 25 44 48 39 42\n",
    "37x45: 29 24 40 22 35 29\n",
    "35x46: 47 38 31 50 38 47\n",
    "37x46: 46 42 52 39 39 44\n",
    "50x45: 58 57 55 62 55 60\n",
    "36x48: 31 50 45 48 51 38\n",
    "43x41: 20 30 34 28 33 37\n",
    "48x45: 38 49 34 42 36 41\n",
    "49x38: 41 46 48 57 50 44\n",
    "44x40: 25 37 29 27 28 35\n",
    "42x47: 32 26 41 39 35 37\n",
    "49x45: 62 52 59 55 59 54\n",
    "48x48: 57 66 61 58 64 48\n",
    "47x37: 44 48 42 47 53 34\n",
    "37x39: 33 36 49 35 30 38\n",
    "48x49: 70 61 66 61 56 51\n",
    "39x41: 28 33 25 26 23 33\n",
    "48x36: 27 35 36 27 32 34\n",
    "40x50: 57 51 48 55 39 60\n",
    "38x46: 46 56 42 42 44 39\n",
    "41x44: 33 32 32 36 21 27\n",
    "50x45: 62 59 50 61 58 58\n",
    "41x43: 40 48 52 32 46 50\n",
    "44x41: 41 50 51 45 44 45\n",
    "50x44: 55 55 62 41 62 61\n",
    "46x47: 39 43 59 55 70 62\n",
    "41x45: 54 38 46 46 49 53\n",
    "48x41: 32 29 45 35 36 31\n",
    "37x40: 22 25 29 29 27 24\n",
    "48x50: 37 41 39 40 48 50\n",
    "44x43: 51 54 45 47 44 51\n",
    "40x46: 27 40 26 40 29 33\n",
    "43x35: 39 42 35 33 46 36\n",
    "42x48: 61 41 51 58 50 53\n",
    "35x46: 30 34 27 26 32 16\n",
    "40x41: 35 25 28 28 22 30\n",
    "35x46: 33 46 43 44 39 41\n",
    "48x40: 49 56 44 51 53 43\n",
    "38x44: 30 31 30 37 17 22\n",
    "39x45: 33 26 36 34 31 35\n",
    "41x50: 26 29 41 36 39 37\n",
    "47x41: 34 36 35 33 22 34\n",
    "38x35: 19 17 24 29 21 21\n",
    "46x37: 32 26 32 28 31 31\n",
    "35x41: 23 31 19 21 20 28\n",
    "36x38: 27 39 38 32 35 37\n",
    "44x36: 48 45 31 33 38 50\n",
    "47x46: 59 60 59 50 48 57\n",
    "42x38: 42 39 51 40 39 35\n",
    "37x45: 35 25 25 31 36 28\n",
    "47x41: 44 42 23 32 19 34\n",
    "50x35: 45 50 45 42 47 40\n",
    "45x38: 49 53 37 39 48 38\n",
    "41x39: 38 34 41 53 36 45\n",
    "47x44: 27 42 29 32 33 46\n",
    "39x39: 46 30 38 44 39 40\n",
    "44x44: 52 48 48 38 59 52\n",
    "50x39: 55 63 45 58 45 37\n",
    "43x49: 44 62 50 51 60 54\n",
    "50x36: 41 50 38 54 45 49\n",
    "35x42: 41 39 35 35 31 46\n",
    "42x40: 44 41 49 42 38 45\n",
    "50x39: 61 56 51 39 37 58\n",
    "45x48: 58 60 63 47 50 54\n",
    "46x49: 52 41 39 31 33 43\n",
    "35x48: 37 52 35 36 44 52\n",
    "48x49: 66 51 66 62 53 66\n",
    "38x45: 38 28 35 27 27 25\n",
    "44x47: 24 36 34 45 30 41\n",
    "50x45: 58 55 52 74 47 63\n",
    "48x49: 49 64 60 69 63 55\n",
    "37x46: 42 38 60 39 46 36\n",
    "41x49: 58 39 49 58 57 51\n",
    "44x46: 47 53 55 57 50 49\n",
    "43x41: 28 36 29 28 35 26\n",
    "50x41: 57 48 48 60 44 61\n",
    "37x35: 18 24 19 24 24 22\n",
    "37x46: 48 48 47 34 43 42\n",
    "47x50: 52 64 63 63 66 52\n",
    "39x38: 36 47 35 27 45 36\n",
    "40x46: 39 18 30 36 33 38\n",
    "37x37: 44 41 37 38 26 28\n",
    "38x47: 38 39 44 55 50 48\n",
    "37x40: 22 23 31 24 28 28\n",
    "45x49: 38 30 41 60 44 27\n",
    "46x37: 65 42 39 41 40 41\n",
    "41x45: 51 49 50 40 45 49\n",
    "37x44: 38 58 36 29 42 45\n",
    "39x35: 27 15 22 27 24 27\n",
    "36x43: 46 39 38 39 36 42\n",
    "35x35: 33 39 20 31 32 34\n",
    "41x49: 38 44 47 61 55 62\n",
    "49x43: 55 44 49 57 61 59\n",
    "50x46: 58 67 64 52 47 65\n",
    "35x37: 31 28 28 34 37 41\n",
    "37x37: 17 29 27 25 28 18\n",
    "45x40: 43 49 46 58 43 39\n",
    "49x46: 58 65 61 44 58 59\n",
    "49x47: 58 55 59 64 56 63\n",
    "42x47: 33 65 52 57 41 52\n",
    "42x47: 27 31 47 31 34 40\n",
    "35x47: 37 45 42 42 42 44\n",
    "50x43: 47 65 55 72 40 52\n",
    "45x39: 30 30 40 25 27 42\n",
    "40x47: 50 51 41 54 50 45\n",
    "38x44: 47 47 33 44 51 37\n",
    "41x38: 23 28 25 28 31 21\n",
    "38x43: 32 42 48 42 37 48\n",
    "46x39: 49 45 47 37 46 52\n",
    "49x47: 71 68 65 46 46 60\n",
    "35x39: 44 29 40 37 27 36\n",
    "46x36: 33 48 38 40 48 45\n",
    "42x38: 44 38 42 42 36 45\n",
    "50x38: 65 58 40 47 47 40\n",
    "50x36: 56 41 43 53 51 37\n",
    "41x48: 45 60 35 47 62 52\n",
    "36x36: 14 26 25 28 19 32\n",
    "40x49: 33 41 18 41 42 33\n",
    "43x44: 52 52 45 40 49 53\n",
    "39x35: 33 32 39 36 27 43\n",
    "46x36: 31 41 38 50 38 55\n",
    "42x42: 57 45 42 38 44 48\n",
    "47x48: 35 56 37 28 44 39\n",
    "49x41: 61 45 46 64 48 50\n",
    "40x43: 31 50 43 49 52 37\n",
    "41x42: 26 27 33 33 30 33\n",
    "43x50: 57 50 44 58 62 61\n",
    "38x42: 30 38 36 43 59 37\n",
    "43x50: 29 37 40 42 41 34\n",
    "36x40: 34 33 36 36 39 43\n",
    "49x40: 26 35 37 31 37 41\n",
    "46x39: 57 35 49 50 35 54\n",
    "47x40: 30 32 42 31 29 30\n",
    "49x35: 50 39 36 44 47 50\n",
    "35x42: 26 19 27 26 25 31\n",
    "43x36: 41 49 37 40 33 39\n",
    "43x47: 54 49 47 52 50 60\n",
    "43x43: 46 44 48 44 65 37\n",
    "41x45: 17 44 29 40 29 36\n",
    "35x49: 35 39 55 55 38 41\n",
    "39x38: 42 34 36 35 42 40\n",
    "44x39: 29 28 32 36 28 29\n",
    "42x36: 21 22 25 30 28 41\n",
    "48x45: 55 59 56 53 61 48\n",
    "35x43: 40 32 48 30 36 45\n",
    "36x47: 45 47 40 36 47 45\n",
    "40x46: 37 33 30 32 26 36\n",
    "38x38: 20 25 22 31 23 23\n",
    "45x46: 49 52 50 55 53 59\n",
    "43x41: 42 47 44 48 35 55\n",
    "43x49: 62 44 48 56 61 56\n",
    "39x42: 50 47 34 44 45 35\n",
    "38x47: 28 32 27 22 30 40\n",
    "44x45: 30 38 39 32 38 33\n",
    "39x49: 34 39 39 35 36 25\n",
    "50x40: 39 31 27 36 32 42\n",
    "36x43: 33 37 51 43 40 33\n",
    "49x44: 52 68 49 63 49 51\n",
    "42x37: 27 29 26 34 25 26\n",
    "38x42: 49 41 39 33 56 29\n",
    "38x43: 42 43 33 45 49 40\n",
    "38x47: 50 55 37 52 39 44\n",
    "48x50: 56 49 62 68 66 68\n",
    "37x41: 21 23 24 38 29 21\n",
    "45x45: 63 54 56 44 59 38\n",
    "42x46: 52 58 39 48 48 53\n",
    "40x38: 21 25 25 24 30 31\n",
    "43x47: 57 51 59 53 43 50\n",
    "45x44: 32 42 41 26 34 34\n",
    "46x37: 31 23 34 36 28 27\n",
    "50x38: 49 45 42 44 56 56\n",
    "44x44: 35 22 36 31 34 37\n",
    "44x41: 44 32 54 37 52 57\n",
    "48x47: 48 59 58 62 60 58\n",
    "46x44: 36 21 39 42 35 36\n",
    "40x43: 38 48 43 35 54 44\n",
    "50x37: 32 43 31 28 27 30\n",
    "38x37: 32 25 20 21 29 17\n",
    "47x38: 39 46 41 51 53 44\n",
    "50x49: 51 52 73 79 59 62\n",
    "49x46: 39 44 35 47 41 34\n",
    "42x37: 38 33 43 41 41 43\n",
    "50x44: 56 64 56 53 41 68\n",
    "41x43: 42 48 49 42 44 45\n",
    "39x45: 44 53 46 52 34 42\n",
    "50x35: 43 45 39 44 51 47\n",
    "49x41: 23 34 32 44 38 37\n",
    "41x35: 26 29 21 33 18 15\n",
    "40x37: 40 44 33 35 45 31\n",
    "36x46: 28 32 31 29 31 28\n",
    "49x45: 44 39 37 33 38 48\n",
    "48x41: 60 39 45 60 54 49\n",
    "49x48: 67 52 62 54 80 48\n",
    "39x41: 50 42 34 50 42 32\n",
    "49x40: 33 24 38 30 37 46\n",
    "44x48: 37 41 31 38 32 45\n",
    "40x41: 28 18 35 29 29 29\n",
    "49x37: 30 31 33 36 29 32\n",
    "36x37: 36 22 22 24 20 20\n",
    "35x39: 30 33 43 30 34 38\n",
    "35x42: 23 19 23 33 33 22\n",
    "39x43: 31 45 31 43 48 57\n",
    "37x37: 35 28 37 36 41 34\n",
    "45x39: 36 36 31 36 27 28\n",
    "38x50: 36 28 35 30 34 29\n",
    "37x42: 22 28 30 29 29 30\n",
    "46x49: 44 41 36 43 42 33\n",
    "47x39: 47 37 55 45 55 43\n",
    "47x39: 54 50 42 44 54 40\n",
    "45x49: 69 63 41 64 40 67\n",
    "50x45: 44 40 48 39 37 31\n",
    "35x35: 19 24 24 13 18 22\n",
    "39x38: 38 46 26 36 40 42\n",
    "45x46: 43 33 33 30 46 40\n",
    "47x36: 54 42 38 54 44 33\n",
    "41x44: 22 26 29 38 35 31\n",
    "36x42: 35 25 31 25 23 29\n",
    "42x49: 38 42 28 41 31 43\n",
    "38x39: 25 27 26 30 26 21\n",
    "35x49: 52 42 39 49 46 39\n",
    "50x46: 36 37 36 40 44 47\n",
    "44x35: 27 29 21 20 34 23\n",
    "49x50: 77 57 57 61 67 62\n",
    "43x36: 26 34 23 26 29 29\n",
    "47x37: 48 46 44 40 38 52\n",
    "49x41: 61 62 44 44 45 55\n",
    "38x38: 20 26 26 30 17 25\n",
    "36x40: 39 34 44 40 29 37\n",
    "38x43: 20 28 22 32 34 31\n",
    "44x39: 54 32 38 70 35 42\n",
    "50x40: 60 61 59 49 49 32\n",
    "38x38: 27 29 26 13 28 21\n",
    "43x42: 44 51 53 35 43 50\n",
    "48x45: 51 65 51 54 51 59\n",
    "35x46: 28 28 23 26 30 30\n",
    "40x46: 45 51 57 42 44 43\n",
    "43x41: 40 61 42 46 44 37\n",
    "50x49: 50 56 61 79 75 55\n",
    "40x35: 22 22 27 26 23 23\n",
    "35x39: 18 20 22 30 19 34\n",
    "48x39: 52 33 47 59 52 48\n",
    "42x46: 45 39 31 44 29 21\n",
    "43x46: 43 62 56 48 34 59\n",
    "45x38: 34 32 26 26 33 28\n",
    "48x39: 39 46 32 33 25 32\n",
    "46x37: 52 47 39 46 41 40\n",
    "39x47: 32 34 24 40 36 29\n",
    "43x45: 39 53 60 42 59 41\n",
    "40x47: 51 42 54 39 51 52\n",
    "35x43: 22 33 31 31 18 19\n",
    "43x43: 40 46 42 51 47 57\n",
    "47x36: 44 48 39 45 45 40\n",
    "43x45: 45 46 53 45 61 46\n",
    "44x42: 25 40 30 31 37 33\n",
    "38x46: 33 48 46 45 39 55\n",
    "41x48: 46 54 50 53 43 56\n",
    "39x50: 49 50 56 56 47 43\n",
    "40x48: 34 33 39 32 33 36\n",
    "47x41: 50 36 53 43 54 60\n",
    "37x50: 48 45 38 48 49 57\n",
    "40x43: 59 28 53 42 46 41\n",
    "37x46: 44 48 37 41 43 49\n",
    "46x50: 57 58 59 55 70 54\n",
    "44x44: 65 45 51 45 37 59\n",
    "46x41: 34 29 37 29 37 28\n",
    "41x45: 54 46 47 53 49 38\n",
    "39x40: 24 29 27 24 29 35\n",
    "39x42: 30 26 29 31 35 30\n",
    "49x40: 30 30 34 37 43 33\n",
    "46x50: 73 57 58 58 50 62\n",
    "41x48: 43 44 54 51 62 47\n",
    "40x48: 34 32 39 39 41 23\n",
    "40x35: 34 31 43 36 27 44\n",
    "48x36: 47 40 39 51 54 37\n",
    "43x40: 27 26 32 35 37 24\n",
    "38x46: 40 33 47 53 53 43\n",
    "49x42: 61 40 61 64 47 48\n",
    "45x48: 67 55 49 56 52 57\n",
    "41x44: 62 46 51 37 37 48\n",
    "38x37: 26 34 36 32 34 51\n",
    "40x39: 33 36 44 39 42 44\n",
    "48x36: 47 47 50 37 42 43\n",
    "44x41: 34 26 39 28 23 31\n",
    "50x40: 46 51 60 49 49 51\n",
    "40x45: 44 48 41 42 47 54\n",
    "38x49: 28 37 28 40 31 28\n",
    "48x36: 27 31 26 33 43 32\n",
    "41x36: 46 44 35 34 44 26\n",
    "38x38: 27 20 25 20 27 24\n",
    "36x49: 39 48 52 45 45 41\n",
    "45x35: 36 39 54 37 37 38\n",
    "48x35: 41 41 42 48 50 37\n",
    "50x41: 54 47 51 67 46 53\n",
    "44x43: 37 28 30 43 32 26\n",
    "46x47: 55 75 44 56 53 50\n",
    "35x48: 29 24 34 32 34 23\n",
    "45x46: 40 26 50 30 36 42\n",
    "38x48: 47 54 47 47 41 45\n",
    "49x39: 36 31 31 24 46 39\n",
    "42x35: 39 37 34 31 44 41\n",
    "36x50: 32 30 27 36 28 38\n",
    "46x40: 35 45 43 42 55 59\n",
    "46x46: 29 36 52 42 30 35\n",
    "45x41: 37 43 54 54 58 36\n",
    "44x40: 50 46 35 48 50 44\n",
    "45x47: 37 39 44 38 39 28\n",
    "40x43: 30 27 29 35 30 31\n",
    "35x49: 44 43 43 51 39 45\n",
    "49x46: 55 70 51 71 52 49\n",
    "40x47: 27 33 35 31 32 37\n",
    "37x43: 41 28 31 22 20 26\n",
    "42x49: 29 42 36 39 38 40\n",
    "35x48: 28 29 33 21 40 24\n",
    "48x36: 49 41 44 47 35 52\n",
    "39x50: 44 58 45 47 42 62\n",
    "46x45: 64 61 46 60 48 44\n",
    "44x41: 48 43 47 37 55 47\n",
    "48x43: 51 43 61 50 51 61\n",
    "37x41: 44 37 42 32 37 42\n",
    "43x44: 46 50 32 66 54 45\n",
    "48x48: 42 36 43 45 37 53\n",
    "41x40: 29 31 25 25 32 27\n",
    "48x40: 51 47 48 54 47 50\n",
    "45x50: 54 62 52 62 59 57\n",
    "50x40: 57 58 45 55 51 44\n",
    "41x50: 29 27 37 38 44 33\n",
    "41x37: 20 22 33 22 24 34\n",
    "49x49: 69 70 58 49 54 70\n",
    "38x46: 31 35 24 35 27 28\n",
    "39x41: 48 46 34 40 43 37\n",
    "38x42: 32 50 48 32 36 44\n",
    "42x44: 50 47 53 44 51 40\n",
    "41x49: 32 26 34 33 44 39\n",
    "49x49: 35 41 50 40 45 45\n",
    "46x44: 37 30 41 32 35 34\n",
    "40x50: 29 36 30 48 32 32\n",
    "50x40: 55 49 44 58 57 47\n",
    "44x37: 30 22 31 30 29 26\n",
    "43x49: 59 59 57 49 54 47\n",
    "49x37: 42 48 46 55 48 40\n",
    "40x42: 53 37 53 40 46 32\n",
    "44x47: 64 46 47 57 53 55\n",
    "42x36: 30 38 32 44 46 41\n",
    "49x49: 51 58 77 58 56 66\n",
    "44x44: 40 61 55 41 56 41\n",
    "35x49: 37 41 45 43 45 51\n",
    "39x38: 41 30 41 43 33 42\n",
    "44x44: 47 49 49 47 50 55\n",
    "45x43: 45 55 53 44 49 50\n",
    "44x47: 48 58 55 46 58 51\n",
    "40x35: 31 32 37 41 35 39\n",
    "48x43: 43 46 24 32 43 36\n",
    "37x42: 35 33 40 39 44 47\n",
    "47x45: 62 46 55 42 53 68\n",
    "38x50: 51 43 56 40 48 54\n",
    "42x38: 36 50 40 46 34 39\n",
    "35x40: 21 28 23 21 24 26\n",
    "37x49: 54 48 41 44 34 60\n",
    "40x42: 26 27 29 36 25 39\n",
    "39x39: 28 31 21 24 39 26\n",
    "44x36: 40 42 42 50 28 43\n",
    "37x48: 51 45 35 53 44 48\n",
    "46x39: 46 48 45 38 50 48\n",
    "43x44: 51 34 46 40 68 52\n",
    "35x42: 43 33 43 38 30 41\n",
    "38x49: 42 50 47 48 48 50\n",
    "44x50: 53 57 54 52 51 70\n",
    "37x45: 36 39 35 45 46 54\n",
    "47x50: 63 69 56 57 54 63\n",
    "35x41: 37 30 43 35 40 36\n",
    "35x47: 34 24 26 19 31 30\n",
    "37x48: 34 32 33 33 35 24\n",
    "38x35: 18 25 26 20 20 22\n",
    "46x35: 24 22 31 34 29 25\n",
    "40x41: 29 25 31 30 26 27\n",
    "35x44: 40 40 47 51 30 31\n",
    "39x50: 51 54 49 47 42 57\n",
    "49x45: 56 42 67 46 65 62\n",
    "49x48: 60 63 56 68 69 47\n",
    "41x39: 40 39 45 41 43 38\n",
    "49x39: 30 38 36 49 37 18\n",
    "48x47: 35 40 42 46 41 35\n",
    "36x36: 45 30 29 32 40 27\n",
    "46x44: 47 50 56 56 51 51\n",
    "43x35: 32 41 46 38 30 43\n",
    "36x41: 57 40 34 39 32 31\n",
    "37x37: 31 32 36 36 34 41\n",
    "37x48: 41 45 47 45 54 40\n",
    "36x47: 47 46 37 46 42 44\n",
    "43x35: 36 47 35 39 31 43\n",
    "45x50: 65 58 58 62 48 58\n",
    "39x42: 35 44 43 46 44 39\n",
    "42x37: 19 30 35 38 24 22\n",
    "49x46: 59 55 44 62 64 64\n",
    "37x45: 33 28 29 29 34 26\n",
    "44x43: 65 43 39 48 60 41\n",
    "35x49: 39 33 42 46 48 55\n",
    "38x38: 29 39 35 42 42 34\n",
    "38x46: 45 42 47 44 51 40\n",
    "48x49: 39 38 52 47 38 42\n",
    "39x44: 40 44 49 51 47 33\n",
    "39x44: 41 50 31 47 44 51\n",
    "45x46: 36 42 39 35 38 34\n",
    "45x45: 46 51 49 64 52 50\n",
    "39x43: 33 31 29 32 21 35\n",
    "40x46: 47 46 55 52 47 37\n",
    "46x41: 61 54 51 49 35 44\n",
    "46x35: 33 22 31 20 27 32\n",
    "47x50: 57 59 64 55 60 65\n",
    "49x41: 48 62 45 56 46 52\n",
    "39x37: 41 29 33 40 40 41\n",
    "43x35: 40 39 44 43 36 31\n",
    "38x46: 56 46 45 50 37 39\n",
    "46x37: 52 48 39 41 41 43\n",
    "39x48: 36 30 41 33 34 34\n",
    "35x37: 20 20 21 28 19 24\n",
    "39x36: 25 27 25 28 26 25\n",
    "46x38: 45 53 44 43 45 39\n",
    "38x39: 37 40 33 32 42 43\n",
    "35x37: 20 28 18 24 20 21\n",
    "36x50: 54 43 41 50 50 42\n",
    "38x47: 46 50 45 52 47 36\n",
    "46x39: 37 62 30 41 47 56\n",
    "35x50: 28 36 18 31 29 34\n",
    "48x36: 39 46 51 53 41 36\n",
    "38x48: 31 28 30 41 33 29\n",
    "49x50: 41 46 46 50 32 41\n",
    "36x49: 57 45 41 38 49 44\n",
    "50x41: 62 48 68 36 48 54\n",
    "37x50: 54 42 54 36 40 59\n",
    "43x41: 41 47 44 37 45 55\n",
    "46x45: 28 50 42 40 35 30\n",
    "38x47: 42 47 40 46 58 41\n",
    "46x44: 65 55 55 42 50 47\n",
    "36x49: 36 28 24 31 32 40\n",
    "40x49: 54 50 47 45 47 59\n",
    "45x43: 38 36 37 33 34 31\n",
    "39x36: 32 39 41 41 36 27\n",
    "48x50: 49 70 63 56 67 60\n",
    "50x50: 63 72 52 74 54 71\n",
    "45x39: 49 40 66 41 35 40\n",
    "47x50: 65 57 55 60 62 64\n",
    "40x44: 42 45 42 44 48 49\n",
    "35x47: 40 46 41 44 42 40\n",
    "46x49: 52 57 62 49 56 68\n",
    "44x36: 38 38 50 46 40 32\n",
    "41x38: 28 17 36 20 29 26\n",
    "36x35: 23 24 16 22 17 29\n",
    "44x41: 55 42 38 44 43 58\n",
    "49x50: 65 66 65 64 55 63\n",
    "48x37: 20 40 36 37 29 30\n",
    "47x49: 68 57 54 50 65 62\n",
    "37x42: 24 37 21 32 26 28\n",
    "39x48: 56 54 48 44 36 52\n",
    "36x36: 20 20 30 24 25 24\n",
    "38x37: 31 29 27 21 17 18\n",
    "44x39: 28 36 26 32 31 28\n",
    "43x35: 41 36 40 43 33 40\n",
    "36x43: 31 28 30 28 24 26\n",
    "38x45: 18 27 26 22 37 49\n",
    "45x39: 31 34 29 34 38 28\n",
    "36x49: 35 28 29 38 32 29\n",
    "40x46: 44 46 43 45 50 54\n",
    "39x48: 51 50 41 48 56 43\n",
    "36x47: 42 40 41 55 41 43\n",
    "38x49: 42 38 26 28 32 25\n",
    "45x42: 42 32 38 33 25 39\n",
    "49x48: 64 52 65 60 63 59\n",
    "37x50: 42 53 40 51 48 50\n",
    "42x37: 21 27 26 35 31 28\n",
    "50x49: 66 64 61 56 71 59\n",
    "38x46: 45 53 50 42 45 34\n",
    "35x43: 34 35 28 20 22 15\n",
    "39x49: 26 33 39 38 34 37\n",
    "38x49: 46 39 56 47 58 40\n",
    "36x39: 27 27 26 32 19 24\n",
    "45x47: 55 55 57 49 46 63\n",
    "39x50: 44 48 52 47 52 55\n",
    "40x44: 61 40 41 41 43 49\n",
    "42x39: 34 43 36 56 37 46\n",
    "46x44: 53 48 53 51 55 52\n",
    "39x46: 44 48 34 40 61 48\n",
    "41x39: 25 26 34 23 31 29\n",
    "47x50: 39 43 46 32 42 37\n",
    "36x40: 36 37 49 33 34 32\n",
    "35x38: 37 25 35 35 36 38\n",
    "36x42: 31 27 28 27 28 26\n",
    "37x48: 37 45 53 51 45 41\n",
    "49x46: 66 55 63 48 57 59\n",
    "46x35: 43 41 39 39 46 40\n",
    "50x48: 55 73 73 56 54 56\n",
    "39x50: 36 38 37 33 34 29\n",
    "40x35: 27 22 21 22 28 23\n",
    "37x50: 39 32 34 27 18 41\n",
    "49x41: 63 51 55 48 45 50\n",
    "42x41: 46 44 47 38 36 54\n",
    "50x50: 46 26 43 46 50 44\n",
    "43x41: 32 33 26 28 27 35\n",
    "45x42: 43 38 33 33 35 27\n",
    "45x40: 56 39 36 54 46 50\n",
    "43x49: 41 39 67 62 62 51\n",
    "45x39: 27 30 22 29 39 48\n",
    "37x43: 35 23 33 23 25 28\n",
    "43x42: 39 32 36 31 22 36\n",
    "48x45: 49 37 35 44 31 43\n",
    "41x44: 42 51 48 42 48 45\n",
    "44x44: 42 47 50 44 47 65\n",
    "40x49: 37 38 28 34 33 37\n",
    "39x47: 37 30 37 30 33 28\n",
    "50x39: 25 34 35 43 34 37\n",
    "47x42: 29 38 31 35 37 40\n",
    "38x48: 41 43 47 51 52 46\n",
    "40x46: 46 62 34 55 46 41\n",
    "41x39: 32 28 24 21 33 30\n",
    "46x42: 45 52 46 55 43 56\n",
    "43x45: 36 33 38 44 25 33\n",
    "50x38: 31 26 35 39 33 28\n",
    "47x49: 66 54 62 47 62 64\n",
    "37x49: 49 44 44 54 47 43\n",
    "44x45: 35 37 37 26 31 44\n",
    "46x44: 36 67 54 52 51 47\n",
    "35x41: 31 42 36 33 39 38\n",
    "44x43: 49 52 51 45 41 53\n",
    "41x37: 34 38 31 38 45 46\n",
    "50x49: 75 57 57 65 60 67\n",
    "49x46: 35 42 37 44 44 38\n",
    "40x49: 60 43 49 45 53 54\n",
    "40x50: 31 29 39 38 36 34\n",
    "45x41: 44 43 46 45 62 43\n",
    "38x38: 33 43 37 41 36 32\n",
    "45x38: 52 43 45 33 40 51\n",
    "38x43: 29 37 21 26 29 25\n",
    "35x40: 25 21 28 23 23 23\n",
    "40x41: 44 44 46 42 42 35\n",
    "37x37: 35 35 36 42 25 39\n",
    "41x45: 54 40 49 41 42 59\n",
    "35x50: 46 47 44 46 40 47\n",
    "41x36: 25 24 25 22 30 29\n",
    "48x36: 34 28 35 29 36 29\n",
    "45x37: 46 49 42 39 44 37\n",
    "44x46: 39 31 34 34 32 40\n",
    "43x37: 41 45 41 39 40 39\n",
    "41x36: 35 26 27 26 20 21\n",
    "45x35: 39 47 39 38 43 36\n",
    "46x42: 54 50 50 38 47 58\n",
    "47x37: 41 40 36 47 51 52\n",
    "39x41: 37 41 41 41 37 48\n",
    "46x42: 50 55 51 52 47 43\n",
    "47x36: 51 42 29 45 54 42\n",
    "41x45: 23 28 34 32 35 43\n",
    "38x45: 44 37 43 41 41 57\n",
    "41x35: 38 36 32 42 40 34\n",
    "40x36: 42 28 31 41 30 52\n",
    "49x50: 77 54 53 60 78 59\n",
    "48x41: 49 50 46 52 51 55\n",
    "35x37: 27 13 25 19 24 24\n",
    "36x49: 39 41 51 60 42 39\n",
    "37x42: 30 29 32 26 25 26\n",
    "41x37: 44 33 34 46 31 48\n",
    "45x50: 49 56 63 71 56 51\n",
    "35x36: 21 18 24 22 21 26\n",
    "43x45: 32 35 33 37 43 30\n",
    "49x35: 24 32 24 36 31 29\n",
    "45x48: 32 38 53 47 35 35\n",
    "39x36: 44 42 31 26 37 37\n",
    "48x40: 44 28 34 33 37 32\n",
    "38x35: 21 26 20 24 26 15\n",
    "50x43: 30 35 26 48 46 39\n",
    "50x40: 48 30 27 35 28 39\n",
    "37x41: 38 37 41 35 41 41\n",
    "40x47: 40 36 36 24 24 34\n",
    "41x37: 30 27 21 29 25 23\n",
    "38x35: 29 19 17 17 26 23\n",
    "45x43: 37 42 38 24 33 35\n",
    "40x39: 39 43 42 40 31 45\n",
    "36x50: 43 50 48 45 42 48\n",
    "36x37: 28 37 35 38 34 32\n",
    "50x45: 69 48 65 59 51 58\n",
    "42x43: 33 29 32 39 28 35\n",
    "44x47: 57 52 58 55 43 55\n",
    "38x45: 27 44 46 46 45 51\n",
    "45x50: 40 39 53 39 35 33\n",
    "42x35: 40 34 37 43 38 36\n",
    "50x36: 38 49 51 53 44 41\n",
    "38x50: 48 46 53 47 49 49\n",
    "45x40: 37 26 36 28 31 37\n",
    "48x39: 53 63 39 43 39 52\n",
    "39x35: 28 38 33 32 44 33\n",
    "39x46: 53 46 42 57 36 46\n",
    "40x47: 51 50 54 46 41 48\n",
    "47x45: 56 50 56 47 65 51\n",
    "41x36: 22 24 19 38 30 22\n",
    "39x39: 33 46 37 29 44 42\n",
    "35x42: 29 42 35 38 40 40\n",
    "39x35: 21 22 29 26 22 22\n",
    "38x44: 31 33 20 33 31 20\n",
    "43x40: 35 40 49 41 44 53\n",
    "37x49: 34 26 31 35 30 36\n",
    "36x37: 31 31 39 32 34 37\n",
    "41x43: 47 49 52 38 41 44\n",
    "49x36: 23 34 33 34 32 36\n",
    "38x39: 35 40 36 29 44 42\n",
    "46x44: 51 48 61 63 46 44\n",
    "46x36: 44 31 48 45 46 42\n",
    "41x38: 32 51 37 42 38 38\n",
    "49x44: 47 42 33 33 28 40\n",
    "44x39: 31 26 36 29 33 26\n",
    "49x38: 38 55 50 48 40 53\n",
    "43x46: 54 47 56 54 50 45\n",
    "39x41: 32 45 46 44 36 41\n",
    "38x49: 33 28 36 37 31 26\n",
    "49x45: 34 39 43 40 32 51\n",
    "40x37: 36 47 40 34 38 32\n",
    "36x45: 47 45 39 41 38 41\n",
    "46x39: 42 47 54 44 45 43\n",
    "43x40: 44 40 47 39 47 47\n",
    "48x41: 42 54 46 60 61 39\n",
    "44x42: 45 46 49 48 37 59\n",
    "48x38: 33 24 39 35 26 34\n",
    "50x46: 69 63 55 58 46 66\n",
    "47x36: 43 45 36 46 45 46\n",
    "46x40: 28 29 34 38 36 30\n",
    "35x45: 19 22 35 24 35 30\n",
    "41x42: 46 42 49 45 33 51\n",
    "46x42: 54 47 51 44 46 56\n",
    "46x39: 34 35 31 32 27 35\n",
    "43x41: 48 45 35 50 54 41\n",
    "35x41: 27 18 25 21 22 30\n",
    "46x44: 46 56 46 52 55 55\n",
    "47x36: 48 39 49 45 36 45\n",
    "39x41: 26 32 26 29 24 32\n",
    "46x41: 44 56 48 47 42 52\n",
    "49x49: 61 66 49 58 69 66\n",
    "47x37: 25 28 36 22 28 41\n",
    "43x41: 51 37 37 45 50 53\n",
    "46x39: 49 49 37 45 57 40\n",
    "37x39: 25 27 28 21 31 23\n",
    "46x35: 23 25 25 23 30 38\n",
    "43x37: 32 38 19 28 26 24\n",
    "35x47: 33 26 24 31 27 23\n",
    "36x43: 29 42 39 43 34 49\n",
    "37x46: 32 35 33 35 20 25\n",
    "41x42: 34 38 42 49 52 48\n",
    "44x41: 38 50 49 43 42 53\n",
    "35x41: 18 21 28 28 26 22\n",
    "36x36: 19 22 27 34 15 26\n",
    "42x44: 29 32 34 31 38 31\n",
    "40x44: 28 29 39 23 35 27\n",
    "38x39: 34 37 47 37 40 32\n",
    "39x38: 38 23 18 32 24 21\n",
    "46x35: 50 38 35 38 46 43\n",
    "41x47: 51 45 51 41 56 52\n",
    "35x45: 31 23 34 25 23 29\n",
    "41x40: 40 40 51 43 40 38\n",
    "42x36: 25 33 36 24 16 34\n",
    "49x44: 33 38 40 36 40 36\n",
    "37x45: 38 33 46 43 54 41\n",
    "45x39: 40 38 25 35 28 28\n",
    "39x36: 35 29 43 37 35 37\n",
    "50x45: 50 62 53 57 59 63\n",
    "45x38: 35 28 26 25 39 26\n",
    "46x37: 16 28 30 40 38 28\n",
    "49x47: 46 46 32 31 40 45\n",
    "40x47: 56 58 45 36 51 44\n",
    "48x43: 38 28 29 49 36 43\n",
    "49x48: 61 67 47 64 63 61\n",
    "41x40: 32 49 50 45 41 33\n",
    "50x46: 39 47 36 33 37 47\n",
    "43x40: 30 27 34 32 24 34\n",
    "48x44: 48 52 50 71 52 53\n",
    "40x48: 35 33 31 41 32 35\n",
    "42x44: 43 27 33 31 26 35\n",
    "46x50: 64 60 54 68 54 57\n",
    "39x46: 51 54 51 42 48 31\n",
    "44x45: 49 60 46 54 38 58\n",
    "49x37: 46 48 57 47 38 43\n",
    "39x35: 25 21 26 31 22 18\n",
    "44x47: 39 33 42 29 34 32\n",
    "42x35: 37 41 41 28 35 43\n",
    "40x43: 47 42 51 52 34 41\n",
    "44x46: 34 42 34 27 34 38\n",
    "48x39: 48 47 47 39 47 59\n",
    "50x48: 61 63 75 44 69 55\n",
    "41x47: 27 26 40 36 32 33\n",
    "36x49: 31 26 30 31 39 34\n",
    "44x37: 45 51 37 44 41 34\n",
    "44x48: 52 50 50 56 56 61\n",
    "37x44: 24 25 21 33 34 31\n",
    "50x39: 61 51 54 48 40 49\n",
    "42x46: 46 44 49 54 48 56\n",
    "35x43: 34 46 39 36 37 38\n",
    "50x40: 37 36 32 34 37 31\n",
    "36x42: 38 29 21 30 28 21\n",
    "44x48: 47 30 38 40 33 36\n",
    "50x35: 45 42 51 42 42 47\n",
    "47x40: 27 25 33 35 39 35\n",
    "41x41: 39 52 32 44 48 43\n",
    "39x44: 39 52 45 46 36 45\n",
    "39x50: 35 38 30 36 35 33\n",
    "44x39: 41 49 40 55 42 38\n",
    "36x44: 52 32 36 52 35 42\n",
    "36x36: 35 35 34 33 34 29\n",
    "37x36: 37 25 23 20 17 21\n",
    "49x39: 51 41 46 64 42 53\n",
    "42x46: 47 50 45 52 48 55\n",
    "39x42: 34 38 29 30 27 23\n",
    "38x35: 29 40 33 38 31 33\n",
    "44x39: 30 32 23 26 39 31\n",
    "39x42: 34 49 38 41 42 46\n",
    "45x39: 52 46 53 49 46 27\n",
    "46x49: 70 57 52 53 54 64\n",
    "43x37: 38 41 45 46 49 26\n",
    "50x41: 33 29 38 38 39 30\n",
    "47x47: 54 59 53 62 57 55\n",
    "42x47: 35 30 33 40 35 36\n",
    "44x40: 32 26 29 27 29 38\n",
    "39x35: 21 25 26 24 24 23\n",
    "40x38: 41 28 35 33 47 50\n",
    "45x49: 51 57 68 71 44 49\n",
    "49x40: 57 49 48 52 52 46\n",
    "38x47: 39 20 25 26 36 34\n",
    "36x40: 28 24 21 25 30 28\n",
    "43x48: 35 36 37 39 37 40\n",
    "36x42: 39 44 32 40 30 48\n",
    "44x47: 38 39 34 36 33 30\n",
    "44x47: 45 58 55 51 49 58\n",
    "35x43: 34 31 52 43 38 33\n",
    "40x45: 37 37 31 22 41 27\n",
    "50x40: 49 57 55 42 55 48\n",
    "40x45: 41 43 50 41 48 52\n",
    "40x39: 43 35 40 47 36 41\n",
    "49x48: 48 62 62 78 61 50\n",
    "50x38: 46 40 50 44 56 55\n",
    "49x35: 54 48 38 51 39 38\n",
    "49x37: 23 37 26 35 36 34\n",
    "49x49: 57 63 59 67 70 53\n",
    "40x35: 42 22 36 39 39 40\n",
    "36x48: 27 29 26 32 40 37\n",
    "43x39: 47 40 35 47 46 45\n",
    "47x36: 44 45 39 38 49 45\n",
    "42x39: 39 49 39 39 40 45\n",
    "43x49: 53 52 51 54 57 57\n",
    "45x42: 31 34 32 35 34 44\n",
    "39x36: 42 33 35 37 41 30\n",
    "50x42: 43 27 41 42 35 35\n",
    "46x41: 48 45 52 53 43 50\n",
    "48x37: 40 25 24 35 38 29\n",
    "50x48: 53 75 67 47 69 54\n",
    "38x49: 38 34 24 38 28 29\n",
    "49x47: 41 39 38 47 40 34\n",
    "36x41: 36 39 38 38 30 46\n",
    "40x37: 29 14 24 25 25 38\n",
    "45x42: 29 38 36 36 38 32\n",
    "42x39: 32 30 31 31 30 27\n",
    "50x38: 23 38 32 33 42 24\n",
    "40x47: 33 42 30 34 29 27\n",
    "37x42: 36 44 39 46 35 39\n",
    "38x43: 40 41 53 41 40 36\n",
    "35x40: 43 28 35 44 40 29\n",
    "47x36: 31 27 27 27 32 36\n",
    "36x48: 37 40 47 43 44 53\n",
    "37x43: 23 31 32 32 26 24\n",
    "38x47: 24 27 35 24 31 38\n",
    "46x41: 52 36 49 45 49 60\n",
    "39x48: 44 34 36 33 29 32\n",
    "46x42: 38 34 33 36 33 36\n",
    "46x49: 55 54 62 49 66 59\n",
    "44x47: 57 56 64 41 55 45\n",
    "39x36: 34 34 35 38 38 37\n",
    "49x44: 32 28 33 42 45 44\n",
    "42x48: 61 44 54 44 56 53\n",
    "50x36: 53 49 55 44 41 37\n",
    "50x35: 50 46 46 38 45 45\n",
    "39x45: 50 36 53 46 42 45\n",
    "37x36: 35 32 35 37 31 36\n",
    "39x47: 37 38 51 58 49 48\n",
    "40x35: 29 19 31 16 23 24\n",
    "41x47: 57 50 52 44 52 43\n",
    "49x37: 31 28 35 33 27 37\n",
    "36x49: 45 32 39 61 46 51\n",
    "45x45: 65 61 43 48 48 50\n",
    "38x43: 28 23 31 27 30 29\n",
    "45x49: 61 63 67 57 42 51\n",
    "47x41: 42 58 40 45 58 51\n",
    "43x46: 51 52 46 61 59 37\n",
    "36x38: 23 32 27 23 20 19\n",
    "39x37: 50 32 33 24 49 36\n",
    "35x46: 27 23 28 29 24 33\n",
    "45x35: 43 42 36 44 47 32\n",
    "45x37: 48 43 45 51 32 40\n",
    "40x38: 24 22 31 32 28 19\n",
    "38x35: 26 24 17 23 23 18\n",
    "38x45: 43 36 50 43 45 46\n",
    "37x35: 34 37 35 21 30 41\n",
    "38x35: 29 33 38 44 34 27\n",
    "40x46: 44 39 54 50 47 49\n",
    "46x47: 42 36 39 32 43 33\n",
    "42x39: 38 22 28 28 27 39\n",
    "41x41: 18 37 27 28 26 33\n",
    "43x42: 50 39 43 52 51 45\n",
    "50x50: 65 55 72 55 66 71\n",
    "36x42: 40 36 37 36 41 43\n",
    "35x44: 29 25 20 31 29 19\n",
    "47x50: 64 58 63 61 64 53\n",
    "45x50: 69 61 62 45 52 59\n",
    "43x50: 30 32 34 35 47 45\n",
    "43x47: 50 58 43 55 49 56\n",
    "39x45: 25 38 39 29 24 40\n",
    "40x50: 43 34 39 37 35 19\n",
    "42x49: 49 54 53 47 62 50\n",
    "42x39: 47 49 33 37 49 38\n",
    "38x46: 42 45 29 42 52 58\n",
    "45x44: 32 36 37 33 38 33\n",
    "48x36: 30 38 24 38 30 32\n",
    "46x50: 36 64 60 70 63 56\n",
    "50x38: 41 26 27 39 34 25\n",
    "48x36: 40 48 53 38 43 42\n",
    "39x43: 26 20 34 31 33 37\n",
    "48x46: 47 41 30 39 40 43\n",
    "43x50: 38 42 28 40 40 35\n",
    "36x41: 25 18 25 20 33 34\n",
    "41x42: 40 49 44 44 41 46\n",
    "36x38: 44 33 32 33 37 34\n",
    "46x40: 51 54 35 50 52 43\n",
    "49x48: 42 49 47 37 29 51\n",
    "37x49: 31 31 33 34 31 32\n",
    "48x49: 34 47 35 43 49 48\n",
    "42x43: 44 35 64 43 46 45\n",
    "46x40: 33 28 39 38 30 26\n",
    "38x38: 32 39 38 38 32 42\n",
    "46x35: 27 25 21 28 39 25\n",
    "44x38: 32 34 41 48 52 48\n",
    "38x50: 35 49 59 45 44 56\n",
    "48x48: 47 47 41 34 51 35\n",
    "45x41: 64 38 38 41 52 55\n",
    "46x38: 24 32 36 31 27 29\n",
    "49x39: 49 27 32 29 38 32\n",
    "50x48: 57 59 60 54 65 72\n",
    "40x38: 24 32 26 20 20 34\n",
    "41x46: 44 57 50 40 44 53\n",
    "37x41: 52 42 34 29 42 37\n",
    "39x37: 23 28 23 27 31 23\n",
    "50x46: 48 44 40 31 40 37\n",
    "39x43: 26 19 40 30 30 37\n",
    "36x37: 28 36 35 39 31 35\n",
    "45x42: 44 37 27 32 34 36\n",
    "37x45: 45 31 50 36 49 45\n",
    "42x36: 35 43 28 41 43 42\n",
    "40x50: 63 44 38 56 56 55\n",
    "40x40: 47 39 37 39 42 44\n",
    "41x39: 40 31 29 19 24 25\n",
    "43x35: 35 46 34 40 36 40\n",
    "40x45: 24 39 35 30 41 25\n",
    "47x40: 40 46 54 47 56 44\n",
    "40x41: 43 49 33 50 36 43\n",
    "47x40: 40 32 34 22 30 37\n",
    "42x49: 46 56 62 47 60 43\n",
    "43x35: 29 27 27 26 19 25\n",
    "38x42: 40 40 39 43 42 42\n",
    "35x38: 27 38 33 34 38 33\n",
    "41x38: 30 23 21 29 22 30\n",
    "36x44: 23 37 29 26 26 27\n",
    "40x44: 26 22 35 32 33 33\n",
    "47x35: 49 47 51 32 37 38\n",
    "38x36: 38 39 30 25 43 35\n",
    "44x43: 47 55 57 50 46 36\n",
    "36x50: 31 34 29 31 34 32\n",
    "48x49: 64 57 49 67 69 58\n",
    "48x40: 39 29 29 36 36 39\n",
    "47x42: 35 33 37 34 38 33\n",
    "40x46: 53 46 43 68 48 30\n",
    "50x41: 42 36 38 34 29 28\n",
    "37x50: 31 39 38 27 26 30\n",
    "42x46: 31 37 38 33 34 37\n",
    "48x45: 29 50 37 41 36 47\n",
    "37x46: 48 44 44 40 45 42\n",
    "50x47: 52 62 66 51 55 72\n",
    "40x50: 41 28 40 32 31 36\n",
    "40x39: 30 29 26 23 25 35\n",
    "46x36: 48 43 42 53 44 28\n",
    "44x37: 26 23 34 29 25 30\n",
    "45x42: 43 35 29 35 26 41\n",
    "46x37: 50 47 46 36 46 38\n",
    "39x45: 46 37 49 48 46 45\n",
    "38x35: 14 24 20 26 24 24\n",
    "45x44: 31 34 39 33 35 37\n",
    "41x46: 38 44 50 58 51 48\n",
    "37x38: 30 40 33 43 36 34\n",
    "41x36: 36 47 32 33 35 43\n",
    "50x39: 53 51 46 50 55 46\n",
    "45x38: 32 26 31 23 32 35\n",
    "50x44: 40 36 31 33 36 47\n",
    "39x38: 19 32 25 16 35 28\n",
    "49x48: 47 25 53 50 42 38\n",
    "37x38: 31 26 15 28 21 22\n",
    "44x43: 38 47 62 39 46 55\n",
    "50x50: 44 58 74 57 85 60\n",
    "36x35: 32 34 27 32 34 35\n",
    "46x36: 44 42 41 31 49 47\n",
    "49x45: 44 56 54 63 51 69\n",
    "49x46: 52 62 43 68 58 64\n",
    "46x49: 45 37 36 37 39 45\n",
    "43x42: 30 32 40 30 26 38\n",
    "44x49: 46 62 57 53 56 55\n",
    "39x39: 25 35 30 18 32 28\n",
    "48x45: 41 46 63 74 43 64\n",
    "50x45: 55 62 63 53 47 65\n",
    "39x36: 47 34 30 40 33 36\n",
    "41x42: 28 26 28 27 42 30\n",
    "36x39: 30 24 25 25 27 25\n",
    "35x46: 21 29 29 29 27 30\n",
    "49x45: 53 62 57 47 55 63\n",
    "37x44: 22 25 26 33 26 36\n",
    "37x40: 32 27 25 24 20 27\n",
    "36x38: 30 27 32 46 36 40\n",
    "40x42: 46 42 39 54 44 36\n",
    "44x45: 54 38 57 58 53 47\n",
    "46x39: 45 27 27 29 27 39\n",
    "45x42: 36 39 37 34 27 37\n",
    "49x40: 26 45 26 38 44 28\n",
    "44x38: 21 26 24 30 34 33\n",
    "45x45: 47 53 49 50 55 56\n",
    "48x38: 49 51 42 43 49 47\n",
    "36x40: 25 26 36 15 26 27\n",
    "47x38: 44 31 48 43 53 55\n",
    "46x35: 22 34 29 20 35 24\n",
    "35x50: 58 47 41 42 41 44\n",
    "41x40: 26 27 27 29 31 29\n",
    "49x43: 39 31 41 31 28 53\n",
    "37x44: 42 40 34 51 41 44\n",
    "46x44: 40 42 67 63 38 60\n",
    "37x37: 26 43 28 33 38 40\n",
    "47x37: 28 49 45 37 56 47\n",
    "44x46: 67 60 46 39 44 58\n",
    "45x35: 36 38 56 46 28 38\n",
    "47x50: 50 73 61 53 56 65\n",
    "38x46: 27 31 37 33 28 24\n",
    "41x40: 47 40 38 42 38 49\n",
    "37x49: 37 31 38 29 30 26\n",
    "35x46: 35 38 31 54 46 44\n",
    "42x40: 28 27 35 32 29 31\n",
    "46x42: 32 33 29 26 44 46\n",
    "37x49: 28 34 38 32 32 27\n",
    "41x36: 39 39 36 39 37 38\n",
    "46x47: 39 40 42 26 47 31\n",
    "41x36: 30 20 23 24 27 32\n",
    "40x38: 45 33 33 32 47 45\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f2b6a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_pieces = []\n",
    "piece = []\n",
    "bin_packs = False\n",
    "board_sizes = []\n",
    "counters = [] \n",
    "for line in input_str.split('\\n'):\n",
    "    if(line.startswith('#') or line.startswith('.')):\n",
    "        piece.append([1 if c=='#' else 0 for c in line])\n",
    "    if(line==''):\n",
    "        puzzle_pieces.append(piece)\n",
    "        piece = []\n",
    "        continue\n",
    "    if(bin_packs or line.startswith('4x4:') or line.startswith('42x45:')):\n",
    "        bin_packs = True\n",
    "        board_sizes.append([int(line.split(':')[0].split('x')[0]),int(line.split(':')[0].split('x')[1])])\n",
    "        counters.append([int(x) for x in line.split(':')[1].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "afb0ced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 44] 2200 1432\n",
      "[42, 49] 2058 1459\n",
      "[40, 46] 1840 1276\n",
      "[45, 44] 1980 1373\n",
      "[44, 39] 1716 1189\n",
      "[47, 50] 2350 1558\n",
      "[50, 48] 2400 1676\n",
      "[39, 35] 1365 931\n",
      "[50, 49] 2450 1673\n",
      "[44, 49] 2156 1442\n",
      "[50, 39] 1950 1349\n",
      "[37, 36] 1332 937\n",
      "[35, 49] 1715 1124\n",
      "[48, 44] 2112 1461\n",
      "[45, 38] 1710 1166\n",
      "[47, 46] 2162 1455\n",
      "[37, 47] 1739 1162\n",
      "[42, 36] 1512 1082\n",
      "[41, 36] 1476 1001\n",
      "[47, 39] 1833 1264\n",
      "[43, 43] 1849 1276\n",
      "[37, 45] 1665 1173\n",
      "[43, 41] 1763 1206\n",
      "[48, 45] 2160 1562\n",
      "[44, 40] 1760 1190\n",
      "[42, 47] 1974 1367\n",
      "[39, 41] 1599 1094\n",
      "[48, 36] 1728 1256\n",
      "[41, 44] 1804 1165\n",
      "[48, 41] 1968 1357\n",
      "[37, 40] 1480 1019\n",
      "[48, 50] 2400 1671\n",
      "[40, 46] 1840 1271\n",
      "[35, 46] 1610 1069\n",
      "[40, 41] 1640 1078\n",
      "[38, 44] 1672 1072\n",
      "[39, 45] 1755 1265\n",
      "[41, 50] 2050 1368\n",
      "[47, 41] 1927 1257\n",
      "[38, 35] 1330 850\n",
      "[46, 37] 1702 1168\n",
      "[35, 41] 1435 927\n",
      "[37, 45] 1665 1159\n",
      "[47, 41] 1927 1238\n",
      "[47, 44] 2068 1377\n",
      "[46, 49] 2254 1538\n",
      "[38, 45] 1710 1157\n",
      "[44, 47] 2068 1377\n",
      "[43, 41] 1763 1190\n",
      "[37, 35] 1295 857\n",
      "[40, 46] 1840 1244\n",
      "[37, 40] 1480 1024\n",
      "[45, 49] 2205 1544\n",
      "[39, 35] 1365 913\n",
      "[37, 37] 1369 949\n",
      "[42, 47] 1974 1385\n",
      "[45, 39] 1755 1273\n",
      "[41, 38] 1558 1018\n",
      "[36, 36] 1296 952\n",
      "[40, 49] 1960 1349\n",
      "[47, 48] 2256 1575\n",
      "[41, 42] 1722 1189\n",
      "[43, 50] 2150 1461\n",
      "[49, 40] 1960 1366\n",
      "[47, 40] 1880 1267\n",
      "[35, 42] 1470 1000\n",
      "[41, 45] 1845 1291\n",
      "[44, 39] 1716 1180\n",
      "[42, 36] 1512 1097\n",
      "[40, 46] 1840 1252\n",
      "[38, 38] 1444 937\n",
      "[38, 47] 1786 1175\n",
      "[44, 45] 1980 1378\n",
      "[39, 49] 1911 1353\n",
      "[50, 40] 2000 1335\n",
      "[42, 37] 1554 1081\n",
      "[37, 41] 1517 1012\n",
      "[40, 38] 1520 1026\n",
      "[45, 44] 1980 1373\n",
      "[46, 37] 1702 1155\n",
      "[44, 44] 1936 1264\n",
      "[46, 44] 2024 1349\n",
      "[50, 37] 1850 1245\n",
      "[38, 37] 1406 923\n",
      "[49, 46] 2254 1555\n",
      "[49, 41] 2009 1366\n",
      "[41, 35] 1435 909\n",
      "[36, 46] 1656 1168\n",
      "[49, 45] 2205 1552\n",
      "[49, 40] 1960 1360\n",
      "[44, 48] 2112 1456\n",
      "[40, 41] 1640 1091\n",
      "[49, 37] 1813 1241\n",
      "[36, 37] 1332 912\n",
      "[35, 42] 1470 992\n",
      "[45, 39] 1755 1250\n",
      "[38, 50] 1900 1242\n",
      "[37, 42] 1554 1103\n",
      "[46, 49] 2254 1542\n",
      "[50, 45] 2250 1546\n",
      "[35, 35] 1225 789\n",
      "[45, 46] 2070 1459\n",
      "[41, 44] 1804 1185\n",
      "[36, 42] 1512 1081\n",
      "[42, 49] 2058 1444\n",
      "[38, 39] 1482 1005\n",
      "[50, 46] 2300 1568\n",
      "[44, 35] 1540 1004\n",
      "[43, 36] 1548 1091\n",
      "[38, 38] 1444 938\n",
      "[38, 43] 1634 1097\n",
      "[38, 38] 1444 941\n",
      "[35, 46] 1610 1073\n",
      "[40, 35] 1400 931\n",
      "[35, 39] 1365 935\n",
      "[42, 46] 1932 1329\n",
      "[45, 38] 1710 1159\n",
      "[48, 39] 1872 1338\n",
      "[39, 47] 1833 1261\n",
      "[35, 43] 1505 1003\n",
      "[44, 42] 1848 1291\n",
      "[40, 48] 1920 1349\n",
      "[46, 41] 1886 1261\n",
      "[39, 40] 1560 1104\n",
      "[39, 42] 1638 1176\n",
      "[49, 40] 1960 1352\n",
      "[40, 48] 1920 1349\n",
      "[43, 40] 1720 1178\n",
      "[44, 41] 1804 1171\n",
      "[38, 49] 1862 1248\n",
      "[48, 36] 1728 1257\n",
      "[38, 38] 1444 927\n",
      "[44, 43] 1892 1255\n",
      "[35, 48] 1680 1142\n",
      "[45, 46] 2070 1458\n",
      "[49, 39] 1911 1353\n",
      "[36, 50] 1800 1237\n",
      "[46, 46] 2116 1468\n",
      "[45, 47] 2115 1463\n",
      "[40, 43] 1720 1179\n",
      "[40, 47] 1880 1280\n",
      "[37, 43] 1591 1072\n",
      "[42, 49] 2058 1471\n",
      "[35, 48] 1680 1148\n",
      "[48, 48] 2304 1663\n",
      "[41, 40] 1640 1100\n",
      "[41, 50] 2050 1360\n",
      "[41, 37] 1517 1023\n",
      "[38, 46] 1748 1163\n",
      "[41, 49] 2009 1359\n",
      "[49, 49] 2401 1682\n",
      "[46, 44] 2024 1357\n",
      "[40, 50] 2000 1343\n",
      "[44, 37] 1628 1086\n",
      "[48, 43] 2064 1450\n",
      "[35, 40] 1400 938\n",
      "[40, 42] 1680 1186\n",
      "[39, 39] 1521 1103\n",
      "[35, 47] 1645 1061\n",
      "[37, 48] 1776 1236\n",
      "[38, 35] 1330 861\n",
      "[46, 35] 1610 1073\n",
      "[40, 41] 1640 1088\n",
      "[49, 39] 1911 1347\n",
      "[48, 47] 2256 1557\n",
      "[42, 37] 1554 1100\n",
      "[37, 45] 1665 1158\n",
      "[48, 49] 2352 1667\n",
      "[45, 46] 2070 1461\n",
      "[39, 43] 1677 1169\n",
      "[46, 35] 1610 1069\n",
      "[39, 48] 1872 1351\n",
      "[35, 37] 1295 856\n",
      "[39, 36] 1404 1014\n",
      "[35, 37] 1295 853\n",
      "[35, 50] 1750 1145\n",
      "[38, 48] 1824 1241\n",
      "[49, 50] 2450 1660\n",
      "[46, 45] 2070 1479\n",
      "[36, 49] 1764 1234\n",
      "[45, 43] 1935 1354\n",
      "[41, 38] 1558 1016\n",
      "[36, 35] 1260 849\n",
      "[48, 37] 1776 1267\n",
      "[37, 42] 1554 1096\n",
      "[36, 36] 1296 937\n",
      "[38, 37] 1406 918\n",
      "[44, 39] 1716 1179\n",
      "[36, 43] 1548 1079\n",
      "[38, 45] 1710 1195\n",
      "[45, 39] 1755 1262\n",
      "[36, 49] 1764 1229\n",
      "[38, 49] 1862 1225\n",
      "[45, 42] 1890 1346\n",
      "[42, 37] 1554 1099\n",
      "[35, 43] 1505 990\n",
      "[39, 49] 1911 1359\n",
      "[36, 39] 1404 999\n",
      "[41, 39] 1599 1103\n",
      "[47, 50] 2350 1563\n",
      "[36, 42] 1512 1080\n",
      "[39, 50] 1950 1344\n",
      "[40, 35] 1400 925\n",
      "[37, 50] 1850 1232\n",
      "[50, 50] 2500 1647\n",
      "[43, 41] 1763 1175\n",
      "[45, 42] 1890 1344\n",
      "[45, 39] 1755 1282\n",
      "[37, 43] 1591 1076\n",
      "[43, 42] 1806 1263\n",
      "[48, 45] 2160 1531\n",
      "[40, 49] 1960 1341\n",
      "[39, 47] 1833 1261\n",
      "[50, 39] 1950 1363\n",
      "[47, 42] 1974 1377\n",
      "[41, 39] 1599 1091\n",
      "[43, 45] 1935 1347\n",
      "[50, 38] 1900 1243\n",
      "[44, 45] 1980 1374\n",
      "[49, 46] 2254 1566\n",
      "[40, 50] 2000 1349\n",
      "[38, 43] 1634 1085\n",
      "[35, 40] 1400 928\n",
      "[41, 36] 1476 1013\n",
      "[48, 36] 1728 1240\n",
      "[44, 46] 2024 1358\n",
      "[41, 36] 1476 989\n",
      "[41, 45] 1845 1287\n",
      "[35, 37] 1295 851\n",
      "[37, 42] 1554 1090\n",
      "[35, 36] 1260 860\n",
      "[43, 45] 1935 1369\n",
      "[49, 35] 1715 1148\n",
      "[45, 48] 2160 1569\n",
      "[48, 40] 1920 1335\n",
      "[38, 35] 1330 858\n",
      "[50, 43] 2150 1460\n",
      "[50, 40] 2000 1318\n",
      "[40, 47] 1880 1254\n",
      "[41, 37] 1517 996\n",
      "[38, 35] 1330 842\n",
      "[45, 43] 1935 1365\n",
      "[42, 43] 1806 1267\n",
      "[45, 50] 2250 1554\n",
      "[45, 40] 1800 1263\n",
      "[41, 36] 1476 1003\n",
      "[39, 35] 1365 926\n",
      "[38, 44] 1672 1081\n",
      "[37, 49] 1813 1241\n",
      "[49, 36] 1764 1264\n",
      "[49, 44] 2156 1434\n",
      "[44, 39] 1716 1176\n",
      "[38, 49] 1862 1234\n",
      "[49, 45] 2205 1565\n",
      "[48, 38] 1824 1236\n",
      "[46, 40] 1840 1271\n",
      "[35, 45] 1575 1093\n",
      "[46, 39] 1794 1258\n",
      "[35, 41] 1435 926\n",
      "[39, 41] 1599 1102\n",
      "[47, 37] 1739 1188\n",
      "[37, 39] 1443 1014\n",
      "[46, 35] 1610 1079\n",
      "[43, 37] 1591 1077\n",
      "[35, 47] 1645 1051\n",
      "[37, 46] 1702 1161\n",
      "[35, 41] 1435 937\n",
      "[36, 36] 1296 929\n",
      "[42, 44] 1848 1276\n",
      "[40, 44] 1760 1188\n",
      "[39, 38] 1482 984\n",
      "[35, 45] 1575 1068\n",
      "[42, 36] 1512 1102\n",
      "[49, 44] 2156 1459\n",
      "[45, 39] 1755 1243\n",
      "[45, 38] 1710 1158\n",
      "[46, 37] 1702 1188\n",
      "[49, 47] 2303 1557\n",
      "[48, 43] 2064 1436\n",
      "[50, 46] 2300 1562\n",
      "[43, 40] 1720 1175\n",
      "[40, 48] 1920 1338\n",
      "[42, 44] 1848 1248\n",
      "[39, 35] 1365 920\n",
      "[44, 47] 2068 1356\n",
      "[44, 46] 2024 1368\n",
      "[41, 47] 1927 1268\n",
      "[36, 49] 1764 1244\n",
      "[37, 44] 1628 1095\n",
      "[50, 40] 2000 1341\n",
      "[36, 42] 1512 1063\n",
      "[44, 48] 2112 1434\n",
      "[47, 40] 1880 1269\n",
      "[39, 50] 1950 1343\n",
      "[37, 36] 1332 907\n",
      "[39, 42] 1638 1169\n",
      "[44, 39] 1716 1181\n",
      "[50, 41] 2050 1345\n",
      "[42, 47] 1974 1353\n",
      "[44, 40] 1760 1176\n",
      "[39, 35] 1365 935\n",
      "[38, 47] 1786 1156\n",
      "[36, 40] 1440 1011\n",
      "[43, 48] 2064 1459\n",
      "[44, 47] 2068 1358\n",
      "[40, 45] 1800 1269\n",
      "[49, 37] 1813 1256\n",
      "[36, 48] 1728 1251\n",
      "[45, 42] 1890 1373\n",
      "[50, 42] 2100 1433\n",
      "[48, 37] 1776 1222\n",
      "[38, 49] 1862 1223\n",
      "[49, 47] 2303 1544\n",
      "[40, 37] 1480 1002\n",
      "[45, 42] 1890 1369\n",
      "[42, 39] 1638 1172\n",
      "[50, 38] 1900 1265\n",
      "[40, 47] 1880 1265\n",
      "[47, 36] 1692 1171\n",
      "[37, 43] 1591 1098\n",
      "[38, 47] 1786 1181\n",
      "[39, 48] 1872 1335\n",
      "[46, 42] 1932 1358\n",
      "[49, 44] 2156 1462\n",
      "[40, 35] 1400 920\n",
      "[49, 37] 1813 1242\n",
      "[38, 43] 1634 1093\n",
      "[36, 38] 1368 939\n",
      "[35, 46] 1610 1065\n",
      "[40, 38] 1520 1012\n",
      "[38, 35] 1330 842\n",
      "[46, 47] 2162 1459\n",
      "[42, 39] 1638 1170\n",
      "[41, 41] 1681 1119\n",
      "[35, 44] 1540 982\n",
      "[43, 50] 2150 1466\n",
      "[39, 45] 1755 1286\n",
      "[40, 50] 2000 1326\n",
      "[45, 44] 1980 1366\n",
      "[48, 36] 1728 1246\n",
      "[50, 38] 1900 1223\n",
      "[39, 43] 1677 1184\n",
      "[48, 46] 2208 1547\n",
      "[43, 50] 2150 1445\n",
      "[36, 41] 1476 1015\n",
      "[49, 48] 2352 1664\n",
      "[37, 49] 1813 1248\n",
      "[48, 49] 2352 1681\n",
      "[46, 40] 1840 1254\n",
      "[46, 35] 1610 1073\n",
      "[48, 48] 2304 1657\n",
      "[46, 38] 1748 1174\n",
      "[49, 39] 1911 1322\n",
      "[40, 38] 1520 1024\n",
      "[39, 37] 1443 1012\n",
      "[50, 46] 2300 1553\n",
      "[39, 43] 1677 1192\n",
      "[45, 42] 1890 1350\n",
      "[41, 39] 1599 1077\n",
      "[40, 45] 1800 1280\n",
      "[47, 40] 1880 1263\n",
      "[43, 35] 1505 987\n",
      "[41, 38] 1558 996\n",
      "[36, 44] 1584 1104\n",
      "[40, 44] 1760 1183\n",
      "[36, 50] 1800 1244\n",
      "[48, 40] 1920 1342\n",
      "[47, 42] 1974 1366\n",
      "[50, 41] 2050 1331\n",
      "[37, 50] 1850 1248\n",
      "[42, 46] 1932 1375\n",
      "[48, 45] 2160 1581\n",
      "[40, 50] 2000 1342\n",
      "[40, 39] 1560 1093\n",
      "[44, 37] 1628 1088\n",
      "[45, 42] 1890 1342\n",
      "[38, 35] 1330 870\n",
      "[45, 44] 1980 1368\n",
      "[45, 38] 1710 1166\n",
      "[50, 44] 2200 1448\n",
      "[39, 38] 1482 1031\n",
      "[49, 48] 2352 1641\n",
      "[37, 38] 1406 911\n",
      "[46, 49] 2254 1546\n",
      "[43, 42] 1806 1282\n",
      "[39, 39] 1521 1108\n",
      "[41, 42] 1722 1184\n",
      "[36, 39] 1404 1007\n",
      "[35, 46] 1610 1084\n",
      "[37, 44] 1628 1099\n",
      "[37, 40] 1480 997\n",
      "[46, 39] 1794 1239\n",
      "[45, 42] 1890 1364\n",
      "[49, 40] 1960 1359\n",
      "[44, 38] 1672 1104\n",
      "[36, 40] 1440 1020\n",
      "[46, 35] 1610 1084\n",
      "[41, 40] 1640 1102\n",
      "[49, 43] 2107 1452\n",
      "[38, 46] 1748 1173\n",
      "[37, 49] 1813 1234\n",
      "[42, 40] 1680 1186\n",
      "[46, 42] 1932 1380\n",
      "[37, 49] 1813 1249\n",
      "[46, 47] 2162 1471\n",
      "[41, 36] 1476 1008\n"
     ]
    }
   ],
   "source": [
    "size_problems = 0 \n",
    "differences = []\n",
    "for idx1 in range(len(counters)):\n",
    "    board_area = board_sizes[idx1][0]*board_sizes[idx1][1]\n",
    "    tot_counter = 0\n",
    "    for idx2 in range(len(counters[idx1])):\n",
    "        tot_counter+=counters[idx1][idx2]*sum([sum(val) for val in puzzle_pieces[idx2]])\n",
    "    if(tot_counter>board_area):\n",
    "        size_problems+=1\n",
    "    else:\n",
    "        print(board_sizes[idx1],board_sizes[idx1][0]*board_sizes[idx1][1],tot_counter)\n",
    "        differences.append(board_area-tot_counter)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "7a577925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "f43ac910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[344,\n",
       " 359,\n",
       " 367,\n",
       " 390,\n",
       " 395,\n",
       " 397,\n",
       " 400,\n",
       " 405,\n",
       " 410,\n",
       " 411,\n",
       " 413,\n",
       " 415,\n",
       " 418,\n",
       " 420,\n",
       " 420,\n",
       " 420,\n",
       " 425,\n",
       " 429,\n",
       " 429,\n",
       " 429,\n",
       " 430,\n",
       " 430,\n",
       " 430,\n",
       " 431,\n",
       " 431,\n",
       " 432,\n",
       " 434,\n",
       " 436,\n",
       " 438,\n",
       " 439,\n",
       " 439,\n",
       " 442,\n",
       " 444,\n",
       " 445,\n",
       " 449,\n",
       " 451,\n",
       " 451,\n",
       " 452,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 460,\n",
       " 461,\n",
       " 461,\n",
       " 462,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 468,\n",
       " 469,\n",
       " 469,\n",
       " 469,\n",
       " 469,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 472,\n",
       " 472,\n",
       " 473,\n",
       " 473,\n",
       " 473,\n",
       " 475,\n",
       " 475,\n",
       " 477,\n",
       " 477,\n",
       " 478,\n",
       " 478,\n",
       " 480,\n",
       " 480,\n",
       " 480,\n",
       " 482,\n",
       " 482,\n",
       " 482,\n",
       " 483,\n",
       " 483,\n",
       " 485,\n",
       " 487,\n",
       " 488,\n",
       " 488,\n",
       " 488,\n",
       " 488,\n",
       " 488,\n",
       " 490,\n",
       " 492,\n",
       " 493,\n",
       " 493,\n",
       " 493,\n",
       " 494,\n",
       " 494,\n",
       " 494,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 498,\n",
       " 500,\n",
       " 502,\n",
       " 503,\n",
       " 505,\n",
       " 505,\n",
       " 505,\n",
       " 506,\n",
       " 506,\n",
       " 507,\n",
       " 507,\n",
       " 507,\n",
       " 508,\n",
       " 508,\n",
       " 508,\n",
       " 508,\n",
       " 509,\n",
       " 509,\n",
       " 512,\n",
       " 514,\n",
       " 514,\n",
       " 515,\n",
       " 515,\n",
       " 515,\n",
       " 517,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 520,\n",
       " 521,\n",
       " 521,\n",
       " 521,\n",
       " 521,\n",
       " 522,\n",
       " 524,\n",
       " 526,\n",
       " 526,\n",
       " 526,\n",
       " 526,\n",
       " 527,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 533,\n",
       " 534,\n",
       " 534,\n",
       " 535,\n",
       " 535,\n",
       " 536,\n",
       " 536,\n",
       " 536,\n",
       " 537,\n",
       " 537,\n",
       " 537,\n",
       " 537,\n",
       " 537,\n",
       " 537,\n",
       " 537,\n",
       " 538,\n",
       " 538,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 540,\n",
       " 540,\n",
       " 540,\n",
       " 540,\n",
       " 540,\n",
       " 541,\n",
       " 541,\n",
       " 541,\n",
       " 541,\n",
       " 541,\n",
       " 542,\n",
       " 542,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 544,\n",
       " 544,\n",
       " 545,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 549,\n",
       " 551,\n",
       " 551,\n",
       " 552,\n",
       " 552,\n",
       " 552,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 557,\n",
       " 557,\n",
       " 557,\n",
       " 558,\n",
       " 558,\n",
       " 558,\n",
       " 558,\n",
       " 562,\n",
       " 562,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 564,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 569,\n",
       " 569,\n",
       " 570,\n",
       " 570,\n",
       " 571,\n",
       " 571,\n",
       " 571,\n",
       " 572,\n",
       " 572,\n",
       " 572,\n",
       " 572,\n",
       " 572,\n",
       " 572,\n",
       " 573,\n",
       " 573,\n",
       " 574,\n",
       " 574,\n",
       " 575,\n",
       " 577,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 579,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 584,\n",
       " 585,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 587,\n",
       " 588,\n",
       " 588,\n",
       " 588,\n",
       " 588,\n",
       " 589,\n",
       " 589,\n",
       " 591,\n",
       " 591,\n",
       " 591,\n",
       " 591,\n",
       " 594,\n",
       " 594,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 600,\n",
       " 600,\n",
       " 600,\n",
       " 601,\n",
       " 601,\n",
       " 602,\n",
       " 602,\n",
       " 603,\n",
       " 605,\n",
       " 605,\n",
       " 605,\n",
       " 605,\n",
       " 606,\n",
       " 606,\n",
       " 607,\n",
       " 607,\n",
       " 607,\n",
       " 607,\n",
       " 608,\n",
       " 608,\n",
       " 609,\n",
       " 611,\n",
       " 611,\n",
       " 611,\n",
       " 611,\n",
       " 611,\n",
       " 612,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 614,\n",
       " 614,\n",
       " 614,\n",
       " 615,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 619,\n",
       " 621,\n",
       " 625,\n",
       " 626,\n",
       " 628,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 633,\n",
       " 635,\n",
       " 637,\n",
       " 637,\n",
       " 639,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 643,\n",
       " 647,\n",
       " 648,\n",
       " 650,\n",
       " 651,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 655,\n",
       " 656,\n",
       " 656,\n",
       " 657,\n",
       " 657,\n",
       " 658,\n",
       " 658,\n",
       " 659,\n",
       " 659,\n",
       " 661,\n",
       " 661,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 667,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 674,\n",
       " 675,\n",
       " 677,\n",
       " 678,\n",
       " 681,\n",
       " 682,\n",
       " 682,\n",
       " 684,\n",
       " 685,\n",
       " 688,\n",
       " 688,\n",
       " 689,\n",
       " 689,\n",
       " 690,\n",
       " 690,\n",
       " 691,\n",
       " 691,\n",
       " 691,\n",
       " 694,\n",
       " 696,\n",
       " 697,\n",
       " 699,\n",
       " 699,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 705,\n",
       " 707,\n",
       " 708,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 712,\n",
       " 714,\n",
       " 716,\n",
       " 719,\n",
       " 719,\n",
       " 722,\n",
       " 724,\n",
       " 729,\n",
       " 732,\n",
       " 738,\n",
       " 746,\n",
       " 747,\n",
       " 752,\n",
       " 759,\n",
       " 768,\n",
       " 777,\n",
       " 787,\n",
       " 790,\n",
       " 792,\n",
       " 853]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "98842266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1, 1], [1, 1, 0], [1, 1, 0]],\n",
       " [[1, 1, 1], [1, 1, 0], [0, 1, 1]],\n",
       " [[0, 1, 1], [1, 1, 1], [1, 1, 0]],\n",
       " [[1, 1, 0], [1, 1, 1], [1, 1, 0]],\n",
       " [[1, 1, 1], [1, 0, 0], [1, 1, 1]],\n",
       " [[1, 1, 1], [0, 1, 0], [1, 1, 1]]]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzle_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42*45-sum([sum(val) for val in puzzle_pieces[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7bd847c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 2, 0]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "42*45-51*5-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
